<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>时间语义与watermark</title>
      <link href="2021/05/30/shi-jian-yu-yi-yu-watermark/"/>
      <url>2021/05/30/shi-jian-yu-yi-yu-watermark/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><h2 id="时间语义与-Wartermark"><a href="#时间语义与-Wartermark" class="headerlink" title="时间语义与 Wartermark"></a>时间语义与 Wartermark</h2><h3 id="Flink-中的时间语义"><a href="#Flink-中的时间语义" class="headerlink" title="Flink 中的时间语义"></a>Flink 中的时间语义</h3><p>在 Flink 的流式处理中，会涉及到时间的不同概念，如下图所示:</p><p><img src="7-1Flink%E6%97%B6%E9%97%B4%E6%A6%82%E5%BF%B5.png" alt="7-1 Flink时间概念"></p><ul><li>Event Time : 事件创建的时间。</li></ul><p>它通常由事件中的时间戳描述，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink 通过时间戳分配器访问事件时间戳。</p><ul><li><p>Ingestion Time : 数据进入 Flink 的时间。</p></li><li><p>Processing Time : 每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是 Processing Time。</p></li></ul><p><strong>注：</strong>迟到数据指的是考虑进入 Flink 时间或时间创建时间。</p><p>一个例子 —— 电影《星球大战》:</p><p><img src="7-2%E6%98%9F%E7%90%83%E5%A4%A7%E6%88%98.png" alt="7-2 星球大战"></p><p>图中可以看出，电影上映时间并不是星球大战电影故事情节发生时间顺序。其中，上映时间可以看作是处理时间（电影上映，我们去观看），故事情节顺序可以看做是事件事件（故事发生先后时间）。</p><p>不同时间语义有不同应用场合，往往更关心事件时间。</p><p><strong>例：</strong>一条日志进入 Flink 的时间为 2021-05-09 10:00:00.123，到达 Window 的系统时间为 2021-05-09 10:00:01.234，日志的内容如下:</p><pre><code>2017-11-02 18:37:15.624 INFO Fail over to rm2</code></pre><p>对于业务来说，要统计 1min 内的故障日志个数，应该使用 eventTime，因为我们要根据日志的生成时间进行统计。</p><h3 id="EventTime-的引入"><a href="#EventTime-的引入" class="headerlink" title="EventTime 的引入"></a>EventTime 的引入</h3><p>在 Flink 的流式处理中，绝大部分的业务都会使用 eventTime，一般只在 eventTime 无法使用时，才会被迫使用 ProcessingTime 或者 IngestionTime。</p><p>如果要使用 EventTime，那么需要引入 EventTime 的时间属性，引入方式如下所示:</p><pre class="line-numbers language-java"><code class="language-java">val env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment<span class="token comment" spellcheck="true">// 从调用时刻开始给 env 创建的每一个 stream 追加时间特征</span>env<span class="token punctuation">.</span><span class="token function">setStreamTimeCharacteristic</span><span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>EventTime<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a>Watermark</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p>流处理从事件产生，到流经 source，再到 operator，中间是有一个过程和时间的，虽然大部分情况下，流到 operator 的数据都是按照事件产生的时间（Event Time）顺序来的，但是也不排除由于网络、分布式等原因，导致乱序的产生。</p><p>所谓乱序，就是指 Flink 接收到的事件的先后顺序不是严格按照事件的 Event Time 顺序排列的。</p><p><img src="7-3%E4%B9%B1%E5%BA%8F.png" alt="7-3 乱序"></p><p>那么此时出现一个问题，一旦出现乱序，如果只根据 eventTime 决定 window 的运行，我们不能明确数据是否全部到位，但又不能无限期的等下去，此时必须要有个机制来保证一个特定的时间后，必须触发 window 去进行计算了，这个特别的机制，就是 Watermark。</p><ul><li><p>Watermark 是一种衡量 Event Time 进展的机制（取代了之前事件时间的时间戳，设定了窗口关闭的延迟触发）。</p></li><li><p>Watermark 是用于处理乱序事件的，而正确的处理乱序事件，通常用 Watermark 机制结合 window 来实现。</p></li><li><p>数据流中的 Watermark 用于表示 timestamp 小于 Watermark 的数据，都已经 到达了，因此，window 的执行也是由 Watermark 触发的。</p></li><li><p>Watermark 可以理解成一个延迟触发机制，我们可以设置 Watermark 的延时时长 t，每次系统会校验已经到达的数据中最大的 maxEventTime，然后认定 eventTime 小于 maxEventTime - t 的所有数据都已经到达，如果有窗口的停止时间等于 maxEventTime – t，那么这个窗口被触发执行。</p></li></ul><p><img src="7-4watermark.png" alt="7-4 watermark"></p><p>上图中是不同 timestamp 对应的不同 watermark</p><p>其中每一个圆圈表示不同秒产生的数据，每个数据到来都会携带一个 watermark（数据产生时间加上 timestamp），如果 watermark 是 3 则表示从此数据之后不再有 3s 之前产生数据的到来（若延迟较长，后面还有，则有窗口函数来接着）。若窗口时间是 5s，则在 watermark=5 的数据到来时，关闭窗口 1。</p><p>当 Flink 接收到数据时，会按照一定的规则去生成 watermark，这条 watermark 就等于当前所有到达数据中的 maxEventTime - 延迟时长，也就是说，watermark 是基于数据携带的时间戳生成的，一旦 watermark 比当前未触发的窗口的停止时间要晚，那么就会触发相应窗口的执行。由于 event time 是由数据携带的，因此，如果运行过程中无法获取新的数据，那么没有被触发的窗口将永远都不被触发。</p><h4 id="Watermark-的传递"><a href="#Watermark-的传递" class="headerlink" title="Watermark 的传递"></a>Watermark 的传递</h4><p>若有一个上游任务向下游任务传递 watermark，则通过广播向下游任务传递；若有多个上游任务给一个下游任务，则选择上游中最小的 watermark 传递给下游。</p><p><img src="7-5watermark%E4%BC%A0%E9%80%92.png" alt="7-5 watermark传递"></p><p>下游任务会专门给上游任务开辟一块分区存储他们的 watermark（Partition WM），然后从所有 watermark 中选择最小的作为自己的时间时钟（Event-time clock）；在不需要更新 watermark 的时候，则不需要向下游广播（图 3）。</p><h4 id="Watermark-的引入"><a href="#Watermark-的引入" class="headerlink" title="Watermark 的引入"></a>Watermark 的引入</h4><p>watermark 的引入很简单，对于乱序数据，最常见的引用方式如下:</p><pre class="line-numbers language-java"><code class="language-java">SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> dataStream <span class="token operator">=</span> inputStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>    String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Double<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 方式1</span>        <span class="token comment" spellcheck="true">// 升序数据设置时间戳和watermark</span>        <span class="token punctuation">.</span><span class="token function">assignTimestampsAndWatermarks</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">AscendingTimestampExtractor</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">extractAscendingTimestamp</span><span class="token punctuation">(</span>SensorReading element<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">return</span> element<span class="token punctuation">.</span><span class="token function">getTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> 1000L<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 方式2</span>        <span class="token comment" spellcheck="true">// 乱序数据设置时间戳和watermark</span>        <span class="token comment" spellcheck="true">// BoundedOutOfOrdernessTimestampExtractor类需要传一个最大乱序程度的值;</span>        <span class="token comment" spellcheck="true">// BoundedOutOfOrdernessTimestampExtractor看底层继承是周期性生成watermark（最大时间戳减掉延迟时间 ）</span>        <span class="token punctuation">.</span><span class="token function">assignTimestampsAndWatermarks</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">BoundedOutOfOrdernessTimestampExtractor</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">extractTimestamp</span><span class="token punctuation">(</span>SensorReading element<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 时间戳是毫秒数</span>                <span class="token keyword">return</span> element<span class="token punctuation">.</span><span class="token function">getTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> 1000L<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Event Time 的使用一定要指定数据源中的时间戳。否则程序无法知道事件的事件时间是什么(数据源里的数据没有时间戳的话，就只能使用 Processing Time 了)。</p><p>我们看到上面的例子中创建了一个看起来有点复杂的类，这个类实现的其实就是分配时间戳的接口。Flink 暴露了 TimestampAssigner 接口供我们实现，使我们可以自定义如何从事件数据中抽取时间戳和生成 watermark</p><p>MyAssigner 可以有两种类型，都继承自 TimestampAssigner</p><ol><li>AssignerWithPeriodicWatermarks</li></ol><ul><li><p>周期性的生成 watermark：系统会周期性的将 watermark 插入到流中</p></li><li><p>默认周期是 200 毫秒，可以使用 ExecutionConfig.setAutoWatermarkInterval()方法进行设置</p></li><li><p>升序和前面乱序的处理 BoundedOutOfOrderness ，都是基于周期性 watermark 的。</p></li></ul><ol start="2"><li>AssignerWithPunctuatedWatermarks</li></ol><ul><li>没有时间周期规律，可打断的生成 watermark</li></ul><h4 id="Watermark-的设定"><a href="#Watermark-的设定" class="headerlink" title="Watermark 的设定"></a>Watermark 的设定</h4><ul><li><p>在 Flink 中，watermark 由应用程序开发人员生成，这通常需要对相应的领域有一定的了解</p></li><li><p>如果 watermark 设置的延迟太久，收到结果的速度可能就会很慢，解决办 法是在水位线到达之前输出一个近似结果</p></li><li><p>而如果 watermark 到达得太早，则可能收到错误结果，不过 Flink 处理迟 到数据的机制可以解决这个问题</p></li></ul><h3 id="EvnetTime-在-window-中的使用"><a href="#EvnetTime-在-window-中的使用" class="headerlink" title="EvnetTime 在 window 中的使用"></a>EvnetTime 在 window 中的使用</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// ...</span><span class="token comment" spellcheck="true">// 转化成SensorReading类型watermark</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> dataStream <span class="token operator">=</span> inputStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>    String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Double<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 乱序数据设置时间戳和watermark</span>        <span class="token comment" spellcheck="true">// BoundedOutOfOrdernessTimestampExtractor类需要传一个最大乱序程度的值;</span>        <span class="token comment" spellcheck="true">// BoundedOutOfOrdernessTimestampExtractor看底层继承是周期性生成watermark（最大时间戳减掉延迟时间 ）</span>        <span class="token punctuation">.</span><span class="token function">assignTimestampsAndWatermarks</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">BoundedOutOfOrdernessTimestampExtractor</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">extractTimestamp</span><span class="token punctuation">(</span>SensorReading element<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 时间戳是毫秒数</span>                <span class="token keyword">return</span> element<span class="token punctuation">.</span><span class="token function">getTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> 1000L<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 基于事件时间的开窗操作，统计15s内温度的最小值</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> minTempStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">minBy</span><span class="token punctuation">(</span><span class="token string">"temperature"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// ...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/window/WindowTest3_EventTimeWindow.java" target="_blank" rel="noopener">demo 地址</a></p><p><strong>确定窗口开始和结束时间</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TumblingEventTimeWindows</span> <span class="token keyword">extends</span> <span class="token class-name">WindowAssigner</span><span class="token operator">&lt;</span>Object<span class="token punctuation">,</span> TimeWindow<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// ...</span>    <span class="token comment" spellcheck="true">// 偏移量属性，一般用来处理不同时区情况</span>    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token keyword">long</span> offset<span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Collection<span class="token operator">&lt;</span>TimeWindow<span class="token operator">></span> <span class="token function">assignWindows</span><span class="token punctuation">(</span>Object element<span class="token punctuation">,</span> <span class="token keyword">long</span> timestamp<span class="token punctuation">,</span> WindowAssignerContext context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>timestamp <span class="token operator">></span> Long<span class="token punctuation">.</span>MIN_VALUE<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// Long.MIN_VALUE is currently assigned when no timestamp is present</span>            <span class="token comment" spellcheck="true">// 获得窗口开始时间，offset是窗口偏移量（修改窗口开始时间）</span>            <span class="token comment" spellcheck="true">// getWindowStartWithOffset 源码见下面代码</span>            <span class="token keyword">long</span> start <span class="token operator">=</span> TimeWindow<span class="token punctuation">.</span><span class="token function">getWindowStartWithOffset</span><span class="token punctuation">(</span>timestamp<span class="token punctuation">,</span> offset<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> Collections<span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> start <span class="token operator">+</span> size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span><span class="token string">"Record has Long.MIN_VALUE timestamp (= no timestamp marker). "</span> <span class="token operator">+</span>                    <span class="token string">"Is the time characteristic set to 'ProcessingTime', or did you forget to call "</span> <span class="token operator">+</span>                    <span class="token string">"'DataStream.assignTimestampsAndWatermarks(...)'?"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// ...</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TimeWindow</span> <span class="token keyword">extends</span> <span class="token class-name">Window</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// ...</span>    <span class="token comment" spellcheck="true">/**     * Method to get the window start for a timestamp.     *     * @param timestamp epoch millisecond to get the window start.     * @param offset The offset which window start would be shifted by.     * @param windowSize The size of the generated windows.     * @return window start     */</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">long</span> <span class="token function">getWindowStartWithOffset</span><span class="token punctuation">(</span><span class="token keyword">long</span> timestamp<span class="token punctuation">,</span> <span class="token keyword">long</span> offset<span class="token punctuation">,</span> <span class="token keyword">long</span> windowSize<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> timestamp <span class="token operator">-</span> <span class="token punctuation">(</span>timestamp <span class="token operator">-</span> offset <span class="token operator">+</span> windowSize<span class="token punctuation">)</span> <span class="token operator">%</span> windowSize<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// ...</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink-Window</title>
      <link href="2021/05/09/flink-window/"/>
      <url>2021/05/09/flink-window/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><h2 id="Flink-中的-window"><a href="#Flink-中的-window" class="headerlink" title="Flink 中的 window"></a>Flink 中的 window</h2><h3 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h3><h4 id="Window-概述"><a href="#Window-概述" class="headerlink" title="Window 概述"></a>Window 概述</h4><p>streaming 流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，而 window 是一种切割无限数据为有限块进行处理的手段。</p><p>Window 是无限数据流处理的核心，Window 将一个无限的 stream 拆分成有限大小的”buckets”（桶），我们可以在这些桶上做计算操作。</p><h4 id="Window-类型"><a href="#Window-类型" class="headerlink" title="Window 类型"></a>Window 类型</h4><h5 id="TimeWindow（时间窗口）"><a href="#TimeWindow（时间窗口）" class="headerlink" title="TimeWindow（时间窗口）"></a>TimeWindow（时间窗口）</h5><p>按照时间生成 Window。对于 TimeWindow，可以根据窗口实现原理的不同分成三类:</p><ol><li>滚动窗口(Tumbling Windows)</li></ol><p>将数据依据固定的窗口长度对数据进行切片。</p><p>特点：时间对齐，窗口长度固定，没有重叠。</p><p>滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，并且不会出现重叠。</p><p>例如:如果你指定了一个 5 分钟大小的滚动窗口，窗口的创建如下图所示</p><p><img src="6-1%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3.png" alt="6-1 滚动窗口"></p><p>适用场景：适合做 BI 统计等(做每个时间段的聚合计算)。</p><ol start="2"><li>滑动窗口(Sliding Windows)</li></ol><p>滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成。</p><p>特点：时间对齐，窗口长度固定，可以有重叠。</p><p>滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，窗口是可以重叠的，在这种情况下元素会被分配到多个窗口中。</p><p>例如，你有 10 分钟的窗口和 5 分钟的滑动，那么每个窗口中 5 分钟的窗口里包含着上个 10 分钟产生的数据，如下图所示:</p><p><img src="6-2%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.png" alt="6-2 滑动窗口"></p><p>适用场景：对最近一个时间段内的统计(求某接口最近 5min 的失败率来决定是否要报警)。</p><p><strong>注：</strong>滚动窗口可看成是特殊的滑动窗口（滑动步长等于窗口长度）</p><ol start="3"><li>会话窗口(Session Windows)</li></ol><p>由一系列事件组合一个指定时间长度的 timeout 间隙（两个窗口之间的最小时间间隔）组成，类似于 web 应用的 session，也就是一段时间没有接收到新数据就会生成新的窗口。</p><p>特点：时间无对齐。</p><p>session 窗口分配器通过 session 活动来对元素进行分组，session 窗口跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况，相反，当它在一个固定的时间周期内不再收到元素，即非活动间隔产生，那个这个窗口就会关闭。一个 session 窗口通过一个 session 间隔来配置，这个 session 间隔定义了非活跃周期的长度，当这个非活跃周期产生，那么当前的 session 将关闭并且后续的元素将被分配到新的 session 窗口中去。</p><p><img src="6-3%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3.png" alt="6-3 会话窗口"></p><h5 id="CountWindow（计数窗口）"><a href="#CountWindow（计数窗口）" class="headerlink" title="CountWindow（计数窗口）"></a>CountWindow（计数窗口）</h5><p>按照指定的数据条数生成一个 Window，与时间无关。</p><ol><li>滚动计数窗口</li></ol><p>将滚动时间窗口中的时间换成了数据条数（每几条数据是一个窗口）</p><ol start="2"><li>滑动计数窗口</li></ol><p>将滑动时间窗口中的时间换成了数据条数（每 x 条数据一个窗口，每个窗口间隔 y 条数据）</p><h3 id="Window-API"><a href="#Window-API" class="headerlink" title="Window API"></a>Window API</h3><h4 id="窗口分配器-——-window-方法"><a href="#窗口分配器-——-window-方法" class="headerlink" title="窗口分配器 —— window() 方法"></a>窗口分配器 —— window() 方法</h4><p>我们可以用 .window() 来定义一个窗口，然后基于这个 window 去做一些聚合或者其它处理操作。注意 window() 方法必须在 keyBy 之后才能用。</p><p>Flink 提供了更加简单的 .timeWindow 和 .countWindow 方法，用于定义时间窗口和计数窗口。</p><p>window() 方法接收的输入参数是一个 WindowAssigner</p><ul><li><p>WindowAssigner 负责将每条输入的数据分发到正确的 window 中</p></li><li><p>Flink 提供了通用的 WindowAssigner</p><p>滚动窗口(tumbling window)</p><p>滑动窗口(sliding window)</p><p>会话窗口(session window)</p><p>全局窗口(global window)</p></li></ul><h4 id="创建不同类型窗口"><a href="#创建不同类型窗口" class="headerlink" title="创建不同类型窗口"></a>创建不同类型窗口</h4><ul><li>滚动时间窗口(tumbling time window)</li></ul><pre class="line-numbers language-java"><code class="language-java"><span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>滑动时间窗口(sliding time window)</li></ul><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 窗口大小 滑动步长</span><span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>会话窗口(session window)</li></ul><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 间隔1分钟的会话窗口</span><span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span>EventTimeSessionWindows<span class="token punctuation">.</span><span class="token function">withGap</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">minutes</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>滚动计数窗口（10 个数据为一个窗口）</li></ul><pre class="line-numbers language-java"><code class="language-java"><span class="token punctuation">.</span><span class="token function">countWindow</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>滑动计数窗口（10 个数据为一个窗口，滑动步长为 2 个数据）</li></ul><pre class="line-numbers language-java"><code class="language-java"><span class="token punctuation">.</span><span class="token function">countWindow</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>样例</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 窗口测试</span><span class="token comment" spellcheck="true">// 基于dataStream可以调windowAll方法</span><span class="token comment" spellcheck="true">// Note: This operation is inherently non-parallel since all elements have to pass through</span><span class="token comment" spellcheck="true">//     * the same operator instance.  （源码注解：因为所有元素都被传递到下游相同的算子中，所以本质上是非并行的）</span><span class="token comment" spellcheck="true">//         mapStream.windowAll();</span><span class="token comment" spellcheck="true">// 开窗口前要先进行keyBy</span>mapStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 时间窗口</span>        <span class="token comment" spellcheck="true">// .window(TumblingProcessingTimeWindows.of(Time.seconds(15)))</span>        <span class="token comment" spellcheck="true">// 根据传参，判断开的是什么窗口（滚动 滑动）</span>        <span class="token comment" spellcheck="true">// .timeWindow(Time.seconds(15))</span>        <span class="token comment" spellcheck="true">// .timeWindow(Time.seconds(15), Time.seconds(5))</span>        <span class="token comment" spellcheck="true">// 会话窗口（1分钟间隔）</span>        <span class="token comment" spellcheck="true">// .window(EventTimeSessionWindows.withGap(Time.minutes(1)))</span>        <span class="token comment" spellcheck="true">// 计数窗口</span>        <span class="token comment" spellcheck="true">// 窗口大小 滑动步长</span>        <span class="token punctuation">.</span><span class="token function">countWindow</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Window-Function（窗口函数）"><a href="#Window-Function（窗口函数）" class="headerlink" title="Window Function（窗口函数）"></a>Window Function（窗口函数）</h3><p>在开窗之前先做一次 keyBy（分组）操作，然后再进行开窗（分桶操作：哪些数据归位一组），最后还需要一次聚合操作进行统计（在分桶之后，要对桶内数据做操作）</p><p>window function 就定义了要对窗口中收集的数据做的计算操作</p><h4 id="不同窗口函数使用"><a href="#不同窗口函数使用" class="headerlink" title="不同窗口函数使用"></a>不同窗口函数使用</h4><ol><li>增量聚合函数(incremental aggregation functions)</li></ol><p>每条数据到来就进行计算，保持一个简单的状态（ReduceFunction, AggregateFunction）</p><ol start="2"><li>全窗口函数(full window functions)</li></ol><p>先把窗口所有数据收集起来，等到计算的时候会遍历所有数据（ProcessWindowFunction，WindowFunction）</p><p>可用于统计数据中位数一类操作</p><p><strong>需求：</strong>统计 15 秒内，每个传感器传过来的数据条数（从增量聚合函数和全窗口函数最后结果可以看出，虽然全窗口函数效率会低一些，但是能拿到更多的信息）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// ...</span><span class="token comment" spellcheck="true">// 增量聚合函数</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>Integer<span class="token operator">></span> resultStream <span class="token operator">=</span> mapStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 第一个Integer为累加器类型，第二个为输出</span>    <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">AggregateFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> Integer<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token annotation punctuation">@Override</span>        <span class="token comment" spellcheck="true">// 创建累加器</span>        <span class="token keyword">public</span> Integer <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 初始值为 0</span>            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token annotation punctuation">@Override</span>        <span class="token comment" spellcheck="true">// sensorReading：传过来的传感器数据   accumulator：累加器</span>        <span class="token keyword">public</span> Integer <span class="token function">add</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">,</span> Integer accumulator<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 来一条数据就加1</span>            <span class="token keyword">return</span> accumulator <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token annotation punctuation">@Override</span>        <span class="token comment" spellcheck="true">// 返回结果</span>        <span class="token keyword">public</span> Integer <span class="token function">getResult</span><span class="token punctuation">(</span>Integer accumulator<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> accumulator<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token annotation punctuation">@Override</span>        <span class="token comment" spellcheck="true">// 一般用于会话窗口中（合并分区）</span>        <span class="token keyword">public</span> Integer <span class="token function">merge</span><span class="token punctuation">(</span>Integer a<span class="token punctuation">,</span> Integer b<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> a <span class="token operator">+</span> b<span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//        resultStream.print();</span><span class="token comment" spellcheck="true">// 全窗口函数</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>Tuple3<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Integer<span class="token operator">>></span> resultStream2 <span class="token operator">=</span> mapStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">/*        * @param &lt;IN> The type of the input value.        * @param &lt;OUT> The type of the output value.        * @param &lt;KEY> The type of the key.        * @param &lt;W> The type of {@code Window} that this window function can be applied on.        */</span>    <span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">WindowFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> Tuple3<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">,</span> Tuple<span class="token punctuation">,</span> TimeWindow<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">apply</span><span class="token punctuation">(</span>Tuple tuple<span class="token punctuation">,</span> TimeWindow window<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> input<span class="token punctuation">,</span> Collector<span class="token operator">&lt;</span>Tuple3<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Integer<span class="token operator">>></span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>            String id <span class="token operator">=</span> tuple<span class="token punctuation">.</span><span class="token function">getField</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            Long timeEnd  <span class="token operator">=</span> window<span class="token punctuation">.</span><span class="token function">getEnd</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> count <span class="token operator">=</span> IteratorUtils<span class="token punctuation">.</span><span class="token function">toList</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple3</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>id<span class="token punctuation">,</span> timeEnd<span class="token punctuation">,</span> count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>resultStream2<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// ...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/window/WindowTest1_TimeWindow.java" target="_blank" rel="noopener">demo 地址</a></p><p><strong>需求</strong>统计传来 10 个数据的平均值（10 个数据为一个窗口，2 个数据为移动步伐）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyAvgTemp</span> <span class="token keyword">implements</span> <span class="token class-name">AggregateFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">,</span> Double<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> <span class="token function">add</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> accu<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>accu<span class="token punctuation">.</span>f0 <span class="token operator">+</span> sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> accu<span class="token punctuation">.</span>f1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Double <span class="token function">getResult</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> accu<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> accu<span class="token punctuation">.</span>f0 <span class="token operator">/</span> accu<span class="token punctuation">.</span>f1<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> <span class="token function">merge</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> a<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>Double<span class="token punctuation">,</span> Integer<span class="token operator">></span> b<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>f0 <span class="token operator">+</span> b<span class="token punctuation">.</span>f0<span class="token punctuation">,</span> a<span class="token punctuation">.</span>f1 <span class="token operator">+</span> b<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/window/WindowTest2_CountWindow.java" target="_blank" rel="noopener">demo 地址</a></p><h3 id="其它可选-API"><a href="#其它可选-API" class="headerlink" title="其它可选 API"></a>其它可选 API</h3><ul><li>.trigger() —— 触发器</li></ul><p>定义 window 什么时候关闭，触发计算并输出结果</p><ul><li>.evitor() —— 移除器</li></ul><p>定义移除某些数据的逻辑</p><ul><li>.allowedLateness() —— 允许处理迟到的数据（传一个时间数：允许的最大延迟时间）</li></ul><p>若此窗口原先九点关闭，那么其在九点会先输出一个结果，然后在以后的一分钟内，若来一个此窗口的数据则更新一下之前输出的结果，直到 9:01</p><ul><li><p>.sideOutputLateData() —— 将迟到的数据放入侧输出流</p></li><li><p>.getSideOutput() —— 获取侧输出流</p></li></ul><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 延迟数据侧输出流</span>OutputTag<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> outputTag <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OutputTag</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"late"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 正常数据</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> sumStream <span class="token operator">=</span> mapStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">timeWindow</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">allowedLateness</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span><span class="token function">minutes</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">sideOutputLateData</span><span class="token punctuation">(</span>outputTag<span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token string">"temp"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 拿到延迟数据</span>sumStream<span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span>outputTag<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"late"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 拿到延迟数据与正常数据之后，再做一个合并就可以取到所有数据的和了</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="6-4%E5%85%B6%E4%BB%96%E5%8F%AF%E9%80%89api.png" alt="6-4 其他可选api.png"></p><p><strong>注：</strong>什么样的数据才算是迟到数据？</p><p>根据事件时间来进行判断，而不是数据到来时间。比如：有一条数据产生于 8:57，但是他 9:01 才到，那么其就是 8:00-9:00 窗口的迟到数据。</p><p><img src="6-5%E8%BD%AC%E6%8D%A2.png" alt="6-5"></p><blockquote><p>断断续续终于完成这部分了，接下来顺顺利利啊～</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink 流处理 API</title>
      <link href="2021/04/18/flink-liu-chu-li-api/"/>
      <url>2021/04/18/flink-liu-chu-li-api/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><h2 id="Flink-流处理-API"><a href="#Flink-流处理-API" class="headerlink" title="Flink 流处理 API"></a>Flink 流处理 API</h2><p><a href="5-1.png"></a></p><p>source：读取数据源</p><p>transform：转换计算</p><p>sink：输出</p><h3 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h3><h4 id="getExecutionEnvironment"><a href="#getExecutionEnvironment" class="headerlink" title="getExecutionEnvironment"></a>getExecutionEnvironment</h4><p>创建一个执行环境，表示当前执行程序的上下文。如果程序是独立调用的，则此方法返回本地执行环境；如果从命令行客户端调用程序以提交到集群，则此方法返回此集群的执行环境，也就是说，getExecutionEnvironment 会根据查询运行的方式决定返回什么样的运行环境，是最常用的一种创建执行环境的方式。</p><pre class="line-numbers language-java"><code class="language-java">ExecutionEnvironment env <span class="token operator">=</span> ExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果没有设置并行度，会以 flink-conf.yaml 中的配置为准，默认是 1。</p><h4 id="createLocalEnvironment"><a href="#createLocalEnvironment" class="headerlink" title="createLocalEnvironment"></a>createLocalEnvironment</h4><p>返回本地执行环境，需要在调用时指定默认的并行度。</p><pre class="line-numbers language-java"><code class="language-java">LocalStreamEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">createLocalEnvironment</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="createRemoteEnvironment"><a href="#createRemoteEnvironment" class="headerlink" title="createRemoteEnvironment"></a>createRemoteEnvironment</h4><p>返回集群执行环境，将 Jar 提交到远程服务器。需要在调用时指定 JobManager 的 IP 和端口号，并指定要在集群中运行的 Jar 包。</p><pre class="line-numbers language-java"><code class="language-java">StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">createRemoteEnvironment</span><span class="token punctuation">(</span><span class="token string">"jobmanage-hostname"</span><span class="token punctuation">,</span> <span class="token number">6123</span><span class="token punctuation">,</span> <span class="token string">"YOURPATH//wordcount.jar"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>其实 getExecutionEnvironment 相当于对后两种创建环境的方式进行了封装，根据运行方式来创建环境。</p><h3 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h3><h4 id="从集合读取数据"><a href="#从集合读取数据" class="headerlink" title="从集合读取数据"></a>从集合读取数据</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>source<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>beans<span class="token punctuation">.</span>SensorReading<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SourceTest1_Collection</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 创建执行环境</span>        StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置并行度是1，保证读取顺序跟存的时候顺序一样</span>        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从集合中读取数据</span>        List<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> dataStream <span class="token operator">=</span> Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">,</span> 1547718199L<span class="token punctuation">,</span> <span class="token number">35.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span><span class="token string">"sensor_6"</span><span class="token punctuation">,</span> 1547718201L<span class="token punctuation">,</span> <span class="token number">15.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span><span class="token string">"sensor_7"</span><span class="token punctuation">,</span> 1547718202L<span class="token punctuation">,</span> <span class="token number">6.7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span><span class="token string">"sensor_10"</span><span class="token punctuation">,</span> 1547718205L<span class="token punctuation">,</span> <span class="token number">38.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        DataStream<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> dataStreamSource <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromCollection</span><span class="token punctuation">(</span>dataStream<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataStreamSource<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中 SensorReading 为自定义传感器类</p><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/source/SourceTest1_Collection.java" target="_blank" rel="noopener">demo 地址</a></p><h4 id="从文件读取数据"><a href="#从文件读取数据" class="headerlink" title="从文件读取数据"></a>从文件读取数据</h4><pre class="line-numbers language-java"><code class="language-java">DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"src/main/resources/sensor.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/source/SourceTest2_File.java" target="_blank" rel="noopener">demo 地址</a></p><h4 id="以-kafka-消息队列的数据作为来源-需要引入-kafka-连接器的依赖"><a href="#以-kafka-消息队列的数据作为来源-需要引入-kafka-连接器的依赖" class="headerlink" title="以 kafka 消息队列的数据作为来源 需要引入 kafka 连接器的依赖:"></a>以 kafka 消息队列的数据作为来源 需要引入 kafka 连接器的依赖:</h4><p>【pom.xml】添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka-0.11 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka-0.11_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.10.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>【SourceTest3_Kafka.java】代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>source<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>SimpleStringSchema<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>FlinkKafkaConsumer011<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @author : swenchao * create at:  2021/1/12  7:34 下午 * @description: 从 Kafka 中读取数据 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SourceTest3_Kafka</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception<span class="token punctuation">{</span>        StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从Kafka读取数据</span>        <span class="token comment" spellcheck="true">// 参数设置</span>        Properties properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 下面不重要</span>        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"consumer"</span> <span class="token operator">+</span> <span class="token string">"-group"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization"</span> <span class="token operator">+</span> <span class="token string">".StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common"</span> <span class="token operator">+</span> <span class="token string">".serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer011</span><span class="token operator">&lt;</span>String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"sensor"</span><span class="token punctuation">,</span>                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 打印</span>        dataStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/source/SourceTest3_Kafka.java" target="_blank" rel="noopener">demo 地址</a></p><h4 id="自定义-Source"><a href="#自定义-Source" class="headerlink" title="自定义 Source"></a>自定义 Source</h4><p>除了以上的 source 数据来源，我们还可以自定义 source。需要做的，只是传入一个 SourceFunction 就可以。具体调用如下:</p><pre class="line-numbers language-java"><code class="language-java">DataStream<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MySensorSource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们希望可以随机生成传感器温度数据</p><p>【MySensorSource 类】代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MySensorSource</span> <span class="token keyword">implements</span> <span class="token class-name">SourceFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 定义标识位，控制数据产生</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> running <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span>SourceContext<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> sourceContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 定义随机数发生器</span>        Random random <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置10个传感器初始温度</span>        HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Double<span class="token operator">></span> sensorTempMap <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span> <span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 随机高斯分布，范围：0 - 120</span>            sensorTempMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"sensor_"</span> <span class="token operator">+</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">60</span> <span class="token operator">+</span> random<span class="token punctuation">.</span><span class="token function">nextGaussian</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 标识位为true生成数据</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>running<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>String sensorId <span class="token operator">:</span> sensorTempMap<span class="token punctuation">.</span><span class="token function">keySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                Double newtemp <span class="token operator">=</span> sensorTempMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>sensorId<span class="token punctuation">)</span> <span class="token operator">+</span> random<span class="token punctuation">.</span><span class="token function">nextGaussian</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                sensorTempMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>sensorId<span class="token punctuation">,</span> newtemp<span class="token punctuation">)</span><span class="token punctuation">;</span>                sourceContext<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>sensorId<span class="token punctuation">,</span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> newtemp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">// 控制输出频率</span>            Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">cancel</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        running <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/source/SourceTest4_UDF.java" target="_blank" rel="noopener">demo 地址</a></p><h3 id="Transform"><a href="#Transform" class="headerlink" title="Transform"></a>Transform</h3><p>其中算子分为两种：基本转换算子（相当于窄依赖，不会影响到分区数据顺序，来一个处理一个）</p><h4 id="基本转换算子"><a href="#基本转换算子" class="headerlink" title="基本转换算子"></a>基本转换算子</h4><h5 id="map"><a href="#map" class="headerlink" title="map"></a>map</h5><p><a href="5-2.png"></a></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 1.map 把String转换成长度输出</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>Integer<span class="token operator">></span> mapStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MapFunction</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Integer <span class="token function">map</span><span class="token punctuation">(</span>String s<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token keyword">return</span> s<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h5><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 2.flatmap 按逗号分词</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>String<span class="token operator">></span> flatMapStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span>String s<span class="token punctuation">,</span> Collector<span class="token operator">&lt;</span>String<span class="token operator">></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> items <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String item <span class="token operator">:</span> items<span class="token punctuation">)</span> <span class="token punctuation">{</span>            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h5><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 3.filter 筛选sensor_1开头的id对应的数据</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>String<span class="token operator">></span> filterStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FilterFunction</span><span class="token operator">&lt;</span>String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span>String s<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token keyword">return</span> s<span class="token punctuation">.</span><span class="token function">startsWith</span><span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>【基本算子使用结果】</p><pre class="line-numbers language-text"><code class="language-text">map> 24flatMap> sensor_1flatMap> 1547718199flatMap> 35.8filter> sensor_1,1547718199,35.8map> 24flatMap> sensor_6flatMap> 1547718201flatMap> 15.4map> 23flatMap> sensor_7flatMap> 1547718202flatMap> 6.7map> 25flatMap> sensor_10flatMap> 1547718205flatMap> 38.1filter> sensor_10,1547718205,38.1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/transform/TransformTest1_Base.java" target="_blank" rel="noopener">demo 地址</a></p><h4 id="复杂算子"><a href="#复杂算子" class="headerlink" title="复杂算子"></a>复杂算子</h4><h5 id="KeyBy"><a href="#KeyBy" class="headerlink" title="KeyBy"></a>KeyBy</h5><p>DataStream ——&gt; KeyedStream：逻辑地将一个流拆分成不相交的分区，每个分区包含具有相同 key 的元素，在内部以 hash 的形式实现的。</p><p><strong>注：</strong>从 DataStream 变成 KeyedStream 之后，其所能调用的 api 就会发生变化。</p><h5 id="滚动聚合算子-Rolling-Aggregation"><a href="#滚动聚合算子-Rolling-Aggregation" class="headerlink" title="滚动聚合算子(Rolling Aggregation)"></a>滚动聚合算子(Rolling Aggregation)</h5><p>这些算子可以针对 KeyedStream 的每一个支流做聚合。</p><ul><li><p>sum()</p></li><li><p>min()</p></li><li><p>max()</p></li><li><p>minBy()</p></li><li><p>maxBy()</p></li></ul><p><strong>max 与 maxby 使用区别（min minby 同理）</strong></p><p>max 只会返回要求的最大的那个值；而 maxby 则会返回整个对象。见下面例子：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>transform<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>beans<span class="token punctuation">.</span>SensorReading<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>MapFunction<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span>Tuple<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>KeyedStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>SingleOutputStreamOperator<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @author : swenchao * create at:  2021/1/17  4:21 下午 * @description: 滚动算子 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TransformTest2_RollingAggregation</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从文件读取数据</span>        DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"src/main/resources/sensor.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 转换成 SensorReading 类型</span>        <span class="token comment" spellcheck="true">// lambda表达式写法</span>        SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> mapLambdaStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> fileds <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Double<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 分组（根据id分组）</span>        <span class="token comment" spellcheck="true">// 其中KeyedStream中后一个范型之所以为tuple，是因为其keyby可根据多个标签进行分组</span>        KeyedStream<span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> Tuple<span class="token operator">></span> keyedStream <span class="token operator">=</span> mapLambdaStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 滚动聚合，取最大温度值</span>        <span class="token comment" spellcheck="true">// max</span><span class="token comment" spellcheck="true">//        SingleOutputStreamOperator&lt;SensorReading> resultStream = keyedStream.max("temperature");</span><span class="token comment" spellcheck="true">//        resultStream.print();</span>        <span class="token comment" spellcheck="true">// maxby</span>        SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> resultTemperature <span class="token operator">=</span> keyedStream<span class="token punctuation">.</span><span class="token function">maxBy</span><span class="token punctuation">(</span><span class="token string">"temperature"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        resultTemperature<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>max 结果，如下：</li></ol><pre class="line-numbers language-text"><code class="language-text">SensorReading{id='sensor_1', timestamp=1547718199, temperature=35.8}SensorReading{id='sensor_6', timestamp=1547718201, temperature=15.4}SensorReading{id='sensor_7', timestamp=1547718202, temperature=6.7}SensorReading{id='sensor_10', timestamp=1547718205, temperature=38.1}SensorReading{id='sensor_1', timestamp=1547718207, temperature=36.3}SensorReading{id='sensor_1', timestamp=1547718207, temperature=36.3}SensorReading{id='sensor_1', timestamp=1547718212, temperature=37.1}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可见其中 id 为 sensor_1 的数据除了最后的 temperature 是不一样的，其他都相同。</p><ol start="2"><li>maxby 结果如下：</li></ol><pre class="line-numbers language-text"><code class="language-text">SensorReading{id='sensor_1', timestamp=1547718199, temperature=35.8}SensorReading{id='sensor_6', timestamp=1547718201, temperature=15.4}SensorReading{id='sensor_7', timestamp=1547718202, temperature=6.7}SensorReading{id='sensor_10', timestamp=1547718205, temperature=38.1}SensorReading{id='sensor_1', timestamp=1547718199, temperature=36.3}SensorReading{id='sensor_1', timestamp=1547718199, temperature=36.3}SensorReading{id='sensor_1', timestamp=1547718199, temperature=37.1}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可见其中 id 为 sensor_1 的数据后两个属性是都一样的。</p><p><strong>注：</strong>其中之所以会出现那个多结果，是因为程序在读取文件时是一个滚动的过程，没来一条数据就更新一次，所以会出现一个传感器多个数据都会显示的情况。</p><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/transform/TransformTest2_RollingAggregation.java" target="_blank" rel="noopener">demo 地址</a></p><h5 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h5><p>KeyedStream → DataStream：一个分组数据流的聚合操作，合并当前的元素和上次聚合的结果，产生一个新的值，返回的流中包含每一次聚合的结果，而不是只返回最后一次聚合的最终结果。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>transform<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>beans<span class="token punctuation">.</span>SensorReading<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>ReduceFunction<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span>Tuple<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>KeyedStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>SingleOutputStreamOperator<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @author : swenchao * create at:  2021/1/17  4:21 下午 * @description: reduce操作 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TransformTest3_Reduce</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从文件读取数据</span>        DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"src/main/resources/sensor.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 转换成 SensorReading 类型</span>        <span class="token comment" spellcheck="true">// lambda表达式写法</span>        SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> mapLambdaStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> fileds <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Double<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 分组（根据id分组）</span>        <span class="token comment" spellcheck="true">// 其中KeyedStream中后一个范型之所以为tuple，是因为其keyby可根据多个标签进行分组</span>        KeyedStream<span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> Tuple<span class="token operator">></span> keyedStream <span class="token operator">=</span> mapLambdaStream<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// reduce聚合，取最大温度值以及当前最新时间戳</span>        SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> resultReduce <span class="token operator">=</span> keyedStream<span class="token punctuation">.</span><span class="token function">reduce</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ReduceFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token comment" spellcheck="true">// sensorReading当前状态；t1新来数据</span>            <span class="token keyword">public</span> SensorReading <span class="token function">reduce</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">,</span> SensorReading t1<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> t1<span class="token punctuation">.</span><span class="token function">getTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        Math<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> t1<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        resultReduce<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果：</p><pre class="line-numbers language-text"><code class="language-text">SensorReading{id='sensor_1', timestamp=1547718199, temperature=35.8}SensorReading{id='sensor_6', timestamp=1547718201, temperature=15.4}SensorReading{id='sensor_7', timestamp=1547718202, temperature=6.7}SensorReading{id='sensor_10', timestamp=1547718205, temperature=38.1}SensorReading{id='sensor_1', timestamp=1547718207, temperature=36.3}SensorReading{id='sensor_1', timestamp=1547718209, temperature=36.3}SensorReading{id='sensor_1', timestamp=1547718212, temperature=37.1}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以发现最后输出的数据中的 temperature 跟上面方法返回的是一样的，只是 timestamp 发生了变化（取的都是当前时间戳）</p><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/transform/TransformTest3_Reduce.java" target="_blank" rel="noopener">demo 地址</a></p><h5 id="多流转换算子（Split-和-Select）"><a href="#多流转换算子（Split-和-Select）" class="headerlink" title="多流转换算子（Split 和 Select）"></a>多流转换算子（Split 和 Select）</h5><ol><li>Split</li></ol><p><img src="5-3.png" alt="5-3"></p><p>DataStream -&gt; SplitStream：根据某些特征把一个 DataStream 拆分成两个或者多个 DataStream。</p><p><strong>注：</strong>名义上是将一条流拆分成了两个，其实它仍然是一条流，其实打上了不同的标签。往往在其后面一定会跟上 Select，其会根据打的不同的标签去提取数据。</p><ol start="2"><li>Select</li></ol><p><img src="5-4.png" alt="5-4"></p><p>SplitStream -&gt; DataStream：从一个 SplitStream 中获取一个或者多个 DataStream。</p><p><strong>需求：</strong>传感器数据按照温度高低(以 30 度为界)，拆分成两个流。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>transform<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>beans<span class="token punctuation">.</span>SensorReading<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>MapFunction<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>ReduceFunction<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span>Tuple<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>collector<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>OutputSelector<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>KeyedStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>SingleOutputStreamOperator<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>SplitStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Collections<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Spliterator<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @author : swenchao * create at:  2021/1/17  4:21 下午 * @description: 多流转换操作 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TransformTest4_MultipleStreams</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        StreamExecutionEnvironment env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从文件读取数据</span>        DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"src/main/resources/sensor.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 转换成 SensorReading 类型</span>        SingleOutputStreamOperator<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> mapStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MapFunction</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> SensorReading<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> SensorReading <span class="token function">map</span><span class="token punctuation">(</span>String s<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                String<span class="token punctuation">[</span><span class="token punctuation">]</span> fileds <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">SensorReading</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Double<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>fileds<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 分组（按照温度值30为界限来区分为高温和低温）</span>        SplitStream<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> splitStream <span class="token operator">=</span> mapStream<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OutputSelector</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Iterable<span class="token operator">&lt;</span>String<span class="token operator">></span> <span class="token function">select</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">return</span> <span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">?</span> Collections<span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">)</span> <span class="token operator">:</span>                        Collections<span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span><span class="token string">"low"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        DataStream<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> highTempStream <span class="token operator">=</span> splitStream<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        DataStream<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> lowTempStream <span class="token operator">=</span> splitStream<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token string">"low"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        DataStream<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> allTempStream <span class="token operator">=</span> splitStream<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">,</span> <span class="token string">"low"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        highTempStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        lowTempStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"low"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        allTempStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果：</p><pre class="line-numbers language-text"><code class="language-text">all> SensorReading{id='sensor_1', timestamp=1547718199, temperature=35.8}high> SensorReading{id='sensor_1', timestamp=1547718199, temperature=35.8}all> SensorReading{id='sensor_6', timestamp=1547718201, temperature=15.4}low> SensorReading{id='sensor_6', timestamp=1547718201, temperature=15.4}all> SensorReading{id='sensor_7', timestamp=1547718202, temperature=6.7}low> SensorReading{id='sensor_7', timestamp=1547718202, temperature=6.7}all> SensorReading{id='sensor_10', timestamp=1547718205, temperature=38.1}high> SensorReading{id='sensor_10', timestamp=1547718205, temperature=38.1}all> SensorReading{id='sensor_1', timestamp=1547718207, temperature=36.3}high> SensorReading{id='sensor_1', timestamp=1547718207, temperature=36.3}all> SensorReading{id='sensor_1', timestamp=1547718209, temperature=32.8}high> SensorReading{id='sensor_1', timestamp=1547718209, temperature=32.8}all> SensorReading{id='sensor_1', timestamp=1547718212, temperature=37.1}high> SensorReading{id='sensor_1', timestamp=1547718212, temperature=37.1}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/transform/TransformTest4_MultipleStreams.java" target="_blank" rel="noopener">demo 地址</a></p><p><strong>注：</strong>上面的代码中，DataStream 类中的 split 方法其实已经被弃用了，应该使用侧输出流来代替。</p><h5 id="Connect-和-CoMap"><a href="#Connect-和-CoMap" class="headerlink" title="Connect 和 CoMap"></a>Connect 和 CoMap</h5><ul><li>Connect</li></ul><p><img src="5-5.png" alt="5-5"></p><p>DataStream,DataStream -&gt; ConnectedStreams：连接两个保持他们类型的数据流，两个数据流被 Connect 之后，只是被放在了一个同一个流中，内部依然保持各自的数据和形式不发生任何变化，两个流相互独立。只能将两个独立的流拼接到一块，无法实现多条流合成一块，若想让多条流和在一块只能使用 union。</p><ul><li>CoMap,CoFlatMap</li></ul><p><img src="5-6.png" alt="5-6"></p><p>ConnectedStreams -&gt; DataStream：作用于 ConnectedStreams 上，功能与 map 和 flatMap 一样，对 ConnectedStreams 中的每一个 Stream 分别进行 map 和 flatMap 处理。经过这种操作之后，才能真正意义上将两条流合成一个。</p><p><strong>需求：</strong>在上一个 demo 基础之上，将区分出来的高低温流进行合并，并输出状态（高温传感器输出 “high warning”警告，低温流输出 “normal”）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 关键代码</span><span class="token comment" spellcheck="true">// 可直接封装进行返回，也可使用下面的方法先包装高温，再结合返回</span><span class="token comment" spellcheck="true">// 将高低温流合并</span>ConnectedStreams<span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> SensorReading<span class="token operator">></span> allConnect <span class="token operator">=</span> highTempStream<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>lowTempStream<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 使用CoMap进行转换</span><span class="token comment" spellcheck="true">// 其中CoMapFunction方法中有两个SensorReading，第一个为原始高温流，第二个为原始低温流（因为是以高温流为基础进行构建的合成流，后来又加入的低温流）</span><span class="token comment" spellcheck="true">// 查看CoMapFunction源码注解可得：CoMapFunction中map1 map2分别对应的connected streams中第一个元素和第二个元素。最终两个map返回相同的类型</span>SingleOutputStreamOperator<span class="token operator">&lt;</span>Object<span class="token operator">></span> resultMap <span class="token operator">=</span> allConnect<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">CoMapFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> Object<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Object <span class="token function">map1</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple3</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"High Warning"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Object <span class="token function">map2</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple3</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Normal"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 第二种写法</span><span class="token comment" spellcheck="true">// 现将高温流进行包装（二元祖）</span><span class="token comment" spellcheck="true">// SingleOutputStreamOperator&lt;Tuple2&lt;String, Double>> warningStream =</span><span class="token comment" spellcheck="true">//         highTempStream.map(new MapFunction&lt;SensorReading, Tuple2&lt;String, Double>>() {</span><span class="token comment" spellcheck="true">//     @Override</span><span class="token comment" spellcheck="true">//     public Tuple2&lt;String, Double> map(SensorReading sensorReading) throws Exception {</span><span class="token comment" spellcheck="true">//         return new Tuple2&lt;>(sensorReading.getId(), sensorReading.getTemperature());</span><span class="token comment" spellcheck="true">//     }</span><span class="token comment" spellcheck="true">// });</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">// 高低温进行组合</span><span class="token comment" spellcheck="true">// ConnectedStreams&lt;Tuple2&lt;String, Double>, SensorReading> connect = warningStream.connect(lowTempStream);</span><span class="token comment" spellcheck="true">// SingleOutputStreamOperator&lt;Object> resultMap = connect.map(new CoMapFunction&lt;Tuple2&lt;String, Double>, SensorReading, Object>() {</span><span class="token comment" spellcheck="true">//     @Override</span><span class="token comment" spellcheck="true">//     public Object map1(Tuple2&lt;String, Double> stringDoubleTuple2) throws Exception {</span><span class="token comment" spellcheck="true">//         return new Tuple3&lt;>(stringDoubleTuple2.f0, stringDoubleTuple2.f1, "high warning");</span><span class="token comment" spellcheck="true">//     }</span><span class="token comment" spellcheck="true">//     @Override</span><span class="token comment" spellcheck="true">//     public Object map2(SensorReading sensorReading) throws Exception {</span><span class="token comment" spellcheck="true">//         return new Tuple2&lt;>(sensorReading.getId(), "normal");</span><span class="token comment" spellcheck="true">//     }</span><span class="token comment" spellcheck="true">// });</span>resultMap<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果：</p><pre class="line-numbers language-text"><code class="language-text">(sensor_1,35.8,High Warning)(sensor_6,15.4,Normal)(sensor_10,38.1,High Warning)(sensor_7,6.7,Normal)(sensor_1,36.3,High Warning)(sensor_1,32.8,High Warning)(sensor_1,37.1,High Warning)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/transform/TransformTest4_MultipleStreams_Connect.java" target="_blank" rel="noopener">demo 地址</a></p><h5 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h5><p><img src="5-7.png" alt="5-7"></p><p>DataStream -&gt; DataStream：对两个或者两个以上的 DataStream 进行 union 操作，产生一个包含所有 DataStream 元素的新 DataStream。</p><p><strong>Connect 与 Union 区别:</strong></p><ol><li><p>Union 之前两个流的类型必须是一样，Connect 可以不一样，在之后的 coMap 中再去调整成为一样的。</p></li><li><p>Connect 只能操作两个流，Union 可以操作多个。</p></li></ol><p><strong>总结：</strong></p><p><img src="5-8.png" alt="5-8"></p><h3 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a>支持的数据类型</h3><p>Flink 流应用程序处理的是以数据对象表示的事件流。所以在 Flink 内部，我们需要能够处理这些对象。它们需要被序列化和反序列化，以便通过网络传送它们；或者从状态后端、检查点和保存点读取它们。为了有效地做到这一点，Flink 需要明确知道应用程序所处理的数据类型。Flink 使用类型信息的概念来表示数据类型，并为每个数据类型生成特定的序列化器、反序列化器和比较器。</p><p>Flink 还具有一个类型提取系统，该系统分析函数的输入和返回类型，以自动获取类型信息，从而获得序列化器和反序列化器。但是，在某些情况下，例如 lambda 函数或泛型类型，需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。</p><p>Flink 支持 Java 和 Scala 中所有常见数据类型。使用最广泛的类型有以下几种。</p><h4 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h4><p>Flink 支持所有的 Java 和 Scala 基础数据类型，Integer, Double, Long, String, …​</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> numbers<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span>fromElements<span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">3L</span><span class="token punctuation">,</span> <span class="token number">4L</span><span class="token punctuation">)</span>numbers<span class="token punctuation">.</span>map<span class="token punctuation">(</span> n <span class="token keyword">=></span> n <span class="token operator">+</span> <span class="token number">1</span> <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="Java-和-Scala-元组-Tuples"><a href="#Java-和-Scala-元组-Tuples" class="headerlink" title="Java 和 Scala 元组(Tuples)"></a>Java 和 Scala 元组(Tuples)</h4><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> persons<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Integer<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span>fromElements<span class="token punctuation">(</span>    <span class="token punctuation">(</span><span class="token string">"Adam"</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">(</span><span class="token string">"Sarah"</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">)</span>persons<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>p <span class="token keyword">=></span> p<span class="token punctuation">.</span>_2 <span class="token operator">></span> <span class="token number">18</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Scala-样例类-case-classes"><a href="#Scala-样例类-case-classes" class="headerlink" title="Scala 样例类(case classes)"></a>Scala 样例类(case classes)</h4><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token keyword">val</span> persons<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span>fromElements<span class="token punctuation">(</span>    Person<span class="token punctuation">(</span><span class="token string">"Adam"</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    Person<span class="token punctuation">(</span><span class="token string">"Sarah"</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">)</span>persons<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>p <span class="token keyword">=></span> p<span class="token punctuation">.</span>age <span class="token operator">></span> <span class="token number">18</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Java-简单对象-POJOs"><a href="#Java-简单对象-POJOs" class="headerlink" title="Java 简单对象(POJOs)"></a>Java 简单对象(POJOs)</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Person</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> String name<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">Person</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">Person</span><span class="token punctuation">(</span>String name<span class="token punctuation">,</span> <span class="token keyword">int</span> age<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>age <span class="token operator">=</span> age<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span>DataStream<span class="token operator">&lt;</span>Person<span class="token operator">></span> persons <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span>    <span class="token keyword">new</span> <span class="token class-name">Person</span><span class="token punctuation">(</span><span class="token string">"Alex"</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token keyword">new</span> <span class="token class-name">Person</span><span class="token punctuation">(</span><span class="token string">"Wendy"</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：</strong>其中类中必须要有一个空参的构造函数；另外属性必须是 public 或者有对应的 public 的 get set 方法。</p><h4 id="其它-Arrays-Lists-Maps-Enums-等等"><a href="#其它-Arrays-Lists-Maps-Enums-等等" class="headerlink" title="其它(Arrays, Lists, Maps, Enums, 等等)"></a>其它(Arrays, Lists, Maps, Enums, 等等)</h4><p>Flink 对 Java 和 Scala 中的一些特殊目的的类型也都是支持的，比如 Java 的 ArrayList，HashMap，Enum 等等。</p><h3 id="实现-UDF-函数——更细粒度的控制流"><a href="#实现-UDF-函数——更细粒度的控制流" class="headerlink" title="实现 UDF 函数——更细粒度的控制流"></a>实现 UDF 函数——更细粒度的控制流</h3><h4 id="函数类-Function-Classes"><a href="#函数类-Function-Classes" class="headerlink" title="函数类(Function Classes)"></a>函数类(Function Classes)</h4><p>Flink 暴露了所有 udf 函数的接口(实现方式为接口或者抽象类)。例如 MapFunction, FilterFunction, ProcessFunction 等等。</p><p>下面例子实现了 FilterFunction 接口:</p><pre class="line-numbers language-java"><code class="language-java">DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> flinkTweets <span class="token operator">=</span> tweets<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkFilter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">FlinkFilter</span> <span class="token keyword">implements</span> <span class="token class-name">FilterFunction</span><span class="token operator">&lt;</span>String<span class="token operator">></span> <span class="token punctuation">{</span>  <span class="token annotation punctuation">@Override</span> <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span>String value<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>    <span class="token keyword">return</span> value<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"flink"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​ 还可以将函数实现成匿名类，这样做的话没有上面那么灵活，通用性差一些（别的地方再用到相同的 filter 时，仍然需要再写一遍）</p><pre class="line-numbers language-java"><code class="language-java">DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> flinkTweets <span class="token operator">=</span> tweets<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>    <span class="token keyword">new</span> <span class="token class-name">FilterFunction</span><span class="token operator">&lt;</span>String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span>String value<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>            <span class="token keyword">return</span> value<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"flink"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​ 我们 filter 的字符串”flink”还可以当作参数传进去。</p><pre class="line-numbers language-java"><code class="language-java">DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> tweets <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"INPUT_FILE "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> flinkTweets <span class="token operator">=</span> tweets<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">KeyWordFilter</span><span class="token punctuation">(</span><span class="token string">"flink"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">KeyWordFilter</span> <span class="token keyword">implements</span> <span class="token class-name">FilterFunction</span><span class="token operator">&lt;</span>String<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> String keyWord<span class="token punctuation">;</span>    <span class="token function">KeyWordFilter</span><span class="token punctuation">(</span>String keyWord<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">this</span><span class="token punctuation">.</span>keyWord <span class="token operator">=</span> keyWord<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span> <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span>String value<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>    <span class="token keyword">return</span> value<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>keyWord<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="匿名函数-Lambda-Functions"><a href="#匿名函数-Lambda-Functions" class="headerlink" title="匿名函数(Lambda Functions)"></a>匿名函数(Lambda Functions)</h4><pre class="line-numbers language-java"><code class="language-java">DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> tweets <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">"INPUT_FILE"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> flinkTweets <span class="token operator">=</span> tweets<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span> tweet <span class="token operator">-</span><span class="token operator">></span> tweet<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"flink"</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="富函数-Rich-Functions"><a href="#富函数-Rich-Functions" class="headerlink" title="富函数(Rich Functions)"></a>富函数(Rich Functions)</h4><p>“富函数”是 DataStream API 提供的一个函数类的接口，所有 Flink 函数类都有其 Rich 版本。它与常规函数的不同在于，可以获取运行环境的上下文（可获取当前状态或者自定义状态做一些更复杂的操作），并拥有一些生命周期方法，所以可以实现更复杂的功能。</p><ul><li><p>RichMapFunction</p></li><li><p>RichFlatMapFunction</p></li><li><p>RichFilterFunction</p></li><li><p>…​</p></li></ul><p>Rich Function 有一个生命周期的概念。典型的生命周期方法有:</p><ul><li><p>open()方法是 rich function 的初始化方法，当一个算子例如 map 或者 filter<br>被调用之前 open()会被调用。</p></li><li><p>close()方法是生命周期中的最后一个调用的方法，做一些清理工作。</p></li><li><p>getRuntimeContext()方法提供了函数的 RuntimeContext 的一些信息，例如函数执行的并行度，任务的名字，以及 state 状态</p></li></ul><p><strong>需求：</strong>返回对应 SensorReading 的 id 以及其所在自任务编号</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyMapFunction</span> <span class="token keyword">extends</span> <span class="token class-name">RichMapFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">>></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span> <span class="token function">map</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">getRuntimeContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getIndexOfThisSubtask</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 进行初始化操作</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">open</span><span class="token punctuation">(</span>Configuration configuration<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"open"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 进行一些结束操作</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"close"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果：</p><pre class="line-numbers language-text"><code class="language-text">openopenopenopen4> (sensor_1,3)4> (sensor_6,3)close3> (sensor_1,2)close1> (sensor_7,0)2> (sensor_1,1)1> (sensor_10,0)2> (sensor_1,1)closeclose<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/transform/TransformTest5_RichFunction.java" target="_blank" rel="noopener">demo 地址</a></p><h3 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h3><p>Flink 没有类似于 spark 中 foreach 方法，让用户进行迭代的操作。虽有对外的输出操作都要利用 Sink 完成。最后通过类似如下方式完成整个任务最终输出操作。</p><pre class="line-numbers language-java"><code class="language-java">stream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MySink</span><span class="token punctuation">(</span>xxxx<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="5-9.jpg" alt="5-9"></p><p>官方提供了一部分的框架的 sink。除此以外，需要用户自定义实现 sink</p><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>【pom.xml】添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka-0.11 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka-0.11_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.10.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主函数中添加</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// sink输出到kafka</span>sensorDataStream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer011</span><span class="token operator">&lt;</span>String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"localhost:9092"</span><span class="token punctuation">,</span> <span class="token string">"flinkTest"</span><span class="token punctuation">,</span>        <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>(demo 地址)[<a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/sink/SinkTest1_Kafka.java]" target="_blank" rel="noopener">https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/sink/SinkTest1_Kafka.java]</a></p><h4 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h4><p>【pom.xml】添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.bahir/flink-connector-redis --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.bahir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-redis_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>需求：</strong>sink 到 redis（若一个传感器有多条数据，则只保留最后一条数据）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>sink<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>apitest<span class="token punctuation">.</span>beans<span class="token punctuation">.</span>SensorReading<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>MapFunction<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStreamSink<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>DataStreamSource<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span>SingleOutputStreamOperator<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span>StreamExecutionEnvironment<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>RedisSink<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>common<span class="token punctuation">.</span>config<span class="token punctuation">.</span>FlinkJedisPoolConfig<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>common<span class="token punctuation">.</span>mapper<span class="token punctuation">.</span>RedisCommand<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>common<span class="token punctuation">.</span>mapper<span class="token punctuation">.</span>RedisCommandDescription<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>redis<span class="token punctuation">.</span>common<span class="token punctuation">.</span>mapper<span class="token punctuation">.</span>RedisMapper<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @author: Swenchao * @description: sink到redis（若一个传感器有多条数据，则只保留最后一条数据） * @create: 2021-03-31 15:22 **/</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SinkTest2_Redis</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// ...</span>        <span class="token comment" spellcheck="true">// 关键代码</span>        FlinkJedisPoolConfig conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlinkJedisPoolConfig<span class="token punctuation">.</span>Builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setHost</span><span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setPort</span><span class="token punctuation">(</span><span class="token number">6379</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        DataStreamSink<span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> sensorReadingDataStreamSink <span class="token operator">=</span> mapStream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">RedisSink</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span>                <span class="token keyword">new</span> <span class="token class-name">MyRedisMapper</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// ...</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * Author: Swenchao     * Description: 自定义RedisMapper     * Date 2021/4/16 10:27 上午     * Version: 1.0     */</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyRedisMapper</span> <span class="token keyword">implements</span> <span class="token class-name">RedisMapper</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 定义保存数据到redis的命令，存成Hash表 redis命令：hset sensor_temp id temperature</span>        <span class="token comment" spellcheck="true">// hset sensor_temp id temperature  redis命令：sensor_temp表名；id：key值；temperature：value（温度值）</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> RedisCommandDescription <span class="token function">getCommandDescription</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// RedisCommand枚举值，列举redis命令；sensor_temp表名</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">RedisCommandDescription</span><span class="token punctuation">(</span>RedisCommand<span class="token punctuation">.</span>HSET<span class="token punctuation">,</span> <span class="token string">"sensor_temp"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> String <span class="token function">getKeyFromData</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获得key值</span>            <span class="token keyword">return</span> sensorReading<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> String <span class="token function">getValueFromData</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获得value值</span>            <span class="token keyword">return</span> String<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/sink/SinkTest2_Redis.java" target="_blank" rel="noopener">demo 地址</a></p><h4 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h4><p>【pom.xml】添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-elasticsearch6_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.10.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>需求：</strong>传感器写入 es</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// ...</span><span class="token comment" spellcheck="true">// 自定义ES写入操作</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyEsSinkFunction</span> <span class="token keyword">implements</span> <span class="token class-name">ElasticsearchSinkFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span>SensorReading sensorReading<span class="token punctuation">,</span> RuntimeContext runtimeContext<span class="token punctuation">,</span> RequestIndexer requestIndexer<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 定义写入数据（dataSource）</span>        HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> dataSource <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        dataSource<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">,</span> sensorReading<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        dataSource<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"temp"</span><span class="token punctuation">,</span> String<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>sensorReading<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        dataSource<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"ts"</span><span class="token punctuation">,</span> sensorReading<span class="token punctuation">.</span><span class="token function">getTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建请求，发送写入命令</span>        IndexRequest indexRequest <span class="token operator">=</span> Requests<span class="token punctuation">.</span><span class="token function">indexRequest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">index</span><span class="token punctuation">(</span><span class="token string">"sensor"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">type</span><span class="token punctuation">(</span><span class="token string">"readingdata"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">source</span><span class="token punctuation">(</span>dataSource<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 用index发送请求</span>        requestIndexer<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>indexRequest<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// ...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/sink/SinkTest3_ElasticSearch.java" target="_blank" rel="noopener">demo 地址</a></p><h4 id="JDBC-自定义-sink"><a href="#JDBC-自定义-sink" class="headerlink" title="JDBC 自定义 sink"></a>JDBC 自定义 sink</h4><p>【pom.xml】添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.44<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>需求：</strong>不断新增更新 mysql 中存储的传感器数据</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// ...</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyJdbcSink</span> <span class="token keyword">extends</span> <span class="token class-name">RichSinkFunction</span><span class="token operator">&lt;</span>SensorReading<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//声明连接和预编译语句</span>    Connection conn <span class="token operator">=</span> null<span class="token punctuation">;</span>    PreparedStatement insertStmt <span class="token operator">=</span> null<span class="token punctuation">;</span>    PreparedStatement updateStmt <span class="token operator">=</span> null<span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">open</span><span class="token punctuation">(</span>Configuration parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 创建数据库连接</span>        conn <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc://mysql://localhost:3306/test"</span><span class="token punctuation">,</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        insertStmt <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span><span class="token string">"insert into sensor_tmp (id, temp) values (?, ?)"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        updateStmt <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span><span class="token string">"update sensor_tmp set temp = ? where id = ?"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token comment" spellcheck="true">// 来数据，执行sql</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">invoke</span><span class="token punctuation">(</span>SensorReading value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 直接执行更新语句，若失败，则插入</span>        updateStmt<span class="token punctuation">.</span><span class="token function">setDouble</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        updateStmt<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        updateStmt<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>updateStmt<span class="token punctuation">.</span><span class="token function">getUpdateCount</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            insertStmt<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            insertStmt<span class="token punctuation">.</span><span class="token function">setDouble</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span><span class="token function">getTemperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            insertStmt<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        insertStmt<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        updateStmt<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        conn<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// ...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/FlinkCode/blob/main/src/main/java/com/swenchao/apitest/sink/SinkTest4_Jdbc.java" target="_blank" rel="noopener">demo 地址</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink运行架构</title>
      <link href="2021/01/08/flink-yun-xing-jia-gou/"/>
      <url>2021/01/08/flink-yun-xing-jia-gou/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><h2 id="Flink-运行架构"><a href="#Flink-运行架构" class="headerlink" title="Flink 运行架构"></a>Flink 运行架构</h2><h3 id="Flink-运行时组件"><a href="#Flink-运行时组件" class="headerlink" title="Flink 运行时组件"></a>Flink 运行时组件</h3><ol><li>作业管理器（JobManager）</li></ol><ul><li><p>控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的 JobManager 所控制执行。</p></li><li><p>JobManager 会先接收到要执行的应用程序，这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的 JAR 包。</p></li><li><p>JobManager 会把 JobGraph 转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。</p></li><li><p>JobManager 会向资源管理器（ResourceManager）请求执行任务必要的资源也就是任务管理器（TaskManager）上的插槽 slot。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的 TaskManager 上。而在运行过程中，JobManager 会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</p></li></ul><ol start="2"><li>任务管理器（TaskManager）</li></ol><ul><li><p>Flink 中的工作进程。通常在 Flink 中会有多个 TaskManager 运行，每一个 TaskManager 都包含了一定数量的插槽(slots)。插槽的数量限制了 TaskManager 能够执行的任务数量。</p></li><li><p>启动之后，TaskManager 会向资源管理器注册它的插槽;收到资源管理 器的指令后，TaskManager 就会将一个或者多个插槽提供给 JobManager 调用。JobManager 就可以向插槽分配任务(tasks)来 执行了。</p></li><li><p>在执行过程中，一个 TaskManager 可以跟其它运行同一应用程序的 TaskManager 交换数据。</p></li></ul><ol start="3"><li>资源管理器(ResourceManager)</li></ol><ul><li><p>主要负责管理任务管理器(TaskManager)的插槽(slot)，TaskManger 插槽是 Flink 中定义的处理资源单元。</p></li><li><p>Flink 为不同的环境和资源管理工具提供了不同资源管理器，比如 YARN、Mesos、K8s，以及 standalone 部署。</p></li><li><p>当 JobManager 申请插槽资源时，ResourceManager 会将有空闲插槽的 TaskManager 分配给 JobManager。如果 ResourceManager 没有足够的插槽来满足 JobManager 的请求，它还可以向资源提供平台发起会话，以提供启动 TaskManager 进程的容器。</p></li></ul><ol start="4"><li>分发器(Dispatcher)</li></ol><ul><li><p>可以跨作业运行，它为应用提交提供了 REST 接口。</p></li><li><p>当一个应用被提交执行时，分发器就会启动并将应用移交给一个 JobManager。</p></li><li><p>Dispatcher 也会启动一个 Web UI，用来方便地展示和监控作业执行的信息。</p></li><li><p>Dispatcher 在架构中可能并不是必需的，这取决于应用提交运行的方式。</p></li></ul><h3 id="任务提交流程"><a href="#任务提交流程" class="headerlink" title="任务提交流程"></a>任务提交流程</h3><p><img src="2-1.jpeg" alt="2-1"></p><h3 id="任务调度原理"><a href="#任务调度原理" class="headerlink" title="任务调度原理"></a>任务调度原理</h3><p><img src="2-2.png" alt="2-2"></p><p><strong>注：</strong>其中的 ResourceManager 是 Yarn 的资源管理器，Flink 的资源管理器在 ApplicationMaster 中。另外在 4 中是 JobManager 先向自身的 RM 请求资源，然后自身的 RM 再去请求 Yarn 的 RM，后面步骤就跟 Flink 任务调度一样了。这是一个 job 模式（Per-Job-Cluster 模式）</p><h3 id="任务调度原理-1"><a href="#任务调度原理-1" class="headerlink" title="任务调度原理"></a>任务调度原理</h3><p><img src="2-3.png" alt="2-3"></p><p><strong>个人解析：</strong></p><ol><li>过程</li></ol><p>一个作业有一个 JobManager，一个 JobManager 有多个 TaskManager，一个 TaskManager 有多个 TaskSlot。</p><p>编写一段程序代码(Flink Program)，基于代码课直接生成一个数据流图(Dataflow graph)，然后通过客户端(Client)将作业提交到集群（通过分发器发给 JobManager），然后 JobManager 将任务分发给各个 TaskSlot 上，这就相当于多线程执行，都并行执行。整个运行过程中，JobManager 并不参与具体工作过程。</p><ol start="2"><li>数据交互</li></ol><p>客户端——&gt;JobManager：提交作业、取消作业</p><p>JobManager——&gt;客户端：作业状态、静态结果</p><p>JobManager——&gt;TaskManager：控制指令（分发任务、撤销任务、触发检查点）</p><p>TaskManager——&gt;JobManager：任务状态、心跳等等</p><h3 id="并行度"><a href="#并行度" class="headerlink" title="并行度"></a>并行度</h3><p>一个特定算子的子任务(subtask)的个数被称之为其并行度(parallelism)。一般情况下，一个 stream 的并行度，可以认为就是其所有算子中最大的并行度</p><p><img src="2-4.png" alt="2-4"></p><h4 id="TaskManager-和-Slots"><a href="#TaskManager-和-Slots" class="headerlink" title="TaskManager 和 Slots"></a>TaskManager 和 Slots</h4><p>在 Flink 中 Slots 就是执行一个独立任务或者一个独立线程的所需要的计算资源的最小单元，每个 slots 都有自己独立的内存，相互之间互不干扰。</p><p><strong>注：</strong>建议 slots 数量：TaskManager 上的 CPU 核心数量（一个 slots 占用一个核，不用相互等待，默认就是整个规则）</p><p>Flink 中每一个 TaskManager 都是一个 JVM 进程，它可能会在独立的线程上执行一个或多个子任务</p><p>为了控制一个 TaskManager 能接收多少个 task，TaskManager 通过 task slot 来进行控制(一个 TaskManager 至少有一个 slot)</p><p><img src="2-5.png" alt="2-5"></p><p>默认情况下，Flink 允许子任务 slot 共享（不同任务共享一个 slot，如下图，第一个 slot 运行三个线程。其可以共享的前提是前后发生的不同的任务的子任务才可以共享）。这样的结果是一个 slot 可以保存作业的整个管道（PipeLine）。</p><p>Task Slot 是静态的概念，是指 TaskManager 具有的并发执行能力</p><p><img src="2-6.png" alt="2-6"></p><p><strong>注：</strong>若是 2-5 图中那样，则会产生不同的 slots 之间，有的会非常“忙碌”，有的会非常“清闲”。比如，2-5 中在第一个 slot 中，只有读取和 map 操作，当数据量很大时，它也能很快做完，但是第二个 slot 就不一样了，当数据量很大时，他会运行非常慢；但是在 2-6 中，在同一个 slot 中有多个任务时，在读取数据和 map 很快操作完之后，其可以继续执行下面的 keyBy、window 等一系列操作，这就使得每个 slot 都能充分利用。</p><p><strong>补充：</strong>配置 slot 共享组</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 当没有配置共享组时，其默认是跟上一个配置的共享组是一组，若上面也没有，则会创建一个默认的</span>DataStream<span class="token operator">&lt;</span>String<span class="token operator">></span> stringDataStream <span class="token operator">=</span> streamEnv<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// slotSharingGroup("green")进行共享组配置，其中的green为共享组名称</span>DataStream<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">>></span> resultStream <span class="token operator">=</span>        stringDataStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">WordCount<span class="token punctuation">.</span>MyFlatMapper</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">slotSharingGroup</span><span class="token punctuation">(</span><span class="token string">"green"</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">slotSharingGroup</span><span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 其共享组是上面的red</span>resultStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过上面的代码可以看出，其一共有三个共享组（默认的第一个、green、red）</p><h4 id="并行子任务的分配"><a href="#并行子任务的分配" class="headerlink" title="并行子任务的分配"></a>并行子任务的分配</h4><p><img src="2-7.png" alt="2-7"></p><p>其中一共 16 个自任务，只需要 4 个 slot 就能解决。一般整个流处理过程的并行度就是其中所有算子最大的子任务数，其决定了 slots 数量。</p><p><img src="2-8.png" alt="2-8"></p><p>第一部分图：其中有 3 个 TaskManager 每个 TaskManager 有 3 个 TaskSlots（其推荐数量为 CPU 核数——逻辑核数）</p><p>第二部分图：提交任务时，未做并行度设置，因此默认是 1</p><p>第三部分图：设置并行度有三种方式——配置文件修改，这种方式需要重启集群；提交 flink-job 的时候，给一个 -p 参数；直接在嗲吗中写死。优先级是从后往前逐渐降低。因为其中三个任务可以共享 slots，因此只需要两个 slots 就可以完成。</p><p><img src="2-9.png" alt="2-9"></p><p>第一部分图：最大限度使用 slots</p><p>第二部分图：其中的 sink 可能需要写到一个文件中，所以在多线程写入的时候，可能会出现问题。所以在某些场景下为了避免出现问题，将 sink 的并行度设为 1</p><h3 id="程序与数据流-DataFlow"><a href="#程序与数据流-DataFlow" class="headerlink" title="程序与数据流(DataFlow)"></a>程序与数据流(DataFlow)</h3><p><img src="2-10.jpeg" alt="2-10"></p><p>所有的 Flink 程序都是由三部分组成的: Source 、Transformation 和 Sink。</p><p>Source 负责读取数据源，Transformation 利用各种算子进行处理加工，Sink 负责输出</p><p><img src="2-11.png" alt="2-11"></p><p>在运行时，Flink 上运行的程序会被映射成“逻辑数据流”(dataflows)，它包含了以上三部分</p><p>每一个 dataflow 以一个或多个 sources 开始以一个或多个 sinks 结束。dataflow 类似于任意的有向无环图(DAG)</p><p>在大部分情况下，程序中的转换运算(transformations)跟 dataflow 中的算子 (operator)是一一对应的关系</p><h3 id="执行图"><a href="#执行图" class="headerlink" title="执行图"></a>执行图</h3><p>Flink 中的执行图可以分成四层:StreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; 物理执行图</p><ol><li><p>StreamGraph:是根据用户通过 Stream API 编写的代码生成的最初的图，用来表示程序的拓扑结构。相当于一个操作一个任务。</p></li><li><p>JobGraph:StreamGraph 经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点串在一起作为一个任务节点</p></li><li><p>ExecutionGraph:JobManager 根据 JobGraph 生成 ExecutionGraph（执行图）。 ExecutionGraph 是 JobGraph 的并行化版本，是调度层最核心的数据结构。</p></li><li><p>物理执行图:JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个 TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。</p></li></ol><p><img src="2-12.png" alt></p><h3 id="数据传输形式"><a href="#数据传输形式" class="headerlink" title="数据传输形式"></a>数据传输形式</h3><p>一个程序中，不同的算子可能具有不同的并行度</p><p>算子之间传输数据的形式可以是 one-to-one (forwarding) 的模式也可以是 redistributing 的模式，具体是哪一种形式，取决于算子的种类</p><ol><li><p>One-to-one:stream 维护着分区以及元素的顺序(比如 source 和 map 之间)。 这意味着 map 算子的子任务看到的元素的个数以及顺序跟 source 算子的子任务生产的元素的个数、顺序相同。map、fliter、flatMap 等算子都是 one-to-one 的对应关系。相当于 spark 的窄依赖。</p></li><li><p>Redistributing:stream 的分区会发生改变。每一个算子的子任务依据所选择的 transformation 发送数据到不同的目标任务。例如，keyBy 基于 hashCode 重分区、而 broadcast 和 rebalance（轮询：若上游有四个任务，下游有三个任务，那么上游的 1 2 3 分别分发给了 1 2 3，上游的 4 就会重新发给下游的 1）会随机重新分区，这些算子都会引起 redistribute 过程，而 redistribute 过程就类似于 Spark 中的 shuffle 过程。相当于 spark 的窄依赖。</p></li></ol><h3 id="任务链-Operator-Chains"><a href="#任务链-Operator-Chains" class="headerlink" title="任务链(Operator Chains)"></a>任务链(Operator Chains)</h3><ol><li><p>Flink 采用了一种称为任务链的优化技术，可以在特定条件下减少本地通信的开销。为了满足任务链的要求，必须将两个或多个算子设为相同的并行度，并通过本地转发(local forward)的方式进行连接</p></li><li><p>相同并行度的 one-to-one 操作，Flink 这样相连的算子链接在一起形成一个 task，原来的算子成为里面的 subtask</p></li></ol><p><strong>注：</strong>并行度相同、并且是 one-to-one 操作，而且是同一 slot 共享组，三个条件缺一不可</p><p><img src="2-13.png" alt></p><p><strong>注：</strong>若不想任务合并，除了破坏上面条件之外，还可以直接在不想合并操作后面使用.disableChaining()；或者在生成的环境后面使用.disableOperatorChaining()——这样就会使所有的操作都不合并</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive自定义函数</title>
      <link href="2020/11/29/hive-zi-ding-yi-han-shu/"/>
      <url>2020/11/29/hive-zi-ding-yi-han-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="系统内置函数"><a href="#系统内置函数" class="headerlink" title="系统内置函数"></a>系统内置函数</h3><ol><li>查看系统自带的函数</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> functions<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>显示自带的函数的用法</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> <span class="token keyword">function</span> upper<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>详细显示自带的函数的用法</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> <span class="token keyword">function</span> <span class="token keyword">extended</span> upper<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h3><ol><li><p>Hive 自带了一些函数，比如：max/min 等，但是数量有限，自己可以通过自定义 UDF 来方便的扩展。</p></li><li><p>当 Hive 提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数(UDF：user-defined function)。</p></li><li><p>根据用户自定义函数类别分为以下三种：</p></li></ol><p>(1) UDF(User-Defined-Function)</p><p>一进一出（给一条数据返回一条数据）</p><p>(2) UDAF(User-Defined Aggregation Function)</p><p>聚集函数，多进一出</p><p>类似于：count/max/min</p><p>(3) UDTF(User-Defined Table-Generating Functions)</p><p>一进多出</p><p>类似于：lateral view explore()</p><ol start="4"><li><p><a href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins" target="_blank" rel="noopener">官方文档地址</a></p></li><li><p>编程步骤：</p></li></ol><p>(1) 继承 Hive 提供的类 org.apache.hadoop.hive.ql.UDF</p><p>(2) 需要实现 evaluate 函数；evaluate 函数支持重载；</p><p>(3) 在 hive 的命令行窗口创建函数</p><p>a) 添加 jar</p><p>add jar linux_jar_path</p><p>b) 创建 function，</p><p>create [temporary] function [dbname.]function_name AS class_name;</p><p>(4) 在 hive 的命令行窗口删除函数</p><p>Drop [temporary] function [if exists] [dbname.]function_name;</p><ol start="6"><li>注意事项</li></ol><p>(1) UDF 必须要有返回类型，可以返回 null，但是返回类型不能为 void；</p><h3 id="自定义-UDF-函数"><a href="#自定义-UDF-函数" class="headerlink" title="自定义 UDF 函数"></a>自定义 UDF 函数</h3><p>需求</p><p>自定义一个 UDF 实现计算给定字符串的长度，例如：</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> my_len<span class="token punctuation">(</span><span class="token string">"abcd"</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol><li><p>创建一个 Maven 工程 Hive</p></li><li><p>导入依赖</p></li></ol><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-exec --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hive-exec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>创建一个类</li></ol><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>udf<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span>UDFArgumentException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>HiveException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericUDF<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>ObjectInspector<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>primitive<span class="token punctuation">.</span>PrimitiveObjectInspectorFactory<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/11/29 12:13 * @Description: * @Modified: NULL * @Version: 1.0 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyUDF</span> <span class="token keyword">extends</span> <span class="token class-name">GenericUDF</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 校验数据参数个数</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ObjectInspector <span class="token function">initialize</span><span class="token punctuation">(</span>ObjectInspector<span class="token punctuation">[</span><span class="token punctuation">]</span> objectInspectors<span class="token punctuation">)</span> <span class="token keyword">throws</span> UDFArgumentException <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>objectInspectors<span class="token punctuation">.</span>length <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">UDFArgumentException</span><span class="token punctuation">(</span><span class="token string">"参数个数不对"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> PrimitiveObjectInspectorFactory<span class="token punctuation">.</span>javaIntObjectInspector<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 处理数据</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Object <span class="token function">evaluate</span><span class="token punctuation">(</span>DeferredObject<span class="token punctuation">[</span><span class="token punctuation">]</span> deferredObjects<span class="token punctuation">)</span> <span class="token keyword">throws</span> HiveException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 取出输入数据</span>        String input <span class="token operator">=</span> deferredObjects<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 判断输入数据是否为null</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>input <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 返回数据长度</span>        <span class="token keyword">return</span> input<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">getDisplayString</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> strings<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li><p>打成 jar 包上传到服务器/opt/module/hive/lib/udf.jar</p></li><li><p>将 jar 包添加到 hive 的 classpath</p></li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">add</span> jar <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>lib<span class="token operator">/</span>udf<span class="token punctuation">.</span>jar<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>创建临时函数与开发好的 java class 关联</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">temporary</span> <span class="token keyword">function</span> myLen <span class="token keyword">as</span> <span class="token string">"com.swenchao.udf.MyUDF"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="7"><li>即可在 hql 中使用自定义的函数 strip</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename<span class="token punctuation">,</span> mylower<span class="token punctuation">(</span>ename<span class="token punctuation">)</span> lowername <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="自定义-UDTF-函数"><a href="#自定义-UDTF-函数" class="headerlink" title="自定义 UDTF 函数"></a>自定义 UDTF 函数</h3><p>需求</p><p>自定义一个 UDTF 实现将一个任意分割符的字符串切割成独立的单词，例如：</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> myudtf<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"hello,world,hadoop,hive"</span><span class="token punctuation">,</span> <span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>——<span class="token operator">></span>helloworldhadoophive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>代码实现代码实现</li></ol><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>udf<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span>UDFArgumentException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>HiveException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericUDTF<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>ObjectInspector<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>ObjectInspectorFactory<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>StructObjectInspector<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>primitive<span class="token punctuation">.</span>PrimitiveObjectInspectorFactory<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/11/29 13:07 * @Description: * @Modified: NULL * @Version: 1.0 * 输入：hello,hadoop,hive * 输出： *      hello *      hadoop *      hive */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyUDTF</span> <span class="token keyword">extends</span> <span class="token class-name">GenericUDTF</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 输出数据集合</span>    <span class="token keyword">private</span> ArrayList<span class="token operator">&lt;</span>String<span class="token operator">></span> outPutList <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> StructObjectInspector <span class="token function">initialize</span><span class="token punctuation">(</span>StructObjectInspector argOIs<span class="token punctuation">)</span> <span class="token keyword">throws</span> UDFArgumentException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输出数据默认列明，可以被别名覆盖</span>        List<span class="token operator">&lt;</span>String<span class="token operator">></span> fieldNames <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        fieldNames<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"word"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 输出数据类型</span>        List<span class="token operator">&lt;</span>ObjectInspector<span class="token operator">></span> fieldOIs <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        fieldOIs<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>PrimitiveObjectInspectorFactory<span class="token punctuation">.</span>javaStringObjectInspector<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 最终返回值</span>        <span class="token keyword">return</span> ObjectInspectorFactory<span class="token punctuation">.</span><span class="token function">getStandardStructObjectInspector</span><span class="token punctuation">(</span>fieldNames<span class="token punctuation">,</span> fieldOIs<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 处理输入数据     * @param objects     * @throws HiveException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span>Object<span class="token punctuation">[</span><span class="token punctuation">]</span> objects<span class="token punctuation">)</span> <span class="token keyword">throws</span> HiveException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 取出数据</span>        String input <span class="token operator">=</span> objects<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 按","分隔字符串</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> input<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 遍历写出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word<span class="token operator">:</span>words<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 清空集合</span>            outPutList<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 将数据放入集合</span>            outPutList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 输出数据</span>            <span class="token function">forward</span><span class="token punctuation">(</span>outPutList<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 收尾方法     * @throws HiveException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> HiveException <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li><p>打成打成 jar 包上传到服务器包上传到服务器/opt/module/hive/lib/udtf.jar</p></li><li><p>将 jar 包添加到 hive 的 classpath 下</p></li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">add</span> jar <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>lib<span class="token operator">/</span>udtf<span class="token punctuation">.</span>jar<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>创建临时函数与开发好的 java class 关联</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">temporary</span> <span class="token keyword">function</span> myudtf <span class="token keyword">as</span> <span class="token string">"com.swenchao.hive.MyUDTF"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>使用自定义的函数</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> myudtf<span class="token punctuation">(</span><span class="token string">"hello,world,hadoop,hive"</span><span class="token punctuation">,</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive查询</title>
      <link href="2020/11/26/hive-cha-xun/"/>
      <url>2020/11/26/hive-cha-xun/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select" target="_blank" rel="noopener">文档</a></p><p>查询语句语法：</p><pre><code>[WITH CommonTableExpression (, CommonTableExpression)*] (Note: Only availablestarting with Hive 0.13.0)SELECT [ALL | DISTINCT] select_expr, select_expr, ...FROM table_reference[WHERE where_condition][GROUP BY col_list][ORDER BY col_list][CLUSTER BY col_list| [DISTRIBUTE BY col_list] [SORT BY col_list]][LIMIT number]</code></pre><h3 id="基本查询-Select…From"><a href="#基本查询-Select…From" class="headerlink" title="基本查询(Select…From)"></a>基本查询(Select…From)</h3><h4 id="全表和特定列查询"><a href="#全表和特定列查询" class="headerlink" title="全表和特定列查询"></a>全表和特定列查询</h4><ol><li>全表查询</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>选择特定列查询</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> empno<span class="token punctuation">,</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong></p><p>(1) SQL 语言大小写不敏感。<br>(2) SQL 可以写在一行或者多行<br>(3) 关键字不能被缩写也不能分行<br>(4) 各子句一般要分行写。<br>(5) 使用缩进提高语句的可读性。</p><h4 id="列别名"><a href="#列别名" class="headerlink" title="列别名"></a>列别名</h4><ol><li><p>重命名一个列</p></li><li><p>便于计算</p></li><li><p>紧跟列名，也可以在列名和别名之间加入关键字 AS</p></li><li><p>案例实操</p></li></ol><p>查询名称和部门</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename <span class="token keyword">AS</span> name<span class="token punctuation">,</span> deptno dn <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h4><p>| 运算符 | 功能              |<br>| —— | —————– | ————— |<br>| A+B    | A 和 B 相加       |<br>| A-B    | A 减去 B          |<br>| A*B   | A 和 B 相乘       |<br>| A/B    | A 除以 B          |<br>| A%B    | A 对 B 取余       |<br>| A&amp;B    | A 和 B 按位取与   |<br>| A      | B                 | A 和 B 按位取或 |<br>| A^B    | A 和 B 按位取异或 |<br>| ~A     | A 按位取反        |</p><p>案例实操</p><p>查询出所有员工的薪水后加 1 显示。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> sal <span class="token operator">+</span> <span class="token number">1</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h4><ol><li>求总行数(count)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> cnt <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>求工资的最大值(max)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token function">max</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> max_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>求工资的最小值(min)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token function">min</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> min_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>求工资的总和(sum)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token function">sum</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> sum_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>求工资的平均值(avg)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Limit-语句"><a href="#Limit-语句" class="headerlink" title="Limit 语句"></a>Limit 语句</h4><p>典型的查询会返回多行数据。LIMIT 子句用于限制返回的行数。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">5</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Where-语句"><a href="#Where-语句" class="headerlink" title="Where 语句"></a>Where 语句</h3><ol><li><p>使用 WHERE 子句，将不满足条件的行过滤掉</p></li><li><p>WHERE 子句紧随 FROM 子句</p></li></ol><p>案例实操</p><p>查询出薪水大于 1000 的所有员工</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> _ <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">></span><span class="token number">1000</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="比较运算符-Between-In-Is-Null"><a href="#比较运算符-Between-In-Is-Null" class="headerlink" title="比较运算符(Between/In/ Is Null)"></a>比较运算符(Between/In/ Is Null)</h4><ol><li>下面图片描述了谓词操作符，这些操作符同样可以用于 JOIN…ON 和 HAVING 语句中。</li></ol><p><img src="6-1.png" alt></p><ol start="2"><li>案例实操</li></ol><p>(1) 查询出薪水等于 5000 的所有员工</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 查询工资在 500 到 1000 的员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">between</span> <span class="token number">500</span> <span class="token operator">and</span> <span class="token number">1000</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 查询 comm 为空的所有员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> comm <span class="token operator">is</span> <span class="token boolean">null</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4) 查询工资是 1500 或 5000 的员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">IN</span> <span class="token punctuation">(</span><span class="token number">1500</span><span class="token punctuation">,</span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Like-和-RLike"><a href="#Like-和-RLike" class="headerlink" title="Like 和 RLike"></a>Like 和 RLike</h4><p>(1) 使用 LIKE 运算选择类似的值</p><p>(2) 选择条件可以包含字符或数字:</p><p>% 代表零个或多个字符(任意个字符)。</p><ul><li>代表一个字符。</li></ul><p>(3) RLIKE 子句是 Hive 中这个功能的一个扩展，其可以通过 Java 的正则表达式这个更强大的语言来指定匹配条件。</p><p>(4) 案例实操</p><p>(1)查找以 2 开头薪水的员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">LIKE</span> <span class="token string">'2%'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)查找第二个数值为 2 的薪水的员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">LIKE</span> <span class="token string">'_2%'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3)查找薪水中含有 2 的员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">RLIKE</span> <span class="token string">'[2]'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="逻辑运算符-And-Or-Not"><a href="#逻辑运算符-And-Or-Not" class="headerlink" title="逻辑运算符(And/Or/Not)"></a>逻辑运算符(And/Or/Not)</h4><table><thead><tr><th>操作符</th><th>含义</th></tr></thead><tbody><tr><td>AND</td><td>逻辑并</td></tr><tr><td>OR</td><td>逻辑或</td></tr><tr><td>NOT</td><td>逻辑否</td></tr></tbody></table><p>案例实操</p><p>(1) 查询薪水大于 1000，部门是 30</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal<span class="token operator">></span><span class="token number">1000</span> <span class="token operator">and</span> deptno<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 查询薪水大于 1000，或者部门是 30</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal<span class="token operator">></span><span class="token number">1000</span> <span class="token operator">or</span> deptno<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 查询除了 20 部门和 30 部门以外的员工信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> deptno <span class="token operator">not</span> <span class="token operator">IN</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h3><h4 id="Group-By-语句"><a href="#Group-By-语句" class="headerlink" title="Group By 语句"></a>Group By 语句</h4><p>GROUP BY 语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p><p>案例实操：</p><p>(1) 计算 emp 表每个部门的平均工资</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> t<span class="token punctuation">.</span>deptno<span class="token punctuation">,</span> <span class="token function">avg</span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp t <span class="token keyword">group</span> <span class="token keyword">by</span> t<span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 计算 emp 每个部门中每个岗位的最高薪水</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> t<span class="token punctuation">.</span>deptno<span class="token punctuation">,</span> t<span class="token punctuation">.</span>job<span class="token punctuation">,</span> <span class="token function">max</span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>sal<span class="token punctuation">)</span> max_sal <span class="token keyword">from</span> emp t <span class="token keyword">group</span> <span class="token keyword">by</span> t<span class="token punctuation">.</span>deptno<span class="token punctuation">,</span> t<span class="token punctuation">.</span>job<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Having-语句"><a href="#Having-语句" class="headerlink" title="Having 语句"></a>Having 语句</h4><ol><li>having 与 where 不同点</li></ol><p>(1) where 针对表中的列发挥作用，查询数据；having 针对查询结果中的列发挥作用，筛选数据。</p><p>(2) where 后面不能写分组函数；而 having 后面可以使用分组函数。</p><p>(3)having 只用于 group by 分组统计语句。</p><ol start="2"><li>案例实操</li></ol><p>(1)求平均薪水大于 2000 的部门的平均工资</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> deptno<span class="token punctuation">,</span> <span class="token function">avg</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp <span class="token keyword">group</span> <span class="token keyword">by</span> deptno <span class="token keyword">having</span> avg_sal <span class="token operator">></span> <span class="token number">2000</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Join-语句"><a href="#Join-语句" class="headerlink" title="Join 语句"></a>Join 语句</h3><h4 id="等值-Join"><a href="#等值-Join" class="headerlink" title="等值 Join"></a>等值 Join</h4><p>Hive 支持通常的 SQL JOIN 语句，但是只支持等值连接，不支持非等值连接。</p><p>案例实操</p><p>(1) 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称；</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>dname <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="表的别名"><a href="#表的别名" class="headerlink" title="表的别名"></a>表的别名</h4><ol><li>好处</li></ol><p>(1)使用别名可以简化查询。</p><p>(2)使用表名前缀可以提高执行效率。</p><p>案例实操</p><p>合并员工表和部门表</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="内连接"><a href="#内连接" class="headerlink" title="内连接"></a>内连接</h4><p>只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="左外连接"><a href="#左外连接" class="headerlink" title="左外连接"></a>左外连接</h4><p>JOIN 操作符左边表中符合 WHERE 子句的所有记录将会被返回。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">left</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="右外连接"><a href="#右外连接" class="headerlink" title="右外连接"></a>右外连接</h4><p>JOIN 操作符右边表中符合 WHERE 子句的所有记录将会被返回。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">right</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="满外连接"><a href="#满外连接" class="headerlink" title="满外连接"></a>满外连接</h4><p>将会返回所有表中符合 WHERE 语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用 NULL 值替代。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">full</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="多表连接"><a href="#多表连接" class="headerlink" title="多表连接"></a>多表连接</h4><p><strong>注：</strong>连接 n 个表，至少需要 n-1 个连接条件。例如：连接三个表，至少需要两个连接条件。</p><ol><li>数据准备</li></ol><p>[location.txt]</p><pre><code>1700    Beijing1800    London1900    Tokyo</code></pre><ol start="2"><li>创建位置表</li></ol><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> <span class="token keyword">default</span><span class="token punctuation">.</span>location<span class="token punctuation">(</span>loc <span class="token keyword">int</span><span class="token punctuation">,</span> loc_name string <span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="3"><li>导入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/location.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>location<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>多表连接查询</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">SELECT</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno<span class="token punctuation">,</span> l<span class="token punctuation">.</span>loc_name <span class="token keyword">FROM</span> emp <span class="token number">e</span> <span class="token keyword">JOIN</span> dept <span class="token number">d</span> <span class="token keyword">ON</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token operator">=</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno <span class="token keyword">JOIN</span> location l <span class="token keyword">ON</span> <span class="token number">d</span><span class="token punctuation">.</span>loc <span class="token operator">=</span> l<span class="token punctuation">.</span>loc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>大多数情况下，Hive 会对每对 JOIN 连接对象启动一个 MapReduce 任务。本例中会首先启动一个 MapReduce job 对表 e 和表 d 进行连接操作，然后会再启动一个 MapReduce job 将第一个 MapReduce job 的输出和表 l 进行连接操作。</p><p><strong>注：</strong>之所以不先进行表 d 和表 l 连接操作是因为 Hive 总是按照从左到右的顺序执行的。</p><h4 id="笛卡尔积"><a href="#笛卡尔积" class="headerlink" title="笛卡尔积"></a>笛卡尔积</h4><ol><li>笛卡尔集会在下面条件下产生</li></ol><p>(1)省略连接条件</p><p>(2)连接条件无效</p><p>(3)所有表中的所有行互相连接</p><ol start="2"><li>案例实操</li></ol><p>hive (default)&gt; select empno, dname from emp, dept;</p><h4 id="连接谓词中不支持-or"><a href="#连接谓词中不支持-or" class="headerlink" title="连接谓词中不支持 or"></a>连接谓词中不支持 or</h4><p><strong>注：</strong>下面是错误的</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token number">e</span><span class="token punctuation">.</span>empno<span class="token punctuation">,</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token punctuation">,</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token keyword">from</span> emp <span class="token number">e</span> <span class="token keyword">join</span> dept <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">e</span><span class="token punctuation">.</span>deptno<span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>deptno <span class="token operator">or</span> <span class="token number">e</span><span class="token punctuation">.</span>ename<span class="token operator">=</span><span class="token number">d</span><span class="token punctuation">.</span>ename<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><h4 id="全局排序-Order-By"><a href="#全局排序-Order-By" class="headerlink" title="全局排序(Order By)"></a>全局排序(Order By)</h4><p>Order By：全局排序，一个 Reducer</p><ol><li>使用 ORDER BY 子句排序</li></ol><p>ASC(ascend): 升序(默认)</p><p>DESC(descend): 降序</p><ol start="2"><li><p>ORDER BY 子句在 SELECT 语句的结尾</p></li><li><p>案例实操</p></li></ol><p>(1)查询员工信息按工资升序排列</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">order</span> <span class="token keyword">by</span> sal<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)查询员工信息按工资降序排列</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">order</span> <span class="token keyword">by</span> sal <span class="token keyword">desc</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="按照别名排序"><a href="#按照别名排序" class="headerlink" title="按照别名排序"></a>按照别名排序</h4><p>按照员工薪水的 2 倍排序</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename<span class="token punctuation">,</span> sal<span class="token operator">*</span><span class="token number">2</span> double_sal <span class="token keyword">from</span> emp <span class="token keyword">order</span> <span class="token keyword">by</span> double_sal<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="多个列排序"><a href="#多个列排序" class="headerlink" title="多个列排序"></a>多个列排序</h4><p>按照部门和工资升序排序</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename<span class="token punctuation">,</span> deptno<span class="token punctuation">,</span> sal <span class="token keyword">from</span> emp <span class="token keyword">order</span> <span class="token keyword">by</span> deptno<span class="token punctuation">,</span> sal <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="每个-MapReduce-内部排序-Sort-By"><a href="#每个-MapReduce-内部排序-Sort-By" class="headerlink" title="每个 MapReduce 内部排序(Sort By)"></a>每个 MapReduce 内部排序(Sort By)</h4><p>Sort By：每个 Reducer 内部进行排序，对全局结果集来说不是排序。</p><ol><li>设置 reduce 个数</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>查看设置 reduce 个数</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>根据部门编号降序查看员工信息</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp sort <span class="token keyword">by</span> empno <span class="token keyword">desc</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>将查询结果导入到文件中(按照部门编号降序排序)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/datas/sortby-result'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp sort <span class="token keyword">by</span> deptno <span class="token keyword">desc</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="分区排序-Distribute-By"><a href="#分区排序-Distribute-By" class="headerlink" title="分区排序(Distribute By)"></a>分区排序(Distribute By)</h4><p>Distribute By：类似 MR 中 partition，进行分区，结合 sort by 使用。</p><p><strong>注：</strong>Hive 要求 DISTRIBUTE BY 语句要写在 SORT BY 语句之前。</p><p>对于 distribute by 进行测试，一定要分配多 reduce 进行处理，否则无法看到 distribute by 的效果。</p><p>案例实操：</p><p>(1) 先按照部门编号分区，再按照员工编号降序排序。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/datas/distribute-result'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp distribute <span class="token keyword">by</span> deptno sort <span class="token keyword">by</span> empno <span class="token keyword">desc</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="Cluster-By"><a href="#Cluster-By" class="headerlink" title="Cluster By"></a>Cluster By</h4><p>当 distribute by 和 sorts by 字段相同时，可以使用 cluster by 方式。</p><p>cluster by 除了具有 distribute by 的功能外还兼具 sort by 的功能。但是排序只能是升序排序，不能指定排序规则为 ASC 或者 DESC。</p><p>1)以下两种写法等价</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp cluster <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp distribute <span class="token keyword">by</span> deptno sort <span class="token keyword">by</span> deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>注：</strong>按照部门编号分区，不一定就是固定死的数值，可以是 20 号和 30 号部门分到一个分区里面去。</p><h3 id="分桶及抽样查询"><a href="#分桶及抽样查询" class="headerlink" title="分桶及抽样查询"></a>分桶及抽样查询</h3><h4 id="分桶表数据存储"><a href="#分桶表数据存储" class="headerlink" title="分桶表数据存储"></a>分桶表数据存储</h4><p>分区针对的是数据的存储路径；分桶针对的是数据文件。</p><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区，特别是之前所提到过的要确定合适的划分大小这个疑虑。</p><p>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</p><ol><li>先创建分桶表，通过直接导入数据文件的方式</li></ol><p>(1) 数据准备</p><p>[student.txt]</p><pre><code>1001  ss11002    ss21003    ss31004    ss41005    ss51006    ss61007    ss71008    ss81009    ss91010    ss101011    ss111012    ss121013    ss131014    ss141015    ss151016    ss16</code></pre><p>(2) 创建分桶表</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> stu_buck<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token keyword">into</span> <span class="token number">4</span> buckets <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 查看表结构</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> formatted stu_buck<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>Num Buckets: <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(4) 导入数据到分桶表中</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_buck<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(5)查看创建的分桶表中是否分成 4 个桶</p><p><img src="6-2.png" alt></p><p>发现并没有分成 4 个桶。</p><ol start="2"><li>创建分桶表时，数据通过子查询的方式导入</li></ol><p>(1) 先建一个普通的 stu 表</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> stu<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 向普通的 stu 表中导入数据</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 清空 stu_buck 表中数据</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">truncate</span> <span class="token keyword">table</span> stu_buck<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4) 导入数据到分桶表，通过子查询的方式</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_buck <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> stu<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="6-3.png" alt></p><p>仍然是一个分区</p><p>(5) 需要设置一个属性</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_buck<span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> stu<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="6-4.png" alt></p><p>(6) 查询分桶的数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> stu_buck<span class="token punctuation">;</span>——<span class="token operator">></span>OKstu_buck<span class="token punctuation">.</span>id stu_buck<span class="token punctuation">.</span>name<span class="token number">1004</span> ss4<span class="token number">1008</span> ss8<span class="token number">1012</span> ss12<span class="token number">1016</span> ss16<span class="token number">1001</span> ss1<span class="token number">1005</span> ss5<span class="token number">1009</span> ss9<span class="token number">1013</span> ss13<span class="token number">1002</span> ss2<span class="token number">1006</span> ss6<span class="token number">1010</span> ss10<span class="token number">1014</span> ss14<span class="token number">1003</span> ss3<span class="token number">1007</span> ss7<span class="token number">1011</span> ss11<span class="token number">1015</span> ss15<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="分桶抽样查询"><a href="#分桶抽样查询" class="headerlink" title="分桶抽样查询"></a>分桶抽样查询</h4><p>对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive 可以通过对表进行抽样来满足这个需求。</p><p>查询表 stu_buck 中的数据。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> stu_buck tablesample<span class="token punctuation">(</span>bucket <span class="token number">1</span> <span class="token keyword">out</span> <span class="token keyword">of</span> <span class="token number">4</span> <span class="token keyword">on</span> id<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>tablesample 是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y)</p><p>y 必须是 table 总 bucket 数的倍数或者因子。hive 根据 y 的大小，决定抽样的比例。例如，table 总共分了 4 份，当 y=2 时，抽取 2(4/2) 个 bucket 的数据，当 y=8 时，抽取(4/8=)1/2 个 bucket 的数据。</p><p>x 表示从哪个 bucket 开始抽取，如果需要取多个分区，以后的分区号为当前分区号加上 y。例如，table 总 bucket 数为 4，tablesample(bucket 1 out of 2)，表示总共抽取(4/2=)2 个 bucket 的数据，抽取第 1(x)个和第 3(x+y)个 bucket 的数据。</p><p><strong>注：</strong>x 的值必须小于等于 y 的值，否则</p><pre><code>FAILED: SemanticException [Error 10061]: Numerator should not be bigger than denominator in sample clause for table stu_buck</code></pre><h3 id="其他常用查询函数"><a href="#其他常用查询函数" class="headerlink" title="其他常用查询函数"></a>其他常用查询函数</h3><h4 id="空字段赋值"><a href="#空字段赋值" class="headerlink" title="空字段赋值"></a>空字段赋值</h4><ol><li>函数说明</li></ol><p>NVL：给值为 NULL 的数据赋值，它的格式是 NVL(string1,replace_with)。它的功能是如果 string1 为 NULL，则 NVL 函数返回 replace_with 的值，否则返回 string1 的值，如果两个参数都为 NULL ，则返回 NULL。</p><ol start="2"><li><p>数据准备：采用员工表</p></li><li><p>查询：如果员工的 comm 为 NULL，则用-1 代替</p></li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> nvl<span class="token punctuation">(</span>comm<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>——<span class="token operator">></span>OK_c0<span class="token number">20.0</span><span class="token number">300.0</span><span class="token number">500.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token number">1400.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token number">0.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span><span class="token number">1.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>查询：如果员工的 comm 为 NULL，则用领导 id 代替</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> nvl<span class="token punctuation">(</span>comm<span class="token punctuation">,</span>mgr<span class="token punctuation">)</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>——<span class="token operator">></span>OK_c0<span class="token number">20.0</span><span class="token number">300.0</span><span class="token number">500.0</span><span class="token number">7839.0</span><span class="token number">1400.0</span><span class="token number">7839.0</span><span class="token number">7839.0</span><span class="token number">7566.0</span><span class="token boolean">NULL</span><span class="token number">0.0</span><span class="token number">7788.0</span><span class="token number">7698.0</span><span class="token number">7566.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="CASE-WHEN"><a href="#CASE-WHEN" class="headerlink" title="CASE WHEN"></a>CASE WHEN</h4><ol><li>数据准备</li></ol><table><thead><tr><th>name</th><th>dept_id</th><th>sex</th></tr></thead><tbody><tr><td>悟空</td><td>A</td><td>男</td></tr><tr><td>大海</td><td>A</td><td>男</td></tr><tr><td>宋宋</td><td>B</td><td>男</td></tr><tr><td>凤姐</td><td>A</td><td>女</td></tr><tr><td>婷姐</td><td>B</td><td>女</td></tr><tr><td>婷婷</td><td>B</td><td>女</td></tr></tbody></table><ol start="2"><li>需求</li></ol><p>求出不同部门男女各多少人：</p><pre><code>A 2 1B 1 2</code></pre><ol start="3"><li>创建本地 emp_sex.txt，导入数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]\$ vim emp_sex.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>悟空    A       男大海    A       男宋宋    B       男凤姐    A       女婷姐    B       女婷婷    B       女</code></pre><ol start="4"><li>创建 hive 表并导入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> emp_sex<span class="token punctuation">(</span>name string<span class="token punctuation">,</span>dept_id string<span class="token punctuation">,</span>sex string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">"\t"</span><span class="token punctuation">;</span><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/emp_sex.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> emp_sex<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="5"><li>按需求查询数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">select</span>dept_id<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> sex <span class="token keyword">when</span> <span class="token string">'男'</span> <span class="token keyword">then</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">end</span><span class="token punctuation">)</span> male_count<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> sex <span class="token keyword">when</span> <span class="token string">'女'</span> <span class="token keyword">then</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">end</span><span class="token punctuation">)</span> female_count<span class="token keyword">from</span>emp_sex<span class="token keyword">group</span> <span class="token keyword">by</span>dept_id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果</p><pre><code>OKdept_id male_count      female_countA       2       1B       1       2</code></pre><h4 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h4><ol><li>相关函数说明</li></ol><p>CONCAT(string A/col, string B/col…)：返回输入字符串连接后的结果，支持任意个输入字符串;</p><p>CONCAT_WS(separator, str1, str2,…)：它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL，返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间;</p><p>COLLECT_SET(col)：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生 array 类型字段。</p><ol start="2"><li>数据准备</li></ol><table><thead><tr><th>name</th><th>constellation</th><th>blood_type</th></tr></thead><tbody><tr><td>孙悟空</td><td>白羊座</td><td>A</td></tr><tr><td>大海</td><td>射手座</td><td>A</td></tr><tr><td>大江</td><td>白羊座</td><td>B</td></tr><tr><td>猪八戒</td><td>白羊座</td><td>A</td></tr><tr><td>凤姐</td><td>射手座</td><td>A</td></tr></tbody></table><ol start="3"><li>需求</li></ol><p>把星座和血型一样的人归类到一起。结果如下：</p><pre><code>射手座,A 大海|凤姐白羊座,A 孙悟空|猪八戒白羊座,B 大江</code></pre><ol start="4"><li>创建本地 constellation.txt，导入数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]$ vim constellation.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>孙悟空  白羊座  A大海    射手座  A大江    白羊座  B猪八戒  白羊座  A凤姐    射手座  A</code></pre><ol start="5"><li>创建 hive 表并导入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> person_info<span class="token punctuation">(</span>name string<span class="token punctuation">,</span> constellation string<span class="token punctuation">,</span> blood_type string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath “<span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>constellation<span class="token punctuation">.</span>txt” <span class="token keyword">into</span> <span class="token keyword">table</span> person_info<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="6"><li>按需求查询数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span>              <span class="token operator">></span> <span class="token number">a</span><span class="token punctuation">.</span>info<span class="token punctuation">,</span>              <span class="token operator">></span> CONCAT_WS<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">,</span> collect_set<span class="token punctuation">(</span><span class="token number">a</span><span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>              <span class="token operator">></span> <span class="token keyword">from</span> <span class="token punctuation">(</span>              <span class="token operator">></span> <span class="token keyword">select</span> name<span class="token punctuation">,</span> concat_ws<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> constellation<span class="token punctuation">,</span> blood_type<span class="token punctuation">)</span> info <span class="token keyword">from</span> person_info              <span class="token operator">></span> <span class="token punctuation">)</span> <span class="token number">a</span>              <span class="token operator">></span> <span class="token keyword">group</span> <span class="token keyword">by</span> <span class="token number">a</span><span class="token punctuation">.</span>info<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h4><ol><li>函数说明</li></ol><p>EXPLODE(col)：将 hive 一列中复杂的 array 或者 map 结构拆分成多行。</p><p>LATERAL VIEW(侧写)</p><p>用法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias</p><p>解释：用于和 split, explode 等 UDTF 一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</p><ol start="2"><li>数据准备</li></ol><table><thead><tr><th>movie</th><th>category</th></tr></thead><tbody><tr><td>《疑犯追踪》</td><td>悬疑,动作,科幻,剧情</td></tr><tr><td>《Lie to me》</td><td>悬疑,警匪,动作,心理,剧情</td></tr><tr><td>《战狼 2》</td><td>战争,动作,灾难</td></tr></tbody></table><ol start="3"><li>需求</li></ol><p>将电影分类中的数组数据展开。结果如下：</p><pre><code>《疑犯追踪》 悬疑《疑犯追踪》 动作《疑犯追踪》 科幻《疑犯追踪》 剧情《Lie to me》 悬疑《Lie to me》 警匪《Lie to me》 动作《Lie to me》 心理《Lie to me》 剧情《战狼 2》 战争《战狼 2》 动作《战狼 2》 灾难</code></pre><ol start="4"><li>创建本地 movie.txt，导入数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]$ vim movie.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>《疑犯追踪》 悬疑,动作,科幻,剧情《Lie to me》 悬疑,警匪,动作,心理,剧情《战狼 2》 战争,动作,灾难</code></pre><ol start="5"><li>创建 hive 表并导入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> movie_info<span class="token punctuation">(</span>              <span class="token operator">></span> movie string<span class="token punctuation">,</span>              <span class="token operator">></span> category array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>              <span class="token operator">></span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">"\t"</span>              <span class="token operator">></span> collection items <span class="token keyword">terminated by</span> <span class="token string">","</span><span class="token punctuation">;</span><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/datas/movie.txt"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> movie_info<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li>按需求查询数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span>              <span class="token operator">></span> movie<span class="token punctuation">,</span>              <span class="token operator">></span> category_name              <span class="token operator">></span> <span class="token keyword">from</span>              <span class="token operator">></span> movie_info lateral <span class="token keyword">view</span> explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> table_tmp <span class="token keyword">as</span> category_name<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h4><ol><li>相关函数说明</li></ol><p>OVER()：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变而变化</p><p>CURRENT ROW：当前行</p><p>n PRECEDING：往前 n 行数据</p><p>n FOLLOWING：往后 n 行数据</p><p>UNBOUNDED：起点，UNBOUNDED PRECEDING 表示从前面的起点， UNBOUNDED FOLLOWING 表示到后面的终点</p><p>LAG(col,n)：往前第 n 行数据</p><p>LEAD(col,n)：往后第 n 行数据</p><p>NTILE(n)：把有序分区中的行分发到指定数据的组中，各个组有编号，编号从 1 开始，对于每一行，NTILE 返回此行所属的组的编号。注意：n 必须为 int 类型。</p><ol start="2"><li>数据准备：</li></ol><p>name,orderdate,cost</p><pre><code>jack,2017-01-01,10tony,2017-01-02,15jack,2017-02-03,23tony,2017-01-04,29jack,2017-01-05,46jack,2017-04-06,42tony,2017-01-07,50jack,2017-01-08,55mart,2017-04-08,62mart,2017-04-09,68neil,2017-05-10,12mart,2017-04-11,75neil,2017-06-12,80mart,2017-04-13,94</code></pre><ol start="3"><li>需求</li></ol><p>(1)查询在 2017 年 4 月份购买过的顾客及总人数</p><p>(2)查询顾客的购买明细及月购买总额</p><p>(3)上述的场景,要将 cost 按照日期进行累加</p><p>(4)查询顾客上次的购买时间</p><p>(5)查询前 20%时间的订单信息</p><ol start="4"><li>创建本地 business.txt，导入数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]$ vim business.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>创建 hive 表并导入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> business<span class="token punctuation">(</span>              <span class="token operator">></span> name string<span class="token punctuation">,</span>              <span class="token operator">></span> orderdate string<span class="token punctuation">,</span>              <span class="token operator">></span> cost <span class="token keyword">int</span>              <span class="token operator">></span> <span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED BY</span> <span class="token string">','</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/datas/business.txt"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> business<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li>按需求查询数据</li></ol><p>(1) 查询在 2017 年 4 月份购买过的顾客及总人数</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> name<span class="token punctuation">,</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">over</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token operator">></span> <span class="token keyword">from</span> business              <span class="token operator">></span> <span class="token keyword">where</span> substring<span class="token punctuation">(</span>orderdate<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token string">'2017-04'</span>              <span class="token operator">></span> <span class="token keyword">group</span> <span class="token keyword">by</span> name<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>select name, orderdate, cost, sum(cost) over() from business;</p><p>(2) 查询顾客的购买明细及月购买总额</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> name<span class="token punctuation">,</span>orderdate<span class="token punctuation">,</span>cost<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> month<span class="token punctuation">(</span>orderdate<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">from</span>              <span class="token operator">></span> business<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(3) 上述的场景,要将 cost 按照日期进行累加</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span>sort <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">UNBOUNDED</span> <span class="token keyword">PRECEDING</span> <span class="token operator">and</span> <span class="token keyword">CURRENT</span> <span class="token keyword">ROW</span><span class="token punctuation">)</span> <span class="token keyword">from</span> business<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>补充</strong></p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sample1<span class="token punctuation">,</span><span class="token comment" spellcheck="true">--所有行相加</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name<span class="token punctuation">)</span> <span class="token keyword">as</span> sample2<span class="token punctuation">,</span><span class="token comment" spellcheck="true">--按 name 分组，组内数据相加</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate<span class="token punctuation">)</span> <span class="token keyword">as</span> sample3<span class="token punctuation">,</span><span class="token comment" spellcheck="true">--按 name 分组，组内数据累加</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">UNBOUNDED</span> <span class="token keyword">PRECEDING</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> sample4 <span class="token punctuation">,</span><span class="token comment" spellcheck="true">--和 sample3 一样,由起点到当前行的聚合</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token number">1</span> <span class="token keyword">PRECEDING</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sample5<span class="token punctuation">,</span> <span class="token comment" spellcheck="true">--当前行和前面一行做聚合</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token number">1</span> <span class="token keyword">PRECEDING</span> <span class="token operator">AND</span> <span class="token number">1</span> <span class="token keyword">FOLLOWING</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> sample6<span class="token punctuation">,</span><span class="token comment" spellcheck="true">--当前行和前边一行及后面一行</span><span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">current</span> <span class="token keyword">row</span> <span class="token operator">and</span> <span class="token keyword">UNBOUNDED</span> <span class="token keyword">FOLLOWING</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> sample7 <span class="token comment" spellcheck="true">--当前行及后面所有行</span><span class="token keyword">from</span> business<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(4) 查看顾客上次的购买时间</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span> lag<span class="token punctuation">(</span>orderdate<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate<span class="token punctuation">)</span> <span class="token keyword">from</span> business<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(5) 查询前 20% 时间的订单信息</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token punctuation">(</span>              <span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span> ntile<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">order</span> <span class="token keyword">by</span> orderdate<span class="token punctuation">)</span> <span class="token keyword">as</span> gid <span class="token keyword">from</span> business<span class="token punctuation">)</span><span class="token number">a</span>              <span class="token operator">></span> <span class="token keyword">where</span> <span class="token number">a</span><span class="token punctuation">.</span>gid <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="Rank"><a href="#Rank" class="headerlink" title="Rank"></a>Rank</h4><ol><li>函数说明</li></ol><p>RANK() 排序相同时会重复，总数不会变</p><p>DENSE_RANK() 排序相同时会重复，总数会减少</p><p>ROW_NUMBER() 会根据顺序计算</p><ol start="2"><li>数据准备</li></ol><table><thead><tr><th>name</th><th>subject</th><th>score</th></tr></thead><tbody><tr><td>孙悟空</td><td>语文</td><td>87</td></tr><tr><td>孙悟空</td><td>数学</td><td>95</td></tr><tr><td>孙悟空</td><td>英语</td><td>68</td></tr><tr><td>大海</td><td>语文</td><td>94</td></tr><tr><td>大海</td><td>数学</td><td>56</td></tr><tr><td>大海</td><td>英语</td><td>84</td></tr><tr><td>小江</td><td>语文</td><td>64</td></tr><tr><td>小江</td><td>数学</td><td>86</td></tr><tr><td>小江</td><td>英语</td><td>84</td></tr><tr><td>婷婷</td><td>语文</td><td>65</td></tr><tr><td>婷婷</td><td>数学</td><td>85</td></tr><tr><td>婷婷</td><td>英语</td><td>78</td></tr></tbody></table><ol start="3"><li>需求</li></ol><p>计算每门学科成绩排名。</p><p>select *, rank(score) from scores group by subject;</p><ol start="4"><li>创建本地 score.txt，导入数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]$ vim score.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>创建 hive 表并导入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> scores<span class="token punctuation">(</span>              <span class="token operator">></span> name string<span class="token punctuation">,</span>              <span class="token operator">></span> subject string<span class="token punctuation">,</span>              <span class="token operator">></span> score <span class="token keyword">int</span><span class="token punctuation">)</span>              <span class="token operator">></span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">"\t"</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> scores<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li>按需求查询数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">select</span> name<span class="token punctuation">,</span>subject<span class="token punctuation">,</span>score<span class="token punctuation">,</span>rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> subject <span class="token keyword">order</span> <span class="token keyword">by</span> score <span class="token keyword">desc</span><span class="token punctuation">)</span> rp<span class="token punctuation">,</span>dense_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> subject <span class="token keyword">order</span> <span class="token keyword">by</span> score <span class="token keyword">desc</span><span class="token punctuation">)</span> drp<span class="token punctuation">,</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> subject <span class="token keyword">order</span> <span class="token keyword">by</span> score <span class="token keyword">desc</span><span class="token punctuation">)</span> rmp<span class="token keyword">from</span> scores<span class="token punctuation">;</span>——<span class="token operator">></span>name subject score rp drp rmp孙悟空 数学 <span class="token number">95</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span>宋宋 数学 <span class="token number">86</span> <span class="token number">2</span> <span class="token number">2</span> <span class="token number">2</span>婷婷 数学 <span class="token number">85</span> <span class="token number">3</span> <span class="token number">3</span> <span class="token number">3</span>大海 数学 <span class="token number">56</span> <span class="token number">4</span> <span class="token number">4</span> <span class="token number">4</span>宋宋 英语 <span class="token number">84</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span>大海 英语 <span class="token number">84</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">2</span>婷婷 英语 <span class="token number">78</span> <span class="token number">3</span> <span class="token number">2</span> <span class="token number">3</span>孙悟空 英语 <span class="token number">68</span> <span class="token number">4</span> <span class="token number">3</span> <span class="token number">4</span>大海 语文 <span class="token number">94</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span>孙悟空 语文 <span class="token number">87</span> <span class="token number">2</span> <span class="token number">2</span> <span class="token number">2</span>婷婷 语文 <span class="token number">65</span> <span class="token number">3</span> <span class="token number">3</span> <span class="token number">3</span>宋宋 语文 <span class="token number">64</span> <span class="token number">4</span> <span class="token number">4</span> <span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive DML数据操作</title>
      <link href="2020/11/23/hive-dml-shu-ju-cao-zuo/"/>
      <url>2020/11/23/hive-dml-shu-ju-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="DML-数据操作"><a href="#DML-数据操作" class="headerlink" title="DML 数据操作"></a>DML 数据操作</h2><h3 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h3><h4 id="向表中装载数据-Load"><a href="#向表中装载数据-Load" class="headerlink" title="向表中装载数据(Load)"></a>向表中装载数据(Load)</h4><ol><li>语法</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token punctuation">[</span><span class="token keyword">local</span><span class="token punctuation">]</span> inpath <span class="token string">'/opt/module/datas/student.txt'</span> overwrite <span class="token operator">|</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student <span class="token punctuation">[</span><span class="token keyword">partition</span> <span class="token punctuation">(</span>partcol1<span class="token operator">=</span>val1<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(1) load data:表示加载数据</p><p>(2) local:表示从本地加载数据到 hive 表；否则从 HDFS 加载数据到 hive 表</p><p>(3) inpath:表示加载数据的路径</p><p>(4) overwrite:表示覆盖表中已有数据，否则表示追加</p><p>(5) into table:表示加载到哪张表</p><p>(6) student:表示具体的表</p><p>(7) partition:表示上传到指定分区</p><ol start="2"><li>实操案例</li></ol><p>(0) 创建一张表</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>id string<span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(1) 加载本地文件到 hive</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 加载 HDFS 文件到 hive 中</p><p>上传文件到 HDFS</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>student<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>user_test<span class="token operator">/</span>hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载 HDFS 上数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/user/user_test/hive/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 加载数据覆盖表中已有的数据</p><p>上传文件到 HDFS</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>student<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>user_test<span class="token operator">/</span>hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载数据覆盖表中已有的数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/user/user_test/hive/student.txt'</span> overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="通过查询语句向表中插入数据-Insert"><a href="#通过查询语句向表中插入数据-Insert" class="headerlink" title="通过查询语句向表中插入数据(Insert)"></a>通过查询语句向表中插入数据(Insert)</h4><ol><li>创建一张分区表</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>month string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>基本插入数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">)</span> <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'wangwu'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>基本模式插入(根据单张表查询结果)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student <span class="token keyword">partition</span> <span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202008'</span><span class="token punctuation">)</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> student <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>多插入模式(根据多张表查询结果)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">from</span> student               <span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202007'</span><span class="token punctuation">)</span>               <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span>               <span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202006'</span><span class="token punctuation">)</span>               <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="查询语句中创建表并加载数据-As-Select"><a href="#查询语句中创建表并加载数据-As-Select" class="headerlink" title="查询语句中创建表并加载数据(As Select)"></a>查询语句中创建表并加载数据(As Select)</h4><p>详见上面创建表部分。</p><p>根据查询结果创建表(查询的结果会添加到新创建的表中)</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student3<span class="token keyword">as</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="创建表时通过-Location-指定加载数据路径"><a href="#创建表时通过-Location-指定加载数据路径" class="headerlink" title="创建表时通过 Location 指定加载数据路径"></a>创建表时通过 Location 指定加载数据路径</h4><ol start="5"><li>创建表，并指定在 hdfs 上的位置</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student5<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>location <span class="token string">'/user/hive/warehouse/student5'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li>上传数据到 hdfs 上</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>student<span class="token punctuation">.</span>txt<span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>student5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="7"><li>查询数据</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Import-数据到指定-Hive-表中"><a href="#Import-数据到指定-Hive-表中" class="headerlink" title="Import 数据到指定 Hive 表中"></a>Import 数据到指定 Hive 表中</h4><p><strong>注：</strong>先用 export 导出后，再将数据导入。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">import</span> <span class="token keyword">table</span> student2 <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">)</span> <span class="token keyword">from</span><span class="token string">'/user/hive/warehouse/export/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h3><h4 id="Insert-导出"><a href="#Insert-导出" class="headerlink" title="Insert 导出"></a>Insert 导出</h4><ol><li>将查询的结果导出到本地</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/datas/export/student'</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="2"><li>将查询的结果格式化导出到本地</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/datas/export/student1'</span><span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED BY</span> <span class="token string">'\t'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="3"><li>将查询的结果导出到 HDFS 上(没有 local)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">insert</span> overwrite directory <span class="token string">'/user/atguigu/student2'</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED BY</span> <span class="token string">'\t'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Hadoop-命令导出到本地"><a href="#Hadoop-命令导出到本地" class="headerlink" title="Hadoop 命令导出到本地"></a>Hadoop 命令导出到本地</h4><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>get <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>student<span class="token operator">/</span>month<span class="token operator">=</span><span class="token number">202009</span><span class="token operator">/</span>000000_0 <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>export<span class="token operator">/</span>student3<span class="token punctuation">.</span>txt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Hive-Shell-命令导出"><a href="#Hive-Shell-命令导出" class="headerlink" title="Hive Shell 命令导出"></a>Hive Shell 命令导出</h4><p>基本语法：(hive -f/-e 执行语句或者脚本 &gt; file)</p><pre class="line-numbers language-shell"><code class="language-shell">[atguigu@hadoop102 hive]\$ bin/hive -e 'select * from default.student;' > /opt/module/datas/export/student4.txt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Export-导出到-HDFS-上"><a href="#Export-导出到-HDFS-上" class="headerlink" title="Export 导出到 HDFS 上"></a>Export 导出到 HDFS 上</h4><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> export <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student <span class="token keyword">to</span><span class="token string">'/user/hive/warehouse/export/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="清除表中数据-Truncate"><a href="#清除表中数据-Truncate" class="headerlink" title="清除表中数据(Truncate)"></a>清除表中数据(Truncate)</h3><p><strong>注：</strong>Truncate 只能删除管理表，不能删除外部表中数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">truncate</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive DDL数据定义</title>
      <link href="2020/11/18/hive-ddl-shu-ju-ding-yi/"/>
      <url>2020/11/18/hive-ddl-shu-ju-ding-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="DDL-数据定义"><a href="#DDL-数据定义" class="headerlink" title="DDL 数据定义"></a>DDL 数据定义</h2><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><ol><li>创建一个数据库，数据库在 HDFS 上的默认存储路径是/user/hive/warehouse</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">database</span> db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>避免要创建的数据库已经存在错误，增加 if not exists 判断。(标准写法)</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">database</span> db_hive<span class="token punctuation">;</span>——<span class="token operator">></span>FAILED: Execution Error<span class="token punctuation">,</span> <span class="token keyword">return</span> code <span class="token number">1</span> <span class="token keyword">from</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>DDLTask<span class="token punctuation">.</span> <span class="token keyword">Database</span> db_hive already <span class="token keyword">exists</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">database</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>创建一个数据库，指定数据库在 HDFS 上存放的位置</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">database</span> db_hive2 location <span class="token string">'/db_hive2.db'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="4-1.png" alt></p><h3 id="查询数据库"><a href="#查询数据库" class="headerlink" title="查询数据库"></a>查询数据库</h3><h4 id="显示数据库"><a href="#显示数据库" class="headerlink" title="显示数据库"></a>显示数据库</h4><ol><li>显示数据库</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>——<span class="token operator">></span>OKdatabase_namedb_hivedb_hive2<span class="token keyword">default</span>Time taken: <span class="token number">0.04</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">3</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>过滤显示查询的数据库</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">databases</span> <span class="token operator">like</span> <span class="token string">'db_hive\*'</span><span class="token punctuation">;</span>——<span class="token operator">></span>OKdb_hivedb_hive_2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="查看数据库详情"><a href="#查看数据库详情" class="headerlink" title="查看数据库详情"></a>查看数据库详情</h4><ol><li>显示数据库信息</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> <span class="token keyword">database</span> db_hive<span class="token punctuation">;</span>——<span class="token operator">></span>OKdb_name <span class="token keyword">comment</span> location        owner_name      owner_type      parametersdb_hive         hdfs:<span class="token comment" spellcheck="true">//hadoop102:9000/user/hive/warehouse/db_hive.db    user_test  USER</span>Time taken: <span class="token number">0.075</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">1</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>显示数据库详细信息——extended</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> <span class="token keyword">database</span> <span class="token keyword">extended</span> db_hive<span class="token punctuation">;</span>——<span class="token operator">></span>OKdb_name <span class="token keyword">comment</span> location        owner_name      owner_type      parametersdb_hive         hdfs:<span class="token comment" spellcheck="true">//hadoop102:9000/user/hive/warehouse/db_hive.db    user_test  USER</span>Time taken: <span class="token number">0.086</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">1</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="切换当前数据库"><a href="#切换当前数据库" class="headerlink" title="切换当前数据库"></a>切换当前数据库</h4><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">use</span> db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h3><p>用户可以使用 ALTER DATABASE 命令为某个数据库的 DBPROPERTIES 设置键-值对属性值，来描述这个数据库的属性信息。数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置。</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">database</span> db_hive <span class="token keyword">set</span> dbproperties<span class="token punctuation">(</span><span class="token string">'createtime'</span><span class="token operator">=</span><span class="token string">'20201111'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 hive 中查看修改结果</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span>db_hive<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> <span class="token keyword">database</span> <span class="token keyword">extended</span> db_hive<span class="token punctuation">;</span>——<span class="token operator">></span>OKdb_name <span class="token keyword">comment</span> location        owner_name      owner_type      parametersdb_hive         hdfs:<span class="token comment" spellcheck="true">//hadoop102:9000/user/hive/warehouse/db_hive.db    user_test     USER    {createtime=20201111}</span>Time taken: <span class="token number">0.152</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">1</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><ol><li>删除空数据库</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span>db_hive<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">database</span> db_hive2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>如果删除的数据库不存在，最好采用 if exists 判断数据库是否存在</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span>db_hive<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">database</span> db_hive<span class="token punctuation">;</span>——<span class="token operator">></span>FAILED: SemanticException <span class="token punctuation">[</span>Error <span class="token number">10072</span><span class="token punctuation">]</span>: <span class="token keyword">Database</span> does <span class="token operator">not</span> exist: db_hivehive<span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">database</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> db_hive2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>如果数据库不为空，可以采用 cascade 命令，强制删除</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span>db_hive<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">database</span> db_hive<span class="token punctuation">;</span>——<span class="token operator">></span>FAILED: Execution Error<span class="token punctuation">,</span> <span class="token keyword">return</span> code <span class="token number">1</span> <span class="token keyword">from</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>DDLTask<span class="token punctuation">.</span> InvalidOperationException<span class="token punctuation">(</span>message:<span class="token keyword">Database</span> db_hive <span class="token operator">is</span> <span class="token operator">not</span> empty<span class="token punctuation">.</span> One <span class="token operator">or</span> more <span class="token keyword">tables</span> exist<span class="token punctuation">.</span><span class="token punctuation">)</span>hive<span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">database</span> db_hive <span class="token keyword">cascade</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><ol><li>建表语法</li></ol><pre><code>CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name[(col_name data_type [COMMENT col_comment], ...)][COMMENT table_comment][PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)][CLUSTERED BY (col_name, col_name, ...)[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS][ROW FORMAT row_format][STORED AS file_format][LOCATION hdfs_path]</code></pre><ol start="2"><li>字段解释说明</li></ol><p>(1) CREATE TABLE：创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；可以用 IF NOT EXISTS 选项来忽略这个异常。</p><p>(2) EXTERNAL：关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径(LOCATION)，Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p><p>(3) COMMENT：为表和列添加注释。</p><p>(4)PARTITIONED BY：创建分区表</p><p>(5) CLUSTERED BY：创建分桶表</p><p>(6) SORTED BY：不常用</p><p><strong>order by | sort by | distribute by</strong></p><p>在 hive 中都有排序和聚集的作用，然而，它们在执行时所启动的 MR 却各不相同。</p><p>order by：会对所给的全部数据进行全局排序，并且只会“叫醒”一个 reducer 干活。它就像一个糊涂蛋一样，不管来多少数据，都只启动一个 reducer 来处理。因此，数据量小还可以，但数据量一旦变大 order by 就会变得异常吃力，甚至“罢工”。</p><p>sort by：是局部排序。相比 order by 的懒惰糊涂，sort by 正好相反，它不但非常勤快，而且具备分身功能。sort by 会根据数据量的大小启动一到多个 reducer 来干活，并且，它会在进入 reduce 之前为每个 reducer 都产生一个排序文件。这样的好处是提高了全局排序的效率。</p><p>distribute by：控制 map 结果的分发，它会将具有相同字段的 map 输出分发到一个 reduce 节点上做处理。即就是，某种情况下，我们需要控制某个特定行到某个 reducer 中，这种操作一般是为后续可能发生的聚集操作做准备。</p><p>(7) ROW FORMAT</p><pre><code>DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char][MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]| SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</code></pre><p>用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive 通过 SerDe 确定表的具体的列的数据。</p><p>SerDe 是 Serialize/Deserilize 的简称，目的是用于序列化和反序列化。</p><p>(8) STORED AS 指定存储文件类型</p><p>常用的存储文件类型：SEQUENCEFILE(二进制序列文件)、TEXTFILE(文本)、RCFILE(列式存储格式文件)。如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p><p>(9) LOCATION ：指定表在 HDFS 上的存储位置。</p><p>(10) LIKE 允许用户复制现有的表结构，但是不复制数据。</p><h4 id="管理表"><a href="#管理表" class="headerlink" title="管理表"></a>管理表</h4><ol><li>理论</li></ol><p>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive 会(或多或少地)控制着数据的生命周期。Hive 默认情况下会将这些表的数据存储在由配置项 hive.metastore.warehouse.dir (例如，/user/hive/warehouse) 所定义的目录的子目录下。当我们删除一个管理表时，Hive 也会删除这个表中数据。管理表不适合和其他工具共享数据。</p><ol start="2"><li>案例实操</li></ol><p>(1) 普通创建表</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student2<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>stored <span class="token keyword">as</span> textfilelocation <span class="token string">'/user/hive/warehouse/student2'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(2) 根据查询结果创建表(查询的结果会添加到新创建的表中)</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student3 <span class="token keyword">as</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 根据已经存在的表结构创建表</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student4 <span class="token operator">like</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4) 查询表的类型</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">Table</span> <span class="token keyword">Type</span>: MANAGED_TABLE<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h4><ol><li>理论</li></ol><p>因为表是外部表，所以 Hive 并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。</p><ol start="2"><li>管理表和外部表的使用场景</li></ol><p>每天将收集到的网站日志定期流入 HDFS 文本文件。在外部表(原始日志表)的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过 SELECT+INSERT 进入内部表。</p><ol start="3"><li>案例实操</li></ol><p>分别创建部门和员工外部表，并向表中导入数据。</p><p>(1) 原始数据</p><p>[dept.txt]</p><pre><code>10    ACCOUNTING    170020    RESEARCH    180030    SALES    190040    OPERATIONS    1700</code></pre><p>[emp.txt]</p><pre><code>7369    SMITH    CLERK    7902    1980-12-17    800.00        207499    ALLEN    SALESMAN    7698    1981-2-20    1600.00    300.00    307521    WARD    SALESMAN    7698    1981-2-22    1250.00    500.00    307566    JONES    MANAGER    7839    1981-4-2    2975.00        207654    MARTIN    SALESMAN    7698    1981-9-28    1250.00    1400.00    307698    BLAKE    MANAGER    7839    1981-5-1    2850.00        307782    CLARK    MANAGER    7839    1981-6-9    2450.00        107788    SCOTT    ANALYST    7566    1987-4-19    3000.00        207839    KING    PRESIDENT        1981-11-17    5000.00        107844    TURNER    SALESMAN    7698    1981-9-8    1500.00    0.00    307876    ADAMS    CLERK    7788    1987-5-23    1100.00        207900    JAMES    CLERK    7698    1981-12-3    950.00        307902    FORD    ANALYST    7566    1981-12-3    3000.00        207934    MILLER    CLERK    7782    1982-1-23    1300.00        10</code></pre><p>(2) 建表语句</p><p>创建部门表</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> <span class="token keyword">default</span><span class="token punctuation">.</span>dept<span class="token punctuation">(</span>deptno <span class="token keyword">int</span><span class="token punctuation">,</span>dname string<span class="token punctuation">,</span>loc <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建员工表</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> <span class="token keyword">default</span><span class="token punctuation">.</span>emp<span class="token punctuation">(</span>empno <span class="token keyword">int</span><span class="token punctuation">,</span>ename string<span class="token punctuation">,</span>job string<span class="token punctuation">,</span>mgr <span class="token keyword">int</span><span class="token punctuation">,</span>hiredate string<span class="token punctuation">,</span>sal <span class="token keyword">double</span><span class="token punctuation">,</span>comm <span class="token keyword">double</span><span class="token punctuation">,</span>deptno <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(3) 查看创建的表</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>——<span class="token operator">></span>OKtab_namedeptemp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(4) 向外部表中导入数据</p><p>导入数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/dept.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>dept<span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/emp.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查询结果</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(5) 查看表格式化数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> formatted dept<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">Table</span> <span class="token keyword">Type</span>: EXTERNAL_TABLE<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="管理表与外部表的互相转换"><a href="#管理表与外部表的互相转换" class="headerlink" title="管理表与外部表的互相转换"></a>管理表与外部表的互相转换</h4><p>(1) 查询表的类型</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">Table</span> <span class="token keyword">Type</span>: MANAGED_TABLE<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(2) 修改内部表 student2 为外部表</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'TRUE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 查询表的类型</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">Table</span> <span class="token keyword">Type</span>: EXTERNAL_TABLE<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(4) 修改外部表 student2 为内部表</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'FALSE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(5) 查询表的类型</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">Table</span> <span class="token keyword">Type</span>: MANAGED_TABLE<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：</strong>(‘EXTERNAL’=’TRUE’)和(‘EXTERNAL’=’FALSE’)为固定写法，区分大小写！</p><h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><p>分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p><h4 id="分区表基本操作"><a href="#分区表基本操作" class="headerlink" title="分区表基本操作"></a>分区表基本操作</h4><ol><li>引入分区表(需要根据日期对日志进行管理)</li></ol><pre><code>/user/hive/warehouse/log_partition/20170702/20170702.log/user/hive/warehouse/log_partition/20170703/20170703.log/user/hive/warehouse/log_partition/20170704/20170704.log</code></pre><ol start="2"><li>创建分区表语法</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition<span class="token punctuation">(</span>deptno <span class="token keyword">int</span><span class="token punctuation">,</span> dname string<span class="token punctuation">,</span> loc string<span class="token punctuation">)</span>partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>month string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>加载数据到分区表中</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/dept.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/dept.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202010'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/dept.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span>'<span class="token number">202011</span>’<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="4-2.png" alt></p><p><img src="4-3.png" alt></p><ol start="4"><li>查询分区表中数据</li></ol><p>单分区查询</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>多分区联合查询</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token keyword">union</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202010'</span><span class="token keyword">union</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202011'</span><span class="token punctuation">;</span>——<span class="token operator">></span>_u3<span class="token punctuation">.</span>deptno      _u3<span class="token punctuation">.</span>dname       _u3<span class="token punctuation">.</span>loc _u3<span class="token punctuation">.</span>month<span class="token number">10</span>      ACCOUNTING      <span class="token number">1700</span>    <span class="token number">202009</span><span class="token number">10</span>      ACCOUNTING      <span class="token number">1700</span>    <span class="token number">202010</span><span class="token number">10</span>      ACCOUNTING      <span class="token number">1700</span>    <span class="token number">202011</span><span class="token number">20</span>      RESEARCH        <span class="token number">1800</span>    <span class="token number">202009</span><span class="token number">20</span>      RESEARCH        <span class="token number">1800</span>    <span class="token number">202010</span><span class="token number">20</span>      RESEARCH        <span class="token number">1800</span>    <span class="token number">202011</span><span class="token number">30</span>      SALES   <span class="token number">1900</span>    <span class="token number">202009</span><span class="token number">30</span>      SALES   <span class="token number">1900</span>    <span class="token number">202010</span><span class="token number">30</span>      SALES   <span class="token number">1900</span>    <span class="token number">202011</span><span class="token number">40</span>      OPERATIONS      <span class="token number">1700</span>    <span class="token number">202009</span><span class="token number">40</span>      OPERATIONS      <span class="token number">1700</span>    <span class="token number">202010</span><span class="token number">40</span>      OPERATIONS      <span class="token number">1700</span>    <span class="token number">202011</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>增加分区</li></ol><p>创建单个分区</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202008'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时创建多个分区</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202007'</span><span class="token punctuation">)</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202006'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>删除分区</li></ol><p>删除单个分区</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202008'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时删除多个分区</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202007'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202006'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="7"><li>查看分区表有多少分区</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> partitions dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="8"><li>查看分区表结构</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> formatted dept_partition<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token comment" spellcheck="true"># Partition Information</span><span class="token comment" spellcheck="true"># col_name  data_type   comment</span>month string<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="分区表注意事项"><a href="#分区表注意事项" class="headerlink" title="分区表注意事项"></a>分区表注意事项</h4><ol><li>创建二级分区表</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition2<span class="token punctuation">(</span>deptno <span class="token keyword">int</span><span class="token punctuation">,</span> dname string<span class="token punctuation">,</span> loc string<span class="token punctuation">)</span>partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>month string<span class="token punctuation">,</span> day string<span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>正常的加载数据</li></ol><p>(1) 加载数据到二级分区表中</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/dept.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span><span class="token keyword">default</span><span class="token punctuation">.</span>dept_partition2 <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">,</span> day<span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(2) 查询分区数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span> <span class="token operator">and</span> day<span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式</li></ol><p>(1) 方式一：上传数据后修复</p><p>上传数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p<span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span>month<span class="token operator">=</span><span class="token number">202009</span><span class="token operator">/</span>day<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>dept<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span>month<span class="token operator">=</span><span class="token number">202009</span><span class="token operator">/</span>day<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>查询数据(查询不到刚上传的数据)</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span> <span class="token operator">and</span> day<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行修复命令</p><pre><code>hive&gt; msck repair table dept_partition2;</code></pre><p>再次查询数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span> <span class="token operator">and</span> day<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 方式二：上传数据后添加分区</p><p>上传数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span> dept_partition2<span class="token operator">/</span>month<span class="token operator">=</span><span class="token number">202009</span><span class="token operator">/</span>day<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token operator">/</span>dept<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span>month<span class="token operator">=</span><span class="token number">202009</span><span class="token operator">/</span>day<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>执行添加分区</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition2 <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">,</span>day<span class="token operator">=</span><span class="token string">'11'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查询数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span> <span class="token operator">and</span> day<span class="token operator">=</span><span class="token string">'11'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 方式三：创建文件夹后 load 数据到分区</p><p>创建目录</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse dept_partition2<span class="token operator">/</span>month<span class="token operator">=</span><span class="token number">202009</span><span class="token operator">/</span>day<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上传数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/dept.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span>dept_partition2 <span class="token keyword">partition</span><span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'202009'</span><span class="token punctuation">,</span>day<span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查询数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> month<span class="token operator">=</span><span class="token string">'202009'</span> <span class="token operator">and</span> day<span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><h4 id="重命名表"><a href="#重命名表" class="headerlink" title="重命名表"></a>重命名表</h4><ol><li>语法</li></ol><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> new_table_name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>实操案例</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition2 <span class="token keyword">rename</span> <span class="token keyword">to</span> dept_partition3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="增加、修改和删除表分区"><a href="#增加、修改和删除表分区" class="headerlink" title="增加、修改和删除表分区"></a>增加、修改和删除表分区</h4><p>详见前面分区表基本操作。</p><h4 id="增加-修改-替换列信息"><a href="#增加-修改-替换列信息" class="headerlink" title="增加/修改/替换列信息"></a>增加/修改/替换列信息</h4><ol><li>语法</li></ol><p>更新列</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name CHANGE <span class="token punctuation">[</span><span class="token keyword">COLUMN</span><span class="token punctuation">]</span> col_old_name col_new_name column_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">FIRST</span><span class="token operator">|</span><span class="token keyword">AFTER</span> column_name<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>增加和替换列</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span><span class="token operator">|</span>REPLACE <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>ADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是表示替换表中所有字段。</p><ol start="2"><li>实操案例</li></ol><p>(1)查询表结构</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)添加列</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">columns</span><span class="token punctuation">(</span>deptdesc string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3)查询表结构</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4)更新列</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition change <span class="token keyword">column</span> deptdesc <span class="token keyword">desc</span> <span class="token keyword">int</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(5)查询表结构</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(6)替换列</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition replace <span class="token keyword">columns</span><span class="token punctuation">(</span>deptno string<span class="token punctuation">,</span> dname string<span class="token punctuation">,</span> loc string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(7)查询表结构</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">table</span> dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive数据类型</title>
      <link href="2020/11/10/hive-shu-ju-lei-xing/"/>
      <url>2020/11/10/hive-shu-ju-lei-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="Hive-数据类型"><a href="#Hive-数据类型" class="headerlink" title="Hive 数据类型"></a>Hive 数据类型</h2><h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><table><thead><tr><th>Hive 数据类型</th><th>Java 数据类型</th><th>长度</th><th>例子</th></tr></thead><tbody><tr><td>TINYINT</td><td>byte</td><td>1byte 有符号整数</td><td>20</td></tr><tr><td>SMALINT</td><td>short</td><td>2byte 有符号整数</td><td>20</td></tr><tr><td>INT</td><td>int</td><td>4byte 有符号整数</td><td>20</td></tr><tr><td>BIGINT</td><td>long</td><td>8byte 有符号整数</td><td>20</td></tr><tr><td>BOOLEAN</td><td>boolean</td><td>布尔类型，true 或者 false</td><td>TRUE FALSE</td></tr><tr><td>FLOAT</td><td>float</td><td>单精度浮点数</td><td>3.14159</td></tr><tr><td>DOUBLE</td><td>double</td><td>双精度浮点数</td><td>3.14159</td></tr><tr><td>STRING</td><td>string</td><td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td><td>‘now is the time’ “for all good men”</td></tr><tr><td>TIMESTAMP</td><td></td><td>时间类型</td><td></td></tr><tr><td>BINARY</td><td></td><td>字节数组</td><td></td></tr></tbody></table><p>对于 Hive 的 String 类型相当于数据库的 varchar 类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储 2GB 的字符数。</p><h3 id="集合数据类型"><a href="#集合数据类型" class="headerlink" title="集合数据类型"></a>集合数据类型</h3><table><thead><tr><th>数据类型</th><th>描述</th><th>语法示例</th></tr></thead><tbody><tr><td>STRUCT</td><td>和 c 语言中的 struct 类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是 STRUCT{first STRING, last STRING},那么第 1 个元素可以通过字段.first 来引用。</td><td>struct()</td></tr><tr><td>MAP</td><td>MAP 是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是 MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td><td>map()</td></tr><tr><td>ARRAY</td><td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第 2 个元素可以通过数组名[1]进行引用。</td><td>Array()</td></tr></tbody></table><p>Hive 有三种复杂数据类型 ARRAY、MAP 和 STRUCT。ARRAY 和 MAP 与 Java 中的 Array 和 Map 类似，而 STRUCT 与 C 语言中的 Struct 类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p><h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><ol><li>假设某表有如下一行，我们用 JSON 格式来表示其数据结构。在 Hive 下访问的格式为</li></ol><pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"zhangsan"</span><span class="token punctuation">,</span>    <span class="token property">"friends"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"lisi"</span> <span class="token punctuation">,</span> <span class="token string">"wangwu"</span><span class="token punctuation">]</span> <span class="token punctuation">,</span>       //列表Array<span class="token punctuation">,</span>    <span class="token property">"children"</span><span class="token operator">:</span> <span class="token punctuation">{</span>                      //键值Map<span class="token punctuation">,</span>        <span class="token property">"xiao san"</span><span class="token operator">:</span> <span class="token number">18</span> <span class="token punctuation">,</span>        <span class="token property">"xiaoxiao san"</span><span class="token operator">:</span> <span class="token number">19</span>    <span class="token punctuation">}</span>    <span class="token property">"address"</span><span class="token operator">:</span> <span class="token punctuation">{</span>                      //结构Struct<span class="token punctuation">,</span>        <span class="token property">"street"</span><span class="token operator">:</span> <span class="token string">"zhong guan cun"</span> <span class="token punctuation">,</span>        <span class="token property">"city"</span><span class="token operator">:</span> <span class="token string">"beijing"</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>基于上述数据结构，我们在 Hive 里创建对应的表，并导入数据。</li></ol><p>创建本地测试文件 test.txt</p><pre><code>zhangsan,lisi_wangwu,xiao san:18_xiaoxiao san:19,zhong guan cun_beijingyangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</code></pre><p><strong>注：</strong>MAP，STRUCT 和 ARRAY 里的元素间关系都可以用同一个字符表示，这里用“_”。</p><ol start="3"><li>Hive 上创建测试表 test</li></ol><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> test<span class="token punctuation">(</span>name string<span class="token punctuation">,</span>friends array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">,</span>children map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token punctuation">,</span>address struct<span class="token operator">&lt;</span>street:string<span class="token punctuation">,</span> city:string<span class="token operator">></span><span class="token punctuation">)</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">','</span>collection items <span class="token keyword">terminated by</span> <span class="token string">'_'</span>map <span class="token keyword">keys</span> <span class="token keyword">terminated by</span> <span class="token string">':'</span><span class="token keyword">lines</span> <span class="token keyword">terminated by</span> <span class="token string">'\n'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字段解释：</p><p>row format delimited fields terminated by ‘,’ – 列分隔符</p><p>collection items terminated by ‘_‘ –MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</p><p>map keys terminated by ‘:’ – MAP 中的 key 与 value 的分隔符</p><p>lines terminated by ‘\n’; – 行分隔符(默认就是’\n’)</p><ol start="4"><li>导入文本数据到测试表</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/test.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>访问三种集合列里的数据，以下分别是 ARRAY，MAP，STRUCT 的访问方式</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> friends<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>children<span class="token punctuation">[</span><span class="token string">'xiao san'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>address<span class="token punctuation">.</span>city <span class="token keyword">from</span> test<span class="token keyword">where</span> name<span class="token operator">=</span><span class="token string">"zhang san"</span><span class="token punctuation">;</span>——<span class="token operator">></span>OK\_c0 \_c1 citywangwu <span class="token number">18</span> beijingTime taken: <span class="token number">0.076</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">1</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中 _c0 _c1 是这个列未命名。</p><p>array —— 用 [0]</p><p>map —— 用 [“字段名称”]</p><p>struct —— 用 .</p><h3 id="类型转化"><a href="#类型转化" class="headerlink" title="类型转化"></a>类型转化</h3><p>Hive 的原子数据类型是可以进行隐式转换的，类似于 Java 的类型转换，例如某表达式使用 INT 类型，TINYINT 会自动转换为 INT 类型，但是 Hive 不会进行反向转化，例如，某表达式使用 TINYINT 类型，INT 不会自动转换为 TINYINT 类型，它会返回错误，除非使用 CAST 操作。</p><ol><li>隐式类型转换规则如下</li></ol><p>(1)任何整数类型都可以隐式地转换为一个范围更广的类型，如 TINYINT 可以转换成 INT，INT 可以转换成 BIGINT。</p><p>(2)所有整数类型、FLOAT 和 STRING(必须是数值字段不能是 “aaa” 这种) 类型都可以隐式地转换成 DOUBLE。</p><p>(3)TINYINT、SMALLINT、INT 都可以转换为 FLOAT。</p><p>(4)BOOLEAN 类型不可以转换为任何其它的类型。</p><ol start="2"><li>可以使用 CAST 操作显示进行数据类型转换</li></ol><p>例如 CAST(‘1’ AS INT)将把字符串’1’ 转换成整数 1；如果强制类型转换失败，如执行 CAST(‘X’ AS INT)，表达式返回空值 NULL。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive安装配置</title>
      <link href="2020/11/06/hive-an-zhuang-pei-zhi/"/>
      <url>2020/11/06/hive-an-zhuang-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="Hive安装"><a href="#Hive安装" class="headerlink" title="Hive安装"></a>Hive安装</h2><h3 id="Hive安装地址"><a href="#Hive安装地址" class="headerlink" title="Hive安装地址"></a>Hive安装地址</h3><p>1．Hive官网地址</p><p><a href="http://hive.apache.org/" target="_blank" rel="noopener">http://hive.apache.org/</a></p><p>2．文档查看地址</p><p><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p><p>3．下载地址</p><p><a href="http://archive.apache.org/dist/hive/" target="_blank" rel="noopener">http://archive.apache.org/dist/hive/</a></p><p>4．github地址</p><p><a href="https://github.com/apache/hive" target="_blank" rel="noopener">https://github.com/apache/hive</a></p><h3 id="Hive安装部署"><a href="#Hive安装部署" class="headerlink" title="Hive安装部署"></a>Hive安装部署</h3><h4 id="Hive安装及配置"><a href="#Hive安装及配置" class="headerlink" title="Hive安装及配置"></a>Hive安装及配置</h4><ol><li><p>把 apache-hive-1.2.1-bin.tar.gz 上传到虚拟机 /opt/software 目录下</p></li><li><p>解压 apache-hive-1.2.1-bin.tar.gz 到 /opt/module/ 目录下面</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 software]$ tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>修改 apache-hive-1.2.1-bin.tar.gz的名称为hive</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 module]$ mv apache-hive-1.2.1-bin/ hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>修改 /opt/module/hive/conf 目录下的 hive-env.sh.template 名称为 hive-env.sh</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ mv hive-env.sh.template hive-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>配置 hive-env.sh 文件</li></ol><p>(1) 配置HADOOP_HOME路径</p><p>export HADOOP_HOME=/opt/module/hadoop-2.7.2</p><p>(2) 配置HIVE_CONF_DIR路径</p><p>export HIVE_CONF_DIR=/opt/module/hive/conf</p><h4 id="Hadoop集群配置"><a href="#Hadoop集群配置" class="headerlink" title="Hadoop集群配置"></a>Hadoop集群配置</h4><ol><li>必须启动hdfs和yarn</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh[user_test@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="2"><li>在HDFS上创建 /tmp 和 /user/hive/warehouse 两个目录并修改他们的同组权限可写</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -mkdir /tmp[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -mkdir -p /user/hive/warehouse[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -chmod g+w /tmp[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -chmod g+w /user/hive/warehouse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>Hive基本操作</li></ol><p>(1) 启动hive</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 查看数据库</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 打开默认数据库</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">use</span> <span class="token keyword">default</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4) 显示default数据库中的表</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(5) 创建一张表</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(6) 显示数据库中有几张表</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(7) 查看表的结构</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">desc</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(8) 向表中插入数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">insert</span> <span class="token keyword">into</span> student <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"zhangsan"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>hive<span class="token operator">></span> <span class="token keyword">insert</span> <span class="token keyword">into</span> student <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"lisi"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(9) 查询表中数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(10) 退出hive</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> quit<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="将本地文件导入Hive案例"><a href="#将本地文件导入Hive案例" class="headerlink" title="将本地文件导入Hive案例"></a>将本地文件导入Hive案例</h3><p>需求</p><p>将本地 /opt/module/datas/student.txt 这个目录下的数据导入到 hive 的 student(id int, name string)表中。</p><ol><li>数据准备</li></ol><p>在/opt/module/datas这个目录下准备数据</p><p>(1) 在/opt/module/目录下创建datas</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 module]$ mkdir datas<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）在/opt/module/datas/目录下创建student.txt文件并添加数据</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]$ touch student.txt[user_test@hadoop102 datas]$ vi student.txt——>1001    zhangsan1002    lisi1003    wangwu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意:</strong>学号和姓名中间以 tab 键间隔。</p><ol start="2"><li>Hive实际操作</li></ol><p>(1) 启动hive</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 显示数据库</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 使用 default 数据库</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">use</span> <span class="token keyword">default</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4) 显示 default 数据库中的表</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(5) 删除已创建的 student 表</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">drop</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(6) 创建 student 表, 并声明文件分隔符’\t’</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(7) 加载 /opt/module/datas/student.txt 文件到student数据库表中。</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/datas/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也可以直接加载 hdfs 的数据</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上面就是从 hdfs 文件加载数据到 hive</p><p><strong>注意：</strong>以上两种方式虽然最终结果一样，但是从本地上传后，本地的数据源文件还在；从 hdfs 上传后，根目录下不再有 student.txt 文件。其实这个过程就是修改了hdfs上文件的源信息，将其地址进行了修改。</p><p>(8) Hive查询结果</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>——<span class="token operator">></span>OK<span class="token number">1001</span>    zhangsan<span class="token number">1002</span>    lisi<span class="token number">1003</span>    wangwuTime taken: <span class="token number">0.083</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">3</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>遇到的问题</li></ol><p>再打开一个客户端窗口启动hive，会产生 java.sql.SQLException 异常。</p><pre class="line-numbers language-java"><code class="language-java">Exception in thread <span class="token string">"main"</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>RuntimeException<span class="token operator">:</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>RuntimeException<span class="token operator">:</span> Unable to instantiate org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>SessionHiveMetaStoreClient        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>session<span class="token punctuation">.</span>SessionState<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span>SessionState<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">522</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>cli<span class="token punctuation">.</span>CliDriver<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>CliDriver<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">677</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>cli<span class="token punctuation">.</span>CliDriver<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span>CliDriver<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">621</span><span class="token punctuation">)</span>        at sun<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>NativeMethodAccessorImpl<span class="token punctuation">.</span><span class="token function">invoke0</span><span class="token punctuation">(</span>Native Method<span class="token punctuation">)</span>        at sun<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>NativeMethodAccessorImpl<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>NativeMethodAccessorImpl<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">57</span><span class="token punctuation">)</span>        at sun<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>DelegatingMethodAccessorImpl<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>DelegatingMethodAccessorImpl<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">43</span><span class="token punctuation">)</span>        at java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>Method<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>Method<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">606</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>RunJar<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>RunJar<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">221</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>RunJar<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span>RunJar<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">136</span><span class="token punctuation">)</span>Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>RuntimeException<span class="token operator">:</span> Unable to instantiate org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>SessionHiveMetaStoreClient        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>metastore<span class="token punctuation">.</span>MetaStoreUtils<span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span>MetaStoreUtils<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1523</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>metastore<span class="token punctuation">.</span>RetryingMetaStoreClient<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>RetryingMetaStoreClient<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">86</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>metastore<span class="token punctuation">.</span>RetryingMetaStoreClient<span class="token punctuation">.</span><span class="token function">getProxy</span><span class="token punctuation">(</span>RetryingMetaStoreClient<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">132</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>metastore<span class="token punctuation">.</span>RetryingMetaStoreClient<span class="token punctuation">.</span><span class="token function">getProxy</span><span class="token punctuation">(</span>RetryingMetaStoreClient<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">104</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>Hive<span class="token punctuation">.</span><span class="token function">createMetaStoreClient</span><span class="token punctuation">(</span>Hive<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">3005</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>Hive<span class="token punctuation">.</span><span class="token function">getMSC</span><span class="token punctuation">(</span>Hive<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">3024</span><span class="token punctuation">)</span>        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>session<span class="token punctuation">.</span>SessionState<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span>SessionState<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">503</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>原因是，Metastore 默认存储在自带的 derby 数据库中，所以只能开一个，因此开两个会报错。修改使用 MySQL 存储 Metastore 可以解决此问题;</p><h3 id="MySql安装"><a href="#MySql安装" class="headerlink" title="MySql安装"></a>MySql安装</h3><h4 id="安装包准备"><a href="#安装包准备" class="headerlink" title="安装包准备"></a>安装包准备</h4><ol><li>查看mysql是否安装，如果安装了，卸载mysql</li></ol><p>执行以下步骤需切换 root，不然可能权限不够</p><p>(1) 查看</p><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 桌面]# rpm -qa|grep mysql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>若执行以上命令什么都没有出来，则说明还未安装，不用进行下面的卸载步骤。若有一些信息，说明已经安装，要执行下面卸载步骤。</p><p>(2) 卸载</p><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 桌面]# rpm -e --nodeps mysql-libs-5.1.73-7.el6.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>–nodeps 删除依赖进行卸载</strong></p><ol start="2"><li>解压mysql-libs.zip文件到当前目录</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 software]# unzip mysql-libs.zip[root@hadoop102 software]# ls——>mysql-libs.zipmysql-libs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>进入到mysql-libs文件夹下</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# ll——>总用量 76048-rw-r--r--. 1 root root 18509960 3月  26 2015 MySQL-client-5.6.24-1.el6.x86_64.rpm-rw-r--r--. 1 root root  3575135 12月  1 2013 mysql-connector-java-5.1.27.tar.gz-rw-r--r--. 1 root root 55782196 3月  26 2015 MySQL-server-5.6.24-1.el6.x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="安装MySql服务器"><a href="#安装MySql服务器" class="headerlink" title="安装MySql服务器"></a>安装MySql服务器</h4><ol><li>安装mysql服务端</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>查看产生的随机密码</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# cat /root/.mysql_secret——># The random password set for the root user at Sun Nov  1 20:10:18 2020 (local time): N5AQmsyBqnsWhzFk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="3"><li>查看mysql状态</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# service mysql status<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>启动mysql</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# service mysql start——>Starting MySQL. SUCCESS!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>出现以上语句，说明启动成功</p><h4 id="安装MySql客户端"><a href="#安装MySql客户端" class="headerlink" title="安装MySql客户端"></a>安装MySql客户端</h4><ol><li>安装mysql客户端</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>连接mysql</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# mysql -uroot -pN5AQmsyBqnsWhzFk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>-u后面是用户名，-p后面是刚才随机生成的密码</strong></p><ol start="3"><li>修改密码</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> SET PASSWORD=PASSWORD('123456');<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>退出mysql</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> exit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：若以上步骤中出现错误，其原因有很多种，最简单暴力的方法有时往往是最有效的——卸载干净重新装（以下步骤）</strong></p><ol><li>centos7 默认安装的是 mariadb，需要先卸载 mariadb，先查看是否安装 mariadb</li></ol><pre class="line-numbers language-shell"><code class="language-shell">rpm -qa | grep mariadb<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果找到，则使用下面命令删除，如删除 mariadb-libs-5.5.35-3.el7.x86_64**</p><pre class="line-numbers language-shell"><code class="language-shell">rpm -e --nodeps mariadb-libs-5.5.35-3.el7.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>查找以前是否安装有mysql，使用下面命令（跟上面相同），若有则进行卸载：</li></ol><pre class="line-numbers language-shell"><code class="language-shell">rpm -qa|grep -i mysql——>MySQL-server-5.6.24-1.el6.x86_64MySQL-client-5.6.24-1.el6.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果显示有如上包则说明已安装mysql</p><ol start="3"><li>如果已安装，则需要删除已安装的数据库，使用以下命令来删除数据库</li></ol><p>删除命令：rpm -e –nodeps 包名</p><pre class="line-numbers language-shell"><code class="language-shell">rpm -ev mysql-4.1.12-3.RHEL4.1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>删除老版本mysql的开发头文件和库</li></ol><pre class="line-numbers language-shell"><code class="language-shell">rm -fr /usr/lib/mysqlrm -fr /usr/include/mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="5"><li>卸载后 /var/lib/mysql 中的数据及 /etc/my.cnf 不会删除，如果确定没用后就手工删除</li></ol><pre class="line-numbers language-shell"><code class="language-shell">rm -f /etc/my.cnfrm -fr /var/lib/mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="MySql中user表中主机配置"><a href="#MySql中user表中主机配置" class="headerlink" title="MySql中user表中主机配置"></a>MySql中user表中主机配置</h4><p>配置只要是root用户+密码，在任何主机上都能登录MySQL数据库。</p><ol><li>进入mysql</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# mysql -uroot -p123456<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>显示数据库</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> show databases;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>使用mysql数据库</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> use mysql;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>展示mysql数据库中的所有表</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> show tables;——>+---------------------------+| Tables_in_mysql           |+---------------------------+| columns_priv              || db                        || event                     || func                      || general_log               || help_category             || help_keyword              || help_relation             || help_topic                || innodb_index_stats        || innodb_table_stats        || ndb_binlog_index          || plugin                    || proc                      || procs_priv                || proxies_priv              || servers                   || slave_master_info         || slave_relay_log_info      || slave_worker_info         || slow_log                  || tables_priv               || time_zone                 || time_zone_leap_second     || time_zone_name            || time_zone_transition      || time_zone_transition_type || user                      |+---------------------------+28 rows in set (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>展示user表的结构</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> desc user;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>查询user表</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> select User, Host, Password from user;——>+------+-----------+-------------------------------------------+| User | Host      | Password                                  |+------+-----------+-------------------------------------------+| root | localhost | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 || root | hadoop102 | *2C084B5A757F38D3807BBF835422112631ED67AF || root | 127.0.0.1 | *2C084B5A757F38D3807BBF835422112631ED67AF || root | ::1       | *2C084B5A757F38D3807BBF835422112631ED67AF |+------+-----------+-------------------------------------------+4 rows in set (0.10 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>因为此时远程登陆会出现问题，所以要配一个如主机登录：需要以下步骤</strong></p><ol start="7"><li>修改user表，把Host表内容修改为%</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> update user set host='%' where host='localhost';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="8"><li>删除root用户的其他host</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> delete from user where Host='hadoop102';mysql> delete from user where Host='127.0.0.1';mysql> delete from user where Host='::1';<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="9"><li>刷新</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> flush privileges;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="10"><li>退出</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> quit;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Hive元数据配置到MySql"><a href="#Hive元数据配置到MySql" class="headerlink" title="Hive元数据配置到MySql"></a>Hive元数据配置到MySql</h3><h4 id="驱动拷贝"><a href="#驱动拷贝" class="headerlink" title="驱动拷贝"></a>驱动拷贝</h4><ol><li>在 /opt/software/mysql-libs 目录下解压 mysql-connector-java-5.1.27.tar.gz 驱动包</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-libs]# tar -zxvf mysql-connector-java-5.1.27.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>拷贝 /opt/software/mysql-libs/mysql-connector-java-5.1.27 目录下的 mysql-connector-java-5.1.27-bin.jar 到 /opt/module/hive/lib/</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[root@hadoop102 mysql-connector-java-5.1.27]# cp mysql-connector-java-5.1.27-bin.jar /opt/module/hive/lib/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="配置Metastore到MySql"><a href="#配置Metastore到MySql" class="headerlink" title="配置Metastore到MySql"></a>配置Metastore到MySql</h4><ol><li>在/opt/module/hive/conf目录下创建一个hive-site.xml</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ touch hive-site.xml[user_test@hadoop102 conf]$ vi hive-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="2"><li>根据官方文档配置参数，拷贝数据到hive-site.xml文件中</li></ol><p><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin</a></p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionURL<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>jdbc:mysql://hadoop102:3306/metastore?createDatabaseIfNotExist=true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>JDBC connect string for a JDBC metastore<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionDriverName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>com.mysql.jdbc.Driver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Driver class name for a JDBC metastore<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionUserName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>username to use against metastore database<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionPassword<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>123456<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>password to use against metastore database<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>配完上面的再去看表就看不到之前debry中的数据</p><ol start="3"><li>配置完毕后，如果启动hive异常，可以重新启动虚拟机。（重启后，别忘了启动hadoop集群）</li></ol><h4 id="多窗口启动Hive测试"><a href="#多窗口启动Hive测试" class="headerlink" title="多窗口启动Hive测试"></a>多窗口启动Hive测试</h4><p>之前在同一服务器上不能同时打开两个hive，但是在不同服务器上可以同时启动多个（因为，在不同服务器上启动hive时，他会在每个服务器的 ./ 目录下重新创建 derbylog 和 metastore_da，相互之间互不相通）</p><ol><li>先启动MySQL</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 mysql-libs]$ mysql -uroot -p123456<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看有几个数据库</p><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> show databases;——>+--------------------+| Database           |+--------------------+| information_schema || mysql             || performance_schema || test               |+--------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>再次打开多个窗口，分别启动hive</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3．启动hive后，回到MySQL窗口查看数据库，显示增加了metastore数据库</p><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> show databases;——>+--------------------+| Database           |+--------------------+| information_schema || metastore          || mysql             || performance_schema || test               |+--------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="HiveJDBC访问"><a href="#HiveJDBC访问" class="headerlink" title="HiveJDBC访问"></a>HiveJDBC访问</h3><p>hive可以像mysql一样在项目中写sql进行一些操作，但是太慢了，所以一般不会用。</p><h4 id="启动hiveserver2服务"><a href="#启动hiveserver2服务" class="headerlink" title="启动hiveserver2服务"></a>启动hiveserver2服务</h4><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hiveserver2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="启动beeline"><a href="#启动beeline" class="headerlink" title="启动beeline"></a>启动beeline</h4><pre class="line-numbers language-shel"><code class="language-shel">[user_test@hadoop102 hive]$ bin/beeline——>Beeline version 1.2.1 by Apache Hivebeeline><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="连接hiveserver2"><a href="#连接hiveserver2" class="headerlink" title="连接hiveserver2"></a>连接hiveserver2</h4><pre class="line-numbers language-shell"><code class="language-shell">beeline> !connect jdbc:hive2://hadoop102:10000——>Connecting to jdbc:hive2://hadoop102:10000Enter username for jdbc:hive2://hadoop102:10000: user_test（安装过程中使用的用户名）——>Enter password for jdbc:hive2://hadoop102:10000: （设置密码，则输入回车；没有设置就直接回车）——>Connected to: Apache Hive (version 1.2.1)Driver: Hive JDBC (version 1.2.1)Transaction isolation: TRANSACTION_REPEATABLE_READ0: jdbc:hive2://hadoop102:10000> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>显示已有数据库</p><pre class="line-numbers language-shell"><code class="language-shell">0: jdbc:hive2://hadoop102:10000> show databases;——>+----------------+--+| database_name  |+----------------+--+| default        |+----------------+--+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Hive常用交互命令"><a href="#Hive常用交互命令" class="headerlink" title="Hive常用交互命令"></a>Hive常用交互命令</h3><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive -help——>usage: hive -d,--define <key=value>          Variable subsitution to apply to hive                                  commands. e.g. -d A=B or --define A=B    --database <databasename>     Specify the database to use -e <quoted-query-string>         SQL from command line -f <filename>                    SQL from files -H,--help                        Print help information    --hiveconf <property=value>   Use value for given property    --hivevar <key=value>         Variable subsitution to apply to hive                                  commands. e.g. --hivevar A=B -i <filename>                    Initialization SQL file -S,--silent                      Silent mode in interactive shell -v,--verbose                     Verbose mode (echo executed SQL to the console)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>“-e”不进入hive的交互窗口执行sql语句</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive -e "select id from student;"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>“-f”执行脚本中sql语句</li></ol><p>(1) 在/opt/module/datas目录下创建hivef.sql文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 datas]$ touch hivef.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件中写入正确的sql语句</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span><span class="token keyword">from</span> student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 执行文件中的sql语句</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive -f /opt/module/datas/hivef.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 执行文件中的sql语句并将结果写入文件中</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hive]$ bin/hive -f /opt/module/datas/hivef.sql  > /opt/module/datas/hive_result.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Hive其他命令操作"><a href="#Hive其他命令操作" class="headerlink" title="Hive其他命令操作"></a>Hive其他命令操作</h3><ol><li>退出hive窗口：</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">exit</span><span class="token punctuation">;</span>hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> quit<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在新版的hive中没区别了，在以前的版本是有的：</p><p>exit:先隐性提交数据，再退出；</p><p>quit:不提交数据，退出；</p><ol start="2"><li>在hive cli命令窗口中查看hdfs文件系统</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> dfs <span class="token operator">-</span>ls <span class="token operator">/</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>在hive cli命令窗口中查看本地文件系统</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token operator">!</span> ls <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>datas<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>查看在hive中输入的所有历史命令</li></ol><p>(1) 进入到当前用户的根目录/root或/home/user_test</p><p>(2) 查看.hivehistory文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 ~]$ cat .hivehistory<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Hive常见属性配置"><a href="#Hive常见属性配置" class="headerlink" title="Hive常见属性配置"></a>Hive常见属性配置</h3><h4 id="Hive数据仓库位置配置"><a href="#Hive数据仓库位置配置" class="headerlink" title="Hive数据仓库位置配置"></a>Hive数据仓库位置配置</h4><ol><li><p>Default数据仓库的最原始位置是在hdfs上的：/user/hive/warehouse路径下。</p></li><li><p>在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。</p></li><li><p>修改default数据仓库原始位置（将hive-default.xml.template如下配置信息拷贝到hive-site.xml文件中）。</p></li></ol><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.warehouse.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/user/hive/warehouse<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>location of default database for the warehouse<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>配置同组用户有执行权限</p><pre class="line-numbers language-shell"><code class="language-shell">bin/hdfs dfs -chmod g+w /user/hive/warehouse<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="查询后信息显示配置"><a href="#查询后信息显示配置" class="headerlink" title="查询后信息显示配置"></a>查询后信息显示配置</h4><ol><li>在hive-site.xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。</li></ol><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.cli.print.header<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.cli.print.current.db<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>重新启动hive，对比配置前后差异。</li></ol><p>（1）配置前，如图6-2所示</p><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>——<span class="token operator">></span><span class="token number">1001</span>    zhangsan<span class="token number">1002</span>    lisi<span class="token number">1003</span>    wangwu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）配置后，如图6-3所示</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>——<span class="token operator">></span>student<span class="token punctuation">.</span>id      student<span class="token punctuation">.</span>name<span class="token number">1001</span>    zhangsan<span class="token number">1002</span>    lisi<span class="token number">1003</span>    wangwu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Hive运行日志信息配置"><a href="#Hive运行日志信息配置" class="headerlink" title="Hive运行日志信息配置"></a>Hive运行日志信息配置</h4><ol><li><p>Hive的log默认存放在/tmp/atguigu/hive.log目录下（当前用户名下）</p></li><li><p>修改hive的log存放日志到/opt/module/hive/logs</p></li></ol><p>(1) 修改/opt/module/hive/conf/hive-log4j.properties.template文件名称为hive-log4j.properties</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ pwd——>/opt/module/hive/conf[user_test@hadoop102 conf]$ mv hive-log4j.properties.template hive-log4j.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(2) 在hive-log4j.properties文件中修改log存放位置</p><pre class="line-numbers language-properties"><code class="language-properties"><span class="token attr-name">hive.log.dir</span><span class="token punctuation">=</span><span class="token attr-value">/opt/module/hive/logs</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="参数配置方式"><a href="#参数配置方式" class="headerlink" title="参数配置方式"></a>参数配置方式</h4><p>hadoop修改配置的途径：*-site.xml文件、程序中的classpath下的set方法、代码中configuration.set进行修改</p><ol><li>查看当前所有的配置信息（最大任务数）</li></ol><pre class="line-numbers language-sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">set</span> mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token punctuation">;</span>——<span class="token operator">></span>mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="2"><li>参数的配置三种方式</li></ol><p>(1) 配置文件方式</p><p>默认配置文件：hive-default.xml</p><p>用户自定义配置文件：hive-site.xml</p><p><strong>注：</strong>用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。</p><p>(2) 命令行参数方式</p><p>启动Hive时，可以在命令行添加 “-hiveconf param=value” 来设定参数，例如：</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop103 hive]$ bin/hive -hiveconf mapred.reduce.tasks=10;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>仅对本次hive启动有效</p><p>查看参数设置：</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 参数声明方式</p><p>可以在HQL中使用SET关键字设定参数，例如：</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>仅对本次hive启动有效。</p><p>查看参数设置</p><pre class="line-numbers language-sql"><code class="language-sql">hive <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述三种设定方式的优先级依次递增。即配置文件 &lt; 命令行参数 &lt; 参数声明。注意某些系统级的参数，例如 log4j 相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间很匆忙</title>
      <link href="2020/11/01/shi-jian-hen-cong-mang/"/>
      <url>2020/11/01/shi-jian-hen-cong-mang/</url>
      
        <content type="html"><![CDATA[<h1 id="时间很匆忙"><a href="#时间很匆忙" class="headerlink" title="时间很匆忙"></a>时间很匆忙</h1><h2 id="废话连篇"><a href="#废话连篇" class="headerlink" title="废话连篇"></a>废话连篇</h2><p>仿佛有很多牢骚想一吐为快，细想又感觉抓不到一丝丝的线索。或许这就是无病呻吟吗~</p><p>距离开学已经两个月，这两个月做了很多的事，又仿佛做的事毫无头绪。这段时间，一直嘟哝着自己，快点，快点，再快点，与其说是督促自己学习，倒不如说是匆匆完成模糊的任务，而不问收获有多少。</p><p>这两个月确实学了些东西，但是，一直未得到很好的应用，另外还迫切渴望完成这一不成形的任务，感觉并未形成体系，就像是一盘散沙，抓都抓不起来。</p><p>一直想找个时间静下来定个更完整的计划，然而却总是以学完这点，找到满意的xx为由，不断地推迟着更长远的打算。或许这就是个人缺陷所在吧——急于求成、懒于思考。</p><p>没有计划，做事一头乱麻，到处乱撞，遇到一点点事就想大开洪荒之口，问候家人祖宗。</p><p>最近真的是太过急于求成，仿佛有种只管低头拉车，却忘了最开始的目的地是哪。</p><p>感觉自己真的是一个及其矛盾的存在，一面不断嚷着自己快点，快点；一面又有时仿佛在逃避些什么，不敢去面对，一拖再拖。</p><h2 id="提上日程"><a href="#提上日程" class="headerlink" title="提上日程"></a>提上日程</h2><p>什么？明年就要秋招？</p><p>每当说到这，总想爆两句粗口（xxx xxxxxx），研究生我特么还啥也没干，就特么要秋招，真的是xxx，xxxx（以上纯属发泄，一点意义没有，该来还是得来，55555）</p><p>之前一直小打小闹，终于要真的去面对不想面对的东西。一直在想为什么这些企业不能让我们这种打工人免费试用，如果做的成果满意就留下这群社畜，不满意就滚蛋呢。这种应对面试又有什么意义呢，哎，难受~</p><p>心理素质差，及其不想去面对这些，太特么难了~</p><p>不想了，放手去吧，好好准备，最后结果自己一定会满意的。希望我们的一切努力，都能温柔以待~</p><h2 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h2><p>废话说了这么多，有些事该做还是要做的~</p><ol><li><p>计划到底还是要定的，不能再拖了</p></li><li><p>以后可能要有比较沉重的研究任务了，得安排下时间，做好各方面的平衡了</p></li><li><p>学过的东西也不能就这么丢了的，还是得重新学下，以更好地去应对更ex的实现</p></li><li><p>时间节点也得理出来的</p></li></ol><h2 id="屁屁和皮皮"><a href="#屁屁和皮皮" class="headerlink" title="屁屁和皮皮"></a>屁屁和皮皮</h2><p>希望我们都会一切顺顺利利，心想都能事成。屁屁尽快融入到现在工作圈子，皮皮也能完成自己的愿望。</p><blockquote><p>收获多多，万事顺利，心想事成~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive概述</title>
      <link href="2020/11/01/hive-gai-shu/"/>
      <url>2020/11/01/hive-gai-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><p>由于种种原因，已经好久没有更大数据相关博客了，经过一些观察之后，发现现在大数据很多都是数仓方向的（可能是部分公司的原因），感觉还是着手下 hive 的学习吧。</p><p>希望以后不会失业，555555</p><h2 id="Hive入门"><a href="#Hive入门" class="headerlink" title="Hive入门"></a>Hive入门</h2><h3 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h3><p>Hive：由Facebook开源用于解决海量结构化日志的数据统计。</p><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p><p>本质是：将HQL转化成MapReduce程序</p><p><img src="1-1.png" alt></p><p>1）Hive处理的数据存储在HDFS</p><p>2）Hive分析数据底层的实现是MapReduce</p><p>3）执行程序运行在Yarn上</p><h3 id="Hive的优缺点"><a href="#Hive的优缺点" class="headerlink" title="Hive的优缺点"></a>Hive的优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>1)    操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。</p><p>2)    避免了去写MapReduce，减少开发人员的学习成本。</p><p>3)    Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。</p><p>4)    Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。</p><p>5)    Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>1．Hive的HQL表达能力有限</p><p>（1）迭代式算法无法表达（此处说hive不删除就是相当于说mr不擅长）</p><p>迭代处理就是不断对分析结果进行处理，算法分好多步，每一步需要上一步的计算结果，在 mr 中输出必须经过 IO，很慢，而且 sql 无法实现计算之后再计算</p><p>（2）数据挖掘方面不擅长</p><p>2．Hive的效率比较低</p><p>（1）Hive自动生成的MapReduce作业，通常情况下不够智能化</p><p>（2）Hive调优比较困难，粒度较粗</p><h3 id="Hive架构原理"><a href="#Hive架构原理" class="headerlink" title="Hive架构原理"></a>Hive架构原理</h3><p><img src="1-2.png" alt></p><p>1．用户接口：Client</p><p>CLI（hive shell）、JDBC/ODBC(java访问hive)、WEBUI（浏览器访问hive）</p><p>2．元数据：Metastore</p><p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；<br>默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore</p><p>3．Hadoop</p><p>使用HDFS进行存储，使用MapReduce进行计算。</p><p>4．驱动器：Driver</p><p>（1）解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</p><p>（2）编译器（Physical Plan）：将AST编译生成逻辑执行计划（将 hql 翻译成 mr）。</p><p>（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。</p><p>（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。</p><p>Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。</p><h3 id="Hive和数据库比较"><a href="#Hive和数据库比较" class="headerlink" title="Hive和数据库比较"></a>Hive和数据库比较</h3><p>由于 Hive 采用了类似SQL 的查询语言 HQL(Hive Query Language)，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无类似之处。本文将从多个方面来阐述 Hive 和数据库的差异。数据库可以用在 Online 的应用中，但是 Hive 是为数据仓库而设计的，清楚这一点，有助于从应用角度理解 Hive 的特性。</p><h4 id="查询语言"><a href="#查询语言" class="headerlink" title="查询语言"></a>查询语言</h4><p>由于SQL被广泛的应用在数据仓库中，因此，专门针对Hive的特性设计了类SQL的查询语言HQL。熟悉SQL开发的开发者可以很方便的使用Hive进行开发。</p><h4 id="数据存储位置"><a href="#数据存储位置" class="headerlink" title="数据存储位置"></a>数据存储位置</h4><p>Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。</p><h4 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h4><p>由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive中不建议对数据的改写，所有的数据都是在加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO …  VALUES 添加数据，使用 UPDATE … SET 修改数据。</p><h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p>Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些Key建立索引。Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 Hive 不适合在线数据查询。</p><h4 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h4><p>Hive中大多数查询的执行是通过 Hadoop 提供的 MapReduce 来实现的。而数据库通常有自己的执行引擎。</p><h4 id="执行延迟"><a href="#执行延迟" class="headerlink" title="执行延迟"></a>执行延迟</h4><p>Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 MapReduce 本身具有较高的延迟，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力（百万级）的时候，Hive的并行计算显然能体现出优势。</p><h4 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h4><p>由于Hive是建立在Hadoop之上的，因此Hive的可扩展性是和Hadoop的可扩展性是一致的（世界上最大的 Hadoop 集群在 Yahoo!，2009年的规模在4000台节点左右）。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有100台左右。</p><h4 id="数据规模"><a href="#数据规模" class="headerlink" title="数据规模"></a>数据规模</h4><p>由于Hive建立在集群上并可以利用MapReduce进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。</p><h2 id="Hive安装"><a href="#Hive安装" class="headerlink" title="Hive安装"></a>Hive安装</h2><h3 id="Hive安装地址"><a href="#Hive安装地址" class="headerlink" title="Hive安装地址"></a>Hive安装地址</h3><p>1．Hive官网地址</p><p><a href="http://hive.apache.org/" target="_blank" rel="noopener">http://hive.apache.org/</a></p><p>2．文档查看地址</p><p><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p><p>3．下载地址</p><p><a href="http://archive.apache.org/dist/hive/" target="_blank" rel="noopener">http://archive.apache.org/dist/hive/</a></p><p>4．github地址</p><p><a href="https://github.com/apache/hive" target="_blank" rel="noopener">https://github.com/apache/hive</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark知识点</title>
      <link href="2020/10/22/spark-zhi-shi-dian/"/>
      <url>2020/10/22/spark-zhi-shi-dian/</url>
      
        <content type="html"><![CDATA[<p>其中有些题目是刷到知乎上一个人整理的，感觉挺好的。但是当初没有保存地址（图片上有水印，可以去搜一下）</p><h1 id="Spark知识点"><a href="#Spark知识点" class="headerlink" title="Spark知识点"></a>Spark知识点</h1><h2 id="spark有哪些组件"><a href="#spark有哪些组件" class="headerlink" title="spark有哪些组件"></a>spark有哪些组件</h2><p>master：管理集群和节点，不参与计算。</p><p>worker：计算节点，进程本身不参与计算，和master汇报。</p><p>Driver：运行程序的main方法，创建spark context对象。</p><p>spark context：控制整个application的生命周期，包括dagsheduler和task scheduler等组件。</p><p>client：用户提交程序的入口。</p><h2 id="对于-Spark-中的数据倾斜问题你有什么好的方案？"><a href="#对于-Spark-中的数据倾斜问题你有什么好的方案？" class="headerlink" title="对于 Spark 中的数据倾斜问题你有什么好的方案？"></a>对于 Spark 中的数据倾斜问题你有什么好的方案？</h2><p>Spark 数据倾斜的几种场景以及对应的解决方案，包括避免数据源倾斜，调整并行度，使用自定义 Partitioner，使用 Map 侧 Join 代替 Reduce 侧 Join（内存表合并），给倾斜 Key 加上随机前缀等。</p><h3 id="什么是数据倾斜"><a href="#什么是数据倾斜" class="headerlink" title="什么是数据倾斜"></a>什么是数据倾斜</h3><p>对 Spark/Hadoop 这样的大数据系统来讲，数据量大并不可怕，可怕的是数据倾斜。数据倾斜指的是，并行处理的数据集中，某一部分（如 Spark 或 Kafka 的一个 Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈（木桶效应）。</p><h3 id="数据倾斜是如何造成的"><a href="#数据倾斜是如何造成的" class="headerlink" title="数据倾斜是如何造成的"></a>数据倾斜是如何造成的</h3><p>在 Spark 中，同一个 Stage（阶段） 的不同 Partition 可以并行处理，而具有依赖关系的不同 Stage 之间是串行处理的。假设某个 Spark Job 分为 Stage 0和 Stage 1两个 Stage，且 Stage 1依赖于 Stage 0，那 Stage 0完全处理结束之前不会处理Stage 1。而 Stage 0可能包含 N 个 Task，这 N 个 Task 可以并行进行。如果其中 N-1个 Task 都在10秒内完成，而另外一个 Task 却耗时1分钟，那该 Stage 的总时间至少为1分钟。换句话说，一个 Stage 所耗费的时间，主要由最慢的那个 Task 决定。由于同一个 Stage 内的所有 Task 执行相同的计算，在排除不同计算节点计算能力差异的前提下，不同 Task 之间耗时的差异主要由该 Task 所处理的数据量决定。</p><h3 id="具体解决方案"><a href="#具体解决方案" class="headerlink" title="具体解决方案"></a>具体解决方案</h3><h4 id="调整并行度分散同一个-Task-的不同-Key"><a href="#调整并行度分散同一个-Task-的不同-Key" class="headerlink" title="调整并行度分散同一个 Task 的不同 Key"></a>调整并行度分散同一个 Task 的不同 Key</h4><p>Spark 在做 Shuffle 时，默认使用 HashPartitioner（非 Hash Shuffle <strong>???</strong>）对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的 Key 对应的数据被分配到了同一个 Task 上，造成该 Task 所处理的数据远大于其它 Task，从而造成数据倾斜。如果调整 Shuffle 时的并行度，使得原本被分配到同一 Task 的不同 Key 发配到不同 Task 上处理，则可降低原 Task 所需处理的数据量，从而缓解数据倾斜问题造成的短板效应。下图左边绿色框表示 kv 样式的数据，key 可以理解成 name。可以看到 Task0 分配了许多的 key，调整并行度，多了几个 Task，那么每个 Task 处理的数据量就分散了。</p><p><img src="https://pic2.zhimg.com/80/v2-c835c4e277645c663e04b355b124ecb5_720w.jpg" alt="img"></p><h4 id="自定义Partitioner"><a href="#自定义Partitioner" class="headerlink" title="自定义Partitioner"></a>自定义Partitioner</h4><p>使用自定义的 Partitioner（默认为 HashPartitioner），将原本被分配到同一个 Task 的不同 Key 分配到不同 Task，可以拿上图继续想象一下，通过自定义 Partitioner 可以把原本分到 Task0 的 Key 分到 Task1，那么 Task0 的要处理的数据量就少了。 </p><h4 id="将-Reduce-侧-Join-转变为-Map-侧-Join"><a href="#将-Reduce-侧-Join-转变为-Map-侧-Join" class="headerlink" title="将 Reduce 侧  Join 转变为 Map 侧  Join"></a>将 Reduce 侧  Join 转变为 Map 侧  Join</h4><p>通过 Spark 的 Broadcast 机制，将 Reduce 侧 Join 转化为 Map 侧 Join，避免 Shuffle 从而完全消除 Shuffle 带来的数据倾斜。可以看到 RDD2 被加载到内存中了。</p><p><img src="https://pic2.zhimg.com/80/v2-673a656c08704b373fe44d247a22a5b5_720w.jpg" alt="img"></p><h4 id="为-skew-的-key-增加随机前-后缀"><a href="#为-skew-的-key-增加随机前-后缀" class="headerlink" title="为 skew 的 key 增加随机前/后缀"></a>为 skew 的 key 增加随机前/后缀</h4><p>为数据量特别大的 Key 增加随机前/后缀，使得原来 Key 相同的数据变为 Key 不相同的数据，从而使倾斜的数据集分散到不同的 Task 中，彻底解决数据倾斜问题。Join 另一则的数据中，与倾斜 Key 对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜 Key 如何加前缀，都能与之正常 Join。</p><p><img src="https://pic3.zhimg.com/80/v2-c82a1e714ee0266d47800fedbefd46f6_720w.jpg" alt="img"></p><h4 id="大表随机添加-N-种随机前缀，小表扩大-N-倍"><a href="#大表随机添加-N-种随机前缀，小表扩大-N-倍" class="headerlink" title="大表随机添加 N 种随机前缀，小表扩大 N 倍"></a>大表随机添加 N 种随机前缀，小表扩大 N 倍</h4><p>如果出现数据倾斜的 Key 比较多，上一种方法将这些大量的倾斜 Key 分拆出来，意义不大（很难一个 Key 一个 Key 都加上后缀）。此时更适合直接对存在数据倾斜的数据集全部加上随机前缀，然后对另外一个不存在严重数据倾斜的数据集整体与随机前缀集作笛卡尔乘积（即将数据量扩大 N 倍），可以看到 RDD2 扩大了 N 倍了，再和加完前缀的大数据做笛卡尔积。</p><p><img src="https://pic3.zhimg.com/80/v2-95bd9d233cb7431864f47ce6a8f3149e_720w.jpg" alt="img"></p><h2 id="你所理解的-Spark-的-shuffle-过程？"><a href="#你所理解的-Spark-的-shuffle-过程？" class="headerlink" title="你所理解的 Spark 的 shuffle 过程？"></a>你所理解的 Spark 的 shuffle 过程？</h2><p>Spark shuffle 处于一个宽依赖，可以实现类似混洗的功能，将相同的 Key 分发至同一个 Reducer上进行处理。</p><h3 id="Shuffle-Read-问题"><a href="#Shuffle-Read-问题" class="headerlink" title="Shuffle Read 问题"></a>Shuffle Read 问题</h3><h4 id="在什么时候获取数据"><a href="#在什么时候获取数据" class="headerlink" title="在什么时候获取数据"></a>在什么时候获取数据</h4><p>当 Parent Stage 的所有 ShuffleMapTasks 结束后再 fetch。</p><h4 id="边获取边处理还是一次性获取完再处理？"><a href="#边获取边处理还是一次性获取完再处理？" class="headerlink" title="边获取边处理还是一次性获取完再处理？"></a>边获取边处理还是一次性获取完再处理？</h4><p>因为 Spark 不要求 Shuffle 后的数据全局有序，因此没必要等到全部数据 shuffle 完成后再处理，所以是边 fetch 边处理。</p><h4 id="获取来的数据存放到哪里"><a href="#获取来的数据存放到哪里" class="headerlink" title="获取来的数据存放到哪里"></a>获取来的数据存放到哪里</h4><p>刚获取来的 FileSegment 存放在 softBuffer 缓冲区，经过处理后的数据放在内存 + 磁盘上。</p><p>内存使用的是AppendOnlyMap ，类似 Java 的HashMap，内存＋磁盘使用的是ExternalAppendOnlyMap，如果内存空间不足时，ExternalAppendOnlyMap可以将 records 进行 sort 后 spill（溢出）到磁盘上，等到需要它们的时候再进行归并</p><h4 id="怎么获得数据的存放位置？"><a href="#怎么获得数据的存放位置？" class="headerlink" title="怎么获得数据的存放位置？"></a>怎么获得数据的存放位置？</h4><p>通过请求 Driver 端的 MapOutputTrackerMaster 询问 ShuffleMapTask 输出的数据位置。</p><h3 id="触发-Shuffle-的操作"><a href="#触发-Shuffle-的操作" class="headerlink" title="触发 Shuffle 的操作"></a>触发 Shuffle 的操作</h3><table><thead><tr><th>分类</th><th>操作</th></tr></thead><tbody><tr><td>repartition相关</td><td>repartition、coalesce</td></tr><tr><td>*ByKey操作</td><td>groupByKey、reduceByKey、combineByKey、aggregateByKey等</td></tr><tr><td>join相关</td><td>cogroup、join</td></tr></tbody></table><h2 id="Spark有哪些聚合类的算子-我们应该尽量避免什么类型的算子？"><a href="#Spark有哪些聚合类的算子-我们应该尽量避免什么类型的算子？" class="headerlink" title="Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子？"></a>Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子？</h2><p>在我们的开发过程中，能避免则尽可能避免使用 reduceByKey、join、distinct、repartition 等会进行 shuffle 的算子，尽量使用 map 类的非 shuffle 算子。这样的话，没有 shuffle 操作或者仅有较少 shuffle 操作的 Spark 作业，可以大大减少性能开销。</p><h2 id="spark-on-yarn-作业执行流程，yarn-client-和-yarn-cluster-有什么区别"><a href="#spark-on-yarn-作业执行流程，yarn-client-和-yarn-cluster-有什么区别" class="headerlink" title="spark on yarn 作业执行流程，yarn-client 和 yarn cluster 有什么区别"></a>spark on yarn 作业执行流程，yarn-client 和 yarn cluster 有什么区别</h2><h3 id="Spark-On-Yarn-的优势"><a href="#Spark-On-Yarn-的优势" class="headerlink" title="Spark On Yarn 的优势"></a>Spark On Yarn 的优势</h3><ol><li><p>Spark 支持资源动态共享，运行于 Yarn 的框架都共享一个集中配置好的资源池 </p></li><li><p>可以很方便的利用 Yarn 的资源调度特性来做分类·，隔离以及优先级控制负载，拥有更灵活的调度策略 </p></li><li><p>Yarn 可以自由地选择 executor 数量 </p></li><li><p>Yarn 是唯一支持 Spark 安全的集群管理器（Mesos???），使用 Yarn，Spark 可以运行于 Kerberized Hadoop 之上，在它们进程之间进行安全认证</p></li></ol><h3 id="yarn-client-和-yarn-cluster-的异同"><a href="#yarn-client-和-yarn-cluster-的异同" class="headerlink" title="yarn-client 和 yarn cluster 的异同"></a>yarn-client 和 yarn cluster 的异同</h3><ol><li><p>从广义上讲，yarn-cluster 适用于生产环境。而 yarn-client 适用于交互和调试，也就是希望快速地看到 application 的输出。 </p></li><li><p>从深层次的含义讲，yarn-cluster 和 yarn-client 模式的区别其实就是 Application Master 进程的区别，yarn-cluster 模式下，driver 运行在 AM(Application Master)中，它负责向 YARN 申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉 Client，作业会继续在 YARN 上运行。然而 yarn-cluster 模式不适合运行交互类型的作业；而 yarn-client 模式下，Application Master 仅仅向 YARN 请求 executor，Client 会和请求的 container 通信来调度他们工作，也就是说 Client 不能离开。</p></li></ol><h3 id="Spark为什么快，Spark-SQL-一定比-Hive-快吗"><a href="#Spark为什么快，Spark-SQL-一定比-Hive-快吗" class="headerlink" title="Spark为什么快，Spark SQL 一定比 Hive 快吗"></a>Spark为什么快，Spark SQL 一定比 Hive 快吗</h3><p>Spark SQL 比 Hadoop Hive 快，是有一定条件的，而且不是 Spark SQL 的引擎比 Hive 的引擎快，相反，Hive 的 HQL 引擎还比 Spark SQL 的引擎更快。其实，关键还是在于 Spark 本身快。</p><h4 id="消除了冗余的-HDFS-读写"><a href="#消除了冗余的-HDFS-读写" class="headerlink" title="消除了冗余的 HDFS 读写"></a>消除了冗余的 HDFS 读写</h4><p>Hadoop 每次 shuffle 操作后，必须写到磁盘，而 Spark 在 shuffle 后不一定落盘，可以 cache 到内存中，以便迭代时使用。如果操作复杂，很多的 shufle 操作，那么 Hadoop 的读写 IO 时间会大大增加，也是 Hive 更慢的主要原因了。</p><h4 id="消除了冗余的-MapReduce-阶段"><a href="#消除了冗余的-MapReduce-阶段" class="headerlink" title="消除了冗余的 MapReduce 阶段"></a>消除了冗余的 MapReduce 阶段</h4><p>Hadoop 的 shuffle 操作一定连着完整的 MapReduce 操作，冗余繁琐。而 Spark 基于 RDD 提供了丰富的算子操作，且 reduce 操作产生 shuffle 数据，可以缓存在内存中。</p><h4 id="JVM-的优化"><a href="#JVM-的优化" class="headerlink" title="JVM 的优化"></a>JVM 的优化</h4><p>Hadoop 每次 MapReduce 操作，启动一个 Task 便会启动一次 JVM，基于进程的操作。而 Spark 每次 MapReduce 操作是基于线程的，只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多少。</p><p><strong>记住一种反例 考虑一种极端查询</strong></p><pre class="line-numbers language-SPARQL"><code class="language-SPARQL">Select month_id, sum(sales) from T group by month_id;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个查询只有一次 shuffle 操作，此时，也许 Hive HQL 的运行时间也许比 Spark 还快，反正 shuffle 完了都会落一次盘，或者都不落盘。</p><p>结论 Spark 快不是绝对的，但是绝大多数，Spark 都比 Hadoop 计算要快。这主要得益于其对 mapreduce 操作的优化以及对 JVM 使用的优化。</p><h2 id="RDD-DAG-Stage怎么理解？"><a href="#RDD-DAG-Stage怎么理解？" class="headerlink" title="RDD, DAG, Stage怎么理解？"></a>RDD, DAG, Stage怎么理解？</h2><h3 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h3><p>Spark 中使用 DAG 对 RDD 的关系进行建模，描述了 RDD 的依赖关系，这种关系也被称之为 lineage（血缘），RDD 的依赖关系使用 Dependency 维护。DAG 在 Spark 中的对应的实现为 DAGScheduler。</p><h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><p>RDD 是 Spark 的灵魂，也称为弹性分布式数据集。一个 RDD 代表一个可以被分区的只读数据集。RDD 内部可以有许多分区(partitions)，每个分区又拥有大量的记录(records)。</p><h4 id="Rdd的五个特征"><a href="#Rdd的五个特征" class="headerlink" title="Rdd的五个特征"></a>Rdd的五个特征</h4><ol><li><p>dependencies：建立 RDD 的依赖关系，主要 RDD 之间是宽窄依赖的关系，具有窄依赖关系的 RDD 可以在同一个 stage 中进行计算。</p></li><li><p>partition：一个 RDD 会有若干个分区，分区的大小决定了对这个 RDD 计算的粒度，每个 RDD 的分区的计算都在一个单独的任务中进行。 </p></li><li><p>preferedlocations：按照“移动数据不如移动计算”原则，在 Spark 进行任务调度的时候，优先将任务分配到数据块存储的位置。</p></li><li><p>compute：Spark 中的计算都是以分区为基本单位的，compute 函数只是对迭代器进行复合，并不保存单次计算的结果。 </p></li><li><p>partitioner：只存在于（K,V）类型的 RDD 中，非（K,V）类型的 partitioner 的值就是 None。</p></li></ol><p>RDD 的算子主要分成2类，action 和 transformation。这里的算子概念，可以理解成就是对数据集的变换。action 会触发真正的作业提交，而 transformation 算子是不会立即触发作业提交的。每一个 transformation 方法返回一个新的 RDD。只是某些 transformation 比较复杂，会包含多个子 transformation，因而会生成多个 RDD。这就是实际 RDD 个数比我们想象的多一些的原因。通常是，当遇到 action 算子时会触发一个job的提交，然后反推回去看前面的 transformation 算子，进而形成一张有向无环图。</p><h3 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h3><p>在 DAG 中又进行 stage 的划分，划分的依据是依赖是否是 shuffle 的，每个 stage 又可以划分成若干 task。接下来的事情就是 driver 发送 task 到 executor，executor 自己的线程池去执行这些 task，完成之后将结果返回给 driver。action 算子是划分不同 job 的依据。</p><h2 id="RDD-如何通过记录更新的方式容错"><a href="#RDD-如何通过记录更新的方式容错" class="headerlink" title="RDD 如何通过记录更新的方式容错"></a>RDD 如何通过记录更新的方式容错</h2><p>RDD 的容错机制实现分布式数据集容错方法有两种</p><ol><li>数据检查点</li></ol><p>虽然RDD的血缘关系天然地可以实现容错，当RDD的某个分区数据失败或丢失，可以通过血缘关系重建。但是对于长时间迭代型应用来说，随着迭代的进行，RDD之间的血缘关系会越来越长，一旦在后续迭代过程中出错，则需要通过非常长的血缘关系去重建，势必影响性能。为此，RDD支持checkpoint将数据保存到持久化的存储中，这样就可以切断之前的血缘关系，因为checkpoint后的RDD不需要知道它的父RDDs了，它可以从checkpoint处拿到数据。</p><ol start="2"><li>记录更新。</li></ol><p>记录所有更新点的成本很高。所以，RDD只支持粗颗粒变换，即只记录单个块（分区）上执行的单个操作，然后创建某个 RDD 的变换序列（血统 lineage）存储下来；变换序列指，每个 RDD 都包含了它是如何由其他 RDD 变换过来的以及如何重建某一块数据的信息。因此 RDD 的容错机制又称“血统”容错。</p><h2 id="RDD任务切分中间分为：Application、Job、Stage和Task"><a href="#RDD任务切分中间分为：Application、Job、Stage和Task" class="headerlink" title="RDD任务切分中间分为：Application、Job、Stage和Task"></a>RDD任务切分中间分为：Application、Job、Stage和Task</h2><ol><li><p>Application：初始化一个 SparkContext 即生成一个 Application</p></li><li><p>Job：一个 Action 算子就会生成一个 Job</p></li><li><p>Stage：根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage。</p></li><li><p>Task：Stage是一个TaskSet，将Stage划分的结果发送到不同的Executor执行即为一个Task。</p></li></ol><p><strong>注意：Application-&gt;Job（行动算子）-&gt;Stage-&gt; Task（分区）每一层都是1对n的关系。</strong></p><p>一个应用可以多次调用行动算子（Job），而每个作业中可以有多个阶段，同时在一个阶段中有多个分区（每个分区就是一个任务）</p><p>阶段划分数量 = 1 + shuffle数量</p><h2 id="说说map和mapPartitions的区别"><a href="#说说map和mapPartitions的区别" class="headerlink" title="说说map和mapPartitions的区别"></a>说说map和mapPartitions的区别</h2><p>map 中的 func 作用的是 RDD 中每一个元素，而 mapPartitioons 中的 func 作用的对象是 RDD 的一整个分区。所以 func 的类型是 Iterator&lt;T&gt; =&gt; Iterator&lt;T&gt;，其中 T 是输入 RDD 的元素类型。</p><h2 id="groupByKey和reduceByKey是属于什么算子"><a href="#groupByKey和reduceByKey是属于什么算子" class="headerlink" title="groupByKey和reduceByKey是属于什么算子"></a>groupByKey和reduceByKey是属于什么算子</h2><p>Transformation算子。因为 Action 输出的不再是 RDD 了，也就意味着输出不是分布式的，而是回送到 Driver 程序。以上两种操作都是返回 RDD，所以应该属于 Transformation。</p><h2 id="Spark支持的3种集群管理器"><a href="#Spark支持的3种集群管理器" class="headerlink" title="Spark支持的3种集群管理器"></a>Spark支持的3种集群管理器</h2><p>Standalone 模式</p><p>资源管理器是 Master 节点，调度策略相对单一，只支持先进先出模式。</p><p>Hadoop Yarn 模式</p><p>资源管理器是 Yarn 集群，主要用来管理资源。Yarn 支持动态资源的管理，还可以调度其他实现了 Yarn 调度接口的集群计算，非常适用于多个集群同时部署的场景，是目前最流行的一种资源管理系统。</p><p>Apache Mesos</p><p>Mesos 是专门用于分布式系统资源管理的开源系统，与 Yarn 一样是 C++ 开发，可以对集群中的资源做弹性管理。</p><h2 id="Spark提供的两种共享变量"><a href="#Spark提供的两种共享变量" class="headerlink" title="Spark提供的两种共享变量"></a>Spark提供的两种共享变量</h2><p>Spark 程序的大部分操作都是 RDD 操作，通过传入函数给 RDD 操作函数来计算，这些函数在不同的节点上并发执行，内部的变量有不同的作用域，不能相互访问，有些情况下不太方便。</p><p>广播变量，是一个只读对象，在所有节点上都有一份缓存，创建方法是 SparkContext.broadcast()。创建之后再更新它的值是没有意义的，一般用 val 来修改定义。</p><p>计数器，只能增加，可以用计数或求和，支持自定义类型。创建方法是 SparkContext.accumulator(V, name)。只有 Driver 程序可以读这个计算器的变量，RDD 操作中读取计数器变量是无意义的。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SparkStreaming</title>
      <link href="2020/10/06/sparkstreaming/"/>
      <url>2020/10/06/sparkstreaming/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkStreaming"><a href="#SparkStreaming" class="headerlink" title="SparkStreaming"></a>SparkStreaming</h1><h2 id="Spark-Streaming概述"><a href="#Spark-Streaming概述" class="headerlink" title="Spark Streaming概述"></a>Spark Streaming概述</h2><h3 id="Spark-Streaming是什么"><a href="#Spark-Streaming是什么" class="headerlink" title="Spark Streaming是什么"></a>Spark Streaming是什么</h3><p>Spark Streaming用于流式数据的处理。Spark Streaming支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ和简单的TCP套接字等等。数据输入后可以用Spark的高度抽象原语如：map、reduce、join、window等进行运算。而结果也能保存在很多地方，如HDFS，数据库等。</p><p><img src="streaming1-2.png" alt></p><p>和Spark基于RDD的概念很相似，Spark Streaming使用离散化流(discretized stream)作为抽象表示，叫作DStream。DStream 是随时间推移而收到的数据的序列。在内部，每个时间区间收到的数据都作为 RDD 存在，而DStream是由这些RDD所组成的序列(因此得名“离散化”)。</p><p><img src="streaming1-3.png" alt></p><p>图中反应数据采集周期是5s，即：每5s汇总一下采集到的数据，然后发送给接收器来封装成一个 DStream 发送给Driver，然后再发送给Executor进行处理。</p><h3 id="Spark-Streaming特点"><a href="#Spark-Streaming特点" class="headerlink" title="Spark Streaming特点"></a>Spark Streaming特点</h3><ol><li><p>易用</p></li><li><p>容错</p></li><li><p>易整合到Spark体系</p></li></ol><h3 id="SparkStreaming架构"><a href="#SparkStreaming架构" class="headerlink" title="SparkStreaming架构"></a>SparkStreaming架构</h3><p><img src="streaming1-1.png" alt></p><p>接收器是不可以停的，一直用来接收数据；同样driver也不能停，得一直处理接收器发送来的DStream</p><h2 id="Dstream入门"><a href="#Dstream入门" class="headerlink" title="Dstream入门"></a>Dstream入门</h2><h3 id="WordCount案例实操"><a href="#WordCount案例实操" class="headerlink" title="WordCount案例实操"></a>WordCount案例实操</h3><p>1．需求：使用netcat工具向9999端口不断的发送数据，通过SparkStreaming读取端口数据并统计不同单词出现的次数</p><p>2．添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-streaming_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．编写代码</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span>ReceiverInputDStream<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/5 下午 09:30 * @Description: 使用 SparkStreaming 完成 WordCount * @Modified: * @Version: */</span><span class="token keyword">object</span> SparkStreaming01_WordCount <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// Spark配置对象</span>        <span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"SparkStreaming01_WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 实时数据分析环境对象（第二个参数是采集周期：以指定时间为周期来采集数据）</span>        <span class="token keyword">val</span> streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 从指定端口中采集数据</span>        <span class="token keyword">val</span> lineStreams<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"hadoop102"</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">//将每一行数据做切分，形成一个个单词</span>        <span class="token keyword">val</span> wordStreams <span class="token operator">=</span> lineStreams<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>line <span class="token keyword">=></span> <span class="token punctuation">{</span>            line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">//将单词映射成元组（word,1）</span>        <span class="token keyword">val</span> wordAndOneStreams <span class="token operator">=</span> wordStreams<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">//将相同的单词次数做统计</span>        <span class="token keyword">val</span> wordAndCountStreams <span class="token operator">=</span> wordAndOneStreams<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">//打印</span>        wordAndCountStreams<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 此时因为是一直采集数据，所以不能停止</span><span class="token comment" spellcheck="true">//        streamingContext.stop</span>        <span class="token comment" spellcheck="true">//启动采集器</span>        streamingContext<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// driver等待采集器执行</span>        streamingContext<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在启动以上程序时，得先执行下一步打开hadoop102的9999端口，不然会出现连接失败</p><p>4．启动程序并通过NetCat发送数据：</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ nc -lk 9999<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输入以下内容</p><pre><code>hello bigData...</code></pre><p>查看idea执行窗口效果</p><p><strong>注意：</strong>如果程序运行时，log日志太多，可以将spark conf目录下的log4j文件里面的日志级别改成ERROR，如下：</p><p>[log4j.properties]</p><pre class="line-numbers language-xml"><code class="language-xml">    log4j.rootLogger=INFO, stdout    log4j.appender.stdout=org.apache.log4j.ConsoleAppender    log4j.appender.stdout.layout=org.apache.log4j.PatternLayout    log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n    log4j.appender.logfile=org.apache.log4j.FileAppender    log4j.appender.logfile.File=target/spring.log    log4j.appender.logfile.layout=org.apache.log4j.PatternLayout    log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="WordCount解析"><a href="#WordCount解析" class="headerlink" title="WordCount解析"></a>WordCount解析</h3><p>Discretized Stream是Spark Streaming的基础抽象，代表持续性的数据流和经过各种Spark原语操作后的结果数据流。在内部实现上，DStream是一系列连续的RDD来表示。每个RDD含有一段时间间隔内的数据，如下图：</p><p><img src="streaming1-4.png" alt></p><p>对数据的操作也是按照RDD为单位来进行的</p><p><img src="streaming1-5.png" alt></p><p>计算过程由Spark engine来完成</p><p><img src="streaming1-6.png" alt></p><h2 id="Dstream创建"><a href="#Dstream创建" class="headerlink" title="Dstream创建"></a>Dstream创建</h2><p>Spark Streaming原生支持一些不同的数据源。一些“核心”数据源已经被打包到Spark Streaming 的 Maven 工件中，而其他的一些则可以通过 spark-streaming-kafka 等附加工件获取。每个接收器都以 Spark 执行器程序中一个长期运行的任务的形式运行，因此会占据分配给应用的 CPU 核心。此外，我们还需要有可用的 CPU 核心来处理数据。这意味着如果要运行多个接收器，就必须至少有和接收器数目相同的核心数，还要加上用来完成计算所需要的核心数。例如，如果我们想要在流计算应用中运行 10 个接收器，那么至少需要为应用分配 11 个 CPU 核心。所以如果在本地模式运行，不要使用local[1]。</p><h3 id="文件数据源"><a href="#文件数据源" class="headerlink" title="文件数据源"></a>文件数据源</h3><h4 id="用法及说明"><a href="#用法及说明" class="headerlink" title="用法及说明"></a>用法及说明</h4><p>文件数据流：能够读取所有HDFS API兼容的文件系统文件，通过fileStream方法进行读取，Spark Streaming 将会监控 dataDirectory 目录并不断处理移动进来的文件，记住目前不支持嵌套目录。</p><p>streamingContext.textFileStream(dataDirectory)</p><p><strong>注意事项：</strong></p><p>1）文件需要有相同的数据格式；</p><p>2）文件进入 dataDirectory 的方式需要通过移动或者重命名来实现；</p><p>3）一旦文件移动进目录，则不能再修改，即便修改了也不会读取新数据；</p><h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><p>（1）在HDFS上建好目录</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ hadoop fs -mkdir /fileStream<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）在/opt/module/data创建三个文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 data]$ touch a.tsv[user_test@hadoop102 data]$ touch b.tsv[user_test@hadoop102 data]$ touch c.tsv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>添加如下数据：</p><pre><code>Hello bigDataHello spark</code></pre><p>（3）编写代码</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/5 下午 09:30 * @Description: 从文件中获取word进行统计 * @Modified: * @Version: */</span><span class="token keyword">object</span> SparkStreaming02_FileDataSource <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1.初始化Spark配置信息</span>        <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span>            <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"StreamWordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 2.初始化SparkStreamingContext</span>        <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 3.从指定文件夹中采集数据</span>        <span class="token keyword">val</span> dirStream <span class="token operator">=</span> ssc<span class="token punctuation">.</span>textFileStream<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/fileStream"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 4.将每一行数据做切分，形成一个个单词</span>        <span class="token keyword">val</span> wordStreams <span class="token operator">=</span> dirStream<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 5.将单词映射成元组（word,1）</span>        <span class="token keyword">val</span> wordAndOneStreams <span class="token operator">=</span> wordStreams<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 6.将相同的单词次数做统计</span>        <span class="token keyword">val</span> wordAndCountStreams<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordAndOneStreams<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 7.打印</span>        wordAndCountStreams<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 8.启动SparkStreamingContext</span>        ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>        ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）启动程序并向fileStream目录上传文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 data]$ hadoop fs -put ./a.tsv /fileStream[user_test@hadoop102 data]$ hadoop fs -put ./b.tsv /fileStream[user_test@hadoop102 data]$ hadoop fs -put ./c.tsv /fileStream<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）获取计算结果</p><pre><code>-------------------------------------------Time: 1601907425000 ms--------------------------------------------------------------------------------------Time: 1601907430000 ms-------------------------------------------(Hello,4)(spark,2)(bigData,2)-------------------------------------------Time: 1601907435000 ms-------------------------------------------(Hello,2)(spark,1)(bigData,1)</code></pre><h3 id="RDD队列（了解）"><a href="#RDD队列（了解）" class="headerlink" title="RDD队列（了解）"></a>RDD队列（了解）</h3><h4 id="用法及说明-1"><a href="#用法及说明-1" class="headerlink" title="用法及说明"></a>用法及说明</h4><p>测试过程中，可以通过使用ssc.queueStream(queueOfRDDs)来创建DStream，每一个推送到这个队列中的RDD，都会作为一个DStream处理。</p><h4 id="案例实操-1"><a href="#案例实操-1" class="headerlink" title="案例实操"></a>案例实操</h4><p>1）需求：循环创建几个RDD，将RDD放入队列。通过SparkStream创建Dstream，计算WordCount</p><p>2）编写代码</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> InputDStream<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span><span class="token keyword">import</span> scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable<span class="token keyword">object</span> RDDStream <span class="token punctuation">{</span>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//1.初始化Spark配置信息</span>    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"RDDStream"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//2.初始化SparkStreamingContext</span>    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>conf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//3.创建RDD队列</span>    <span class="token keyword">val</span> rddQueue <span class="token operator">=</span> <span class="token keyword">new</span> mutable<span class="token punctuation">.</span>Queue<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//4.创建QueueInputDStream</span>    <span class="token keyword">val</span> inputStream <span class="token operator">=</span> ssc<span class="token punctuation">.</span>queueStream<span class="token punctuation">(</span>rddQueue<span class="token punctuation">,</span>oneAtATime <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//5.处理队列中的RDD数据</span>    <span class="token keyword">val</span> mappedStream <span class="token operator">=</span> inputStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> reducedStream <span class="token operator">=</span> mappedStream<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//6.打印结果</span>    reducedStream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//7.启动任务</span>    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//8.循环创建并向RDD队列中放入RDD</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token keyword">&lt;-</span> <span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      rddQueue <span class="token operator">+=</span> ssc<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>      Thread<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）结果展示</p><pre><code>-------------------------------------------Time: 1539075280000 ms-------------------------------------------(4,60)(0,60)(6,60)(8,60)(2,60)(1,60)(3,60)(7,60)(9,60)(5,60)-------------------------------------------Time: 1539075284000 ms-------------------------------------------(4,60)(0,60)(6,60)(8,60)(2,60)(1,60)(3,60)(7,60)(9,60)(5,60)-------------------------------------------Time: 1539075288000 ms-------------------------------------------(4,30)(0,30)(6,30)(8,30)(2,30)(1,30)(3,30)(7,30)(9,30)(5,30)-------------------------------------------Time: 1539075292000 ms-------------------------------------------</code></pre><h3 id="自定义数据源"><a href="#自定义数据源" class="headerlink" title="自定义数据源"></a>自定义数据源</h3><h4 id="用法及说明-2"><a href="#用法及说明-2" class="headerlink" title="用法及说明"></a>用法及说明</h4><p>需要继承Receiver，并实现onStart、onStop方法来自定义数据源采集。</p><h4 id="案例实操-2"><a href="#案例实操-2" class="headerlink" title="案例实操"></a>案例实操</h4><p>1）需求：自定义数据源，实现监控某个端口号，获取该端口号内容。</p><p>2）自定义采集器并使用自定义的数据源采集数据</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token punctuation">{</span>BufferedReader<span class="token punctuation">,</span> InputStreamReader<span class="token punctuation">}</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>Socket<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span>StorageLevel<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>receiver<span class="token punctuation">.</span>Receiver<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/6 下午 12:30 * @Description: 自定义采集器 * @Modified: * @Version: */</span><span class="token keyword">object</span> SparkStreaming03_MyReceiver <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1.初始化Spark配置信息</span>        <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span>            <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"StreamWordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 2.初始化SparkStreamingContext</span>        <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 3.从指定文件夹中采集数据</span>        <span class="token keyword">val</span> receiverDStream<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span>receiverStream<span class="token punctuation">(</span><span class="token keyword">new</span> MyReceiver<span class="token punctuation">(</span><span class="token string">"hadoop102"</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 4.将每一行数据做切分，形成一个个单词</span>        <span class="token keyword">val</span> wordStreams <span class="token operator">=</span> receiverDStream<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 5.将单词映射成元组（word,1）</span>        <span class="token keyword">val</span> wordAndOneStreams <span class="token operator">=</span> wordStreams<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 6.将相同的单词次数做统计</span>        <span class="token keyword">val</span> wordAndCountStreams<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordAndOneStreams<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 7.打印</span>        wordAndCountStreams<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 8.启动SparkStreamingContext</span>        ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>        ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 声明采集器</span><span class="token comment" spellcheck="true">// 1. 继承Receiver</span><span class="token comment" spellcheck="true">// 2. 实现方法（onStart、onStop）</span><span class="token keyword">class</span> MyReceiver<span class="token punctuation">(</span>host<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> port<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Receiver<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> socket<span class="token operator">:</span> Socket <span class="token operator">=</span> _    <span class="token keyword">def</span> receive<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        socket <span class="token operator">=</span> <span class="token keyword">new</span> Socket<span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span>        <span class="token keyword">val</span> reader <span class="token operator">=</span> <span class="token keyword">new</span> BufferedReader<span class="token punctuation">(</span><span class="token keyword">new</span> InputStreamReader<span class="token punctuation">(</span>socket<span class="token punctuation">.</span>getInputStream<span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">var</span> line<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token keyword">null</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>line <span class="token operator">=</span> reader<span class="token punctuation">.</span>readLine<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 将采集的数据存储到采集器的内部进行转换</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span> <span class="token string">"END"</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>line<span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">return</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                <span class="token keyword">this</span><span class="token punctuation">.</span>store<span class="token punctuation">(</span>line<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> onStart<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">new</span> Thread<span class="token punctuation">(</span><span class="token keyword">new</span> Runnable <span class="token punctuation">{</span>            <span class="token keyword">override</span> <span class="token keyword">def</span> run<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>                receive<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> onStop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>socket <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            socket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>            socket <span class="token operator">=</span> <span class="token keyword">null</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Kafka数据源（重点）"><a href="#Kafka数据源（重点）" class="headerlink" title="Kafka数据源（重点）"></a>Kafka数据源（重点）</h3><h4 id="用法及说明-3"><a href="#用法及说明-3" class="headerlink" title="用法及说明"></a>用法及说明</h4><p>在工程中需要引入 Maven 工件 spark- streaming-kafka_2.10 来使用它。包内提供的 KafkaUtils 对象可以在 StreamingContext 和 JavaStreamingContext 中以你的 Kafka 消息创建出 DStream。由于 KafkaUtils 可以订阅多个主题，因此它创建出的 DStream 由成对的主题和消息组成。要创建出一个流数据，需要使用 StreamingContext 实例、一个由逗号隔开的 ZooKeeper 主机列表字符串、消费者组的名字(唯一名字)，以及一个从主题到针对这个主题的接收器线程数的映射表来调用 createStream() 方法。</p><h4 id="案例实操-3"><a href="#案例实操-3" class="headerlink" title="案例实操"></a>案例实操</h4><p>需求：通过SparkStreaming从Kafka读取数据，并将读取过来的数据做简单计算(WordCount)，最终打印到控制台。</p><p>（1）导入依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-streaming-kafka-0-8_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>0.11.0.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写代码</p><p>由于当前未配KafKa，所以还没尝试</p><h2 id="DStream转换"><a href="#DStream转换" class="headerlink" title="DStream转换"></a>DStream转换</h2><p>DStream上的原语与RDD的类似，分为Transformations（转换）和Output Operations（输出）两种，此外转换操作中还有一些比较特殊的原语，如：updateStateByKey()、transform()以及各种Window相关的原语。</p><h3 id="无状态转化操作"><a href="#无状态转化操作" class="headerlink" title="无状态转化操作"></a>无状态转化操作</h3><p>无状态转化操作就是把简单的RDD转化操作应用到每个批次上，也就是转化DStream中的每一个RDD。部分无状态转化操作列在了下表中。</p><p><img src="streaming4-1.png" alt></p><p><strong>注意：</strong>针对键值对的DStream转化操作(比如 reduceByKey())要添加以下引用才可使用</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">import</span> StreamingContext<span class="token punctuation">.</span>_ <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要记住的是，尽管这些函数看起来像作用在整个流上一样，但事实上每个DStream在内部是由许多RDD(批次)组成，且无状态转化操作是分别应用到每个RDD上的。例如，reduceByKey()会归约每个时间区间中的数据，但不会归约不同区间之间的数据。 </p><p>举个例子，在之前的wordcount程序中，我们只会统计5秒内接收到的数据的单词个数，而不会累加。 </p><p>无状态转化操作也能在多个DStream间整合数据，不过也是在各个时间区间内。例如，键 值对DStream拥有和RDD一样的与连接相关的转化操作，也就是cogroup()、join()、leftOuterJoin() 等。我们可以在DStream上使用这些操作，这样就对每个批次分别执行了对应的RDD操作。</p><p>我们还可以像在常规的Spark 中一样使用 DStream的union() 操作将它和另一个DStream 的内容合并起来，也可以使用StreamingContext.union()来合并多个流。 </p><h3 id="有状态转化操作（重点）"><a href="#有状态转化操作（重点）" class="headerlink" title="有状态转化操作（重点）"></a>有状态转化操作（重点）</h3><h5 id="UpdateStateByKey"><a href="#UpdateStateByKey" class="headerlink" title="UpdateStateByKey"></a>UpdateStateByKey</h5><p>UpdateStateByKey原语用于记录历史记录，有时，我们需要在 DStream 中跨批次维护状态(例如流计算中累加wordcount)。针对这种情况，updateStateByKey() 为我们提供了对一个状态变量的访问，用于键值对形式的 DStream。给定一个由(键，事件)对构成的 DStream，并传递一个指定如何根据新的事件 更新每个键对应状态的函数，它可以构建出一个新的 DStream，其内部数据为(键，状态) 对。 </p><p>updateStateByKey() 的结果会是一个新的 DStream，其内部的 RDD 序列是由每个时间区间对应的(键，状态)对组成的。</p><p>updateStateByKey操作使得我们可以在用新信息进行更新时保持任意的状态。使用这个功能，需要做下面两步： </p><ol><li><p>定义状态，状态可以是一个任意的数据类型。 </p></li><li><p>定义状态更新函数，用此函数阐明如何使用之前的状态和来自输入流的新值对状态进行更新。</p></li></ol><p>使用updateStateByKey需要对检查点目录进行配置，会使用检查点来保存状态。</p><p>更新版的wordcount：</p><p>（1）编写代码</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token punctuation">{</span>BufferedReader<span class="token punctuation">,</span> InputStreamReader<span class="token punctuation">}</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>Socket<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span>StorageLevel<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>receiver<span class="token punctuation">.</span>Receiver<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/6 14:25 * @Description: 有状态数据统计 * @Modified: * @Version: */</span><span class="token keyword">object</span> SparkStreaming04_UpdateState <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 定义更新状态方法，参数values为当前批次单词频度，state为以往批次单词频度</span>        <span class="token keyword">val</span> updateFunc <span class="token operator">=</span> <span class="token punctuation">(</span>values<span class="token operator">:</span> Seq<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> state<span class="token operator">:</span> Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> currentCount <span class="token operator">=</span> values<span class="token punctuation">.</span>foldLeft<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>            <span class="token keyword">val</span> previousCount <span class="token operator">=</span> state<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            Some<span class="token punctuation">(</span>currentCount <span class="token operator">+</span> previousCount<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"NetworkWordCount"</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>conf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 保存数据状态需要设置检查点路径</span>        ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">"/streamCheck"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// Create a DStream that will connect to hostname:port, like hadoop102:9999</span>        <span class="token keyword">val</span> lines <span class="token operator">=</span> ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"hadoop102"</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// Split each line into words</span>        <span class="token keyword">val</span> words <span class="token operator">=</span> lines<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">//import org.apache.spark.streaming.StreamingContext._ // not necessary since Spark 1.3</span>        <span class="token comment" spellcheck="true">// Count each word in each batch</span>        <span class="token keyword">val</span> pairs <span class="token operator">=</span> words<span class="token punctuation">.</span>map<span class="token punctuation">(</span>word <span class="token keyword">=></span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 使用updateStateByKey来更新状态，统计从运行开始以来单词总的次数</span>        <span class="token keyword">val</span> stateDstream <span class="token operator">=</span> pairs<span class="token punctuation">.</span>updateStateByKey<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span>updateFunc<span class="token punctuation">)</span>        stateDstream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">//val wordCounts = pairs.reduceByKey(_ + _)</span>        <span class="token comment" spellcheck="true">// Print the first ten elements of each RDD generated in this DStream to the console</span>        <span class="token comment" spellcheck="true">//wordCounts.print()</span>        ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>             <span class="token comment" spellcheck="true">// Start the computation</span>        ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">// Wait for the computation to terminate</span>        <span class="token comment" spellcheck="true">//ssc.stop()</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）启动程序并向9999端口发送数据</p><pre class="line-numbers language-shell"><code class="language-shell">[atguigu@hadoop102 kafka]$ nc -lk 9999ni shi shuini hao ma<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）结果展示</p><pre><code>-------------------------------------------Time: 1601967225000 ms--------------------------------------------------------------------------------------Time: 1601967228000 ms-------------------------------------------(shi,1)(shui,1)(ni,1)-------------------------------------------Time: 1601967231000 ms-------------------------------------------(shi,1)(ma,1)(hao,1)(shui,1)(ni,2)</code></pre><h4 id="Window-Operations"><a href="#Window-Operations" class="headerlink" title="Window Operations"></a>Window Operations</h4><p>Window Operations可以设置窗口的大小和滑动窗口的间隔来动态的获取当前Steaming的允许状态。基于窗口的操作会在一个比 StreamingContext 的批次间隔更长的时间范围内，通过整合多个批次的结果，计算出整个窗口的结果。 </p><p><img src="streaming4-2.png" alt></p><p><strong>注意：</strong>所有基于窗口的操作都需要两个参数，分别为窗口时长以及滑动步长，两者都必须是 StreamContext 的采集周期的整数倍。</p><p>窗口时长控制每次计算最近的多少个批次的数据，其实就是最近的 windowDuration/batchInterval 个批次。如果有一个以 10 秒为批次间隔的源 DStream，要创建一个最近 30 秒的时间窗口(即最近 3 个批次)，就应当把 windowDuration 设为 30 秒。而滑动步长的默认值与批次间隔相等，用来控制对新的 DStream 进行计算的间隔。如果源 DStream 批次间隔为 10 秒，并且我们只希望每两个批次计算一次窗口结果， 就应该把滑动步长设置为 20 秒。 </p><p>假设，你想拓展前例从而每隔十秒对持续30秒的数据生成word count。为做到这个，我们需要在持续30秒数据的(word,1)对DStream上应用reduceByKey。使用操作reduceByKeyAndWindow。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 以上所说例子</span>windowedWordCounts <span class="token operator">=</span> pairs<span class="token punctuation">.</span>reduceByKeyAndWindow<span class="token punctuation">(</span>lambda x<span class="token punctuation">,</span> y<span class="token operator">:</span> x <span class="token operator">+</span> y<span class="token punctuation">,</span> lambda x<span class="token punctuation">,</span> y<span class="token operator">:</span> x <span class="token operator">-</span>y<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>例子：</strong>采集周期是3s，一共采集了三次，在第一次中有2个hello，第二次中有3个hello，第三次中有1个hello。窗口大小是9s，每3s滑动一次，hello统计出现情况是：2 5 6 4 1</p><p>因为窗口从开始逐渐进来，最后又走出去，试一个逐渐由少到多再到少的过程。</p><p>关于Window的操作有如下原语：</p><p>（1）window(windowLength, slideInterval)：基于对源DStream窗化的批次进行计算返回一个新的Dstream</p><p>（2）countByWindow(windowLength, slideInterval)：返回一个滑动窗口计数流中的元素。</p><p>（3）reduceByWindow(func, windowLength, slideInterval)：通过使用自定义函数整合滑动区间流元素来创建一个新的单元素流。</p><p>（4）reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks])：当在一个(K,V)对的DStream上调用此函数，会返回一个新(K,V)对的DStream，此处通过对滑动窗口中批次数据使用reduce函数来整合每个key的value值。Note:默认情况下，这个操作使用Spark的默认数量并行任务(本地是2)，在集群模式中依据配置属性(spark.default.parallelism)来做grouping。你可以通过设置可选参数numTasks来设置不同数量的tasks。</p><p>（5）reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval, [numTasks])：这个函数是上述函数的更高效版本，每个窗口的reduce值都是通过用前一个窗的reduce值来递增计算。通过reduce进入到滑动窗口数据并”反向reduce”离开窗口的旧数据来实现这个操作。一个例子是随着窗口滑动对keys的“加”“减”计数。通过前边介绍可以想到，这个函数只适用于”可逆的reduce函数”，也就是这些reduce函数有相应的”反reduce”函数(以参数invFunc形式传入)。如前述函数，reduce任务的数量通过可选参数来配置。注意：为了使用这个操作，检查点必须可用。 </p><p>（6）countByValueAndWindow(windowLength,slideInterval, [numTasks])：对(K,V)对的DStream调用，返回(K,Long)对的新DStream，其中每个key的值是其在滑动窗口中频率。如上，可配置reduce任务数量。</p><p>reduceByWindow() 和 reduceByKeyAndWindow() 让我们可以对每个窗口更高效地进行归约操作。它们接收一个归约函数，在整个窗口上执行，比如 +。除此以外，它们还有一种特殊形式，通过只考虑新进入窗口的数据和离开窗口的数据，让 Spark 增量计算归约结果。这种特殊形式需要提供归约函数的一个逆函数，比 如 + 对应的逆函数为 -。对于较大的窗口，提供逆函数可以大大提高执行效率 </p><h3 id="其他重要操作"><a href="#其他重要操作" class="headerlink" title="其他重要操作"></a>其他重要操作</h3><h4 id="Transform"><a href="#Transform" class="headerlink" title="Transform"></a>Transform</h4><p>Transform原语允许DStream上执行任意的RDD-to-RDD函数。即使这些函数并没有在DStream的API中暴露出来，通过该函数可以方便的扩展Spark API。该函数每一批次调度一次。其实也就是对DStream中的RDD应用转换。</p><p>map和transform区别</p><pre class="line-numbers language-scala"><code class="language-scala">        <span class="token comment" spellcheck="true">// 在此处写的代码是在driver中执行，只会执行一次</span>        lineStreams<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">{</span>            <span class="token keyword">case</span> x <span class="token keyword">=></span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 在此处写的代码是在executor中执行，会执行n次（几个executor就会执行几次）</span>                x            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 转换</span>        <span class="token comment" spellcheck="true">// 在此处写的代码是在driver中执行，只会执行一次</span>        lineStreams<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">{</span>            <span class="token keyword">case</span> rdd <span class="token keyword">=></span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 在此处写的代码是在 driver 中执行，会执行 m 次（每个采集周期中执行一次）</span>                rdd<span class="token punctuation">.</span>map<span class="token punctuation">{</span>                    <span class="token keyword">case</span> x <span class="token keyword">=></span> <span class="token punctuation">{</span>                        <span class="token comment" spellcheck="true">// 在此处写的代码是在executor中执行，会执行n次（几个executor就会执行几次）</span>                        x                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>比如下面的例子，在进行单词统计的时候，想要过滤掉spam的数据，就要每个周期过滤一下。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> spamInfoRDD <span class="token operator">=</span> ssc<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>newAPIHadoopRDD<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// RDD containing spam information</span><span class="token keyword">val</span> cleanedDStream <span class="token operator">=</span> wordCounts<span class="token punctuation">.</span>transform <span class="token punctuation">{</span> rdd <span class="token keyword">=></span>  rdd<span class="token punctuation">.</span>join<span class="token punctuation">(</span>spamInfoRDD<span class="token punctuation">)</span><span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// join data stream with spam information to do data cleaning</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h4><p>连接操作（leftOuterJoin, rightOuterJoin, fullOuterJoin也可以），可以连接Stream-Stream，windows-stream to windows-stream、stream-dataset</p><p>Stream-Stream Joins</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> stream1<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">val</span> stream2<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">val</span> joinedStream <span class="token operator">=</span> stream1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>stream2<span class="token punctuation">)</span><span class="token keyword">val</span> windowedStream1 <span class="token operator">=</span> stream1<span class="token punctuation">.</span>window<span class="token punctuation">(</span>Seconds<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">val</span> windowedStream2 <span class="token operator">=</span> stream2<span class="token punctuation">.</span>window<span class="token punctuation">(</span>Minutes<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">val</span> joinedStream <span class="token operator">=</span> windowedStream1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>windowedStream2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Stream-dataset joins</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> dataset<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">val</span> windowedStream <span class="token operator">=</span> stream<span class="token punctuation">.</span>window<span class="token punctuation">(</span>Seconds<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">val</span> joinedStream <span class="token operator">=</span> windowedStream<span class="token punctuation">.</span>transform <span class="token punctuation">{</span> rdd <span class="token keyword">=></span> rdd<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>跟RDD的join是一样的，不再累述。</p><h2 id="DStream输出"><a href="#DStream输出" class="headerlink" title="DStream输出"></a>DStream输出</h2><p>输出操作指定了对流数据经转化操作得到的数据所要执行的操作(例如把结果推入外部数据库或输出到屏幕上)。与RDD中的惰性求值类似，如果一个DStream及其派生出的DStream都没有被执行输出操作，那么这些DStream就都不会被求值。如果StreamingContext中没有设定输出操作，整个context就都不会启动。 </p><p>输出操作如下：</p><p>（1）print()：在运行流程序的驱动结点上打印DStream中每一批次数据的最开始10个元素。这用于开发和调试。在Python API中，同样的操作叫print()。</p><p>（2）saveAsTextFiles(prefix, [suffix])：以text文件形式存储这个DStream的内容。每一批次的存储文件名基于参数中的prefix和suffix。”prefix-Time_IN_MS[.suffix]”. </p><p>（3）saveAsObjectFiles(prefix, [suffix])：以Java对象序列化的方式将Stream中的数据保存为 SequenceFiles . 每一批次的存储文件名基于参数中的为”prefix-TIME_IN_MS[.suffix]”. Python中目前不可用。</p><p>（4）saveAsHadoopFiles(prefix, [suffix])：将Stream中的数据保存为 Hadoop files. 每一批次的存储文件名基于参数中的为”prefix-TIME_IN_MS[.suffix]”。</p><p>Python API Python中目前不可用。</p><p>（5）foreachRDD(func)：这是最通用的输出操作，即将函数 func 用于产生于 stream的每一个RDD。其中参数传入的函数func应该实现将每一个RDD中数据推送到外部系统，如将RDD存入文件或者通过网络将其写入数据库。注意：函数func在运行流应用的驱动中被执行，同时其中一般函数RDD操作从而强制其对于流RDD的运算。</p><p>通用的输出操作foreachRDD()，它用来对DStream中的RDD运行任意计算。这和transform() 有些类似，都可以让我们访问任意RDD。在foreachRDD()中，可以重用我们在Spark中实现的所有行动操作。</p><p><strong>注：</strong>在一个DStream中可能有一个也可能有多个RDD（一个采集周期形成一个RDD，然后封装成DStream；若有多个采集周期，那么就会有多个RDD然后封装成一个DStream），而这个foreachRDD就是用来遍历DStream中多个RDD的，如下：</p><pre class="line-numbers language-scala"><code class="language-scala">lineDStream<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd <span class="token keyword">=></span> <span class="token punctuation">{</span>    rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>比如，常见的用例之一是把数据写到诸如MySQL的外部数据库中。 注意：</p><p>（1）连接不能写在driver层面（connection无法序列化）；</p><p>（2）如果写在foreach则每个RDD都创建，得不偿失；</p><p>（3）增加foreachPartition，在分区创建。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkStreaming </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SparkSQL</title>
      <link href="2020/10/06/sparksql/"/>
      <url>2020/10/06/sparksql/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkSQL"><a href="#SparkSQL" class="headerlink" title="SparkSQL"></a>SparkSQL</h1><h2 id="Spark-SQL概述"><a href="#Spark-SQL概述" class="headerlink" title="Spark SQL概述"></a>Spark SQL概述</h2><h3 id="什么是Spark-SQL"><a href="#什么是Spark-SQL" class="headerlink" title="什么是Spark SQL"></a>什么是Spark SQL</h3><p>Spark SQL是Spark用来处理结构化数据的一个模块，它提供了2个编程抽象：DataFrame和DataSet，并且作为分布式SQL查询引擎的作用（DataFrame当表来用，DataSet当对象来用）。</p><p><strong>注：</strong>本来spark是没有数据结构的（最多是一个k-v，但是没有什么确定的name age之类的）</p><p>它是将Hive SQL转换成MapReduce然后提交到集群上执行，大大简化了编写MapReduc的程序的复杂性，由于MapReduce这种计算模型执行效率比较慢。所有Spark SQL的应运而生，它是将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！</p><h3 id="Spark-SQL的特点"><a href="#Spark-SQL的特点" class="headerlink" title="Spark SQL的特点"></a>Spark SQL的特点</h3><p>1）易整合</p><p>2）统一的数据访问方式</p><p>3）兼容Hive</p><p>4）标准的数据连接</p><h3 id="什么是DataFrame"><a href="#什么是DataFrame" class="headerlink" title="什么是DataFrame"></a>什么是DataFrame</h3><p>与RDD类似，DataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好。</p><p><img src="1-1.png" alt="DataFrame和RDD的区别"></p><p>左侧的RDD[Person]虽然以Person为类型参数，但Spark框架本身不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得Spark SQL可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待，DataFrame也是懒执行的。性能上比RDD要高，主要原因：</p><p>优化的执行计划：查询计划通过Spark catalyst optimiser进行优化。</p><pre class="line-numbers language-scala"><code class="language-scala">users<span class="token punctuation">.</span>join<span class="token punctuation">(</span>events<span class="token punctuation">,</span> users<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span> <span class="token operator">==</span><span class="token operator">=</span> events<span class="token punctuation">(</span><span class="token string">"uid"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>filter<span class="token punctuation">(</span>events<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"2020-10-04"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="1-2.png" alt></p><p>其中第一幅为我们自己写RDD时，所写的，可以实现合并过滤功能，但是中间会有很多无用的shuffle过程大大降低了效率。后面两幅是逐渐的优化。</p><p>图中构造了两个DataFrame，将它们join之后又做了一次filter操作。如果原封不动地执行这个执行计划，最终的执行效率是不高的。因为join是一个代价较大的操作，也可能会产生一个较大的数据集。如果我们能将filter下推到 join下方，先对DataFrame进行过滤，再join过滤后的较小的结果集，便可以有效缩短执行时间。而Spark SQL的查询优化器正是这样做的。简而言之，逻辑查询计划优化就是一个利用基于关系代数的等价变换，将高成本的操作替换为低成本操作的过程。 </p><h3 id="什么是DataSet"><a href="#什么是DataSet" class="headerlink" title="什么是DataSet"></a>什么是DataSet</h3><p>1）是Dataframe API的一个扩展，是Spark最新的数据抽象。</p><p>2）用户友好的API风格，既具有类型安全检查也具有Dataframe的查询优化特性。</p><p>3）Dataset支持编解码器，当需要访问非堆上的数据时可以避免反序列化整个对象，提高了效率。</p><p>4）样例类被用来在Dataset中定义数据的结构信息，样例类中每个属性的名称直接映射到DataSet中的字段名称。</p><p>5） Dataframe是Dataset的特列，DataFrame=Dataset[Row] ，所以可以通过as方法将Dataframe转换为Dataset。Row是一个类型，跟Car、Person这些的类型一样，所有的表结构信息我都用Row来表示。</p><p>6）DataSet是强类型的。比如可以有Dataset[Car]，Dataset[Person].</p><p>7）DataFrame只是知道字段，但是不知道字段的类型，所以在执行这些操作的时候是没办法在编译的时候检查是否类型失败的，比如你可以对一个String进行减法操作，在执行的时候才报错，而DataSet不仅仅知道字段，而且知道字段类型，所以有更严格的错误检查。就跟JSON对象和类对象之间的类比。</p><p><img src="2-1.png" alt="DataSet和DataFrame和RDD的关系"></p><p>RDD加上了关系就成了 DataFrame，DataFrame加上了类和属性就成了DataSet</p><h2 id="SparkSQL编程"><a href="#SparkSQL编程" class="headerlink" title="SparkSQL编程"></a>SparkSQL编程</h2><h3 id="SparkSession新的起始点"><a href="#SparkSession新的起始点" class="headerlink" title="SparkSession新的起始点"></a>SparkSession新的起始点</h3><p>在老的版本中，SparkSQL提供两种SQL查询起始点：一个叫SQLContext，用于Spark自己提供的SQL查询；一个叫HiveContext，用于连接Hive的查询。</p><p>SparkSession是Spark最新的SQL查询起始点，实质上是SQLContext和HiveContext的组合，所以在SQLContext和HiveContext上可用的API在SparkSession上同样是可以使用的。SparkSession内部封装了sparkContext，所以计算实际上是由sparkContext完成的。</p><h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><p>在Spark SQL中SparkSession是创建DataFrame和执行SQL的入口，创建DataFrame有三种方式：通过Spark的数据源进行创建；从一个存在的RDD进行转换；还可以从Hive Table进行查询返回。</p><p>1）从Spark数据源进行创建</p><p>（1）查看Spark数据源进行创建的文件格式</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>——<span class="token operator">></span><span class="token comment" spellcheck="true">// 可读取文件格式</span>csv   format   jdbc   json   load   option   options   orc   parquet   schema   table   text   textFile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）读取json文件创建DataFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"file///opt/module/spark/data/input/user.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token comment" spellcheck="true">// 直接得到了DataFrame并获得了字段</span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）展示结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）从RDD进行转换</p><p>后面用到细说</p><p>3）从Hive Table进行查询返回</p><p>hive数据库那节会细说</p><h4 id="SQL风格语法-主要"><a href="#SQL风格语法-主要" class="headerlink" title="SQL风格语法(主要)"></a>SQL风格语法(主要)</h4><p>1）创建一个DataFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"file///opt/module/spark/data/input/user.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）对DataFrame创建一个临时视图（之所以叫临时视图不叫临时表是因为RDD是不可变的，表是可变的，视图是不可变的）就可以用sql来进行查询了</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"student"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）通过SQL语句实现查询全表</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> sqlDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select * from student"</span><span class="token punctuation">)</span>——<span class="token operator">></span>sqlDF<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）结果展示</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> sqlDF<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>scala<span class="token operator">></span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select age from student"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>scala<span class="token operator">></span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select avg(age) from student"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> avg<span class="token punctuation">(</span>age<span class="token punctuation">)</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>     <span class="token number">20.0</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：临时表是Session范围内的，Session退出后，表就失效了。如果想应用范围内有效，可以使用全局表。注意使用全局表时需要全路径访问，如：global_temp.student</p><p>5）对于DataFrame创建一个全局表</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>createGlobalTempView<span class="token punctuation">(</span><span class="token string">"student"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）通过SQL语句实现查询全表</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM global_temp.student"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>scala<span class="token operator">></span> spark<span class="token punctuation">.</span>newSession<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM global_temp.student"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="DSL风格语法-次要"><a href="#DSL风格语法-次要" class="headerlink" title="DSL风格语法(次要)"></a>DSL风格语法(次要)</h4><p>1）创建一个DateFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>——<span class="token operator">></span>csv   format   jdbc   json   load   option   options   orc   parquet   schema   table   text   textFile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）查看DataFrame的Schema信息</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>printSchema——<span class="token operator">></span>root <span class="token operator">|</span><span class="token operator">--</span> age<span class="token operator">:</span> long <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">|</span><span class="token operator">--</span> name<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）只查看”name”列数据</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）查看”name”列数据以及”age+1”数据</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"name"</span><span class="token punctuation">,</span> $<span class="token string">"age"</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>   name<span class="token operator">|</span><span class="token punctuation">(</span>age <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>Michael<span class="token operator">|</span>     <span class="token keyword">null</span><span class="token operator">|</span><span class="token operator">|</span>   Andy<span class="token operator">|</span>       <span class="token number">31</span><span class="token operator">|</span><span class="token operator">|</span> Justin<span class="token operator">|</span>       <span class="token number">20</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）查看”age”大于”21”的数据</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">"age"</span> <span class="token operator">></span> <span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span>age<span class="token operator">|</span>name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span> <span class="token number">30</span><span class="token operator">|</span>Andy<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6）按照”age”分组，查看数据条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span> count<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span>     <span class="token number">1</span><span class="token operator">|</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>     <span class="token number">1</span><span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>     <span class="token number">1</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="RDD转换为DateFrame"><a href="#RDD转换为DateFrame" class="headerlink" title="RDD转换为DateFrame"></a>RDD转换为DateFrame</h4><p><strong>注意：</strong>如果需要RDD与DF或者DS之间操作，那么都需要引入 import spark.implicits._  (spark不是包名，而是sparkSession对象的名称)</p><p>前置条件：导入隐式转换并创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">import</span> spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span>_——<span class="token operator">></span><span class="token keyword">import</span> spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span>_scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"zhangsan"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"lisi"</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">"wangwu"</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>1）通过手动确定转换</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span>rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"age"</span><span class="token punctuation">)</span>——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>id<span class="token operator">:</span> int<span class="token punctuation">,</span> name<span class="token operator">:</span> string <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">1</span> more field<span class="token punctuation">]</span>scala<span class="token operator">></span> df<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> id<span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>  <span class="token number">1</span><span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">30</span><span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">3</span><span class="token operator">|</span>  wangwu<span class="token operator">|</span> <span class="token number">40</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）通过反射确定（需要用到样例类）</p><p>（1）创建一个样例类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">case</span> <span class="token keyword">class</span> People<span class="token punctuation">(</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span>——<span class="token operator">></span>defined <span class="token keyword">class</span> People<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）根据样例类将RDD转换为DataFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"zhangsan"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"lisi"</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"wangwu"</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span>scala<span class="token operator">></span> <span class="token keyword">val</span> peopleRDD <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>t<span class="token keyword">=></span><span class="token punctuation">{</span>People<span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>——<span class="token operator">></span>peopleRDD<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>People<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span>scala<span class="token operator">></span> peopleRDD<span class="token punctuation">.</span>toDF——<span class="token operator">></span>res2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> int<span class="token punctuation">]</span>scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> peopleRDD<span class="token punctuation">.</span>toDF——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> int<span class="token punctuation">]</span>scala<span class="token operator">></span> df<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span><span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">30</span><span class="token operator">|</span><span class="token operator">|</span>  wangwu<span class="token operator">|</span> <span class="token number">40</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）通过编程的方式（了解）</p><p>（1）导入所需的类型</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span>_——<span class="token operator">></span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span>_<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建Schema</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> structType<span class="token operator">:</span> StructType <span class="token operator">=</span> StructType<span class="token punctuation">(</span>StructField<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> StringType<span class="token punctuation">)</span> <span class="token operator">:</span><span class="token operator">:</span> StructField<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span> IntegerType<span class="token punctuation">)</span> <span class="token operator">:</span><span class="token operator">:</span> Nil<span class="token punctuation">)</span>——<span class="token operator">></span>structType<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span>StructType <span class="token operator">=</span> StructType<span class="token punctuation">(</span>StructField<span class="token punctuation">(</span>name<span class="token punctuation">,</span>StringType<span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">,</span> StructField<span class="token punctuation">(</span>age<span class="token punctuation">,</span>IntegerType<span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）导入所需的类型</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）根据给定的类型创建二元组RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> data <span class="token operator">=</span> peopleRDD<span class="token punctuation">.</span>map<span class="token punctuation">{</span> x <span class="token keyword">=></span> <span class="token keyword">val</span> para <span class="token operator">=</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Row<span class="token punctuation">(</span>para<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>para<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">}</span>data<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">33</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）根据数据及给定的schema创建DataFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> dataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> structType<span class="token punctuation">)</span>dataFrame<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> int<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="DateFrame转换为RDD"><a href="#DateFrame转换为RDD" class="headerlink" title="DateFrame转换为RDD"></a>DateFrame转换为RDD</h4><p>直接调用rdd即可</p><p>1）创建一个DataFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"/opt/module/spark/examples/src/main/resources/people.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）将DataFrame转换为RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> dfToRDD <span class="token operator">=</span> df<span class="token punctuation">.</span>rdddfToRDD<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at rdd at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">29</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）打印RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> dfToRDD<span class="token punctuation">.</span>collectres13<span class="token operator">:</span> Array<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">[</span>Michael<span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>Andy<span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>Justin<span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><p>Dataset是具有强类型的数据集合，需要提供对应的类型信息。</p><h4 id="创建-1"><a href="#创建-1" class="headerlink" title="创建"></a>创建</h4><p>1）创建一个样例类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span>——<span class="token operator">></span>defined <span class="token keyword">class</span> Person<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）创建DataSet</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> caseClassDS <span class="token operator">=</span> Seq<span class="token punctuation">(</span>Person<span class="token punctuation">(</span><span class="token string">"Andy"</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>caseClassDS<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> bigint<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）查看</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> caseClassDS<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>name<span class="token operator">|</span>age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>Andy<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="RDD转换为DataSet"><a href="#RDD转换为DataSet" class="headerlink" title="RDD转换为DataSet"></a>RDD转换为DataSet</h4><p>SparkSQL能够自动将包含有case类的RDD转换成DataFrame，case类定义了table的结构，case类属性通过反射变成了表的列名。</p><p>1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"zhangsan"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"lisi"</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"wangwu"</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）创建一个样例类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span>——<span class="token operator">></span>defined <span class="token keyword">class</span> Person<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）将RDD转化为DataSet</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> mapRDD <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>t <span class="token keyword">=></span> <span class="token punctuation">{</span>Person<span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>——<span class="token operator">></span>mapRDD<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span>scala<span class="token operator">></span> mapRDD<span class="token punctuation">.</span>toDS<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span><span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">30</span><span class="token operator">|</span><span class="token operator">|</span>  wangwu<span class="token operator">|</span> <span class="token number">40</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="DataSet转换为RDD"><a href="#DataSet转换为RDD" class="headerlink" title="DataSet转换为RDD"></a>DataSet转换为RDD</h4><p>调用rdd方法即可。</p><p>1）创建一个DataSet</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> DS <span class="token operator">=</span> Seq<span class="token punctuation">(</span>Person<span class="token punctuation">(</span><span class="token string">"Andy"</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>DS<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> bigint<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）将DataSet转换为RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> DS<span class="token punctuation">.</span>rdd——<span class="token operator">></span>res11<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span> at rdd at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="DataFrame与DataSet的互操作"><a href="#DataFrame与DataSet的互操作" class="headerlink" title="DataFrame与DataSet的互操作"></a>DataFrame与DataSet的互操作</h3><ol><li>DataFrame转换为DataSet</li></ol><p>1）创建一个DateFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"examples/src/main/resources/people.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）创建一个样例类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span>——<span class="token operator">></span>defined <span class="token keyword">class</span> Person<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）将DateFrame转化为DataSet</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>as<span class="token punctuation">[</span>Person<span class="token punctuation">]</span>——<span class="token operator">></span>res14<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="2"><li>DataSet转换为DataFrame</li></ol><p>1）创建一个样例类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span>——<span class="token operator">></span>defined <span class="token keyword">class</span> Person<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）创建DataSet</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> ds <span class="token operator">=</span> Seq<span class="token punctuation">(</span>Person<span class="token punctuation">(</span><span class="token string">"Andy"</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>ds<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> bigint<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）将DataSet转化为DataFrame</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> ds<span class="token punctuation">.</span>toDF——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> bigint<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）展示</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> df<span class="token punctuation">.</span>show——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>name<span class="token operator">|</span>age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span>Andy<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="DataSet转DataFrame"><a href="#DataSet转DataFrame" class="headerlink" title="DataSet转DataFrame"></a>DataSet转DataFrame</h4><p>这个很简单，因为只是把case class封装成Row</p><p>（1）导入隐式转换</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">import</span> spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span>_<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）转换</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> testDF <span class="token operator">=</span> testDS<span class="token punctuation">.</span>toDF<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="DataFrame转DataSet"><a href="#DataFrame转DataSet" class="headerlink" title="DataFrame转DataSet"></a>DataFrame转DataSet</h4><p>（1）导入隐式转换</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">import</span> spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span>_<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建样例类</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">case</span> <span class="token keyword">class</span> Coltest<span class="token punctuation">(</span>col1<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>col2<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token keyword">extends</span> Serializable <span class="token comment" spellcheck="true">//定义字段名和类型</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）转换</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> testDS <span class="token operator">=</span> testDF<span class="token punctuation">.</span>as<span class="token punctuation">[</span>Coltest<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这种方法就是在给出每一列的类型后，使用as方法，转成Dataset，这在数据类型是DataFrame又需要针对各个字段处理时极为方便。在使用一些特殊的操作时，一定要加上 import spark.implicits._ 不然toDF、toDS无法使用。</p><p><img src="2-2.png" alt></p><p>RDD加上结构就是DF，DF加上类型就是DS ——&gt; RDD加上类就是DS</p><h3 id="RDD、DataFrame、DataSet"><a href="#RDD、DataFrame、DataSet" class="headerlink" title="RDD、DataFrame、DataSet"></a>RDD、DataFrame、DataSet</h3><p>在SparkSQL中Spark为我们提供了两个新的抽象，分别是DataFrame和DataSet。</p><p>DF、DS和RDD区别：</p><p>版本的产生：RDD (Spark1.0) —&gt; Dataframe(Spark1.3) —&gt; Dataset(Spark1.6)</p><p>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。</p><p>在后期的Spark版本中，DataSet会逐步取代RDD和DataFrame成为唯一的API接口。</p><h4 id="三者的共性"><a href="#三者的共性" class="headerlink" title="三者的共性"></a>三者的共性</h4><ol><li><p>RDD、DataFrame、Dataset全都是spark平台下的分布式弹性数据集，为处理超大型数据提供便利</p></li><li><p>三者都有惰性机制，在进行创建、转换，如map方法时，不会立即执行，只有在遇到Action如foreach时，三者才会开始遍历运算。</p></li><li><p>三者都会根据spark的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存溢出。</p></li><li><p>三者都有partition的概念</p></li><li><p>三者有许多共同的函数，如filter，排序等</p></li><li><p>在对DataFrame和Dataset进行操作许多操作都需要这个包进行支持<br>import spark.implicits._</p></li><li><p>DataFrame和Dataset均可使用模式匹配获取各个字段的值和类型</p></li></ol><h4 id="三者的区别"><a href="#三者的区别" class="headerlink" title="三者的区别"></a>三者的区别</h4><ol><li>RDD:</li></ol><p>1）RDD一般和spark mlib（机器学习库）同时使用</p><p>2）RDD不支持sparksql操作</p><ol start="2"><li>DataFrame:</li></ol><p>1）与RDD和Dataset不同，DataFrame每一行的类型固定为Row，每一列的值没法直接访问，只有通过解析才能获取各个字段的值，如：</p><pre class="line-numbers language-scala"><code class="language-scala">testDF<span class="token punctuation">.</span>foreach<span class="token punctuation">{</span>    line <span class="token keyword">=></span>    <span class="token keyword">val</span> col1<span class="token operator">=</span>line<span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> col2<span class="token operator">=</span>line<span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"col2"</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）DataFrame与Dataset一般不与spark mlib同时使用</p><p>3）DataFrame与Dataset均支持sparksql的操作，比如select，groupby之类，还能注册临时表/视窗，进行sql语句操作，如：</p><pre class="line-numbers language-scala"><code class="language-scala">dataDF<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"tmp"</span><span class="token punctuation">)</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select  ROW,DATE from tmp where DATE is not null order by DATE"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）DataFrame与Dataset支持一些特别方便的保存方式，比如保存成csv，可以带上表头，这样每一列的字段名一目了然</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//保存</span><span class="token keyword">val</span> saveoptions <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token string">"header"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"true"</span><span class="token punctuation">,</span> <span class="token string">"delimiter"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"\t"</span><span class="token punctuation">,</span> <span class="token string">"path"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"hdfs://hadoop102:9000/test"</span><span class="token punctuation">)</span>datawDF<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"com.atguigu.spark.csv"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span><span class="token punctuation">.</span>options<span class="token punctuation">(</span>saveoptions<span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//读取</span><span class="token keyword">val</span> options <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token string">"header"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"true"</span><span class="token punctuation">,</span> <span class="token string">"delimiter"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"\t"</span><span class="token punctuation">,</span> <span class="token string">"path"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"hdfs://hadoop102:9000/test"</span><span class="token punctuation">)</span><span class="token keyword">val</span> datarDF<span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>options<span class="token punctuation">(</span>options<span class="token punctuation">)</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"com.atguigu.spark.csv"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>利用这样的保存方式，可以方便的获得字段名和列的对应，而且分隔符（delimiter）可以自由指定。</p><ol start="3"><li>Dataset:</li></ol><p>1）Dataset和DataFrame拥有完全相同的成员函数，区别只是每一行的数据类型不同。</p><p>2）DataFrame也可以叫Dataset[Row],每一行的类型是Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用上面提到的getAS方法或者共性中的第七条提到的模式匹配拿出特定字段。而Dataset中，每一行是什么类型是不一定的，在自定义了case class之后可以很自由的获得每一行的信息</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">case</span> <span class="token keyword">class</span> Coltest<span class="token punctuation">(</span>col1<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>col2<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token keyword">extends</span> Serializable <span class="token comment" spellcheck="true">//定义字段名和类型</span><span class="token comment" spellcheck="true">/** rdd ("a", 1) ("b", 1) ("a", 1)**/</span><span class="token keyword">val</span> test<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>Coltest<span class="token punctuation">]</span><span class="token operator">=</span>rdd<span class="token punctuation">.</span>map<span class="token punctuation">{</span>line<span class="token keyword">=></span>      Coltest<span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">.</span>toDStest<span class="token punctuation">.</span>map<span class="token punctuation">{</span>      line<span class="token keyword">=></span>        println<span class="token punctuation">(</span>line<span class="token punctuation">.</span>col1<span class="token punctuation">)</span>        println<span class="token punctuation">(</span>line<span class="token punctuation">.</span>col2<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看出，Dataset在需要访问列中的某个字段时是非常方便的，然而，如果要写一些适配性很强的函数时，如果使用Dataset，行的类型又不确定，可能是各种case class，无法实现适配，这时候用DataFrame即Dataset[Row]就能比较好的解决问题</p><h3 id="IDEA创建SparkSQL程序"><a href="#IDEA创建SparkSQL程序" class="headerlink" title="IDEA创建SparkSQL程序"></a>IDEA创建SparkSQL程序</h3><p>IDEA中程序的打包和运行方式都和SparkCore类似，Maven依赖中需要添加新的依赖项：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-sql_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>程序如下：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/5 下午 04:38 * @Description: * @Modified: * @Version: */</span><span class="token keyword">object</span> SparkSQL01_demo <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 创建配置对象</span>        <span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"SparkSQL01_demo"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建SparkSession</span>        <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取文件数据</span>        <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"in/user.json"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 展示</span>        frame<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>        spark<span class="token punctuation">.</span>stop    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="用户自定义函数"><a href="#用户自定义函数" class="headerlink" title="用户自定义函数"></a>用户自定义函数</h3><p>在Shell窗口中可以通过spark.udf功能用户可以自定义函数。</p><h4 id="用户自定义UDF函数"><a href="#用户自定义UDF函数" class="headerlink" title="用户自定义UDF函数"></a>用户自定义UDF函数</h4><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"file///opt/module/spark/data/input/user.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span>df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span>scala<span class="token operator">></span> df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>scala<span class="token operator">></span> spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">"addName"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token keyword">=></span> <span class="token string">"Name:"</span><span class="token operator">+</span>x<span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span>UserDefinedFunction <span class="token operator">=</span> UserDefinedFunction<span class="token punctuation">(</span><span class="token operator">&lt;</span>function1<span class="token operator">></span><span class="token punctuation">,</span>StringType<span class="token punctuation">,</span>Some<span class="token punctuation">(</span>List<span class="token punctuation">(</span>StringType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>scala<span class="token operator">></span> df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"people"</span><span class="token punctuation">)</span>scala<span class="token operator">></span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"Select addName(name), age from people"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span>UDF<span class="token operator">:</span>addName<span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token operator">|</span> age<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">|</span>     Name<span class="token operator">:</span>Michael<span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span><span class="token operator">|</span>        Name<span class="token operator">:</span>Andy<span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span><span class="token operator">|</span>      Name<span class="token operator">:</span>Justin<span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="用户自定义聚合函数"><a href="#用户自定义聚合函数" class="headerlink" title="用户自定义聚合函数"></a>用户自定义聚合函数</h4><p>强类型的Dataset和弱类型的DataFrame都提供了相关的聚合函数， 如 count()，countDistinct()，avg()，max()，min()。除此之外，用户可以设定自己的自定义聚合函数。</p><p>弱类型用户自定义聚合函数：通过继承UserDefinedAggregateFunction来实现用户自定义聚合函数。下面展示一个求平均工资的自定义聚合函数。</p><p>demo地址：</p><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/sql/SparkSQL05_UDAF.scala" target="_blank" rel="noopener">com/swenchao/spark/sql/SparkSQL05_UDAF.scala</a></p><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/sql/SparkSQL06_UDAF_Class.scala" target="_blank" rel="noopener">com/swenchao/spark/sql/SparkSQL06_UDAF_Class.scala</a></p><h2 id="SparkSQL数据源"><a href="#SparkSQL数据源" class="headerlink" title="SparkSQL数据源"></a>SparkSQL数据源</h2><h3 id="通用加载-保存方法"><a href="#通用加载-保存方法" class="headerlink" title="通用加载/保存方法"></a>通用加载/保存方法</h3><h4 id="手动指定选项"><a href="#手动指定选项" class="headerlink" title="手动指定选项"></a>手动指定选项</h4><p>Spark SQL的DataFrame接口支持多种数据源的操作。一个DataFrame可以进行RDDs方式的操作，也可以被注册为临时表。把DataFrame注册为临时表之后，就可以对该DataFrame执行SQL查询。</p><p>Spark SQL的默认数据源为Parquet格式。数据源为Parquet文件时，Spark SQL可以方便的执行所有的操作。修改配置项 spark.sql.sources.default，可修改默认数据源格式。</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"examples/src/main/resources/users.parquet"</span><span class="token punctuation">)</span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"favorite_color"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>write<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"namesAndFavColors.parquet"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当数据源格式不是parquet格式文件时，需要手动指定数据源的格式。数据源格式需要指定全名（例如：org.apache.spark.sql.parquet），如果数据源格式为内置格式，则只需要指定简称定json, parquet, jdbc, orc, libsvm, csv, text来指定数据的格式。</p><p>可以通过 SparkSession 提供的 read.load 方法用于通用加载数据，使用write和save保存数据。 </p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> peopleDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"examples/src/main/resources/people.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span>peopleDF<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"parquet"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/namesAndAges.parquet"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>除此之外，可以直接运行SQL在文件上：</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> sqlDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM parquet.`hdfs://hadoop102:9000/namesAndAges.parquet`"</span><span class="token punctuation">)</span>scala<span class="token operator">></span> sqlDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>scala<span class="token operator">></span> <span class="token keyword">val</span> peopleDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"examples/src/main/resources/people.json"</span><span class="token punctuation">)</span>——<span class="token operator">></span>peopleDF<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span>scala<span class="token operator">></span> peopleDF<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"parquet"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/namesAndAges.parquet"</span><span class="token punctuation">)</span>scala<span class="token operator">></span> peopleDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>scala<span class="token operator">></span> <span class="token keyword">val</span> sqlDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM parquet.`hdfs:// hadoop102:9000/namesAndAges.parquet`"</span><span class="token punctuation">)</span>scala<span class="token operator">></span> sqlDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span><span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="文件保存选项"><a href="#文件保存选项" class="headerlink" title="文件保存选项"></a>文件保存选项</h4><p>可以采用SaveMode执行存储操作，SaveMode定义了对数据的处理模式。需要注意的是，这些保存模式不使用任何锁定，不是原子操作。此外，当使用Overwrite方式执行时，在输出新数据之前原数据就已经被删除。SaveMode详细介绍如下表：</p><table><thead><tr><th>Scala/Java</th><th>Any Language</th><th>Meaning</th></tr></thead><tbody><tr><td>SaveMode.ErrorIfExists(default)</td><td>“error”(default)</td><td>如果文件存在，则报错</td></tr><tr><td>SaveMode.Append</td><td>“append”</td><td>追加</td></tr><tr><td>SaveMode.Overwrite</td><td>“overwrite”</td><td>覆写</td></tr><tr><td>SaveMode.Ignore</td><td>“ignore”</td><td>数据存在，则忽略</td></tr></tbody></table><h3 id="JSON文件"><a href="#JSON文件" class="headerlink" title="JSON文件"></a>JSON文件</h3><p>Spark SQL 能够自动推测 JSON数据集的结构，并将它加载为一个Dataset[Row]. 可以通过SparkSession.read.json()去加载一个 一个JSON 文件。</p><p><strong>注意：</strong>这个JSON文件不是一个传统的JSON文件，每一行都得是一个JSON串。</p><pre><code>{&quot;name&quot;:&quot;Michael&quot;}{&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30}{&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19}</code></pre><h3 id="Parquet文件"><a href="#Parquet文件" class="headerlink" title="Parquet文件"></a>Parquet文件</h3><p>Parquet是一种流行的列式存储格式，可以高效地存储具有嵌套字段的记录。Parquet格式经常在Hadoop生态圈中被使用，它也支持Spark SQL的全部数据类型。Spark SQL 提供了直接读取和存储 Parquet 格式文件的方法。 </p><h3 id="JDBC"><a href="#JDBC" class="headerlink" title="JDBC"></a>JDBC</h3><p>Spark SQL可以通过JDBC从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中。</p><p><strong>注意：</strong>需要将相关的数据库驱动放到spark的类路径下。</p><p>（1）启动spark-shell</p><pre class="line-numbers language-shell"><code class="language-shell">$ bin/spark-shell<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）从Mysql数据库加载数据方式一</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> jdbcDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> <span class="token string">"jdbc:mysql://hadoop102:3306/rdd"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> <span class="token string">"rddtable"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）从Mysql数据库加载数据方式二</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> connectionProperties <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>connectionProperties<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span>connectionProperties<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span><span class="token keyword">val</span> jdbcDF2 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">"jdbc:mysql://hadoop102:3306/rdd"</span><span class="token punctuation">,</span> <span class="token string">"rddtable"</span><span class="token punctuation">,</span> connectionProperties<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）将数据写入Mysql方式一</p><pre class="line-numbers language-scala"><code class="language-scala">jdbcDF<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> <span class="token string">"jdbc:mysql://hadoop102:3306/rdd"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> <span class="token string">"dftable"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）将数据写入Mysql方式二</p><pre class="line-numbers language-scala"><code class="language-scala">jdbcDF2<span class="token punctuation">.</span>write<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">"jdbc:mysql://hadoop102:3306/rdd"</span><span class="token punctuation">,</span> <span class="token string">"db"</span><span class="token punctuation">,</span> connectionProperties<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Hive数据库"><a href="#Hive数据库" class="headerlink" title="Hive数据库"></a>Hive数据库</h3><p>Apache Hive是Hadoop上的SQL引擎，Spark SQL编译时可以包含Hive支持，也可以不包含。包含Hive支持的Spark SQL可以支持Hive表访问、UDF(用户自定义函数)以及 Hive 查询语言(HiveQL/HQL)等。需要强调的一点是，如果要在Spark SQL中包含Hive的库，并不需要事先安装Hive。一般来说，最好还是在编译Spark SQL时引入Hive支持，这样就可以使用这些特性了。如果你下载的是二进制版本的 Spark，它应该已经在编译时添加了 Hive 支持。 </p><p>若要把Spark SQL连接到一个部署好的Hive上，你必须把hive-site.xml复制到 Spark的配置文件目录中($SPARK_HOME/conf)。即使没有部署好Hive，Spark SQL也可以运行。 需要注意的是，如果你没有部署好Hive，Spark SQL会在当前的工作目录中创建出自己的Hive 元数据仓库，叫作 metastore_db。此外，如果你尝试使用 HiveQL 中的 CREATE TABLE (并非 CREATE EXTERNAL TABLE)语句来创建表，这些表会被放在你默认的文件系统中的 /user/hive/warehouse 目录中(如果你的 classpath 中有配好的 hdfs-site.xml，默认的文件系统就是 HDFS，否则就是本地文件系统)。</p><h4 id="内嵌Hive应用"><a href="#内嵌Hive应用" class="headerlink" title="内嵌Hive应用"></a>内嵌Hive应用</h4><p>如果要使用内嵌的Hive，什么都不用做，直接用就可以了。 </p><p>可以通过添加参数初次指定数据仓库地址：</p><pre class="line-numbers language-xml"><code class="language-xml">--conf spark.sql.warehouse.dir=hdfs://hadoop102/spark-wearhouse<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="3-1.png" alt></p><p><strong>注意：</strong>如果你使用的是内部的Hive，在Spark2.0之后，spark.sql.warehouse.dir用于指定数据仓库的地址，如果你需要是用HDFS作为路径，那么需要将core-site.xml和hdfs-site.xml 加入到Spark conf目录，否则只会创建master节点上的warehouse目录，查询时会出现文件找不到的问题，这是需要使用HDFS，则需要将metastore删除，重启集群。</p><h4 id="外部Hive应用"><a href="#外部Hive应用" class="headerlink" title="外部Hive应用"></a>外部Hive应用</h4><p>如果想连接外部已经部署好的Hive，需要通过以下几个步骤。</p><p>1) 将Hive中的hive-site.xml拷贝或者软连接到Spark安装目录下的conf目录下。</p><p>2) 打开spark shell，注意带上访问Hive元数据库的JDBC客户端</p><pre class="line-numbers language-shell"><code class="language-shell">$ bin/spark-shell  --jars mysql-connector-java-5.1.27-bin.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3) 运行结果</p><p><img src="3-2.png" alt></p><p>外部hive创建的表</p><h4 id="运行Spark-SQL-CLI"><a href="#运行Spark-SQL-CLI" class="headerlink" title="运行Spark SQL CLI"></a>运行Spark SQL CLI</h4><p>Spark SQL CLI可以很方便的在本地运行Hive元数据服务以及从命令行执行查询任务。在Spark目录下执行如下命令启动Spark SQL CLI：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token punctuation">.</span>/bin<span class="token operator">/</span>spark<span class="token operator">-</span>sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>进入另外一个sparkSQL的界面，可以直接写sql，类似于mysql的黑白框</p><h4 id="代码中使用Hive"><a href="#代码中使用Hive" class="headerlink" title="代码中使用Hive"></a>代码中使用Hive</h4><p>（1）添加依赖：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-hive --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-hive_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-exec --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hive-exec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建SparkSession时需要添加hive支持（.enableHiveSupport() 这部分）</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 使用内置Hive需要指定一个Hive仓库地址（config("spark.sql.warehouse.dir", warehouseLocation) 这部分类似）</span><span class="token keyword">val</span> warehouseLocation<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token keyword">new</span> File<span class="token punctuation">(</span><span class="token string">"spark-warehouse"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getAbsolutePath<span class="token keyword">val</span> spark <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"Spark Hive Example"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.warehouse.dir"</span><span class="token punctuation">,</span> warehouseLocation<span class="token punctuation">)</span><span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：</strong>若使用的是外部Hive，则需要将hive-site.xml添加到ClassPath下。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SparkCore完整笔记</title>
      <link href="2020/10/05/sparkcore-wan-zheng-bi-ji/"/>
      <url>2020/10/05/sparkcore-wan-zheng-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>SparkCore笔记全部整理完了，在这传个完整版。</p><h1 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h1><h2 id="JAVA-IO"><a href="#JAVA-IO" class="headerlink" title="JAVA IO"></a>JAVA IO</h2><p>输入 输出——&gt;字节 字符</p><p>输入输出文件通过字节还是字符要看文件存的什么类型内容（文件格式），比如：</p><p>txt文件一般是使用字符流，因为其中存的一般是一些文字信息，是一些字符串，而字符串又恰恰是由一个个字符组成的。</p><p>rar、zip、png这些文件一般是使用字节流的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a>字节流</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 文件输入流</span>InputStream in <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>若像上面那么操作，效率并不是很高，因为是按字节来操作（一个字节一个字节来读取，速度会很慢），因此应该加个缓冲流</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 缓冲流（其中new FileInputStream("test.txt")就相当于上面文件输入流的 in）</span>InputStream bufferIn <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Java中的IO就体现了装饰者设计模式（功能扩招——本来没这个功能，包装一下就有了这个功能）</p><p><img src="8.png" alt></p><p>从上面可以看出，FileInputStream（in）首先从文件中读取数据，然后通过 channel（通道）写入到 BufferedInputStream（缓冲区）中，然后当 BufferedInputStream 中数据达到一定数量的时候，统一往外写出。</p><p>因此，其实读取文件的其实依然是FileInputStream（in）而不是 BufferedInputStream 对象。这就相当于是对 BufferedInputStream 对象的一个功能的补充，也就是装饰者模式。</p><h3 id="字符流"><a href="#字符流" class="headerlink" title="字符流"></a>字符流</h3><p>按行读取文件需要用到字符流）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 文件输入流</span>InputStream in <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 字符流读取一行数据（之所以要传"UTF-8"是因为BufferedReader不知道如何将字节组合成字符，因为不同编码方式其组合方式是不同的）</span>Reader reader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">InputSteamReader</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="9.png" alt></p><p>其中并不是一开始便开始执行，而是从最后的readLine开始，当发起readLine请求，才一步步往前推开始执行</p><h2 id="RDD概述"><a href="#RDD概述" class="headerlink" title="RDD概述"></a>RDD概述</h2><h3 id="RDD中的装饰者模式"><a href="#RDD中的装饰者模式" class="headerlink" title="RDD中的装饰者模式"></a>RDD中的装饰者模式</h3><p><img src="10.png" alt></p><p>其中textFile将数据读取之后自己没法处理，因此在其外面包了一层新的类来对数据进行切分（flatMap）；然后发现切分后没法统计，因此又包了一层来对数据进行分别统计（map）；统计后又没法整合，因此又包了一层（reduceByKey）</p><p>其与JAVA IO的区别在于RDD从属于分布式的集群操作以及RDD是将数据处理逻辑进行了封装，而JAVA IO是封装的类。</p><p>另外RDD每层封装数据并没发生变化，始终都是都进来的那些数据。</p><h3 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h3><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据（逻辑）抽象。代码中是一个抽象类，它代表一个不可变、可分区（并行）、里面的元素可并行计算的集合。</p><h3 id="RDD的属性"><a href="#RDD的属性" class="headerlink" title="RDD的属性"></a>RDD的属性</h3><p><img src="7.png" alt></p><p>1) 一组分区（Partition），即数据集的基本组成单位;</p><p>2) 一个计算每个分区的函数;</p><p>3) RDD之间的依赖关系（逻辑不断嵌套，依赖关系越来越长）;</p><p>4) 一个Partitioner，即RDD的分片函数;</p><p>5) 一个列表，存储存取每个P  artition的优先位置（preferred location）。</p><p><img src="11.png" alt></p><p>从上图可看出Driver要将当前任务分发给哪个Executor执行取决于当前任务所需要数据在哪个DN上（因为Executor就是部署在DN上的），而数据所在DN就是其优先位置，也就是列表中所存的。</p><h3 id="RDD特点"><a href="#RDD特点" class="headerlink" title="RDD特点"></a>RDD特点</h3><p>RDD表示只读的分区的数据集，对RDD进行改动，只能通过RDD的转换操作，由一个RDD得到一个新的RDD，新的RDD包含了从其他RDD衍生所必需的信息。RDD之间存在依赖，RDD的执行是按照血缘关系延时计算的。如果血缘关系较长，可以通过持久化RDD来切断血缘关系。</p><p>延时计算：当用到的时候才会去计算，就像RDD中的装饰者模式中给出的图，其中只有在执行collect的时候，才会一步步往前推产生计算关系。</p><h4 id="分区——便于并行计算"><a href="#分区——便于并行计算" class="headerlink" title="分区——便于并行计算"></a>分区——便于并行计算</h4><p>RDD逻辑上是分区的，每个分区的数据是抽象存在的，计算的时候会通过一个compute函数得到每个分区的数据。如果RDD是通过已有的文件系统构建，则compute函数是读取指定文件系统中的数据，如果RDD是通过其他RDD转换而来，则compute函数是执行转换逻辑将其他RDD的数据进行转换。</p><p><img src="1.png" alt></p><h4 id="只读"><a href="#只读" class="headerlink" title="只读"></a>只读</h4><p>RDD是只读的，要想改变RDD中的数据，只能在现有的RDD基础上创建新的RDD。</p><p><img src="2.png" alt></p><p>由一个RDD转换到另一个RDD，可以通过丰富的操作算子实现，不再像MapReduce那样只能写map和reduce了，如图</p><p><img src="3.png" alt></p><p>算子：从认知心理学角度讲，解决问题其实是将问题的初始状态通过一系列的操作（算子、Operate）对问题的状态进行转换，然后达到完成（解决）状态。Spark中方法就是算子。</p><p>RDD的操作算子包括两类，一类叫做transformations（转换算子），它是用来将RDD进行转化，构建RDD的血缘关系；另一类叫做actions（行动算子），它是用来触发RDD的计算，得到RDD的相关计算结果或者将RDD保存的文件系统中。下图是RDD所支持的操作算子列表。</p><p>transformations（转换算子）：只转换数据的结构——textFile、flatMap、map、reduceByKey</p><p>actions（行动算子）：触发数据计算——collect</p><h4 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h4><p>RDD通过操作算子进行转换，转换得到的新RDD包含了从其他RDD衍生所必需的信息，RDD之间维护着这种血缘关系，也称之为依赖。如下图，依赖包括两种，一种是窄依赖，RDD之间分区是一一对应的，另一种是宽依赖，下游RDD的每个分区与上游RDD(也称之为父RDD)的每个分区都有关，是多对多的关系。</p><p><img src="4.png" alt></p><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>如果在应用程序中多次使用同一个RDD，可以将该RDD缓存起来，该RDD只有在第一次计算的时候会根据血缘关系得到分区的数据，在后续其他地方用到该RDD的时候，会直接从缓存处取而不用再根据血缘关系计算，这样就加速后期的重用。如下图所示，RDD-1经过一系列的转换后得到RDD-n并保存到hdfs，RDD-1在这一过程中会有个中间结果，如果将其缓存到内存，那么在随后的RDD-1转换到RDD-m这一过程中，就不会计算其之前的RDD-0了。</p><p><img src="5.png" alt></p><h4 id="CheckPoint"><a href="#CheckPoint" class="headerlink" title="CheckPoint"></a>CheckPoint</h4><p>虽然RDD的血缘关系天然地可以实现容错，当RDD的某个分区数据失败或丢失，可以通过血缘关系重建。但是对于长时间迭代型应用来说，随着迭代的进行，RDD之间的血缘关系会越来越长，一旦在后续迭代过程中出错，则需要通过非常长的血缘关系去重建，势必影响性能。为此，RDD支持checkpoint将数据保存到持久化的存储中，这样就可以切断之前的血缘关系，因为checkpoint后的RDD不需要知道它的父RDDs了，它可以从checkpoint处拿到数据。</p><h2 id="RDD编程"><a href="#RDD编程" class="headerlink" title="RDD编程"></a>RDD编程</h2><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p>在Spark中，RDD被表示为对象，通过对象上的方法调用来对RDD进行转换。经过一系列的transformations定义RDD之后，就可以调用actions触发RDD的计算，action可以是向应用程序返回结果(count, collect等)，或者是向存储系统保存数据(saveAsTextFile等)。在Spark中，只有遇到action，才会执行RDD的计算(即延迟计算)，这样在运行时可以通过管道的方式传输多个转换。</p><p>要使用Spark，开发者需要编写一个Driver程序，它被提交到集群以调度运行Worker，如下图所示。Driver中定义了一个或多个RDD，并调用RDD上的action，Worker则执行RDD分区计算任务。</p><p><img src="12.png" alt></p><h3 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h3><p>在Spark中创建RDD的创建方式可以分为三种：从集合中创建RDD；从外部存储创建RDD；从其他RDD创建。</p><h4 id="从集合中创建"><a href="#从集合中创建" class="headerlink" title="从集合中创建"></a>从集合中创建</h4><p>从集合中创建RDD，Spark主要提供了两种函数：parallelize（并行）和makeRDD</p><p>1）使用parallelize()从集合创建</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）使用makeRDD()从集合创建，其底层实现，其实就是调用了parallelize</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>以上两种方法其实都有一个默认参数（defaultParallelism）没有传。这个默认参数就是分区，如果没有传他会根据当前运行电脑核数跟2来比较进行赋值，如下</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">override</span> <span class="token keyword">def</span> defaultParallelism<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    conf<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token string">"spark.default.parallelism"</span><span class="token punctuation">,</span> math<span class="token punctuation">.</span>max<span class="token punctuation">(</span>totalCoreCount<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="由外部存储系统的数据集创建"><a href="#由外部存储系统的数据集创建" class="headerlink" title="由外部存储系统的数据集创建"></a>由外部存储系统的数据集创建</h4><p>默认情况可读取项目路径。同时也可以读取其他路径。</p><p>包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等，在数据读取与保存章节中会有详细介绍。</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2<span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/RELEASE"</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span> hadoop102<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>RELEASE MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>默认从文件中读取的数据都是字符串类型。此方法也有一个默认参数（minPartitions: Int = defaultMinPartitions）没有传。如果没有传他也会根据 defaultParallelism 跟2来比较进行赋值（更上面稍有不同），如下</p><pre class="line-numbers language-scala"><code class="language-scala">    <span class="token keyword">def</span> defaultMinPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> math<span class="token punctuation">.</span>min<span class="token punctuation">(</span>defaultParallelism<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中 defaultParallelism 跟上面取值是一样的。这个参数是最小分区数，但是最后分区的数量不一定就是这个，其取决于hadoop读取文件时的分片规则</p><h4 id="从其他RDD创建"><a href="#从其他RDD创建" class="headerlink" title="从其他RDD创建"></a>从其他RDD创建</h4><p>详见2.3节</p><h3 id="RDD的转换（面试开发重点）"><a href="#RDD的转换（面试开发重点）" class="headerlink" title="RDD的转换（面试开发重点）"></a>RDD的转换（面试开发重点）</h3><p>RDD整体上分为Value类型和Key-Value类型</p><h4 id="Value类型"><a href="#Value类型" class="headerlink" title="Value类型"></a>Value类型</h4><h5 id="map-func-案例"><a href="#map-func-案例" class="headerlink" title="map(func)案例"></a>map(func)案例</h5><ol><li><p>作用：返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成</p></li><li><p>需求：创建一个1-10数组的RDD，将所有元素*2形成新的RDD</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2 */</span><span class="token keyword">object</span> Spark02_oper1 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> x <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        mapRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：</strong>上面整个过程除了x =&gt; x * 2操作（在executor上操作），其他都是在driver上运行</p><h5 id="mapPartitions-func-案例"><a href="#mapPartitions-func-案例" class="headerlink" title="mapPartitions(func) 案例"></a>mapPartitions(func) 案例</h5><ol><li><p>作用：类似于map，但独立地在RDD的每一个分片（分区）上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] =&gt; Iterator[U]。假设有N个元素，有M个分区，那么map的函数的将被调用N次,而mapPartitions被调用M次,一个函数一次处理所有分区。</p></li><li><p>需求：创建一个RDD，使每个元素*2组成新的RDD</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2 */</span><span class="token keyword">object</span> Spark02_Oper2 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// mapPartitions可以对一个RDD中所有的分区进行遍历，不是数据</span>        <span class="token keyword">val</span> mapPartitionsRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>datas <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// _*2是scala的东西不算是一个计算（只有交给executor的才算计算）</span>            <span class="token comment" spellcheck="true">// datas.map(_*2)这个整体是一个计算，要整块发给executor</span>            <span class="token comment" spellcheck="true">// mapPartitions效率优于map算子，因为减少了执行器网络交互</span>            <span class="token comment" spellcheck="true">// 虽然效率高，但是可能会出现内存溢出（因为它是按区操作，整个区操作不完，不会释放内存）</span>            datas<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        mapPartitionsRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="mapPartitionsWithIndex-func-案例"><a href="#mapPartitionsWithIndex-func-案例" class="headerlink" title="mapPartitionsWithIndex(func) 案例"></a>mapPartitionsWithIndex(func) 案例</h5><ol><li><p>作用：类似于mapPartitions，但此方法带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Interator[T]) =&gt; Iterator[U]；</p></li><li><p>需求：创建一个RDD，使每个元素跟所在分区形成一个元组组成一个新的RDD</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2（mapPartitionsWithIndex） */</span><span class="token keyword">object</span> Spark03_Oper3 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> tupleRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>mapPartitionsWithIndex <span class="token punctuation">{</span>            <span class="token keyword">case</span> <span class="token punctuation">(</span>num<span class="token punctuation">,</span> datas<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span>                datas<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token string">"分区号："</span> <span class="token operator">+</span> num<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        tupleRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="15.png" alt></p><p><strong>executor和driver</strong></p><p>driver要往executor上传数据，只能传可序列化的</p><p><img src="16.png" alt></p><h5 id="flatMap-func-案例"><a href="#flatMap-func-案例" class="headerlink" title="flatMap(func) 案例"></a>flatMap(func) 案例</h5><ol><li><p>作用：类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以方法应该返回一个序列，而不是单一元素）</p></li><li><p>需求：创建一个元素为1-4的RDD，运用flatMap创建一个新的RDD，将所有数字分开</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 将所有数字分开（flatMap） */</span><span class="token keyword">object</span> Spark05_Oper4 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> List<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// flatMap拆成 1 2 3 4</span>        <span class="token keyword">val</span> flatMapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>datas <span class="token keyword">=></span> datas<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        flatMapRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="map-和mapPartition-的区别"><a href="#map-和mapPartition-的区别" class="headerlink" title="map()和mapPartition()的区别"></a>map()和mapPartition()的区别</h5><ol><li>map()：每次处理一条数据。</li></ol><p><img src="13.png" alt></p><p>其中有几个数据就会执行几次 “X” + _ 操作（4次）</p><ol start="2"><li>mapPartition()：每次处理一个分区的数据，这个分区的数据处理完后，原RDD中分区的数据才能释放，可能导致OOM（内存溢出）。</li></ol><p><img src="14.png" alt></p><ol start="3"><li>开发指导：当内存空间较大的时候建议使用mapPartition()，以提高处理效率。</li></ol><h5 id="glom案例"><a href="#glom案例" class="headerlink" title="glom案例"></a>glom案例</h5><ol><li><p>作用：将每一个分区形成一个数组，形成新的RDD类型时RDD[Array[T]]</p></li><li><p>需求：创建一个4个分区的RDD，并将每个分区的数据放到一个数组</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2（mapPartitionsWithIndex） */</span><span class="token keyword">object</span> Spark06_Oper5 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 将一个分区数据放到一个数组中</span>        <span class="token keyword">val</span> glomRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>glom<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        glomRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>array <span class="token keyword">=></span> <span class="token punctuation">{</span>            println<span class="token punctuation">(</span>array<span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将每一个分区形成一个数组，会有很多操作会很方便（求最大（小）值、求和等等）。</p><h5 id="groupBy-func-案例"><a href="#groupBy-func-案例" class="headerlink" title="groupBy(func)案例"></a>groupBy(func)案例</h5><ol><li><p>作用：分组，按照传入函数的返回值进行分组。将相同的key对应的值放入一个迭代器。</p></li><li><p>需求：创建一个RDD，按照元素模以2的值进行分组。</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: groupBy */</span><span class="token keyword">object</span> Spark07_Oper6 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 将一个分区数据放到一个数组中（分组后形成了对偶元组（k-v），k表示分组key，v表示分组数据集合）</span>        <span class="token comment" spellcheck="true">// (0,CompactBuffer(2, 4))</span>        <span class="token comment" spellcheck="true">// (1,CompactBuffer(1, 3))</span>        <span class="token comment" spellcheck="true">// 可见其中Int是分组号，Iterable[Int]是组内元素</span>        <span class="token keyword">val</span> groupByRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>i <span class="token keyword">=></span> i <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        groupByRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="filter-func-案例"><a href="#filter-func-案例" class="headerlink" title="filter(func) 案例"></a>filter(func) 案例</h5><ol><li><p>作用：过滤。返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成。</p></li><li><p>需求：创建一个RDD（1 2 3 4），过滤出一个新RDD（%2为0的）</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: filter */</span><span class="token keyword">object</span> Spark08_Oper7 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// %2余数为0留下，余数不为0拿走</span>        <span class="token keyword">val</span> filterRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        filterRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sample-withReplacement-fraction-seed-案例"><a href="#sample-withReplacement-fraction-seed-案例" class="headerlink" title="sample(withReplacement, fraction, seed) 案例"></a>sample(withReplacement, fraction, seed) 案例</h5><ol><li><p>作用：以指定的随机种子随机抽样出数量为fraction的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样；seed用于指定随机数生成器种子。</p></li><li><p>需求：创建一个RDD（1-10），从中选择放回和不放回抽样</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: sample */</span><span class="token keyword">object</span> Spark09_Oper8 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 从指定数据集合中进行抽样处理，根据不同的算法进行抽样</span>        <span class="token comment" spellcheck="true">// 有放回</span>        <span class="token comment" spellcheck="true">// val sampleRDD: RDD[Int] = listRDD.sample(false, 0.4, 1)</span>        <span class="token comment" spellcheck="true">// 无放回</span>        <span class="token keyword">val</span> sampleRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        sampleRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="distinct-numTasks-案例"><a href="#distinct-numTasks-案例" class="headerlink" title="distinct([numTasks])) 案例"></a>distinct([numTasks])) 案例</h5><ol><li>作用：对源RDD进行去重后返回一个新的RDD。默认情况下，只有8个并行任务来操作，但是可以传入一个可选的numTasks（numPartitions）参数改变它。</li></ol><p><strong>有没有shuffle区别</strong></p><p><img src="19.png" alt></p><p>从中可以看出如果中间是map，没有shuffle的过程，那么其中两个红框内分区就可以看成一个整体，p0也就不需要等待p1完成再接着执行。</p><p><img src="20.png" alt></p><p>若其中map换成distinct，则其将会分成前后两个过程。在左边p0分区执行完后，要等左边p1分区执行完才能向后继续执行。</p><p>这就出现了一个分区一个任务，一个任务会被分配到Executor中执行，所以此时 numTasks 和 numPartitions 是一样的。</p><ol start="2"><li>需求：创建一个RDD，使用distinct()对其去重。</li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: distinct */</span><span class="token keyword">object</span> Spark10_Oper9 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        val distinctRDD: RDD[Int] = listRDD.distinct()</span>        <span class="token comment" spellcheck="true">// 重组后的数据分成两个分区保存</span>        <span class="token keyword">val</span> distinctRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>distinct<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span><span class="token comment" spellcheck="true">//        distinctRDD.collect().foreach(println)</span>        <span class="token comment" spellcheck="true">// 保存文件</span>        distinctRDD<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行上面程序不论是写入文件还是输出，会发现原来的顺序都被打乱了，这就说明经过了一个重排序的阶段（shuffle）。</p><p>将RDD中一个分区的数据打乱（其中在一块的不再在一块）重组到其他不同的分区的操作，称之为shuffle操作。</p><p><img src="17.png" alt></p><p>若shuffle过程未做完，整个过程就不会往后走，即：</p><p>当前两个分区（{1，3}， {4，5}）走完后，不能继续往后走，必须得等后面两个（{1，2}， {2，6}）一块在做完才能继续（因为不进行完并不知道后面有没有重复）</p><p><img src="18.png" alt></p><p>上面是无shuffle过程，其中p0分区执行完并不需要等p1分区，因为两个互不相干</p><p>Spark中所有转换算子没有shuffle的算子，性能比较快</p><h5 id="coalesce-numPartitions-案例"><a href="#coalesce-numPartitions-案例" class="headerlink" title="coalesce(numPartitions) 案例"></a>coalesce(numPartitions) 案例</h5><ol><li><p>作用：缩减分区数，用于大数据集过滤后，提高小数据集的执行效率。</p></li><li><p>需求：创建一个4个分区的RDD，对其缩减分区</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: coalesce */</span><span class="token keyword">object</span> Spark11_Oper10 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 缩减分区数量（可以简单理解为合并分区——最后两个，并未打乱顺序）</span>        println<span class="token punctuation">(</span><span class="token string">"缩减分区前："</span> <span class="token operator">+</span> listRDD<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size<span class="token punctuation">)</span>        <span class="token keyword">val</span> coalesceRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        println<span class="token punctuation">(</span><span class="token string">"缩减分区后："</span> <span class="token operator">+</span> coalesceRDD<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 保存文件</span>        coalesceRDD<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="repartition-numPartitions-案例"><a href="#repartition-numPartitions-案例" class="headerlink" title="repartition(numPartitions) 案例"></a>repartition(numPartitions) 案例</h5><ol><li><p>作用：根据分区数，重新通过网络随机洗牌所有数据。</p></li><li><p>需求：创建一个4个分区的RDD，对其重新分区</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>collect——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>scala<span class="token operator">></span> <span class="token keyword">var</span> rerdd <span class="token operator">=</span> rdd<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>scala<span class="token operator">></span> rerdd<span class="token punctuation">.</span>collect——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span># 可见已经分成了两组scala<span class="token operator">></span> rerdd<span class="token punctuation">.</span>glom<span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="coalesce和repartition的区别"><a href="#coalesce和repartition的区别" class="headerlink" title="coalesce和repartition的区别"></a>coalesce和repartition的区别</h5><ol><li><p>coalesce重新分区，可以选择是否进行shuffle过程。由参数shuffle: Boolean = false/true决定。</p></li><li><p>repartition实际上是调用的coalesce，默认是进行shuffle的。源码如下：</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> repartition<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>    coalesce<span class="token punctuation">(</span>numPartitions<span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> coalesce<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> shuffle<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span>             partitionCoalescer<span class="token operator">:</span> Option<span class="token punctuation">[</span>PartitionCoalescer<span class="token punctuation">]</span> <span class="token operator">=</span> Option<span class="token punctuation">.</span>empty<span class="token punctuation">)</span>            <span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>    <span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sortBy-func-ascending-numTasks-案例"><a href="#sortBy-func-ascending-numTasks-案例" class="headerlink" title="sortBy(func,[ascending], [numTasks]) 案例"></a>sortBy(func,[ascending], [numTasks]) 案例</h5><ol><li><p>作用；使用func先对数据进行处理，按照处理后的数据比较结果排序，默认为正序。</p></li><li><p>需求：创建一个RDD，按照不同的规则进行排序</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）按照自身大小排序（顺序）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>按照自身大小排序（倒序）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）按照与3余数的大小排序</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token operator">%</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="pipe-command-envVars-案例"><a href="#pipe-command-envVars-案例" class="headerlink" title="pipe(command, [envVars]) 案例"></a>pipe(command, [envVars]) 案例</h5><ol><li><p>作用：管道，针对每个分区，都执行一个shell脚本，返回输出的RDD。<br>注意：脚本需要放在Worker节点可以访问到的位置</p></li><li><p>需求：编写一个脚本，使用管道将脚本作用于RDD上。</p></li></ol><p>（1）编写一个脚本</p><p>Shell脚本</p><pre class="line-numbers language-shell"><code class="language-shell">#!/bin/shecho "AA"while read LINE; do   echo ">>>"${LINE}done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="双Value类型交互"><a href="#双Value类型交互" class="headerlink" title="双Value类型交互"></a>双Value类型交互</h4><h5 id="union-otherDataset-案例"><a href="#union-otherDataset-案例" class="headerlink" title="union(otherDataset) 案例"></a>union(otherDataset) 案例</h5><ol><li><p>作用：对源RDD和参数RDD求并集后返回一个新的RDD</p></li><li><p>需求：创建两个RDD，求并集</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">5</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算两个RDD的并集</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> UnionRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at union at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）打印并集结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd3<span class="token punctuation">.</span>collect——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="subtract-otherDataset-案例"><a href="#subtract-otherDataset-案例" class="headerlink" title="subtract (otherDataset) 案例"></a>subtract (otherDataset) 案例</h5><ol><li><p>作用：计算差的一种函数，去除两个RDD中相同的元素，不同的RDD将保留下来</p></li><li><p>需求：创建两个RDD，求第一个RDD与第二个RDD的差集</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">3</span> to <span class="token number">8</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算第一个RDD与第二个RDD的差集并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>subtract<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="intersection-otherDataset-案例"><a href="#intersection-otherDataset-案例" class="headerlink" title="intersection(otherDataset) 案例"></a>intersection(otherDataset) 案例</h5><ol><li><p>作用：对源RDD和参数RDD求交集后返回一个新的RDD</p></li><li><p>需求：创建两个RDD，求两个RDD的交集</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">7</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">5</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算两个RDD的交集</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>intersection<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span> at intersection at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）打印计算结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd3<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="cartesian-otherDataset-案例"><a href="#cartesian-otherDataset-案例" class="headerlink" title="cartesian(otherDataset) 案例"></a>cartesian(otherDataset) 案例</h5><ol><li><p>作用：笛卡尔积（尽量避免使用）</p></li><li><p>需求：创建两个RDD，计算两个RDD的笛卡尔积</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">2</span> to <span class="token number">5</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算两个RDD的笛卡尔积并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>cartesian<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="zip-otherDataset-案例"><a href="#zip-otherDataset-案例" class="headerlink" title="zip(otherDataset)案例"></a>zip(otherDataset)案例</h5><ol><li><p>作用：将两个RDD组合成Key/Value形式的RDD,这里默认两个RDD的partition数量以及元素数量都相同，否则会抛出异常。</p></li><li><p>需求：创建两个RDD，并将两个RDD组合到一起形成一个(k,v)RDD</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD（与1分区数相同）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）第一个RDD组合第二个RDD并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>zip<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>c<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）第二个RDD组合第一个RDD并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd2<span class="token punctuation">.</span>zip<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>c<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）创建第三个RDD（与1,2分区数不同）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）第一个RDD组合第三个RDD并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>zip<span class="token punctuation">(</span>rdd3<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>报错了</p><pre><code>    java.lang.IllegalArgumentException: Can&#39;t zip RDDs with unequal numbers of partitions: List(3, 2)</code></pre><p>同理，若 val rdd3 = sc.parallelize(Array(“a”,”b”,”c”,”d”),3) 也会报错</p><pre><code>    Can only zip RDDs with same number of elements in each partition</code></pre><h4 id="Key-Value类型"><a href="#Key-Value类型" class="headerlink" title="Key-Value类型"></a>Key-Value类型</h4><h5 id="partitionBy案例"><a href="#partitionBy案例" class="headerlink" title="partitionBy案例"></a>partitionBy案例</h5><ol><li><p>作用：对 pairRDD 进行分区操作，如果原有的 partionRDD 和现有的 partionRDD 是一致的话就不进行分区， 否则会生成 ShuffleRDD，即会产生 shuffle 过程。</p></li><li><p>需求：创建一个4个分区的RDD，对其重新分区</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"aaa"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"bbb"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"ccc"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">"ddd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）查看RDD的分区数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）对RDD重新分区</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd2 <span class="token operator">=</span> rdd<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at partitionBy at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）查看新RDD的分区数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd2<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/Spark12_Oper11.scala" target="_blank" rel="noopener">案例地址</a></p><h5 id="groupByKey案例"><a href="#groupByKey案例" class="headerlink" title="groupByKey案例"></a>groupByKey案例</h5><ol><li><p>作用：groupByKey也是对每个key进行操作，但只生成一个sequence。</p></li><li><p>需求：创建一个pairRDD，将相同key对应值聚合到一个sequence中，并计算相同key对应值的相加结果。</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> words <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token string">"one"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">)</span>——<span class="token operator">></span>words<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>one<span class="token punctuation">,</span> two<span class="token punctuation">,</span> two<span class="token punctuation">,</span> three<span class="token punctuation">,</span> three<span class="token punctuation">,</span> three<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> wordPairsRDD <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>word <span class="token keyword">=></span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>wordPairsRDD<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将相同key对应值聚合到一个sequence中</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> group <span class="token operator">=</span> wordPairsRDD<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>group<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> at groupByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> group<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>two<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>one<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>three<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）计算相同key对应值的相加结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> group<span class="token punctuation">.</span>map<span class="token punctuation">(</span>t <span class="token keyword">=></span> <span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>sum<span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>res2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">31</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> res2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>two<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>one<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>three<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="reduceByKey-func-numTasks-案例"><a href="#reduceByKey-func-numTasks-案例" class="headerlink" title="reduceByKey(func, [numTasks]) 案例"></a>reduceByKey(func, [numTasks]) 案例</h5><ol><li><p>在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，reduce任务的个数可以通过第二个可选的参数来设置。</p></li><li><p>需求：创建一个pairRDD，计算相同key对应值的相加结果</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"female"</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"male"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"female"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"male"</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）计算相同key对应值的相加结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> reduce <span class="token operator">=</span> rdd<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token keyword">=></span> x<span class="token operator">+</span>y<span class="token punctuation">)</span>——<span class="token operator">></span>reduce<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span> at reduceByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> reduce<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>female<span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>male<span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="reduceByKey和groupByKey的区别"><a href="#reduceByKey和groupByKey的区别" class="headerlink" title="reduceByKey和groupByKey的区别"></a>reduceByKey和groupByKey的区别</h5><p><img src="21.png" alt></p><p>从图中可以看出，groupByKey 本来有6个数据（上面的绿框），处理之后依然有6个数据（下面的绿框），说明其在中间有一次shuffle过程；而 reduceByKey 本来有6个数据（上面的绿框），处理之后依然有3个数据（下面的绿框），说明在中间shuffle过程之前有一次合并的过程（预聚合）</p><ol><li><p>reduceByKey：按照key进行聚合，在shuffle之前有combine（预聚合）操作，返回结果是RDD[k,v].</p></li><li><p>groupByKey：按照key进行分组，直接进行shuffle。</p></li><li><p>开发指导：reduceByKey比groupByKey，建议使用。但是需要注意是否会影响业务逻辑。</p></li></ol><p><strong>注：</strong>如果shuffle过程中有预聚合操作，性能可以得到提高</p><h5 id="aggregateByKey案例"><a href="#aggregateByKey案例" class="headerlink" title="aggregateByKey案例"></a>aggregateByKey案例</h5><p>参数：(zeroValue:U,[partitioner: Partitioner]) (seqOp: (U, V) =&gt; U,combOp: (U, U) =&gt; U)</p><p>zeroValue：默认值</p><p>seqOp：分区内运算规则</p><p>combOp：分区间分区规则</p><ol><li><p>作用：在kv对的RDD中，按key将value进行分组合并，合并时，将每个value和初始值作为seq函数的参数，进行计算，返回的结果作为一个新的kv对，然后再将结果按照key进行合并，最后将每个分组的value传递给combine函数进行计算（先将前两个value进行计算，将返回结果和下一个value传给combine函数，以此类推），将key与计算结果作为一个新的kv对输出。</p></li><li><p>参数描述：</p></li></ol><p>（1）zeroValue：给每一个分区中的每一个key一个初始值；</p><p>（2）seqOp：函数用于在每一个分区中用初始值逐步迭代value；</p><p>（3）combOp：函数用于合并每个分区中的结果。</p><ol start="3"><li><p>需求：创建一个pairRDD，取出每个分区相同key对应值的最大值，然后相加</p></li><li><p>需求分析</p></li></ol><p><img src="22.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>Partitioner<span class="token punctuation">,</span> SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: aggregateByKey案例 */</span><span class="token keyword">object</span> Spark13_Oper12 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> aggRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 查看分区</span><span class="token comment" spellcheck="true">//        val glomRDD: RDD[Array[(String, Int)]] = aggRDD.glom()</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//        glomRDD.collect().foreach(s</span><span class="token comment" spellcheck="true">//            => {println(s.mkString(","))}</span><span class="token comment" spellcheck="true">//        )</span>        <span class="token comment" spellcheck="true">// 取出每个分区相同key对应值的最大值，然后相加</span>        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> aggRDD<span class="token punctuation">.</span>aggregateByKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>max<span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">)</span><span class="token punctuation">,</span> _ <span class="token operator">+</span> _<span class="token punctuation">)</span>        resRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="foldByKey案例"><a href="#foldByKey案例" class="headerlink" title="foldByKey案例"></a>foldByKey案例</h5><p>参数：(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)]</p><ol><li><p>作用：aggregateByKey的简化操作，seqop和combop相同</p></li><li><p>需求：创建一个pairRDD，计算相同key对应值的相加结果</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: foldByKey案例 */</span><span class="token keyword">object</span> Spark14_Oper13 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> foldRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 查看分区</span><span class="token comment" spellcheck="true">//        val glomRDD: RDD[Array[(String, Int)]] = aggRDD.glom()</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//        glomRDD.collect().foreach(s</span><span class="token comment" spellcheck="true">//            => {println(s.mkString(","))}</span><span class="token comment" spellcheck="true">//        )</span>        <span class="token comment" spellcheck="true">// 相加</span>        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> foldRDD<span class="token punctuation">.</span>foldByKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        resRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="combineByKey-C-案例"><a href="#combineByKey-C-案例" class="headerlink" title="combineByKey[C] 案例"></a>combineByKey[C] 案例</h5><p>参数：(createCombiner: V =&gt; C,  mergeValue: (C, V) =&gt; C,  mergeCombiners: (C, C) =&gt; C) </p><ol><li><p>作用：对相同K，把V合并成一个集合。</p></li><li><p>参数描述：</p></li></ol><p>（1）createCombiner: combineByKey() 会遍历分区中的所有元素，因此每个元素的键要么还没有遇到过，要么就和之前的某个元素的键相同。如果这是一个新的元素,combineByKey()会使用一个叫作createCombiner()的函数来创建那个键对应的累加器的初始值</p><p>（2）mergeValue: 如果这是一个在处理当前分区之前已经遇到的键，它会使用mergeValue()方法将该键的累加器对应的当前值与这个新的值进行合并</p><p>（3）mergeCombiners: 由于每个分区都是独立处理的， 因此对于同一个键可以有多个累加器。如果有两个或者更多的分区都有对应同一个键的累加器， 就需要使用用户提供的 mergeCombiners() 方法将各个分区的结果进行合并。</p><ol start="3"><li><p>需求：创建一个pairRDD，根据key计算每种key的均值。（先计算每个key出现的次数以及可以对应值的总和，再相除得到结果）</p></li><li><p>需求分析：</p></li></ol><p><img src="23.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: combineByKey案例 */</span><span class="token keyword">object</span> Spark15_Oper14 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> combineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">88</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 相加</span>        <span class="token keyword">val</span> sumRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> combineRDD<span class="token punctuation">.</span>combineByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>acc<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>acc<span class="token punctuation">.</span>_1 <span class="token operator">+</span> v<span class="token punctuation">,</span> acc<span class="token punctuation">.</span>_2 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>acc1<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> acc2<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>acc1<span class="token punctuation">.</span>_1 <span class="token operator">+</span> acc2<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> acc1<span class="token punctuation">.</span>_2 <span class="token operator">+</span> acc2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>        sumRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 求平均值</span>        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sumRDD<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">.</span>_1 <span class="token operator">/</span> value<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span> <span class="token punctuation">}</span>        resRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sortByKey-ascending-numTasks-案例"><a href="#sortByKey-ascending-numTasks-案例" class="headerlink" title="sortByKey([ascending], [numTasks]) 案例"></a>sortByKey([ascending], [numTasks]) 案例</h5><ol><li><p>作用：在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD</p></li><li><p>需求：创建一个pairRDD，按照key的正序和倒序进行排序</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"aa"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token string">"cc"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"bb"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"dd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）按照key的正序</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>dd<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>bb<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>aa<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span>cc<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）按照key的倒序</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span>cc<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>aa<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>bb<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>dd<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="mapValues案例"><a href="#mapValues案例" class="headerlink" title="mapValues案例"></a>mapValues案例</h5><ol><li><p>针对于(K,V)形式的类型只对V进行操作</p></li><li><p>需求：创建一个pairRDD，并将value添加字符串”|||”</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"d"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）对value添加字符串”|||”</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd3<span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>_<span class="token operator">+</span><span class="token string">"|||"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>a<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>d<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>b<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>c<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="join-otherDataset-numTasks-案例"><a href="#join-otherDataset-numTasks-案例" class="headerlink" title="join(otherDataset, [numTasks]) 案例"></a>join(otherDataset, [numTasks]) 案例</h5><ol><li><p>作用：在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD</p></li><li><p>需求：创建两个pairRDD，并将key相同的数据聚合到一个元组。</p></li></ol><p>（1）创建第一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）join操作并打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="cogroup-otherDataset-numTasks-案例"><a href="#cogroup-otherDataset-numTasks-案例" class="headerlink" title="cogroup(otherDataset, [numTasks]) 案例"></a>cogroup(otherDataset, [numTasks]) 案例</h5><ol><li><p>作用：在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable&lt;V&gt;,Iterable&lt;W&gt;))类型的RDD</p></li><li><p>需求：创建两个pairRDD，并将key相同的数据聚合到一个迭代器。</p></li></ol><p>（1）创建第一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）cogroup两个RDD并打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>cogroup<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res6<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Iterable<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><ol><li>数据结构：时间戳，省份，城市，用户，广告，中间字段使用空格分割。</li></ol><p>样本如下：</p><pre><code>1516609143867 6 7 64 161516609143869 9 4 75 181516609143869 1 7 87 12...</code></pre><p><a href="https://github.com/Swenchao/SparkCode/blob/master/in/agent.log" target="_blank" rel="noopener">样本地址</a></p><ol start="2"><li><p>需求：统计出每一个省份广告被点击次数的TOP3</p></li><li><p>实现过程：</p></li></ol><p><img src="24.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/22 下午 10:14 * @Func: 统计出每一个省份广告被点击次数的TOP3 */</span><span class="token keyword">object</span> adTop3 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//创建conf对象</span>        <span class="token comment" spellcheck="true">// app id对应一个应用名称</span>        <span class="token keyword">val</span> config<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"AdTop3"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建上下文对象</span>        <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>config<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取文件生成RDD</span>        <span class="token keyword">val</span> lines<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"in/agent.log"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 分解成：((Province,AD),1)</span>        <span class="token comment" spellcheck="true">// 原来样式：时间戳 省份 城市 用户 广告</span>        <span class="token keyword">val</span> provinceAD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> lines<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> details<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>            <span class="token punctuation">(</span><span class="token punctuation">(</span>details<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> details<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 检验样式：((5,10),1)</span><span class="token comment" spellcheck="true">//        provinceAD.foreach(println)</span>        <span class="token comment" spellcheck="true">// 点击次数相加</span>        <span class="token keyword">val</span> sumProvinceAD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> provinceAD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">=></span> x <span class="token operator">+</span> y<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        sumProvinceAD.foreach(println)</span>        <span class="token comment" spellcheck="true">// 改变样式 (Province,(AD,1))</span>        <span class="token keyword">val</span> provinceToADSum<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sumProvinceAD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token punctuation">(</span>x<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> x<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        provinceToADSum.foreach(x=>println(x._1))</span>        <span class="token comment" spellcheck="true">// 根据省份分组</span>        <span class="token keyword">val</span> provinceSum<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> provinceToADSum<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        provinceSum.foreach(println)</span>        <span class="token comment" spellcheck="true">// 排序取前三</span>        <span class="token keyword">val</span> provinceADTop3<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> provinceSum<span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">{</span>            x<span class="token punctuation">.</span>toList<span class="token punctuation">.</span>sortWith<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">=></span> x<span class="token punctuation">.</span>_2 <span class="token operator">&lt;</span> y<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        provinceADTop3<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        provinceADTop3.saveAsTextFile("output")</span>        <span class="token comment" spellcheck="true">//9.关闭与spark的连接</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Action"><a href="#Action" class="headerlink" title="Action"></a>Action</h3><h4 id="reduce-func-案例"><a href="#reduce-func-案例" class="headerlink" title="reduce(func)案例"></a>reduce(func)案例</h4><ol><li><p>作用：通过func函数聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据。</p></li><li><p>需求：创建一个RDD，将所有元素聚合得到结果。</p></li></ol><p>（1）创建一个RDD[Int]</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）聚合RDD[Int]所有元素</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）创建一个RDD[String]</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）聚合RDD[String]所有数据</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd2<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>_1 <span class="token operator">+</span> y<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>x<span class="token punctuation">.</span>_2 <span class="token operator">+</span> y<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">(</span>adca<span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="collect-案例"><a href="#collect-案例" class="headerlink" title="collect()案例"></a>collect()案例</h4><ol><li><p>作用：在驱动程序中，以数组的形式返回数据集的所有元素。</p></li><li><p>需求：创建一个RDD，并将RDD内容收集到Driver端打印</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将结果收集到Driver端</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>collect——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="count-案例"><a href="#count-案例" class="headerlink" title="count()案例"></a>count()案例</h4><ol><li><p>作用：返回RDD中元素的个数</p></li><li><p>需求：创建一个RDD，统计该RDD的条数</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>count——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">10</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="first-案例"><a href="#first-案例" class="headerlink" title="first()案例"></a>first()案例</h4><ol><li><p>作用：返回RDD中的第一个元素</p></li><li><p>需求：创建一个RDD，返回该RDD中的第一个元素</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>first——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="take-n-案例"><a href="#take-n-案例" class="headerlink" title="take(n)案例"></a>take(n)案例</h4><ol><li><p>作用：返回一个由RDD的前n个元素组成的数组</p></li><li><p>需求：创建一个RDD，统计该RDD的条数</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="takeOrdered-n-案例"><a href="#takeOrdered-n-案例" class="headerlink" title="takeOrdered(n)案例"></a>takeOrdered(n)案例</h4><ol><li><p>作用：返回该RDD<strong>排序</strong>后的前n个元素组成的数组</p></li><li><p>需求：创建一个RDD，统计该RDD的条数</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>takeOrdered<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="aggregate案例"><a href="#aggregate案例" class="headerlink" title="aggregate案例"></a>aggregate案例</h4><ol><li><p>参数：(zeroValue: U)(seqOp: (U, T) ⇒ U, combOp: (U, U) ⇒ U)</p></li><li><p>作用：aggregate函数将每个分区里面的元素通过seqOp和初始值进行聚合，然后用combine函数将每个分区的结果和初始值(zeroValue)进行combine操作。这个函数最终返回的类型不需要和RDD中元素类型一致。</p></li><li><p>需求：创建一个RDD，将所有元素相加得到结果</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将该RDD所有元素相加得到结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>aggregate<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">,</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>此处初始值使用与 aggregateByKey 不太一样，分区内会操作一次，在分区间也会操作一次，如下：</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>aggregate<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">,</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res6<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">85</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>初始值是10，每个分区在求和的时候都是在10的基础上进行的，然后在两个分区相加的时候又会加一次：（10+1+2+3+4+5+6+7+8+9+10）+（10+1+2+3+4+5+6+7+8+9+10）+10</p><h4 id="fold-num-func-案例"><a href="#fold-num-func-案例" class="headerlink" title="fold(num)(func)案例"></a>fold(num)(func)案例</h4><ol><li><p>作用：折叠操作，aggregate的简化操作，seqop和combop一样。</p></li><li><p>需求：创建一个RDD，将所有元素相加得到结果</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将该RDD所有元素相加得到结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>fold<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res6<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>以上两个操作可以对应 xxxByKey 操作</p><h4 id="saveAsTextFile-path"><a href="#saveAsTextFile-path" class="headerlink" title="saveAsTextFile(path)"></a>saveAsTextFile(path)</h4><p>作用：将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本</p><h4 id="saveAsSequenceFile-path"><a href="#saveAsSequenceFile-path" class="headerlink" title="saveAsSequenceFile(path)"></a>saveAsSequenceFile(path)</h4><p>作用：将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。</p><h4 id="saveAsObjectFile-path"><a href="#saveAsObjectFile-path" class="headerlink" title="saveAsObjectFile(path)"></a>saveAsObjectFile(path)</h4><p>作用：用于将RDD中的元素序列化成对象，存储到文件中。</p><h4 id="countByKey-案例"><a href="#countByKey-案例" class="headerlink" title="countByKey()案例"></a>countByKey()案例</h4><ol><li><p>作用：针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。</p></li><li><p>需求：创建一个PairRDD，统计每种key的个数</p></li></ol><p>（1）创建一个PairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计每种key的个数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>countByKey——<span class="token operator">></span>res1<span class="token operator">:</span> scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token number">3</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="foreach-func-案例"><a href="#foreach-func-案例" class="headerlink" title="foreach(func)案例"></a>foreach(func)案例</h4><ol><li><p>作用：在数据集的每一个元素上，运行函数func进行更新。</p></li><li><p>需求：创建一个RDD，对每个元素进行打印</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）对该RDD每个元素进行打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token number">3</span><span class="token number">4</span><span class="token number">5</span><span class="token number">1</span><span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RDD中的函数传递"><a href="#RDD中的函数传递" class="headerlink" title="RDD中的函数传递"></a>RDD中的函数传递</h3><p>在实际开发中我们往往需要自己定义一些对于RDD的操作，那么此时需要主要的是，初始化工作是在Driver端进行的，而实际运行程序是在Executor端进行的，这就涉及到了跨进程通信，是需要序列化的。下面我们看几个例子：</p><h4 id="传递一个方法"><a href="#传递一个方法" class="headerlink" title="传递一个方法"></a>传递一个方法</h4><p>1．创建一个搜索类</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">/** * 搜索类 * @param query */</span><span class="token keyword">class</span> Search<span class="token punctuation">(</span>query<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的数据</span>    <span class="token keyword">def</span> isMatch<span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        s<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span>    <span class="token keyword">def</span> getMatch1 <span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span>    <span class="token keyword">def</span> getMatche2<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．创建Spark主程序</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: RDD中的函数传递（序列化） */</span><span class="token keyword">object</span> Spark16_Serializable <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建search对象</span>        <span class="token keyword">val</span> search <span class="token operator">=</span> <span class="token keyword">new</span> Search<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 运用第一个过滤函数并打印结果</span>        <span class="token keyword">val</span> match1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> search<span class="token punctuation">.</span>getMatch1<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        match1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．运行程序</p><pre class="line-numbers language-scala"><code class="language-scala">Exception in thread <span class="token string">"main"</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkException<span class="token operator">:</span> Task not serializable    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>ensureSerializable<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">298</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>org$apache$spark$util$ClosureCleaner$$clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">288</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">108</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>SparkContext<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">2101</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">387</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">151</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">112</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">362</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span class="token punctuation">.</span>getMatche1<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">39</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest$<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">18</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token punctuation">)</span>Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NotSerializableException<span class="token operator">:</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．问题说明</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span><span class="token keyword">def</span> getMatch1 <span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在这个方法中所调用的方法isMatch()是定义在Search这个类中的，实际上调用的是this. isMatch()，this表示Search这个类的对象，程序在运行过程中需要将Search对象序列化以后传递到Executor端。</p><p>5．解决方案</p><p>使类继承scala.Serializable即可。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">class</span> Search<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Serializable<span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="6"><li>修改之后完整代码</li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: RDD中的函数传递（序列化） */</span><span class="token keyword">object</span> Spark16_Serializable <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建search对象</span>        <span class="token keyword">val</span> search <span class="token operator">=</span> <span class="token keyword">new</span> Search<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 运用第一个过滤函数并打印结果</span>        <span class="token keyword">val</span> match1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> search<span class="token punctuation">.</span>getMatch1<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        match1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * 搜索类（需要序列化） * @param query */</span><span class="token keyword">class</span> Search<span class="token punctuation">(</span>query<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Serializable <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的数据</span>    <span class="token keyword">def</span> isMatch<span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        s<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span>    <span class="token comment" spellcheck="true">// 此方法是要在executor中执行，而此方法是一个成员方法（来源于某个对象），因此在使用的时候，这个类也要传给executor（因此这个类也需要序列化）</span>    <span class="token keyword">def</span> getMatch1 <span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="传递一个属性"><a href="#传递一个属性" class="headerlink" title="传递一个属性"></a>传递一个属性</h4><p>1．创建Spark主程序</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: RDD中的函数传递（序列化） */</span><span class="token keyword">object</span> Spark16_Serializable <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建search对象</span>        <span class="token keyword">val</span> search <span class="token operator">=</span> <span class="token keyword">new</span> Search<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 运用第一个过滤函数并打印结果</span><span class="token comment" spellcheck="true">//        val match1: RDD[String] = search.getMatch1(rdd)</span><span class="token comment" spellcheck="true">//        match1.collect().foreach(println)</span>        <span class="token comment" spellcheck="true">// 运用第二个</span>        <span class="token keyword">val</span> match2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> search<span class="token punctuation">.</span>getMatche2<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        match2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．运行程序</p><pre class="line-numbers language-scala"><code class="language-scala">Exception in thread <span class="token string">"main"</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkException<span class="token operator">:</span> Task not serializable    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>ensureSerializable<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">298</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>org$apache$spark$util$ClosureCleaner$$clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">288</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">108</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>SparkContext<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">2101</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">387</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">151</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">112</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">362</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span class="token punctuation">.</span>getMatche1<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">39</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest$<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">18</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token punctuation">)</span>Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NotSerializableException<span class="token operator">:</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．问题说明</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span><span class="token keyword">def</span> getMatche2<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在这个方法中所调用的方法query是定义在Search这个类中的字段，实际上调用的是this. query，this表示Search这个类的对象，程序在运行过程中需要将Search对象序列化以后传递到Executor端。</p><p>4．解决方案</p><p>1）使类继承scala.Serializable即可。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">class</span> Search<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Serializable<span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）将类变量query赋值给局部变量</p><p>修改getMatche2为</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span><span class="token keyword">def</span> getMatche2<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> query_ <span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>query<span class="token comment" spellcheck="true">//将类变量赋值给局部变量</span>    rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RDD依赖关系"><a href="#RDD依赖关系" class="headerlink" title="RDD依赖关系"></a>RDD依赖关系</h3><h4 id="Lineage"><a href="#Lineage" class="headerlink" title="Lineage"></a>Lineage</h4><p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p><p>（1）读取一个HDFS文件并将其中内容映射成一个个元组</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> wordAndOne <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"/fruit.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>wordAndOne<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计每一种key对应的个数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> wordAndCount <span class="token operator">=</span> wordAndOne<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>wordAndCount<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span> at reduceByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）查看“wordAndOne”的Lineage</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndOne<span class="token punctuation">.</span>toDebugString——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at flatMap at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv HadoopRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）查看“wordAndCount”的Lineage</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndCount<span class="token punctuation">.</span>toDebugString——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span> at reduceByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at flatMap at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv HadoopRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）查看“wordAndOne”的依赖类型</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndOne<span class="token punctuation">.</span>dependencies——<span class="token operator">></span>res3<span class="token operator">:</span> Seq<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> List<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>OneToOneDependency<span class="token annotation punctuation">@5d5db92b</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）查看“wordAndCount”的依赖类型</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndCount<span class="token punctuation">.</span>dependencies——<span class="token operator">></span>res4<span class="token operator">:</span> Seq<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> List<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>ShuffleDependency<span class="token annotation punctuation">@63f3e6a8</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>注意：</strong>RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。</p><h4 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h4><p>窄依赖指的是每一个父RDD的Partition最多被子RDD的一个Partition使用,窄依赖我们形象的比喻为独生子女（一对一）</p><p><img src="25.png" alt></p><h4 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h4><p>宽依赖指的是多个子RDD的Partition会依赖同一个父RDD的Partition，会引起shuffle,总结：宽依赖我们形象的比喻为超生（多对一）</p><p><img src="26.png" alt></p><h4 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h4><p>DAG(Directed Acyclic Graph) 叫做有向无环图，原始的 RDD 通过一系列的转换就就形成了 DAG，根据 RDD 之间的依赖关系的不同将 DAG 划分成不同的 Stage（阶段），对于窄依赖，partition的转换处理在Stage中完成计算。对于宽依赖，由于有 Shuffle 的存在，只能在 parent RDD 处理完成后，才能开始接下来的计算，因此宽依赖是划分 Stage 的依据。</p><p><img src="27.png" alt></p><p>上图可看，A与B试一个宽依赖所以分成两个stage；F与G试一个宽依赖，所以分成了两个stage。</p><h4 id="任务划分（面试重点）"><a href="#任务划分（面试重点）" class="headerlink" title="任务划分（面试重点）"></a>任务划分（面试重点）</h4><p>RDD任务切分中间分为：Application、Job、Stage和Task</p><p>1）Application：初始化一个 SparkContext 即生成一个 Application</p><p>2）Job：一个 Action 算子就会生成一个 Job</p><p>3）Stage：根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage。</p><p>4）Task：Stage是一个TaskSet，将Stage划分的结果发送到不同的Executor执行即为一个Task。</p><p>WordCount案列规划图</p><p><img src="28.png" alt></p><p><strong>注意：</strong>Application-&gt;Job（行动算子）-&gt;Stage-&gt; Task（分区）每一层都是1对n的关系。</p><p>一个应用可以多次调用行动算子（Job），而每个作业中可以有多个阶段，同时在一个阶段中有多个分区（每个分区就是一个任务）</p><p>阶段划分数量 = 1 + shuffle数量，源码分析：</p><p>[DAGScheduler.scala]</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">private</span><span class="token punctuation">[</span>scheduler<span class="token punctuation">]</span> <span class="token keyword">def</span> handleJobSubmitted<span class="token punctuation">(</span>jobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span>    finalRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">,</span>    func<span class="token operator">:</span> <span class="token punctuation">(</span>TaskContext<span class="token punctuation">,</span> Iterator<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=></span> _<span class="token punctuation">,</span>    partitions<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    callSite<span class="token operator">:</span> CallSite<span class="token punctuation">,</span>    listener<span class="token operator">:</span> JobListener<span class="token punctuation">,</span>    properties<span class="token operator">:</span> Properties<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">var</span> finalStage<span class="token operator">:</span> ResultStage <span class="token operator">=</span> <span class="token keyword">null</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// New stage creation may throw an exception if, for example, jobs are run on a</span>        <span class="token comment" spellcheck="true">// HadoopRDD whose underlying HDFS files have been deleted.</span>        <span class="token comment" spellcheck="true">// 此处便是阶段数量中的1</span>        finalStage <span class="token operator">=</span> createResultStage<span class="token punctuation">(</span>finalRDD<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitions<span class="token punctuation">,</span> jobId<span class="token punctuation">,</span> callSite<span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true">// 提交</span>        submitStage<span class="token punctuation">(</span>finalStage<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接上面 createResultStage</span><span class="token comment" spellcheck="true">/*** Create a ResultStage associated with the provided jobId.*/</span><span class="token keyword">private</span> <span class="token keyword">def</span> createResultStage<span class="token punctuation">(</span>    rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">,</span>    func<span class="token operator">:</span> <span class="token punctuation">(</span>TaskContext<span class="token punctuation">,</span> Iterator<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=></span> _<span class="token punctuation">,</span>    partitions<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    jobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span>    callSite<span class="token operator">:</span> CallSite<span class="token punctuation">)</span><span class="token operator">:</span> ResultStage <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取或创建阶段</span>        <span class="token keyword">val</span> parents <span class="token operator">=</span> getOrCreateParentStages<span class="token punctuation">(</span>rdd<span class="token punctuation">,</span> jobId<span class="token punctuation">)</span>        <span class="token keyword">val</span> id <span class="token operator">=</span> nextStageId<span class="token punctuation">.</span>getAndIncrement<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> stage <span class="token operator">=</span> <span class="token keyword">new</span> ResultStage<span class="token punctuation">(</span>id<span class="token punctuation">,</span> rdd<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitions<span class="token punctuation">,</span> parents<span class="token punctuation">,</span> jobId<span class="token punctuation">,</span> callSite<span class="token punctuation">)</span>        stageIdToStage<span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">=</span> stage        updateJobIdStageIdMaps<span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> stage<span class="token punctuation">)</span>        stage<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接上面 getOrCreateParentStages</span><span class="token comment" spellcheck="true">/*** Get or create the list of parent stages for a given RDD.  The new Stages will be created with* the provided firstJobId.*/</span><span class="token keyword">private</span> <span class="token keyword">def</span> getOrCreateParentStages<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">,</span> firstJobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> List<span class="token punctuation">[</span>Stage<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 拿到shuffle依赖做转换</span>    getShuffleDependencies<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{</span> shuffleDep <span class="token keyword">=></span>        getOrCreateShuffleMapStage<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">,</span> firstJobId<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">.</span>toList<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接上面 getShuffleDependencies</span><span class="token keyword">private</span><span class="token punctuation">[</span>scheduler<span class="token punctuation">]</span> <span class="token keyword">def</span> getShuffleDependencies<span class="token punctuation">(</span>    rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> HashSet<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 返回值（其返回set中类型为ShuffleDependency，因此其中放的值便为shuffle）</span>        <span class="token keyword">val</span> parents <span class="token operator">=</span> <span class="token keyword">new</span> HashSet<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">val</span> visited <span class="token operator">=</span> <span class="token keyword">new</span> HashSet<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">val</span> waitingForVisit <span class="token operator">=</span> <span class="token keyword">new</span> Stack<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span>        waitingForVisit<span class="token punctuation">.</span>push<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>waitingForVisit<span class="token punctuation">.</span>nonEmpty<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> toVisit <span class="token operator">=</span> waitingForVisit<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>visited<span class="token punctuation">(</span>toVisit<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                visited <span class="token operator">+=</span> toVisit                toVisit<span class="token punctuation">.</span>dependencies<span class="token punctuation">.</span>foreach <span class="token punctuation">{</span>                    <span class="token comment" spellcheck="true">// 模式匹配，只要某个RDD的依赖是shuffle的，就加到返回的parents中</span>                    <span class="token keyword">case</span> shuffleDep<span class="token operator">:</span> ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span> <span class="token keyword">=></span>                         parents <span class="token operator">+=</span> shuffleDep                    <span class="token keyword">case</span> dependency <span class="token keyword">=></span>                        waitingForVisit<span class="token punctuation">.</span>push<span class="token punctuation">(</span>dependency<span class="token punctuation">.</span>rdd<span class="token punctuation">)</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    parents<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 在上面那个方法返回parents之后进行转换</span><span class="token comment" spellcheck="true">// 接上上面 getOrCreateShuffleMapStage</span><span class="token comment" spellcheck="true">/*** Gets a shuffle map stage if one exists in shuffleIdToMapStage. Otherwise, if the* shuffle map stage doesn't already exist, this method will create the shuffle map stage in* addition to any missing ancestor shuffle map stages.*/</span><span class="token keyword">private</span> <span class="token keyword">def</span> getOrCreateShuffleMapStage<span class="token punctuation">(</span>    shuffleDep<span class="token operator">:</span> ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">,</span>    firstJobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> ShuffleMapStage <span class="token operator">=</span> <span class="token punctuation">{</span>        shuffleIdToMapStage<span class="token punctuation">.</span>get<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">.</span>shuffleId<span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 模式匹配，若当前stage已经有了，则直接返回；</span>            <span class="token keyword">case</span> Some<span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token keyword">=></span>                stage            <span class="token comment" spellcheck="true">// 若没有则创建</span>            <span class="token keyword">case</span> None <span class="token keyword">=></span>            <span class="token comment" spellcheck="true">// Create stages for all missing ancestor shuffle dependencies.</span>                getMissingAncestorShuffleDependencies<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">.</span>rdd<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach <span class="token punctuation">{</span> dep <span class="token keyword">=></span>            <span class="token comment" spellcheck="true">// Even though getMissingAncestorShuffleDependencies only returns shuffle dependencies</span>            <span class="token comment" spellcheck="true">// that were not already in shuffleIdToMapStage, it's possible that by the time we</span>            <span class="token comment" spellcheck="true">// get to a particular dependency in the foreach loop, it's been added to</span>            <span class="token comment" spellcheck="true">// shuffleIdToMapStage by the stage creation process for an earlier dependency. See</span>            <span class="token comment" spellcheck="true">// SPARK-13902 for more information.</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>shuffleIdToMapStage<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>dep<span class="token punctuation">.</span>shuffleId<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                createShuffleMapStage<span class="token punctuation">(</span>dep<span class="token punctuation">,</span> firstJobId<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// Finally, create a stage for the given shuffle dependency.</span>        createShuffleMapStage<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">,</span> firstJobId<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接第一个最后的提交</span><span class="token comment" spellcheck="true">/** Submits stage, but first recursively submits any missing parents. */</span><span class="token keyword">private</span> <span class="token keyword">def</span> submitStage<span class="token punctuation">(</span>stage<span class="token operator">:</span> Stage<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> jobId <span class="token operator">=</span> activeJobForStage<span class="token punctuation">(</span>stage<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>jobId<span class="token punctuation">.</span>isDefined<span class="token punctuation">)</span> <span class="token punctuation">{</span>        logDebug<span class="token punctuation">(</span><span class="token string">"submitStage("</span> <span class="token operator">+</span> stage <span class="token operator">+</span> <span class="token string">")"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>waitingStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>runningStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>failedStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> missing <span class="token operator">=</span> getMissingParentStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span><span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span>            logDebug<span class="token punctuation">(</span><span class="token string">"missing: "</span> <span class="token operator">+</span> missing<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>missing<span class="token punctuation">.</span>isEmpty<span class="token punctuation">)</span> <span class="token punctuation">{</span>                logInfo<span class="token punctuation">(</span><span class="token string">"Submitting "</span> <span class="token operator">+</span> stage <span class="token operator">+</span> <span class="token string">" ("</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>rdd <span class="token operator">+</span> <span class="token string">"), which has no missing parents"</span><span class="token punctuation">)</span>                submitMissingTasks<span class="token punctuation">(</span>stage<span class="token punctuation">,</span> jobId<span class="token punctuation">.</span>get<span class="token punctuation">)</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span>parent <span class="token keyword">&lt;-</span> missing<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    submitStage<span class="token punctuation">(</span>parent<span class="token punctuation">)</span>                <span class="token punctuation">}</span>                waitingStages <span class="token operator">+=</span> stage            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        abortStage<span class="token punctuation">(</span>stage<span class="token punctuation">,</span> <span class="token string">"No active job for stage "</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> None<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala">  <span class="token comment" spellcheck="true">// 接上面的 submitMissingTasks（这只是其中一部分）</span>  <span class="token comment" spellcheck="true">/** Called when stage's parents are available and we can now do its task. */</span>  <span class="token keyword">private</span> <span class="token keyword">def</span> submitMissingTasks<span class="token punctuation">(</span>stage<span class="token operator">:</span> Stage<span class="token punctuation">,</span> jobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">val</span> tasks<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Task<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token punctuation">{</span>      stage <span class="token keyword">match</span> <span class="token punctuation">{</span>        <span class="token keyword">case</span> stage<span class="token operator">:</span> ShuffleMapStage <span class="token keyword">=></span>          <span class="token comment" spellcheck="true">// 根据分区计算任务</span>          partitionsToCompute<span class="token punctuation">.</span>map <span class="token punctuation">{</span> id <span class="token keyword">=></span>            <span class="token keyword">val</span> locs <span class="token operator">=</span> taskIdToLocations<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token keyword">val</span> part <span class="token operator">=</span> stage<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">// 最后返回为一个task</span>            <span class="token keyword">new</span> ShuffleMapTask<span class="token punctuation">(</span>stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptId<span class="token punctuation">,</span>              taskBinary<span class="token punctuation">,</span> part<span class="token punctuation">,</span> locs<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>taskMetrics<span class="token punctuation">,</span> properties<span class="token punctuation">,</span> Option<span class="token punctuation">(</span>jobId<span class="token punctuation">)</span><span class="token punctuation">,</span>              Option<span class="token punctuation">(</span>sc<span class="token punctuation">.</span>applicationId<span class="token punctuation">)</span><span class="token punctuation">,</span> sc<span class="token punctuation">.</span>applicationAttemptId<span class="token punctuation">)</span>          <span class="token punctuation">}</span>        <span class="token keyword">case</span> stage<span class="token operator">:</span> ResultStage <span class="token keyword">=></span>          partitionsToCompute<span class="token punctuation">.</span>map <span class="token punctuation">{</span> id <span class="token keyword">=></span>            <span class="token keyword">val</span> p<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> stage<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token keyword">val</span> part <span class="token operator">=</span> stage<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span>p<span class="token punctuation">)</span>            <span class="token keyword">val</span> locs <span class="token operator">=</span> taskIdToLocations<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token keyword">new</span> ResultTask<span class="token punctuation">(</span>stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptId<span class="token punctuation">,</span>              taskBinary<span class="token punctuation">,</span> part<span class="token punctuation">,</span> locs<span class="token punctuation">,</span> id<span class="token punctuation">,</span> properties<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>taskMetrics<span class="token punctuation">,</span>              Option<span class="token punctuation">(</span>jobId<span class="token punctuation">)</span><span class="token punctuation">,</span> Option<span class="token punctuation">(</span>sc<span class="token punctuation">.</span>applicationId<span class="token punctuation">)</span><span class="token punctuation">,</span> sc<span class="token punctuation">.</span>applicationAttemptId<span class="token punctuation">)</span>          <span class="token punctuation">}</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>tasks<span class="token punctuation">.</span>size <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      logInfo<span class="token punctuation">(</span><span class="token string">"Submitting "</span> <span class="token operator">+</span> tasks<span class="token punctuation">.</span>size <span class="token operator">+</span> <span class="token string">" missing tasks from "</span> <span class="token operator">+</span> stage <span class="token operator">+</span> <span class="token string">" ("</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>rdd <span class="token operator">+</span> <span class="token string">")"</span><span class="token punctuation">)</span>      stage<span class="token punctuation">.</span>pendingPartitions <span class="token operator">++</span><span class="token operator">=</span> tasks<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>partitionId<span class="token punctuation">)</span>      logDebug<span class="token punctuation">(</span><span class="token string">"New pending partitions: "</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>pendingPartitions<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">// 将所有信息封装成一个TaskSet进行提交</span>      taskScheduler<span class="token punctuation">.</span>submitTasks<span class="token punctuation">(</span><span class="token keyword">new</span> TaskSet<span class="token punctuation">(</span>        tasks<span class="token punctuation">.</span>toArray<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptId<span class="token punctuation">,</span> jobId<span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">)</span>      stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>submissionTime <span class="token operator">=</span> Some<span class="token punctuation">(</span>clock<span class="token punctuation">.</span>getTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RDD缓存"><a href="#RDD缓存" class="headerlink" title="RDD缓存"></a>RDD缓存</h3><p>RDD通过persist方法或cache方法可以将前面的计算结果缓存，默认情况下 persist() 会把数据以序列化的形式缓存在 JVM 的堆空间中。 </p><p>但是并不是这两个方法被调用时立即缓存，而是触发后面的action时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> persist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> persist<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过查看源码发现cache最终也是调用了persist方法，默认的存储级别都是仅在内存存储一份，Spark的存储级别还有好多种，存储级别在object StorageLevel中定义的。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">object</span> StorageLevel <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 不缓存</span>    <span class="token keyword">val</span> NONE <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 只缓存到磁盘</span>    <span class="token keyword">val</span> DISK_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 缓存盘2份副本</span>    <span class="token keyword">val</span> DISK_ONLY_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 只缓存到内存</span>    <span class="token keyword">val</span> MEMORY_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_ONLY_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 缓存到内存序列化</span>    <span class="token keyword">val</span> MEMORY_ONLY_SER <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_ONLY_SER_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK_SER <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK_SER_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 堆外内存（JVM里面的内存是堆内，不是其中的内存叫堆外）</span>    <span class="token keyword">val</span> OFF_HEAP <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在存储级别的末尾加上“_2”来把持久化数据存为两份 </p><p><img src="29.png" alt></p><p>缓存有可能丢失，或者存储存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将RDD转换为携带当前时间戳不做缓存</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 后面加上一个时间戳</span>scala<span class="token operator">></span> <span class="token keyword">val</span> nocache <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>toString<span class="token operator">+</span>System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">)</span>——<span class="token operator">></span>nocache<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）多次打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> nocache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728101126<span class="token punctuation">)</span>scala<span class="token operator">></span> nocache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728114573<span class="token punctuation">)</span>scala<span class="token operator">></span> nocache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728141278<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）将RDD转换为携带当前时间戳并做缓存</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> cache <span class="token operator">=</span>  rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>toString<span class="token operator">+</span>System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">)</span><span class="token punctuation">.</span>cache——<span class="token operator">></span>cache<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）多次打印做了缓存的结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> cache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728208803<span class="token punctuation">)</span>                               scala<span class="token operator">></span> cache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728208803<span class="token punctuation">)</span>scala<span class="token operator">></span> cache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728208803<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> cache<span class="token punctuation">.</span>toDebugStringres8<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span> <span class="token punctuation">[</span>Memory Deserialized 1x Replicated<span class="token punctuation">]</span> <span class="token operator">|</span>       CachedPartitions<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">;</span> MemorySize<span class="token operator">:</span> <span class="token number">104.0</span> B<span class="token punctuation">;</span> ExternalBlockStoreSize<span class="token operator">:</span> <span class="token number">0.0</span> B<span class="token punctuation">;</span> DiskSize<span class="token operator">:</span> <span class="token number">0.0</span> B <span class="token operator">|</span>  ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span>Memory Deserialized 1x Replicated<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>debug之后可以看出，其在依赖关系中间加了一个缓存步骤</p><h3 id="RDD-CheckPoint"><a href="#RDD-CheckPoint" class="headerlink" title="RDD CheckPoint"></a>RDD CheckPoint</h3><p>Spark中对于数据的保存除了持久化操作之外，还提供了一种检查点的机制，检查点（本质是通过将RDD写入Disk做检查点）是为了通过lineage做容错的辅助，lineage过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的RDD开始重做Lineage，就会减少开销。检查点通过将数据写入到HDFS文件系统实现了RDD的检查点功能。</p><p>为当前RDD设置检查点。该函数将会创建一个二进制的文件，并存储到checkpoint目录中，该目录是用SparkContext.setCheckpointDir()设置的。在checkpoint的过程中，该RDD的所有依赖于父RDD中的信息将全部被移除。对RDD进行checkpoint操作并不会马上被执行，必须执行Action操作才能触发。</p><p>案例实操：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/03 下午 08:25 * @Func: 检查点（设置检查点就是将血缘关系保存成文件） */</span><span class="token keyword">object</span> Spark17_Checkpoint <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 设定检查点保存目录</span>        sc<span class="token punctuation">.</span>setCheckpointDir<span class="token punctuation">(</span><span class="token string">"CheckPoint"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 构造rdd</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 进行简单处理</span>        <span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> reduceRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 设置检查点</span>        reduceRDD<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 输出查看</span>        reduceRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 血缘关系</span>        println<span class="token punctuation">(</span>reduceRDD<span class="token punctuation">.</span>toDebugString<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果差距（运行两遍，查看血缘关系的变化）</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 运行第一遍</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at reduceByKey at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">27</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at map at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">26</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">23</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">// 运行第二遍</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at reduceByKey at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">27</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  ReliableCheckpointRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at foreach at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">33</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="键值对RDD数据分区器"><a href="#键值对RDD数据分区器" class="headerlink" title="键值对RDD数据分区器"></a>键值对RDD数据分区器</h2><p>Spark目前支持Hash分区和Range分区，用户也可以自定义分区，Hash分区为当前的默认分区，Spark中分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle过程属于哪个分区和Reduce的个数</p><p><strong>注意：</strong></p><p>(1)只有Key-Value类型的RDD才有分区器的，非Key-Value类型的RDD分区器的值是None</p><p>(2)每个RDD的分区ID范围：0~numPartitions-1，决定这个值是属于那个分区的。</p><h3 id="获取RDD分区"><a href="#获取RDD分区" class="headerlink" title="获取RDD分区"></a>获取RDD分区</h3><p>可以通过使用RDD的partitioner 属性来获取 RDD 的分区方式。它会返回一个 scala.Option 对象， 通过get方法获取其中的值。相关源码如下：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> getPartition<span class="token punctuation">(</span>key<span class="token operator">:</span> <span class="token builtin">Any</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> key <span class="token keyword">match</span> <span class="token punctuation">{</span>  <span class="token keyword">case</span> <span class="token keyword">null</span> <span class="token keyword">=></span> <span class="token number">0</span>  <span class="token keyword">case</span> _ <span class="token keyword">=></span> Utils<span class="token punctuation">.</span>nonNegativeMod<span class="token punctuation">(</span>key<span class="token punctuation">.</span>hashCode<span class="token punctuation">,</span> numPartitions<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">def</span> nonNegativeMod<span class="token punctuation">(</span>x<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> mod<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>  <span class="token keyword">val</span> rawMod <span class="token operator">=</span> x <span class="token operator">%</span> mod  rawMod <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">if</span> <span class="token punctuation">(</span>rawMod <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> mod <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> pairs <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>pairs<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）查看RDD的分区器</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> pairs<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res1<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> None<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）导入HashPartitioner类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）使用HashPartitioner对RDD进行重新分区</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> partitioned <span class="token operator">=</span> pairs<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> HashPartitioner<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>partitioned<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at partitionBy at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">27</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）查看重新分区后RDD的分区器</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> partitioned<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res2<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> Some<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token annotation punctuation">@2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Hash分区"><a href="#Hash分区" class="headerlink" title="Hash分区"></a>Hash分区</h3><p>HashPartitioner分区的原理：对于给定的key，计算其hashCode，并除以分区的个数取余，如果余数小于0，则用余数+分区的个数（否则加0），最后返回的值就是这个key所属的分区ID。</p><p>使用Hash分区的实操</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> nopar<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res1<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> Nonescala<span class="token operator">></span> <span class="token keyword">val</span> nopar <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>——<span class="token operator">></span>nopar<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span>scala<span class="token operator">></span>nopar<span class="token punctuation">.</span>mapPartitionsWithIndex<span class="token punctuation">(</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span>iter<span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">{</span> Iterator<span class="token punctuation">(</span>index<span class="token punctuation">.</span>toString<span class="token operator">+</span><span class="token string">" : "</span><span class="token operator">+</span>iter<span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token string">"0 : "</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"4 : "</span><span class="token punctuation">,</span> <span class="token number">5</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">6</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">7</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span> scala<span class="token operator">></span> <span class="token keyword">val</span> hashpar <span class="token operator">=</span> nopar<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>hashpar<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span> at partitionBy at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span>scala<span class="token operator">></span> hashpar<span class="token punctuation">.</span>count——<span class="token operator">></span>res3<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">6</span>scala<span class="token operator">></span> hashpar<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res4<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> Some<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token annotation punctuation">@7</span><span class="token punctuation">)</span>scala<span class="token operator">></span> hashpar<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>iter <span class="token keyword">=></span> Iterator<span class="token punctuation">(</span>iter<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>res19<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Ranger分区"><a href="#Ranger分区" class="headerlink" title="Ranger分区"></a>Ranger分区</h3><p>HashPartitioner分区弊端：可能导致每个分区中数据量的不均匀，极端情况下会导致某些分区拥有RDD的全部数据。</p><p>RangePartitioner作用：将一定范围内的数映射到某一个分区内，尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，一个分区中的元素肯定都是比另一个分区内的元素小或者大，但是分区内的元素是不能保证顺序的。简单的说就是将一定范围内的数映射到某一个分区内。实现过程为：</p><p>第一步：先重整个RDD中抽取出样本数据，将样本数据排序，计算出每个分区的最大key值，形成一个Array[KEY]类型的数组变量rangeBounds；</p><p>第二步：判断key在rangeBounds中所处的范围，给出该key值在下一个RDD中的分区id下标；该分区器要求RDD中的KEY类型必须是可以排序的</p><h3 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h3><p>要实现自定义的分区器，你需要继承 org.apache.spark.Partitioner 类并实现下面三个方法。 </p><p>（1）numPartitions：Int:返回创建出来的分区数。</p><p>（2）getPartition(key: Any)：Int:返回给定键的分区编号(0到numPartitions-1)。 </p><p>（3）equals()：Java 判断相等性的标准方法。这个方法的实现非常重要，Spark 需要用这个方法来检查你的分区器对象是否和其他分区器实例相同，这样 Spark 才可以判断两个 RDD 的分区方式是否相同。(这个方法某些情况下不写也是可以的)</p><p>使用自定义的 Partitioner 是很容易的：只要把它传给 partitionBy() 方法即可。Spark 中有许多依赖于数据混洗的方法，比如 join() 和 groupByKey()，它们也可以接收一个可选的 Partitioner 对象来控制输出数据的分区方式。</p><p>因为之前实现过自定义分区器，这里不在累述，demo地址</p><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/Spark12_Oper11.scala" target="_blank" rel="noopener">com.swenchao.spark.Spark12_Oper11</a></p><h2 id="数据读取与保存"><a href="#数据读取与保存" class="headerlink" title="数据读取与保存"></a>数据读取与保存</h2><p>Spark的数据读取及数据保存可以从两个维度来作区分：文件格式以及文件系统。</p><p>文件格式分为：text文件、json文件、csv文件、sequence文件以及object文件；</p><p>文件系统分为：本地文件系统、HDFS、HBASE以及数据库。</p><h3 id="文件类数据读取与保存"><a href="#文件类数据读取与保存" class="headerlink" title="文件类数据读取与保存"></a>文件类数据读取与保存</h3><h4 id="Text文件"><a href="#Text文件" class="headerlink" title="Text文件"></a>Text文件</h4><p>1）数据读取:textFile(String)</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> hdfsFile <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/fruit.txt"</span><span class="token punctuation">)</span>——<span class="token operator">></span>hdfsFile<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop102<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>fruit<span class="token punctuation">.</span>txt MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）数据保存: saveAsTextFile(String)</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> hdfsFile<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"/fruitOut"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Json文件"><a href="#Json文件" class="headerlink" title="Json文件"></a>Json文件</h4><p>如果JSON文件中每一行就是一个JSON记录，那么可以通过将JSON文件当做文本文件来读取，然后利用相关的JSON库对每一条数据进行JSON解析。</p><p><strong>注意：</strong>使用RDD读取JSON文件处理很复杂，同时SparkSQL集成了很好的处理JSON文件的方式，所以应用中多是采用SparkSQL处理JSON文件。</p><p>其中JSON文件地址：<a href="https://github.com/Swenchao/SparkCode/blob/master/in/user.json" target="_blank" rel="noopener">in/user.json</a></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>parsing<span class="token punctuation">.</span>json<span class="token punctuation">.</span>JSON<span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/03 下午 09:33 * @Func: Json文件处理 */</span><span class="token keyword">object</span> Spark18_Json <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取json文件</span>        <span class="token keyword">val</span> jsonRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"in/user.json"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 进行解析</span>        <span class="token keyword">val</span> res<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Option<span class="token punctuation">[</span><span class="token builtin">Any</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> jsonRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>JSON<span class="token punctuation">.</span>parseFull<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 输出</span>        res<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果输出</p><pre><code>    Some(Map(name -&gt; zhangsan, age -&gt; 18.0))    Some(Map(name -&gt; wangwu, age -&gt; 18.0))    Some(Map(name -&gt; zhaoliu, age -&gt; 18.0))    Some(Map(name -&gt; lisi, age -&gt; 18.0))</code></pre><p><strong>注：</strong>这个包显示不能用了，但是结果还是出来了。从网上还没找到完全的替代品。</p><h4 id="Sequence文件"><a href="#Sequence文件" class="headerlink" title="Sequence文件"></a>Sequence文件</h4><p>SequenceFile文件是Hadoop用来存储二进制形式的key-value对而设计的一种平面文件(Flat File)。Spark 有专门用来读取 SequenceFile 的接口。在 SparkContext 中，可以调用 sequenceFile<a href="path"> keyClass, valueClass</a>。</p><p><strong>注意：</strong>SequenceFile文件只针对PairRDD</p><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将RDD保存为Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>saveAsSequenceFile<span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/seqFile"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看该文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 seqFile]$ pwd——>/opt/module/spark/seqFile[user_test@hadoop102 seqFile]$ ll总用量 8-rw-r--r-- 1 atguigu atguigu 108 10月  9 10:29 part-00000-rw-r--r-- 1 atguigu atguigu 124 10月  9 10:29 part-00001-rw-r--r-- 1 atguigu atguigu   0 10月  9 10:29 _SUCCESS[user_test@hadoop102 seqFile]$ cat part-00000——>SEQ org.apache.hadoop.io.IntWritable org.apache.hadoop.io.IntWritable<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）读取Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> seq <span class="token operator">=</span> sc<span class="token punctuation">.</span>sequenceFile<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/seqFile"</span><span class="token punctuation">)</span>——<span class="token operator">></span>seq<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span> at sequenceFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）打印读取后的Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> seq<span class="token punctuation">.</span>collect——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="对象文件"><a href="#对象文件" class="headerlink" title="对象文件"></a>对象文件</h4><p>对象文件是将对象序列化后保存的文件，采用Java的序列化机制。可以通过objectFile<a href="path">k,v</a> 函数接收一个路径，读取对象文件，返回对应的 RDD，也可以通过调用saveAsObjectFile() 实现对对象文件的输出。因为是序列化所以要指定类型。</p><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将RDD保存为Object文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>saveAsObjectFile<span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/objectFile"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看该文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 objectFile]$ pwd——>/opt/module/spark/objectFile[user_test@hadoop102 objectFile]$ ll——>总用量 8-rw-r--r-- 1 atguigu atguigu 142 10月  9 10:37 part-00000-rw-r--r-- 1 atguigu atguigu 142 10月  9 10:37 part-00001-rw-r--r-- 1 atguigu atguigu   0 10月  9 10:37 _SUCCESS[user_test@hadoop102 objectFile]$ cat part-00000 ——>SEQ!org.apache.hadoop.io.NullWritable"org.apache.hadoop.io.BytesWritableW@`l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）读取Object文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> objFile <span class="token operator">=</span> sc<span class="token punctuation">.</span>objectFile<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/objectFile"</span><span class="token punctuation">)</span>——<span class="token operator">></span>objFile<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span> at objectFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）打印读取后的Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> objFile<span class="token punctuation">.</span>collectres19<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="文件系统类数据读取与保存"><a href="#文件系统类数据读取与保存" class="headerlink" title="文件系统类数据读取与保存"></a>文件系统类数据读取与保存</h3><h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>Spark的整个生态系统与Hadoop是完全兼容的，所以对于Hadoop所支持的文件类型或者数据库类型，Spark也同样支持。另外，由于Hadoop的API有新旧两个版本，所以Spark为了能够兼容Hadoop所有的版本，也提供了两套创建操作接口。对于外部存储创建操作而言，hadoopRDD和newHadoopRDD是最为抽象的两个函数接口，主要包含以下四个参数。</p><p>1）输入格式(InputFormat)：制定数据输入的类型，如TextInputFormat等，新旧两个版本所引用的版本分别是 org.apache.hadoop.mapred.InputFormat 和 org.apache.hadoop.mapreduce.InputFormat(NewInputFormat)</p><p>2）键类型：指定[K,V]键值对中K的类型</p><p>3）值类型：指定[K,V]键值对中V的类型</p><p>4）分区值：指定由外部存储生成的RDD的partition数量的最小值,如果没有指定,系统会使用默认值defaultMinSplits</p><p><strong>注意：</strong>其他创建操作的API接口都是为了方便最终的Spark程序开发者而设置的,是这两个接口的高效实现版本。例如，对于textFile而言，只有path这个指定文件路径的参数,其他参数在系统内部指定了默认值。</p><ol><li><p>在Hadoop中以压缩形式存储的数据,不需要指定解压方式就能够进行读取,因为Hadoop本身有一个解压器会根据压缩文件的后缀推断解压算法进行解压。</p></li><li><p>如果用Spark从Hadoop中读取某种类型的数据不知道怎么读取的时候,上网查找一个使用map-reduce的时候是怎么读取这种这种数据的,然后再将对应的读取方式改写成上面的hadoopRDD和newAPIHadoopRDD两个类就行了</p></li></ol><h4 id="MySQL数据库连接"><a href="#MySQL数据库连接" class="headerlink" title="MySQL数据库连接"></a>MySQL数据库连接</h4><p>支持通过Java JDBC访问关系型数据库。需要通过JdbcRDD进行，示例:</p><p>表结构</p><p>[user]</p><table><thead><tr><th>列名</th><th>类型</th></tr></thead><tbody><tr><td>id</td><td>int(11)</td></tr><tr><td>name</td><td>varchar(255)</td></tr><tr><td>age</td><td>int(11)</td></tr></tbody></table><p>（1）添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.27<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）Mysql读取与新增：</p><p>demo地址：</p><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/Spark19_Mysql.scala" target="_blank" rel="noopener">com.swenchao.spark.Spark19_Mysql</a></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span><span class="token punctuation">{</span>JdbcRDD<span class="token punctuation">,</span> RDD<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/04 下午 09:33 * @Func: Mysql连接 */</span><span class="token keyword">object</span> Spark19_Mysql <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 定义mysql参数</span>        <span class="token keyword">val</span> driver <span class="token operator">=</span> <span class="token string">"com.mysql.jdbc.Driver"</span>        <span class="token keyword">val</span> url <span class="token operator">=</span> <span class="token string">"jdbc:mysql://127.0.0.1:3306/rdd"</span>        <span class="token keyword">val</span> userName <span class="token operator">=</span> <span class="token string">"root"</span>        <span class="token keyword">val</span> passWd <span class="token operator">=</span> <span class="token string">"123456"</span>        <span class="token comment" spellcheck="true">/***************询数据*********************/</span>        <span class="token comment" spellcheck="true">//创建 JdbcRDD，访问数据库</span><span class="token comment" spellcheck="true">//        val selectRDD = new JdbcRDD(</span><span class="token comment" spellcheck="true">//            sc,</span><span class="token comment" spellcheck="true">//            () => {</span><span class="token comment" spellcheck="true">//                // 获取数据库连接对象</span><span class="token comment" spellcheck="true">//                Class.forName(driver)</span><span class="token comment" spellcheck="true">//                DriverManager.getConnection(url, userName, passWd)</span><span class="token comment" spellcheck="true">//            },</span><span class="token comment" spellcheck="true">//            "select name, age from user where id >= ? and id &lt;= ?",</span><span class="token comment" spellcheck="true">//            // 1是sql的第一个问号，2是sql的第二个问号</span><span class="token comment" spellcheck="true">//            1,</span><span class="token comment" spellcheck="true">//            3,</span><span class="token comment" spellcheck="true">//            2,</span><span class="token comment" spellcheck="true">//            (rs) => {</span><span class="token comment" spellcheck="true">//                // sql中取的第一个是name ，取的第二个是age，所以是string 1， int 2</span><span class="token comment" spellcheck="true">//                println(rs.getString(1), rs.getInt(2))</span><span class="token comment" spellcheck="true">//            }</span><span class="token comment" spellcheck="true">//        )</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//        //打印最后结果</span><span class="token comment" spellcheck="true">//        selectRDD.collect()</span>        <span class="token comment" spellcheck="true">/*******保存数据********/</span>        <span class="token keyword">val</span> saveRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"韩七"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"周八"</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"吴九"</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 此部分在executor中执行，所以要新增的三条数据不一定发给了谁，不一定谁先执行，因此其中的id可能不是这个顺序</span><span class="token comment" spellcheck="true">//        saveRDD.foreach({</span><span class="token comment" spellcheck="true">//            case (name, age) => {</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                // 新增多少条数据，就会创建多少个connection，所以效率很低。但是connection又不可以序列化，所以无法把这两句提到foreach外面</span><span class="token comment" spellcheck="true">//                Class.forName(driver)</span><span class="token comment" spellcheck="true">//                val connection: Connection = DriverManager.getConnection(url, userName, passWd)</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                val sql = "insert into user (name, age) values (?, ?)"</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                val statement: PreparedStatement = connection.prepareStatement(sql)</span><span class="token comment" spellcheck="true">//                statement.setString(1, name)</span><span class="token comment" spellcheck="true">//                statement.setInt(2, age)</span><span class="token comment" spellcheck="true">//                statement.executeUpdate()</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                statement.close()</span><span class="token comment" spellcheck="true">//                connection.close()</span><span class="token comment" spellcheck="true">//            }</span><span class="token comment" spellcheck="true">//        })</span>        <span class="token comment" spellcheck="true">/*******优化的新增数据***********/</span>        <span class="token comment" spellcheck="true">// 以分区为整体来建立与mysql的连接（一个分区用一个connection），但是由于以分区为单位来执行，因此可能会出现内存溢出</span>        saveRDD<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>datas <span class="token keyword">=></span> <span class="token punctuation">{</span>            Class<span class="token punctuation">.</span>forName<span class="token punctuation">(</span>driver<span class="token punctuation">)</span>            <span class="token keyword">val</span> connection<span class="token operator">:</span> Connection <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span>url<span class="token punctuation">,</span> userName<span class="token punctuation">,</span> passWd<span class="token punctuation">)</span>            datas<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token punctuation">{</span>                <span class="token keyword">case</span> <span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span>                    <span class="token keyword">val</span> sql <span class="token operator">=</span> <span class="token string">"insert into user (name, age) values (?, ?)"</span>                    <span class="token keyword">val</span> statement<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> connection<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> age<span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>executeUpdate<span class="token punctuation">(</span><span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span><span class="token punctuation">)</span>            connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HBase数据库"><a href="#HBase数据库" class="headerlink" title="HBase数据库"></a>HBase数据库</h4><p>由于 org.apache.hadoop.hbase.mapreduce.TableInputFormat 类的实现，Spark 可以通过Hadoop输入格式访问HBase。这个输入格式会返回键值对数据，其中键的类型为org. apache.hadoop.hbase.io.ImmutableBytesWritable，而值的类型为org.apache.hadoop.hbase.client.<br>Result。</p><p>（1）添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hbase-server<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.3.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hbase-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.3.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）从HBase读取数据</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>Result<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>io<span class="token punctuation">.</span>ImmutableBytesWritable<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TableInputFormat<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token keyword">object</span> HBaseSpark <span class="token punctuation">{</span>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//创建spark配置信息</span>    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"JdbcRDD"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//创建SparkContext</span>    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//构建HBase配置信息</span>    <span class="token keyword">val</span> conf<span class="token operator">:</span> Configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>    conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">"hbase.zookeeper.quorum"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102,hadoop103,hadoop104"</span><span class="token punctuation">)</span>    conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span>TableInputFormat<span class="token punctuation">.</span>INPUT_TABLE<span class="token punctuation">,</span> <span class="token string">"rddtable"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//从HBase读取数据形成RDD</span>    <span class="token keyword">val</span> hbaseRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>ImmutableBytesWritable<span class="token punctuation">,</span> Result<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>newAPIHadoopRDD<span class="token punctuation">(</span>      conf<span class="token punctuation">,</span>      classOf<span class="token punctuation">[</span>TableInputFormat<span class="token punctuation">]</span><span class="token punctuation">,</span>      classOf<span class="token punctuation">[</span>ImmutableBytesWritable<span class="token punctuation">]</span><span class="token punctuation">,</span>      classOf<span class="token punctuation">[</span>Result<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> count<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> hbaseRDD<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>    println<span class="token punctuation">(</span>count<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//对hbaseRDD进行处理</span>    hbaseRDD<span class="token punctuation">.</span>foreach <span class="token punctuation">{</span>      <span class="token keyword">case</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> result<span class="token punctuation">)</span> <span class="token keyword">=></span>        <span class="token keyword">val</span> key<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> Bytes<span class="token punctuation">.</span>toString<span class="token punctuation">(</span>result<span class="token punctuation">.</span>getRow<span class="token punctuation">)</span>        <span class="token keyword">val</span> name<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> Bytes<span class="token punctuation">.</span>toString<span class="token punctuation">(</span>result<span class="token punctuation">.</span>getValue<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> color<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> Bytes<span class="token punctuation">.</span>toString<span class="token punctuation">(</span>result<span class="token punctuation">.</span>getValue<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"color"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        println<span class="token punctuation">(</span><span class="token string">"RowKey:"</span> <span class="token operator">+</span> key <span class="token operator">+</span> <span class="token string">",Name:"</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">",Color:"</span> <span class="token operator">+</span> color<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//关闭连接</span>    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）往HBase写入</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//获取Spark配置信息并创建与spark的连接</span>  <span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"HBaseApp"</span><span class="token punctuation">)</span>  <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//创建HBaseConf</span>  <span class="token keyword">val</span> conf <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">val</span> jobConf <span class="token operator">=</span> <span class="token keyword">new</span> JobConf<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>  jobConf<span class="token punctuation">.</span>setOutputFormat<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>TableOutputFormat<span class="token punctuation">]</span><span class="token punctuation">)</span>  jobConf<span class="token punctuation">.</span>set<span class="token punctuation">(</span>TableOutputFormat<span class="token punctuation">.</span>OUTPUT_TABLE<span class="token punctuation">,</span> <span class="token string">"fruit_spark"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//构建Hbase表描述器</span>  <span class="token keyword">val</span> fruitTable <span class="token operator">=</span> TableName<span class="token punctuation">.</span>valueOf<span class="token punctuation">(</span><span class="token string">"fruit_spark"</span><span class="token punctuation">)</span>  <span class="token keyword">val</span> tableDescr <span class="token operator">=</span> <span class="token keyword">new</span> HTableDescriptor<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span>  tableDescr<span class="token punctuation">.</span>addFamily<span class="token punctuation">(</span><span class="token keyword">new</span> HColumnDescriptor<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//创建Hbase表</span>  <span class="token keyword">val</span> admin <span class="token operator">=</span> <span class="token keyword">new</span> HBaseAdmin<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>admin<span class="token punctuation">.</span>tableExists<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    admin<span class="token punctuation">.</span>disableTable<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span>    admin<span class="token punctuation">.</span>deleteTable<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span>  <span class="token punctuation">}</span>  admin<span class="token punctuation">.</span>createTable<span class="token punctuation">(</span>tableDescr<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//定义往Hbase插入数据的方法</span>  <span class="token keyword">def</span> convert<span class="token punctuation">(</span>triple<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> put <span class="token operator">=</span> <span class="token keyword">new</span> Put<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span>triple<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span>    put<span class="token punctuation">.</span>addImmutable<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span>triple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>    put<span class="token punctuation">.</span>addImmutable<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"price"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span>triple<span class="token punctuation">.</span>_3<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token keyword">new</span> ImmutableBytesWritable<span class="token punctuation">,</span> put<span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token comment" spellcheck="true">//创建一个RDD</span>  <span class="token keyword">val</span> initialRDD <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"apple"</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"banana"</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"pear"</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//将RDD内容写到HBase</span>  <span class="token keyword">val</span> localData <span class="token operator">=</span> initialRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>convert<span class="token punctuation">)</span>  localData<span class="token punctuation">.</span>saveAsHadoopDataset<span class="token punctuation">(</span>jobConf<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="RDD编程进阶"><a href="#RDD编程进阶" class="headerlink" title="RDD编程进阶"></a>RDD编程进阶</h2><p>Spark三大数据结构：RDD（分布式数据集）、广播变量（分布式只读共享变量）、累加器（分布式只写共享变量）</p><h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><p>累加器用来对信息进行聚合，通常在向 Spark传递函数时，比如使用 map() 函数或者用 filter() 传条件时，可以使用驱动器程序中定义的变量，但是集群中运行的每个任务都会得到这些变量的一份新的副本，更新这些副本的值也不会影响驱动器中的对应变量。如果我们想实现所有分片处理时更新共享变量的功能，那么累加器可以实现我们想要的效果。</p><h4 id="系统累加器"><a href="#系统累加器" class="headerlink" title="系统累加器"></a>系统累加器</h4><p>针对一个输入的日志文件，如果我们想计算文件中所有空行的数量，我们可以编写以下程序：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>LongAccumulator<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/04 下午 19:33 * @Func: 分布式共享数据 */</span><span class="token keyword">object</span> Spark20_ShareData <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> dataRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 累加求和</span><span class="token comment" spellcheck="true">//        val sum: Int = dataRDD.reduce(_ + _)</span><span class="token comment" spellcheck="true">//        println(sum)</span>        <span class="token comment" spellcheck="true">// 简化(错误版本)：下面这样是不能实现的，因为我们的dataRDD是两个分区，但是sum现在在driver中，所以序列化分别传到两个分区中后是</span>        <span class="token comment" spellcheck="true">// 相互隔离的，在两个分区中分别求和后没法再两个分区相加。另外在分别求完和后的sum也没法从两个分区传回driver，所以没法实现。</span><span class="token comment" spellcheck="true">//        var sum:Int = 0</span><span class="token comment" spellcheck="true">//        dataRDD.foreach(i => {</span><span class="token comment" spellcheck="true">//            sum = sum + i</span><span class="token comment" spellcheck="true">//        })</span><span class="token comment" spellcheck="true">//        println(sum)</span>        <span class="token comment" spellcheck="true">// 简化(正确版本)：使用累加器</span>        <span class="token comment" spellcheck="true">// 创建累加器对象</span>        <span class="token keyword">val</span> accumulator<span class="token operator">:</span> LongAccumulator <span class="token operator">=</span> sc<span class="token punctuation">.</span>longAccumulator        dataRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">{</span>            <span class="token keyword">case</span> i <span class="token keyword">=></span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 执行累加器</span>                accumulator<span class="token punctuation">.</span>add<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        println<span class="token punctuation">(</span>accumulator<span class="token punctuation">.</span>value<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过在驱动器中调用 SparkContext.accumulator(initialValue) 方法，创建出存有初始值的累加器。返回值为 org.apache.spark.Accumulator[T] 对象，其中 T 是初始值 initialValue 的类型。Spark闭包里的执行器代码可以使用累加器的 += 方法(在Java中是 add)增加累加器的值。 驱动器程序可以调用累加器的value属性(在Java中使用value()或setValue())来访问累加器的值。 </p><p><strong>注意：</strong>工作节点上的任务不能访问累加器的值。从这些任务的角度来看，累加器是一个只写变量。</p><p>对于要在行动操作中使用的累加器，Spark只会把每个任务对各累加器的修改应用一次。因此，如果想要一个无论在失败还是重复计算时都绝对可靠的累加器，我们必须把它放在 foreach() 这样的行动操作中。转化操作中累加器可能会发生不止一次更新。</p><p><strong>补：</strong></p><p><img src="5-1.png" alt></p><p>其中反映了driver中的sum为何不会变化的原因（sum只会从driver序列化到executor中，但是在做了操作后不会返回到driver中）</p><h4 id="自定义累加器"><a href="#自定义累加器" class="headerlink" title="自定义累加器"></a>自定义累加器</h4><p>自定义累加器类型的功能在1.X版本中就已经提供了，但是使用起来比较麻烦，在2.0版本后，累加器的易用性有了较大的改进，而且官方还提供了一个新的抽象类：AccumulatorV2来提供更加友好的自定义类型累加器的实现方式。实现自定义类型累加器需要继承AccumulatorV2并至少覆写下例中出现的方法，下面这个累加器可以用于在程序运行过程中收集一些文本类信息，最终以Set[String]的形式返回。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span><span class="token punctuation">{</span>AccumulatorV2<span class="token punctuation">,</span> LongAccumulator<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/04 下午 19:59 * @Func: 自定义累加器 */</span><span class="token keyword">object</span> Spark21_Accumulator <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> dataRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token string">"Hadoop"</span><span class="token punctuation">,</span> <span class="token string">"Hive"</span><span class="token punctuation">,</span> <span class="token string">"HBase"</span><span class="token punctuation">,</span> <span class="token string">"Scala"</span><span class="token punctuation">,</span> <span class="token string">"Spark"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// TODO 创建累加器</span>        <span class="token keyword">val</span> wordAccumulator <span class="token operator">=</span> <span class="token keyword">new</span> WordAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// TODO 注册累加器</span>        sc<span class="token punctuation">.</span>register<span class="token punctuation">(</span>wordAccumulator<span class="token punctuation">)</span>        dataRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">{</span>            <span class="token keyword">case</span> word <span class="token keyword">=></span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 执行累加器</span>                wordAccumulator<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// TODO 获取累加器值</span>        println<span class="token punctuation">(</span>wordAccumulator<span class="token punctuation">.</span>value<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * 声明累加器 * 1. 继承 AccumulatorV2 * 2. 实现抽象方法 * 3. 创建累加器 */</span><span class="token keyword">class</span> WordAccumulator <span class="token keyword">extends</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token punctuation">{</span>    <span class="token keyword">val</span> list <span class="token operator">=</span> <span class="token keyword">new</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 当前累加器是否为初始化状态</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> isZero<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> list<span class="token punctuation">.</span>isEmpty    <span class="token comment" spellcheck="true">// 复制累加器</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">new</span> WordAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 重置累加器</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        list<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 向累加器中增加数据</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>v<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>v<span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">"H"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            list<span class="token punctuation">.</span>add<span class="token punctuation">(</span>v<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 合并累加器</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>other<span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        list<span class="token punctuation">.</span>addAll<span class="token punctuation">(</span>other<span class="token punctuation">.</span>value<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 获取累加器结果</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> value<span class="token operator">:</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> list<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="广播变量（调优策略）"><a href="#广播变量（调优策略）" class="headerlink" title="广播变量（调优策略）"></a>广播变量（调优策略）</h3><p>广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个或多个Spark操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，甚至是机器学习算法中的一个很大的特征向量，广播变量用起来都很顺手。 在多个并行操作中使用同一个变量，但是 Spark会为每个任务分别发送。</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> broadcastVar <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>broadcastVar<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>broadcast<span class="token punctuation">.</span>Broadcast<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> Broadcast<span class="token punctuation">(</span><span class="token number">35</span><span class="token punctuation">)</span>scala<span class="token operator">></span> broadcastVar<span class="token punctuation">.</span>value——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用广播变量的过程如下：</p><p>(1) 通过对一个类型 T 的对象调用 SparkContext.broadcast 创建出一个 Broadcast[T] 对象。 任何可序列化的类型都可以这么实现。 </p><p>(2) 通过 value 属性访问该对象的值(在 Java 中为 value() 方法)。 </p><p>(3) 变量只会被发到各个节点一次，应作为只读值处理(修改这个值不会影响到别的节点)。</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="RDD相关概念关系"><a href="#RDD相关概念关系" class="headerlink" title="RDD相关概念关系"></a>RDD相关概念关系</h3><p><img src="6-1.png" alt></p><p>输入可能以多个文件的形式存储在HDFS上，每个File都包含了很多块，称为Block。当Spark读取这些文件作为输入时，会根据具体数据格式对应的InputFormat进行解析，一般是将若干个Block合并成一个输入分片，称为InputSplit，注意InputSplit不能跨越文件。随后将为这些输入分片生成具体的Task。InputSplit与Task是一一对应的关系。随后这些具体的Task每个都会被分配到集群上的某个节点的某个Executor去执行。</p><p>1)    每个节点可以起一个或多个Executor。</p><p>2)    每个Executor由若干core组成，每个Executor的每个core一次只能执行一个Task。</p><p>3)    每个Task执行的结果就是生成了目标RDD的一个partiton。</p><p><strong>注意：</strong> 这里的core是虚拟的core而不是机器的物理CPU核，可以理解为就是Executor的一个工作线程。而 Task被执行的并发度 = Executor数目 * 每个Executor核数。至于partition的数目：</p><p>1)    对于数据读入阶段，例如sc.textFile，输入文件被划分为多少InputSplit就会需要多少初始Task。</p><p>2)    在Map阶段partition数目保持不变。</p><p>3)    在Reduce阶段，RDD的聚合会触发shuffle操作，聚合后的RDD的partition数目跟具体操作有关，例如repartition操作会聚合成指定分区数，还有一些算子是可配置的。</p><p>RDD在计算的时候，每个分区都会起一个task，所以rdd的分区数目决定了总的的task数目。申请的计算节点（Executor）数目和每个计算节点核数，决定了你同一时刻可以并行执行的task。</p><p>比如的RDD有100个分区，那么计算的时候就会生成100个task，你的资源配置为10个计算节点，每个两2个核，同一时刻可以并行的task数目为20，计算这个RDD就需要5个轮次。如果计算资源不变，你有101个task的话，就需要6个轮次，在最后一轮中，只有一个task在执行，其余核都在空转。如果资源不变，你的RDD只有2个分区，那么同一时刻只有2个task运行，其余18个核空转，造成资源浪费。这就是在spark调优中，增大RDD分区数目，增大任务并行度的做法。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkCore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-SparkCore-RDD编程进阶及补充（SparkCore系列五）</title>
      <link href="2020/10/05/spark-sparkcore-rdd-bian-cheng-jin-jie-ji-bu-chong-sparkcore-xi-lie-wu/"/>
      <url>2020/10/05/spark-sparkcore-rdd-bian-cheng-jin-jie-ji-bu-chong-sparkcore-xi-lie-wu/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h1><h2 id="RDD编程进阶"><a href="#RDD编程进阶" class="headerlink" title="RDD编程进阶"></a>RDD编程进阶</h2><p>Spark三大数据结构：RDD（分布式数据集）、广播变量（分布式只读共享变量）、累加器（分布式只写共享变量）</p><h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><p>累加器用来对信息进行聚合，通常在向 Spark传递函数时，比如使用 map() 函数或者用 filter() 传条件时，可以使用驱动器程序中定义的变量，但是集群中运行的每个任务都会得到这些变量的一份新的副本，更新这些副本的值也不会影响驱动器中的对应变量。如果我们想实现所有分片处理时更新共享变量的功能，那么累加器可以实现我们想要的效果。</p><h4 id="系统累加器"><a href="#系统累加器" class="headerlink" title="系统累加器"></a>系统累加器</h4><p>针对一个输入的日志文件，如果我们想计算文件中所有空行的数量，我们可以编写以下程序：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>LongAccumulator<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/04 下午 19:33 * @Func: 分布式共享数据 */</span><span class="token keyword">object</span> Spark20_ShareData <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> dataRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 累加求和</span><span class="token comment" spellcheck="true">//        val sum: Int = dataRDD.reduce(_ + _)</span><span class="token comment" spellcheck="true">//        println(sum)</span>        <span class="token comment" spellcheck="true">// 简化(错误版本)：下面这样是不能实现的，因为我们的dataRDD是两个分区，但是sum现在在driver中，所以序列化分别传到两个分区中后是</span>        <span class="token comment" spellcheck="true">// 相互隔离的，在两个分区中分别求和后没法再两个分区相加。另外在分别求完和后的sum也没法从两个分区传回driver，所以没法实现。</span><span class="token comment" spellcheck="true">//        var sum:Int = 0</span><span class="token comment" spellcheck="true">//        dataRDD.foreach(i => {</span><span class="token comment" spellcheck="true">//            sum = sum + i</span><span class="token comment" spellcheck="true">//        })</span><span class="token comment" spellcheck="true">//        println(sum)</span>        <span class="token comment" spellcheck="true">// 简化(正确版本)：使用累加器</span>        <span class="token comment" spellcheck="true">// 创建累加器对象</span>        <span class="token keyword">val</span> accumulator<span class="token operator">:</span> LongAccumulator <span class="token operator">=</span> sc<span class="token punctuation">.</span>longAccumulator        dataRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">{</span>            <span class="token keyword">case</span> i <span class="token keyword">=></span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 执行累加器</span>                accumulator<span class="token punctuation">.</span>add<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        println<span class="token punctuation">(</span>accumulator<span class="token punctuation">.</span>value<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过在驱动器中调用 SparkContext.accumulator(initialValue) 方法，创建出存有初始值的累加器。返回值为 org.apache.spark.Accumulator[T] 对象，其中 T 是初始值 initialValue 的类型。Spark闭包里的执行器代码可以使用累加器的 += 方法(在Java中是 add)增加累加器的值。 驱动器程序可以调用累加器的value属性(在Java中使用value()或setValue())来访问累加器的值。 </p><p><strong>注意：</strong>工作节点上的任务不能访问累加器的值。从这些任务的角度来看，累加器是一个只写变量。</p><p>对于要在行动操作中使用的累加器，Spark只会把每个任务对各累加器的修改应用一次。因此，如果想要一个无论在失败还是重复计算时都绝对可靠的累加器，我们必须把它放在 foreach() 这样的行动操作中。转化操作中累加器可能会发生不止一次更新。</p><p><strong>补：</strong></p><p><img src="5-1.png" alt></p><p>其中反映了driver中的sum为何不会变化的原因（sum只会从driver序列化到executor中，但是在做了操作后不会返回到driver中）</p><h4 id="自定义累加器"><a href="#自定义累加器" class="headerlink" title="自定义累加器"></a>自定义累加器</h4><p>自定义累加器类型的功能在1.X版本中就已经提供了，但是使用起来比较麻烦，在2.0版本后，累加器的易用性有了较大的改进，而且官方还提供了一个新的抽象类：AccumulatorV2来提供更加友好的自定义类型累加器的实现方式。实现自定义类型累加器需要继承AccumulatorV2并至少覆写下例中出现的方法，下面这个累加器可以用于在程序运行过程中收集一些文本类信息，最终以Set[String]的形式返回。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span><span class="token punctuation">{</span>AccumulatorV2<span class="token punctuation">,</span> LongAccumulator<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/04 下午 19:59 * @Func: 自定义累加器 */</span><span class="token keyword">object</span> Spark21_Accumulator <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> dataRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token string">"Hadoop"</span><span class="token punctuation">,</span> <span class="token string">"Hive"</span><span class="token punctuation">,</span> <span class="token string">"HBase"</span><span class="token punctuation">,</span> <span class="token string">"Scala"</span><span class="token punctuation">,</span> <span class="token string">"Spark"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// TODO 创建累加器</span>        <span class="token keyword">val</span> wordAccumulator <span class="token operator">=</span> <span class="token keyword">new</span> WordAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// TODO 注册累加器</span>        sc<span class="token punctuation">.</span>register<span class="token punctuation">(</span>wordAccumulator<span class="token punctuation">)</span>        dataRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">{</span>            <span class="token keyword">case</span> word <span class="token keyword">=></span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 执行累加器</span>                wordAccumulator<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// TODO 获取累加器值</span>        println<span class="token punctuation">(</span>wordAccumulator<span class="token punctuation">.</span>value<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * 声明累加器 * 1. 继承 AccumulatorV2 * 2. 实现抽象方法 * 3. 创建累加器 */</span><span class="token keyword">class</span> WordAccumulator <span class="token keyword">extends</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token punctuation">{</span>    <span class="token keyword">val</span> list <span class="token operator">=</span> <span class="token keyword">new</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 当前累加器是否为初始化状态</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> isZero<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> list<span class="token punctuation">.</span>isEmpty    <span class="token comment" spellcheck="true">// 复制累加器</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">new</span> WordAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 重置累加器</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        list<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 向累加器中增加数据</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>v<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>v<span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">"H"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            list<span class="token punctuation">.</span>add<span class="token punctuation">(</span>v<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 合并累加器</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>other<span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        list<span class="token punctuation">.</span>addAll<span class="token punctuation">(</span>other<span class="token punctuation">.</span>value<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 获取累加器结果</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> value<span class="token operator">:</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> list<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="广播变量（调优策略）"><a href="#广播变量（调优策略）" class="headerlink" title="广播变量（调优策略）"></a>广播变量（调优策略）</h3><p>广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个或多个Spark操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，甚至是机器学习算法中的一个很大的特征向量，广播变量用起来都很顺手。 在多个并行操作中使用同一个变量，但是 Spark会为每个任务分别发送。</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> broadcastVar <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>broadcastVar<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>broadcast<span class="token punctuation">.</span>Broadcast<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> Broadcast<span class="token punctuation">(</span><span class="token number">35</span><span class="token punctuation">)</span>scala<span class="token operator">></span> broadcastVar<span class="token punctuation">.</span>value——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用广播变量的过程如下：</p><p>(1) 通过对一个类型 T 的对象调用 SparkContext.broadcast 创建出一个 Broadcast[T] 对象。 任何可序列化的类型都可以这么实现。 </p><p>(2) 通过 value 属性访问该对象的值(在 Java 中为 value() 方法)。 </p><p>(3) 变量只会被发到各个节点一次，应作为只读值处理(修改这个值不会影响到别的节点)。</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="RDD相关概念关系"><a href="#RDD相关概念关系" class="headerlink" title="RDD相关概念关系"></a>RDD相关概念关系</h3><p><img src="6-1.png" alt></p><p>输入可能以多个文件的形式存储在HDFS上，每个File都包含了很多块，称为Block。当Spark读取这些文件作为输入时，会根据具体数据格式对应的InputFormat进行解析，一般是将若干个Block合并成一个输入分片，称为InputSplit，注意InputSplit不能跨越文件。随后将为这些输入分片生成具体的Task。InputSplit与Task是一一对应的关系。随后这些具体的Task每个都会被分配到集群上的某个节点的某个Executor去执行。</p><p>1)    每个节点可以起一个或多个Executor。</p><p>2)    每个Executor由若干core组成，每个Executor的每个core一次只能执行一个Task。</p><p>3)    每个Task执行的结果就是生成了目标RDD的一个partiton。</p><p><strong>注意：</strong> 这里的core是虚拟的core而不是机器的物理CPU核，可以理解为就是Executor的一个工作线程。而 Task被执行的并发度 = Executor数目 * 每个Executor核数。至于partition的数目：</p><p>1)    对于数据读入阶段，例如sc.textFile，输入文件被划分为多少InputSplit就会需要多少初始Task。</p><p>2)    在Map阶段partition数目保持不变。</p><p>3)    在Reduce阶段，RDD的聚合会触发shuffle操作，聚合后的RDD的partition数目跟具体操作有关，例如repartition操作会聚合成指定分区数，还有一些算子是可配置的。</p><p>RDD在计算的时候，每个分区都会起一个task，所以rdd的分区数目决定了总的的task数目。申请的计算节点（Executor）数目和每个计算节点核数，决定了你同一时刻可以并行执行的task。</p><p>比如的RDD有100个分区，那么计算的时候就会生成100个task，你的资源配置为10个计算节点，每个两2个核，同一时刻可以并行的task数目为20，计算这个RDD就需要5个轮次。如果计算资源不变，你有101个task的话，就需要6个轮次，在最后一轮中，只有一个task在执行，其余核都在空转。如果资源不变，你的RDD只有2个分区，那么同一时刻只有2个task运行，其余18个核空转，造成资源浪费。这就是在spark调优中，增大RDD分区数目，增大任务并行度的做法。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkCore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-SparkCore-数据读取与保存（SparkCore系列四）</title>
      <link href="2020/10/04/spark-sparkcore-shu-ju-du-qu-yu-bao-cun-sparkcore-xi-lie-si/"/>
      <url>2020/10/04/spark-sparkcore-shu-ju-du-qu-yu-bao-cun-sparkcore-xi-lie-si/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h1><h2 id="数据读取与保存"><a href="#数据读取与保存" class="headerlink" title="数据读取与保存"></a>数据读取与保存</h2><p>Spark的数据读取及数据保存可以从两个维度来作区分：文件格式以及文件系统。</p><p>文件格式分为：text文件、json文件、csv文件、sequence文件以及object文件；</p><p>文件系统分为：本地文件系统、HDFS、HBASE以及数据库。</p><h3 id="文件类数据读取与保存"><a href="#文件类数据读取与保存" class="headerlink" title="文件类数据读取与保存"></a>文件类数据读取与保存</h3><h4 id="Text文件"><a href="#Text文件" class="headerlink" title="Text文件"></a>Text文件</h4><p>1）数据读取:textFile(String)</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> hdfsFile <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/fruit.txt"</span><span class="token punctuation">)</span>——<span class="token operator">></span>hdfsFile<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop102<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>fruit<span class="token punctuation">.</span>txt MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）数据保存: saveAsTextFile(String)</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> hdfsFile<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"/fruitOut"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Json文件"><a href="#Json文件" class="headerlink" title="Json文件"></a>Json文件</h4><p>如果JSON文件中每一行就是一个JSON记录，那么可以通过将JSON文件当做文本文件来读取，然后利用相关的JSON库对每一条数据进行JSON解析。</p><p><strong>注意：</strong>使用RDD读取JSON文件处理很复杂，同时SparkSQL集成了很好的处理JSON文件的方式，所以应用中多是采用SparkSQL处理JSON文件。</p><p>其中JSON文件地址：<a href="https://github.com/Swenchao/SparkCode/blob/master/in/user.json" target="_blank" rel="noopener">in/user.json</a></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>parsing<span class="token punctuation">.</span>json<span class="token punctuation">.</span>JSON<span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/03 下午 09:33 * @Func: Json文件处理 */</span><span class="token keyword">object</span> Spark18_Json <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取json文件</span>        <span class="token keyword">val</span> jsonRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"in/user.json"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 进行解析</span>        <span class="token keyword">val</span> res<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Option<span class="token punctuation">[</span><span class="token builtin">Any</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> jsonRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>JSON<span class="token punctuation">.</span>parseFull<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 输出</span>        res<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果输出</p><pre><code>    Some(Map(name -&gt; zhangsan, age -&gt; 18.0))    Some(Map(name -&gt; wangwu, age -&gt; 18.0))    Some(Map(name -&gt; zhaoliu, age -&gt; 18.0))    Some(Map(name -&gt; lisi, age -&gt; 18.0))</code></pre><p><strong>注：</strong>这个包显示不能用了，但是结果还是出来了。从网上还没找到完全的替代品。</p><h4 id="Sequence文件"><a href="#Sequence文件" class="headerlink" title="Sequence文件"></a>Sequence文件</h4><p>SequenceFile文件是Hadoop用来存储二进制形式的key-value对而设计的一种平面文件(Flat File)。Spark 有专门用来读取 SequenceFile 的接口。在 SparkContext 中，可以调用 sequenceFile<a href="path"> keyClass, valueClass</a>。</p><p><strong>注意：</strong>SequenceFile文件只针对PairRDD</p><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将RDD保存为Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>saveAsSequenceFile<span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/seqFile"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看该文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 seqFile]$ pwd——>/opt/module/spark/seqFile[user_test@hadoop102 seqFile]$ ll总用量 8-rw-r--r-- 1 atguigu atguigu 108 10月  9 10:29 part-00000-rw-r--r-- 1 atguigu atguigu 124 10月  9 10:29 part-00001-rw-r--r-- 1 atguigu atguigu   0 10月  9 10:29 _SUCCESS[user_test@hadoop102 seqFile]$ cat part-00000——>SEQ org.apache.hadoop.io.IntWritable org.apache.hadoop.io.IntWritable<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）读取Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> seq <span class="token operator">=</span> sc<span class="token punctuation">.</span>sequenceFile<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/seqFile"</span><span class="token punctuation">)</span>——<span class="token operator">></span>seq<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span> at sequenceFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）打印读取后的Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> seq<span class="token punctuation">.</span>collect——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="对象文件"><a href="#对象文件" class="headerlink" title="对象文件"></a>对象文件</h4><p>对象文件是将对象序列化后保存的文件，采用Java的序列化机制。可以通过objectFile<a href="path">k,v</a> 函数接收一个路径，读取对象文件，返回对应的 RDD，也可以通过调用saveAsObjectFile() 实现对对象文件的输出。因为是序列化所以要指定类型。</p><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将RDD保存为Object文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>saveAsObjectFile<span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/objectFile"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看该文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 objectFile]$ pwd——>/opt/module/spark/objectFile[user_test@hadoop102 objectFile]$ ll——>总用量 8-rw-r--r-- 1 atguigu atguigu 142 10月  9 10:37 part-00000-rw-r--r-- 1 atguigu atguigu 142 10月  9 10:37 part-00001-rw-r--r-- 1 atguigu atguigu   0 10月  9 10:37 _SUCCESS[user_test@hadoop102 objectFile]$ cat part-00000 ——>SEQ!org.apache.hadoop.io.NullWritable"org.apache.hadoop.io.BytesWritableW@`l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）读取Object文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> objFile <span class="token operator">=</span> sc<span class="token punctuation">.</span>objectFile<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"file:///opt/module/spark/objectFile"</span><span class="token punctuation">)</span>——<span class="token operator">></span>objFile<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span> at objectFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）打印读取后的Sequence文件</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> objFile<span class="token punctuation">.</span>collectres19<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="文件系统类数据读取与保存"><a href="#文件系统类数据读取与保存" class="headerlink" title="文件系统类数据读取与保存"></a>文件系统类数据读取与保存</h3><h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>Spark的整个生态系统与Hadoop是完全兼容的，所以对于Hadoop所支持的文件类型或者数据库类型，Spark也同样支持。另外，由于Hadoop的API有新旧两个版本，所以Spark为了能够兼容Hadoop所有的版本，也提供了两套创建操作接口。对于外部存储创建操作而言，hadoopRDD和newHadoopRDD是最为抽象的两个函数接口，主要包含以下四个参数。</p><p>1）输入格式(InputFormat)：制定数据输入的类型，如TextInputFormat等，新旧两个版本所引用的版本分别是 org.apache.hadoop.mapred.InputFormat 和 org.apache.hadoop.mapreduce.InputFormat(NewInputFormat)</p><p>2）键类型：指定[K,V]键值对中K的类型</p><p>3）值类型：指定[K,V]键值对中V的类型</p><p>4）分区值：指定由外部存储生成的RDD的partition数量的最小值,如果没有指定,系统会使用默认值defaultMinSplits</p><p><strong>注意：</strong>其他创建操作的API接口都是为了方便最终的Spark程序开发者而设置的,是这两个接口的高效实现版本。例如，对于textFile而言，只有path这个指定文件路径的参数,其他参数在系统内部指定了默认值。</p><ol><li><p>在Hadoop中以压缩形式存储的数据,不需要指定解压方式就能够进行读取,因为Hadoop本身有一个解压器会根据压缩文件的后缀推断解压算法进行解压。</p></li><li><p>如果用Spark从Hadoop中读取某种类型的数据不知道怎么读取的时候,上网查找一个使用map-reduce的时候是怎么读取这种这种数据的,然后再将对应的读取方式改写成上面的hadoopRDD和newAPIHadoopRDD两个类就行了</p></li></ol><h4 id="MySQL数据库连接"><a href="#MySQL数据库连接" class="headerlink" title="MySQL数据库连接"></a>MySQL数据库连接</h4><p>支持通过Java JDBC访问关系型数据库。需要通过JdbcRDD进行，示例:</p><p>表结构</p><p>[user]</p><table><thead><tr><th>列名</th><th>类型</th></tr></thead><tbody><tr><td>id</td><td>int(11)</td></tr><tr><td>name</td><td>varchar(255)</td></tr><tr><td>age</td><td>int(11)</td></tr></tbody></table><p>（1）添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.27<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）Mysql读取与新增：</p><p>demo地址：</p><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/Spark19_Mysql.scala" target="_blank" rel="noopener">com.swenchao.spark.Spark19_Mysql</a></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span><span class="token punctuation">{</span>JdbcRDD<span class="token punctuation">,</span> RDD<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/04 下午 09:33 * @Func: Mysql连接 */</span><span class="token keyword">object</span> Spark19_Mysql <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 定义mysql参数</span>        <span class="token keyword">val</span> driver <span class="token operator">=</span> <span class="token string">"com.mysql.jdbc.Driver"</span>        <span class="token keyword">val</span> url <span class="token operator">=</span> <span class="token string">"jdbc:mysql://127.0.0.1:3306/rdd"</span>        <span class="token keyword">val</span> userName <span class="token operator">=</span> <span class="token string">"root"</span>        <span class="token keyword">val</span> passWd <span class="token operator">=</span> <span class="token string">"123456"</span>        <span class="token comment" spellcheck="true">/***************询数据*********************/</span>        <span class="token comment" spellcheck="true">//创建 JdbcRDD，访问数据库</span><span class="token comment" spellcheck="true">//        val selectRDD = new JdbcRDD(</span><span class="token comment" spellcheck="true">//            sc,</span><span class="token comment" spellcheck="true">//            () => {</span><span class="token comment" spellcheck="true">//                // 获取数据库连接对象</span><span class="token comment" spellcheck="true">//                Class.forName(driver)</span><span class="token comment" spellcheck="true">//                DriverManager.getConnection(url, userName, passWd)</span><span class="token comment" spellcheck="true">//            },</span><span class="token comment" spellcheck="true">//            "select name, age from user where id >= ? and id &lt;= ?",</span><span class="token comment" spellcheck="true">//            // 1是sql的第一个问号，2是sql的第二个问号</span><span class="token comment" spellcheck="true">//            1,</span><span class="token comment" spellcheck="true">//            3,</span><span class="token comment" spellcheck="true">//            2,</span><span class="token comment" spellcheck="true">//            (rs) => {</span><span class="token comment" spellcheck="true">//                // sql中取的第一个是name ，取的第二个是age，所以是string 1， int 2</span><span class="token comment" spellcheck="true">//                println(rs.getString(1), rs.getInt(2))</span><span class="token comment" spellcheck="true">//            }</span><span class="token comment" spellcheck="true">//        )</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//        //打印最后结果</span><span class="token comment" spellcheck="true">//        selectRDD.collect()</span>        <span class="token comment" spellcheck="true">/*******保存数据********/</span>        <span class="token keyword">val</span> saveRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"韩七"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"周八"</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"吴九"</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 此部分在executor中执行，所以要新增的三条数据不一定发给了谁，不一定谁先执行，因此其中的id可能不是这个顺序</span><span class="token comment" spellcheck="true">//        saveRDD.foreach({</span><span class="token comment" spellcheck="true">//            case (name, age) => {</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                // 新增多少条数据，就会创建多少个connection，所以效率很低。但是connection又不可以序列化，所以无法把这两句提到foreach外面</span><span class="token comment" spellcheck="true">//                Class.forName(driver)</span><span class="token comment" spellcheck="true">//                val connection: Connection = DriverManager.getConnection(url, userName, passWd)</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                val sql = "insert into user (name, age) values (?, ?)"</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                val statement: PreparedStatement = connection.prepareStatement(sql)</span><span class="token comment" spellcheck="true">//                statement.setString(1, name)</span><span class="token comment" spellcheck="true">//                statement.setInt(2, age)</span><span class="token comment" spellcheck="true">//                statement.executeUpdate()</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//                statement.close()</span><span class="token comment" spellcheck="true">//                connection.close()</span><span class="token comment" spellcheck="true">//            }</span><span class="token comment" spellcheck="true">//        })</span>        <span class="token comment" spellcheck="true">/*******优化的新增数据***********/</span>        <span class="token comment" spellcheck="true">// 以分区为整体来建立与mysql的连接（一个分区用一个connection），但是由于以分区为单位来执行，因此可能会出现内存溢出</span>        saveRDD<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>datas <span class="token keyword">=></span> <span class="token punctuation">{</span>            Class<span class="token punctuation">.</span>forName<span class="token punctuation">(</span>driver<span class="token punctuation">)</span>            <span class="token keyword">val</span> connection<span class="token operator">:</span> Connection <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span>url<span class="token punctuation">,</span> userName<span class="token punctuation">,</span> passWd<span class="token punctuation">)</span>            datas<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token punctuation">{</span>                <span class="token keyword">case</span> <span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span>                    <span class="token keyword">val</span> sql <span class="token operator">=</span> <span class="token string">"insert into user (name, age) values (?, ?)"</span>                    <span class="token keyword">val</span> statement<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> connection<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> age<span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>executeUpdate<span class="token punctuation">(</span><span class="token punctuation">)</span>                    statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span><span class="token punctuation">)</span>            connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HBase数据库"><a href="#HBase数据库" class="headerlink" title="HBase数据库"></a>HBase数据库</h4><p>由于 org.apache.hadoop.hbase.mapreduce.TableInputFormat 类的实现，Spark 可以通过Hadoop输入格式访问HBase。这个输入格式会返回键值对数据，其中键的类型为org. apache.hadoop.hbase.io.ImmutableBytesWritable，而值的类型为org.apache.hadoop.hbase.client.<br>Result。</p><p>（1）添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hbase-server<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.3.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hbase-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.3.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）从HBase读取数据</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>Result<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>io<span class="token punctuation">.</span>ImmutableBytesWritable<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TableInputFormat<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token keyword">object</span> HBaseSpark <span class="token punctuation">{</span>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//创建spark配置信息</span>    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"JdbcRDD"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//创建SparkContext</span>    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//构建HBase配置信息</span>    <span class="token keyword">val</span> conf<span class="token operator">:</span> Configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>    conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">"hbase.zookeeper.quorum"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102,hadoop103,hadoop104"</span><span class="token punctuation">)</span>    conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span>TableInputFormat<span class="token punctuation">.</span>INPUT_TABLE<span class="token punctuation">,</span> <span class="token string">"rddtable"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//从HBase读取数据形成RDD</span>    <span class="token keyword">val</span> hbaseRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>ImmutableBytesWritable<span class="token punctuation">,</span> Result<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>newAPIHadoopRDD<span class="token punctuation">(</span>      conf<span class="token punctuation">,</span>      classOf<span class="token punctuation">[</span>TableInputFormat<span class="token punctuation">]</span><span class="token punctuation">,</span>      classOf<span class="token punctuation">[</span>ImmutableBytesWritable<span class="token punctuation">]</span><span class="token punctuation">,</span>      classOf<span class="token punctuation">[</span>Result<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> count<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> hbaseRDD<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>    println<span class="token punctuation">(</span>count<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//对hbaseRDD进行处理</span>    hbaseRDD<span class="token punctuation">.</span>foreach <span class="token punctuation">{</span>      <span class="token keyword">case</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> result<span class="token punctuation">)</span> <span class="token keyword">=></span>        <span class="token keyword">val</span> key<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> Bytes<span class="token punctuation">.</span>toString<span class="token punctuation">(</span>result<span class="token punctuation">.</span>getRow<span class="token punctuation">)</span>        <span class="token keyword">val</span> name<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> Bytes<span class="token punctuation">.</span>toString<span class="token punctuation">(</span>result<span class="token punctuation">.</span>getValue<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> color<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> Bytes<span class="token punctuation">.</span>toString<span class="token punctuation">(</span>result<span class="token punctuation">.</span>getValue<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"color"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        println<span class="token punctuation">(</span><span class="token string">"RowKey:"</span> <span class="token operator">+</span> key <span class="token operator">+</span> <span class="token string">",Name:"</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">",Color:"</span> <span class="token operator">+</span> color<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//关闭连接</span>    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）往HBase写入</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//获取Spark配置信息并创建与spark的连接</span>  <span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"HBaseApp"</span><span class="token punctuation">)</span>  <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//创建HBaseConf</span>  <span class="token keyword">val</span> conf <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">val</span> jobConf <span class="token operator">=</span> <span class="token keyword">new</span> JobConf<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>  jobConf<span class="token punctuation">.</span>setOutputFormat<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>TableOutputFormat<span class="token punctuation">]</span><span class="token punctuation">)</span>  jobConf<span class="token punctuation">.</span>set<span class="token punctuation">(</span>TableOutputFormat<span class="token punctuation">.</span>OUTPUT_TABLE<span class="token punctuation">,</span> <span class="token string">"fruit_spark"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//构建Hbase表描述器</span>  <span class="token keyword">val</span> fruitTable <span class="token operator">=</span> TableName<span class="token punctuation">.</span>valueOf<span class="token punctuation">(</span><span class="token string">"fruit_spark"</span><span class="token punctuation">)</span>  <span class="token keyword">val</span> tableDescr <span class="token operator">=</span> <span class="token keyword">new</span> HTableDescriptor<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span>  tableDescr<span class="token punctuation">.</span>addFamily<span class="token punctuation">(</span><span class="token keyword">new</span> HColumnDescriptor<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//创建Hbase表</span>  <span class="token keyword">val</span> admin <span class="token operator">=</span> <span class="token keyword">new</span> HBaseAdmin<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>admin<span class="token punctuation">.</span>tableExists<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    admin<span class="token punctuation">.</span>disableTable<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span>    admin<span class="token punctuation">.</span>deleteTable<span class="token punctuation">(</span>fruitTable<span class="token punctuation">)</span>  <span class="token punctuation">}</span>  admin<span class="token punctuation">.</span>createTable<span class="token punctuation">(</span>tableDescr<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//定义往Hbase插入数据的方法</span>  <span class="token keyword">def</span> convert<span class="token punctuation">(</span>triple<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> put <span class="token operator">=</span> <span class="token keyword">new</span> Put<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span>triple<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span>    put<span class="token punctuation">.</span>addImmutable<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span>triple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>    put<span class="token punctuation">.</span>addImmutable<span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span><span class="token string">"price"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span>toBytes<span class="token punctuation">(</span>triple<span class="token punctuation">.</span>_3<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token keyword">new</span> ImmutableBytesWritable<span class="token punctuation">,</span> put<span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token comment" spellcheck="true">//创建一个RDD</span>  <span class="token keyword">val</span> initialRDD <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"apple"</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"banana"</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"pear"</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//将RDD内容写到HBase</span>  <span class="token keyword">val</span> localData <span class="token operator">=</span> initialRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>convert<span class="token punctuation">)</span>  localData<span class="token punctuation">.</span>saveAsHadoopDataset<span class="token punctuation">(</span>jobConf<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkCore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-SparkCore-键值对RDD数据分区器（SparkCore系列三）</title>
      <link href="2020/10/03/spark-sparkcore-jian-zhi-dui-rdd-shu-ju-fen-qu-qi-sparkcore-xi-lie-san/"/>
      <url>2020/10/03/spark-sparkcore-jian-zhi-dui-rdd-shu-ju-fen-qu-qi-sparkcore-xi-lie-san/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h1><h2 id="键值对RDD数据分区器"><a href="#键值对RDD数据分区器" class="headerlink" title="键值对RDD数据分区器"></a>键值对RDD数据分区器</h2><p>Spark目前支持Hash分区和Range分区，用户也可以自定义分区，Hash分区为当前的默认分区，Spark中分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle过程属于哪个分区和Reduce的个数</p><p><strong>注意：</strong></p><p>(1)只有Key-Value类型的RDD才有分区器的，非Key-Value类型的RDD分区器的值是None</p><p>(2)每个RDD的分区ID范围：0~numPartitions-1，决定这个值是属于那个分区的。</p><h3 id="获取RDD分区"><a href="#获取RDD分区" class="headerlink" title="获取RDD分区"></a>获取RDD分区</h3><p>可以通过使用RDD的partitioner 属性来获取 RDD 的分区方式。它会返回一个 scala.Option 对象， 通过get方法获取其中的值。相关源码如下：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> getPartition<span class="token punctuation">(</span>key<span class="token operator">:</span> <span class="token builtin">Any</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> key <span class="token keyword">match</span> <span class="token punctuation">{</span>  <span class="token keyword">case</span> <span class="token keyword">null</span> <span class="token keyword">=></span> <span class="token number">0</span>  <span class="token keyword">case</span> _ <span class="token keyword">=></span> Utils<span class="token punctuation">.</span>nonNegativeMod<span class="token punctuation">(</span>key<span class="token punctuation">.</span>hashCode<span class="token punctuation">,</span> numPartitions<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">def</span> nonNegativeMod<span class="token punctuation">(</span>x<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> mod<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>  <span class="token keyword">val</span> rawMod <span class="token operator">=</span> x <span class="token operator">%</span> mod  rawMod <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">if</span> <span class="token punctuation">(</span>rawMod <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> mod <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> pairs <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>pairs<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）查看RDD的分区器</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> pairs<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res1<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> None<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）导入HashPartitioner类</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）使用HashPartitioner对RDD进行重新分区</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> partitioned <span class="token operator">=</span> pairs<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> HashPartitioner<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>partitioned<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at partitionBy at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">27</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）查看重新分区后RDD的分区器</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> partitioned<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res2<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> Some<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token annotation punctuation">@2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Hash分区"><a href="#Hash分区" class="headerlink" title="Hash分区"></a>Hash分区</h3><p>HashPartitioner分区的原理：对于给定的key，计算其hashCode，并除以分区的个数取余，如果余数小于0，则用余数+分区的个数（否则加0），最后返回的值就是这个key所属的分区ID。</p><p>使用Hash分区的实操</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> nopar<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res1<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> Nonescala<span class="token operator">></span> <span class="token keyword">val</span> nopar <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>——<span class="token operator">></span>nopar<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span>scala<span class="token operator">></span>nopar<span class="token punctuation">.</span>mapPartitionsWithIndex<span class="token punctuation">(</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span>iter<span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">{</span> Iterator<span class="token punctuation">(</span>index<span class="token punctuation">.</span>toString<span class="token operator">+</span><span class="token string">" : "</span><span class="token operator">+</span>iter<span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token string">"0 : "</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"4 : "</span><span class="token punctuation">,</span> <span class="token number">5</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">6</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">7</span> <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span> scala<span class="token operator">></span> <span class="token keyword">val</span> hashpar <span class="token operator">=</span> nopar<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>hashpar<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span> at partitionBy at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span>scala<span class="token operator">></span> hashpar<span class="token punctuation">.</span>count——<span class="token operator">></span>res3<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">6</span>scala<span class="token operator">></span> hashpar<span class="token punctuation">.</span>partitioner——<span class="token operator">></span>res4<span class="token operator">:</span> Option<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> Some<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token annotation punctuation">@7</span><span class="token punctuation">)</span>scala<span class="token operator">></span> hashpar<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>iter <span class="token keyword">=></span> Iterator<span class="token punctuation">(</span>iter<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>res19<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Ranger分区"><a href="#Ranger分区" class="headerlink" title="Ranger分区"></a>Ranger分区</h3><p>HashPartitioner分区弊端：可能导致每个分区中数据量的不均匀，极端情况下会导致某些分区拥有RDD的全部数据。</p><p>RangePartitioner作用：将一定范围内的数映射到某一个分区内，尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，一个分区中的元素肯定都是比另一个分区内的元素小或者大，但是分区内的元素是不能保证顺序的。简单的说就是将一定范围内的数映射到某一个分区内。实现过程为：</p><p>第一步：先重整个RDD中抽取出样本数据，将样本数据排序，计算出每个分区的最大key值，形成一个Array[KEY]类型的数组变量rangeBounds；</p><p>第二步：判断key在rangeBounds中所处的范围，给出该key值在下一个RDD中的分区id下标；该分区器要求RDD中的KEY类型必须是可以排序的</p><h3 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h3><p>要实现自定义的分区器，你需要继承 org.apache.spark.Partitioner 类并实现下面三个方法。 </p><p>（1）numPartitions：Int:返回创建出来的分区数。</p><p>（2）getPartition(key: Any)：Int:返回给定键的分区编号(0到numPartitions-1)。 </p><p>（3）equals()：Java 判断相等性的标准方法。这个方法的实现非常重要，Spark 需要用这个方法来检查你的分区器对象是否和其他分区器实例相同，这样 Spark 才可以判断两个 RDD 的分区方式是否相同。(这个方法某些情况下不写也是可以的)</p><p>使用自定义的 Partitioner 是很容易的：只要把它传给 partitionBy() 方法即可。Spark 中有许多依赖于数据混洗的方法，比如 join() 和 groupByKey()，它们也可以接收一个可选的 Partitioner 对象来控制输出数据的分区方式。</p><p>因为之前实现过自定义分区器，这里不在累述，demo地址</p><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/Spark12_Oper11.scala" target="_blank" rel="noopener">com.swenchao.spark.Spark12_Oper11</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkCore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-SparkCore-RDD编程（SparkCore系列二）</title>
      <link href="2020/10/03/spark-sparkcore-rdd-bian-cheng-sparkcore-xi-lie-er/"/>
      <url>2020/10/03/spark-sparkcore-rdd-bian-cheng-sparkcore-xi-lie-er/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h1><h2 id="RDD编程"><a href="#RDD编程" class="headerlink" title="RDD编程"></a>RDD编程</h2><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p>在Spark中，RDD被表示为对象，通过对象上的方法调用来对RDD进行转换。经过一系列的transformations定义RDD之后，就可以调用actions触发RDD的计算，action可以是向应用程序返回结果(count, collect等)，或者是向存储系统保存数据(saveAsTextFile等)。在Spark中，只有遇到action，才会执行RDD的计算(即延迟计算)，这样在运行时可以通过管道的方式传输多个转换。</p><p>要使用Spark，开发者需要编写一个Driver程序，它被提交到集群以调度运行Worker，如下图所示。Driver中定义了一个或多个RDD，并调用RDD上的action，Worker则执行RDD分区计算任务。</p><p><img src="12.png" alt></p><h3 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h3><p>在Spark中创建RDD的创建方式可以分为三种：从集合中创建RDD；从外部存储创建RDD；从其他RDD创建。</p><h4 id="从集合中创建"><a href="#从集合中创建" class="headerlink" title="从集合中创建"></a>从集合中创建</h4><p>从集合中创建RDD，Spark主要提供了两种函数：parallelize（并行）和makeRDD</p><p>1）使用parallelize()从集合创建</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）使用makeRDD()从集合创建，其底层实现，其实就是调用了parallelize</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>以上两种方法其实都有一个默认参数（defaultParallelism）没有传。这个默认参数就是分区，如果没有传他会根据当前运行电脑核数跟2来比较进行赋值，如下</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">override</span> <span class="token keyword">def</span> defaultParallelism<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    conf<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token string">"spark.default.parallelism"</span><span class="token punctuation">,</span> math<span class="token punctuation">.</span>max<span class="token punctuation">(</span>totalCoreCount<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="由外部存储系统的数据集创建"><a href="#由外部存储系统的数据集创建" class="headerlink" title="由外部存储系统的数据集创建"></a>由外部存储系统的数据集创建</h4><p>默认情况可读取项目路径。同时也可以读取其他路径。</p><p>包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等，在数据读取与保存章节中会有详细介绍。</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2<span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000/RELEASE"</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span> hadoop102<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>RELEASE MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>默认从文件中读取的数据都是字符串类型。此方法也有一个默认参数（minPartitions: Int = defaultMinPartitions）没有传。如果没有传他也会根据 defaultParallelism 跟2来比较进行赋值（更上面稍有不同），如下</p><pre class="line-numbers language-scala"><code class="language-scala">    <span class="token keyword">def</span> defaultMinPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> math<span class="token punctuation">.</span>min<span class="token punctuation">(</span>defaultParallelism<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中 defaultParallelism 跟上面取值是一样的。这个参数是最小分区数，但是最后分区的数量不一定就是这个，其取决于hadoop读取文件时的分片规则</p><h4 id="从其他RDD创建"><a href="#从其他RDD创建" class="headerlink" title="从其他RDD创建"></a>从其他RDD创建</h4><p>详见2.3节</p><h3 id="RDD的转换（面试开发重点）"><a href="#RDD的转换（面试开发重点）" class="headerlink" title="RDD的转换（面试开发重点）"></a>RDD的转换（面试开发重点）</h3><p>RDD整体上分为Value类型和Key-Value类型</p><h4 id="Value类型"><a href="#Value类型" class="headerlink" title="Value类型"></a>Value类型</h4><h5 id="map-func-案例"><a href="#map-func-案例" class="headerlink" title="map(func)案例"></a>map(func)案例</h5><ol><li><p>作用：返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成</p></li><li><p>需求：创建一个1-10数组的RDD，将所有元素*2形成新的RDD</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2 */</span><span class="token keyword">object</span> Spark02_oper1 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> x <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        mapRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：</strong>上面整个过程除了x =&gt; x * 2操作（在executor上操作），其他都是在driver上运行</p><h5 id="mapPartitions-func-案例"><a href="#mapPartitions-func-案例" class="headerlink" title="mapPartitions(func) 案例"></a>mapPartitions(func) 案例</h5><ol><li><p>作用：类似于map，但独立地在RDD的每一个分片（分区）上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] =&gt; Iterator[U]。假设有N个元素，有M个分区，那么map的函数的将被调用N次,而mapPartitions被调用M次,一个函数一次处理所有分区。</p></li><li><p>需求：创建一个RDD，使每个元素*2组成新的RDD</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2 */</span><span class="token keyword">object</span> Spark02_Oper2 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// mapPartitions可以对一个RDD中所有的分区进行遍历，不是数据</span>        <span class="token keyword">val</span> mapPartitionsRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>datas <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// _*2是scala的东西不算是一个计算（只有交给executor的才算计算）</span>            <span class="token comment" spellcheck="true">// datas.map(_*2)这个整体是一个计算，要整块发给executor</span>            <span class="token comment" spellcheck="true">// mapPartitions效率优于map算子，因为减少了执行器网络交互</span>            <span class="token comment" spellcheck="true">// 虽然效率高，但是可能会出现内存溢出（因为它是按区操作，整个区操作不完，不会释放内存）</span>            datas<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        mapPartitionsRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="mapPartitionsWithIndex-func-案例"><a href="#mapPartitionsWithIndex-func-案例" class="headerlink" title="mapPartitionsWithIndex(func) 案例"></a>mapPartitionsWithIndex(func) 案例</h5><ol><li><p>作用：类似于mapPartitions，但此方法带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Interator[T]) =&gt; Iterator[U]；</p></li><li><p>需求：创建一个RDD，使每个元素跟所在分区形成一个元组组成一个新的RDD</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2（mapPartitionsWithIndex） */</span><span class="token keyword">object</span> Spark03_Oper3 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> tupleRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>mapPartitionsWithIndex <span class="token punctuation">{</span>            <span class="token keyword">case</span> <span class="token punctuation">(</span>num<span class="token punctuation">,</span> datas<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span>                datas<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token string">"分区号："</span> <span class="token operator">+</span> num<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        tupleRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="15.png" alt></p><p><strong>executor和driver</strong></p><p>driver要往executor上传数据，只能传可序列化的</p><p><img src="16.png" alt></p><h5 id="flatMap-func-案例"><a href="#flatMap-func-案例" class="headerlink" title="flatMap(func) 案例"></a>flatMap(func) 案例</h5><ol><li><p>作用：类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以方法应该返回一个序列，而不是单一元素）</p></li><li><p>需求：创建一个元素为1-4的RDD，运用flatMap创建一个新的RDD，将所有数字分开</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 将所有数字分开（flatMap） */</span><span class="token keyword">object</span> Spark05_Oper4 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// map算子</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> List<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// flatMap拆成 1 2 3 4</span>        <span class="token keyword">val</span> flatMapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>datas <span class="token keyword">=></span> datas<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        flatMapRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="map-和mapPartition-的区别"><a href="#map-和mapPartition-的区别" class="headerlink" title="map()和mapPartition()的区别"></a>map()和mapPartition()的区别</h5><ol><li>map()：每次处理一条数据。</li></ol><p><img src="13.png" alt></p><p>其中有几个数据就会执行几次 “X” + _ 操作（4次）</p><ol start="2"><li>mapPartition()：每次处理一个分区的数据，这个分区的数据处理完后，原RDD中分区的数据才能释放，可能导致OOM（内存溢出）。</li></ol><p><img src="14.png" alt></p><ol start="3"><li>开发指导：当内存空间较大的时候建议使用mapPartition()，以提高处理效率。</li></ol><h5 id="glom案例"><a href="#glom案例" class="headerlink" title="glom案例"></a>glom案例</h5><ol><li><p>作用：将每一个分区形成一个数组，形成新的RDD类型时RDD[Array[T]]</p></li><li><p>需求：创建一个4个分区的RDD，并将每个分区的数据放到一个数组</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: 所有元素乘以2（mapPartitionsWithIndex） */</span><span class="token keyword">object</span> Spark06_Oper5 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 将一个分区数据放到一个数组中</span>        <span class="token keyword">val</span> glomRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>glom<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        glomRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>array <span class="token keyword">=></span> <span class="token punctuation">{</span>            println<span class="token punctuation">(</span>array<span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将每一个分区形成一个数组，会有很多操作会很方便（求最大（小）值、求和等等）。</p><h5 id="groupBy-func-案例"><a href="#groupBy-func-案例" class="headerlink" title="groupBy(func)案例"></a>groupBy(func)案例</h5><ol><li><p>作用：分组，按照传入函数的返回值进行分组。将相同的key对应的值放入一个迭代器。</p></li><li><p>需求：创建一个RDD，按照元素模以2的值进行分组。</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: groupBy */</span><span class="token keyword">object</span> Spark07_Oper6 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 将一个分区数据放到一个数组中（分组后形成了对偶元组（k-v），k表示分组key，v表示分组数据集合）</span>        <span class="token comment" spellcheck="true">// (0,CompactBuffer(2, 4))</span>        <span class="token comment" spellcheck="true">// (1,CompactBuffer(1, 3))</span>        <span class="token comment" spellcheck="true">// 可见其中Int是分组号，Iterable[Int]是组内元素</span>        <span class="token keyword">val</span> groupByRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>i <span class="token keyword">=></span> i <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        groupByRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="filter-func-案例"><a href="#filter-func-案例" class="headerlink" title="filter(func) 案例"></a>filter(func) 案例</h5><ol><li><p>作用：过滤。返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成。</p></li><li><p>需求：创建一个RDD（1 2 3 4），过滤出一个新RDD（%2为0的）</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: filter */</span><span class="token keyword">object</span> Spark08_Oper7 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// %2余数为0留下，余数不为0拿走</span>        <span class="token keyword">val</span> filterRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        filterRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sample-withReplacement-fraction-seed-案例"><a href="#sample-withReplacement-fraction-seed-案例" class="headerlink" title="sample(withReplacement, fraction, seed) 案例"></a>sample(withReplacement, fraction, seed) 案例</h5><ol><li><p>作用：以指定的随机种子随机抽样出数量为fraction的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样；seed用于指定随机数生成器种子。</p></li><li><p>需求：创建一个RDD（1-10），从中选择放回和不放回抽样</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: sample */</span><span class="token keyword">object</span> Spark09_Oper8 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 从指定数据集合中进行抽样处理，根据不同的算法进行抽样</span>        <span class="token comment" spellcheck="true">// 有放回</span>        <span class="token comment" spellcheck="true">// val sampleRDD: RDD[Int] = listRDD.sample(false, 0.4, 1)</span>        <span class="token comment" spellcheck="true">// 无放回</span>        <span class="token keyword">val</span> sampleRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span>        sampleRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="distinct-numTasks-案例"><a href="#distinct-numTasks-案例" class="headerlink" title="distinct([numTasks])) 案例"></a>distinct([numTasks])) 案例</h5><ol><li>作用：对源RDD进行去重后返回一个新的RDD。默认情况下，只有8个并行任务来操作，但是可以传入一个可选的numTasks（numPartitions）参数改变它。</li></ol><p><strong>有没有shuffle区别</strong></p><p><img src="19.png" alt></p><p>从中可以看出如果中间是map，没有shuffle的过程，那么其中两个红框内分区就可以看成一个整体，p0也就不需要等待p1完成再接着执行。</p><p><img src="20.png" alt></p><p>若其中map换成distinct，则其将会分成前后两个过程。在左边p0分区执行完后，要等左边p1分区执行完才能向后继续执行。</p><p>这就出现了一个分区一个任务，一个任务会被分配到Executor中执行，所以此时 numTasks 和 numPartitions 是一样的。</p><ol start="2"><li>需求：创建一个RDD，使用distinct()对其去重。</li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: distinct */</span><span class="token keyword">object</span> Spark10_Oper9 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        val distinctRDD: RDD[Int] = listRDD.distinct()</span>        <span class="token comment" spellcheck="true">// 重组后的数据分成两个分区保存</span>        <span class="token keyword">val</span> distinctRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>distinct<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印最终结果</span><span class="token comment" spellcheck="true">//        distinctRDD.collect().foreach(println)</span>        <span class="token comment" spellcheck="true">// 保存文件</span>        distinctRDD<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行上面程序不论是写入文件还是输出，会发现原来的顺序都被打乱了，这就说明经过了一个重排序的阶段（shuffle）。</p><p>将RDD中一个分区的数据打乱（其中在一块的不再在一块）重组到其他不同的分区的操作，称之为shuffle操作。</p><p><img src="17.png" alt></p><p>若shuffle过程未做完，整个过程就不会往后走，即：</p><p>当前两个分区（{1，3}， {4，5}）走完后，不能继续往后走，必须得等后面两个（{1，2}， {2，6}）一块在做完才能继续（因为不进行完并不知道后面有没有重复）</p><p><img src="18.png" alt></p><p>上面是无shuffle过程，其中p0分区执行完并不需要等p1分区，因为两个互不相干</p><p>Spark中所有转换算子没有shuffle的算子，性能比较快</p><h5 id="coalesce-numPartitions-案例"><a href="#coalesce-numPartitions-案例" class="headerlink" title="coalesce(numPartitions) 案例"></a>coalesce(numPartitions) 案例</h5><ol><li><p>作用：缩减分区数，用于大数据集过滤后，提高小数据集的执行效率。</p></li><li><p>需求：创建一个4个分区的RDD，对其缩减分区</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/24 下午 08:57 * @Func: coalesce */</span><span class="token keyword">object</span> Spark11_Oper10 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> listRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 缩减分区数量（可以简单理解为合并分区——最后两个，并未打乱顺序）</span>        println<span class="token punctuation">(</span><span class="token string">"缩减分区前："</span> <span class="token operator">+</span> listRDD<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size<span class="token punctuation">)</span>        <span class="token keyword">val</span> coalesceRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> listRDD<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        println<span class="token punctuation">(</span><span class="token string">"缩减分区后："</span> <span class="token operator">+</span> coalesceRDD<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 保存文件</span>        coalesceRDD<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="repartition-numPartitions-案例"><a href="#repartition-numPartitions-案例" class="headerlink" title="repartition(numPartitions) 案例"></a>repartition(numPartitions) 案例</h5><ol><li><p>作用：根据分区数，重新通过网络随机洗牌所有数据。</p></li><li><p>需求：创建一个4个分区的RDD，对其重新分区</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>collect——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>scala<span class="token operator">></span> <span class="token keyword">var</span> rerdd <span class="token operator">=</span> rdd<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>scala<span class="token operator">></span> rerdd<span class="token punctuation">.</span>collect——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span># 可见已经分成了两组scala<span class="token operator">></span> rerdd<span class="token punctuation">.</span>glom<span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="coalesce和repartition的区别"><a href="#coalesce和repartition的区别" class="headerlink" title="coalesce和repartition的区别"></a>coalesce和repartition的区别</h5><ol><li><p>coalesce重新分区，可以选择是否进行shuffle过程。由参数shuffle: Boolean = false/true决定。</p></li><li><p>repartition实际上是调用的coalesce，默认是进行shuffle的。源码如下：</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> repartition<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>    coalesce<span class="token punctuation">(</span>numPartitions<span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> coalesce<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> shuffle<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span>             partitionCoalescer<span class="token operator">:</span> Option<span class="token punctuation">[</span>PartitionCoalescer<span class="token punctuation">]</span> <span class="token operator">=</span> Option<span class="token punctuation">.</span>empty<span class="token punctuation">)</span>            <span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>    <span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sortBy-func-ascending-numTasks-案例"><a href="#sortBy-func-ascending-numTasks-案例" class="headerlink" title="sortBy(func,[ascending], [numTasks]) 案例"></a>sortBy(func,[ascending], [numTasks]) 案例</h5><ol><li><p>作用；使用func先对数据进行处理，按照处理后的数据比较结果排序，默认为正序。</p></li><li><p>需求：创建一个RDD，按照不同的规则进行排序</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）按照自身大小排序（顺序）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>按照自身大小排序（倒序）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）按照与3余数的大小排序</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token operator">%</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="pipe-command-envVars-案例"><a href="#pipe-command-envVars-案例" class="headerlink" title="pipe(command, [envVars]) 案例"></a>pipe(command, [envVars]) 案例</h5><ol><li><p>作用：管道，针对每个分区，都执行一个shell脚本，返回输出的RDD。<br>注意：脚本需要放在Worker节点可以访问到的位置</p></li><li><p>需求：编写一个脚本，使用管道将脚本作用于RDD上。</p></li></ol><p>（1）编写一个脚本</p><p>Shell脚本</p><pre class="line-numbers language-shell"><code class="language-shell">#!/bin/shecho "AA"while read LINE; do   echo ">>>"${LINE}done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="双Value类型交互"><a href="#双Value类型交互" class="headerlink" title="双Value类型交互"></a>双Value类型交互</h4><h5 id="union-otherDataset-案例"><a href="#union-otherDataset-案例" class="headerlink" title="union(otherDataset) 案例"></a>union(otherDataset) 案例</h5><ol><li><p>作用：对源RDD和参数RDD求并集后返回一个新的RDD</p></li><li><p>需求：创建两个RDD，求并集</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">5</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算两个RDD的并集</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> UnionRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at union at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）打印并集结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd3<span class="token punctuation">.</span>collect——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="subtract-otherDataset-案例"><a href="#subtract-otherDataset-案例" class="headerlink" title="subtract (otherDataset) 案例"></a>subtract (otherDataset) 案例</h5><ol><li><p>作用：计算差的一种函数，去除两个RDD中相同的元素，不同的RDD将保留下来</p></li><li><p>需求：创建两个RDD，求第一个RDD与第二个RDD的差集</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">3</span> to <span class="token number">8</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算第一个RDD与第二个RDD的差集并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>subtract<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="intersection-otherDataset-案例"><a href="#intersection-otherDataset-案例" class="headerlink" title="intersection(otherDataset) 案例"></a>intersection(otherDataset) 案例</h5><ol><li><p>作用：对源RDD和参数RDD求交集后返回一个新的RDD</p></li><li><p>需求：创建两个RDD，求两个RDD的交集</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">7</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">5</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算两个RDD的交集</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>intersection<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span> at intersection at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）打印计算结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd3<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="cartesian-otherDataset-案例"><a href="#cartesian-otherDataset-案例" class="headerlink" title="cartesian(otherDataset) 案例"></a>cartesian(otherDataset) 案例</h5><ol><li><p>作用：笛卡尔积（尽量避免使用）</p></li><li><p>需求：创建两个RDD，计算两个RDD的笛卡尔积</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">2</span> to <span class="token number">5</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）计算两个RDD的笛卡尔积并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>cartesian<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="zip-otherDataset-案例"><a href="#zip-otherDataset-案例" class="headerlink" title="zip(otherDataset)案例"></a>zip(otherDataset)案例</h5><ol><li><p>作用：将两个RDD组合成Key/Value形式的RDD,这里默认两个RDD的partition数量以及元素数量都相同，否则会抛出异常。</p></li><li><p>需求：创建两个RDD，并将两个RDD组合到一起形成一个(k,v)RDD</p></li></ol><p>（1）创建第一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个RDD（与1分区数相同）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）第一个RDD组合第二个RDD并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>zip<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>c<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）第二个RDD组合第一个RDD并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd2<span class="token punctuation">.</span>zip<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>c<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）创建第三个RDD（与1,2分区数不同）</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）第一个RDD组合第三个RDD并打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>zip<span class="token punctuation">(</span>rdd3<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>报错了</p><pre><code>    java.lang.IllegalArgumentException: Can&#39;t zip RDDs with unequal numbers of partitions: List(3, 2)</code></pre><p>同理，若 val rdd3 = sc.parallelize(Array(“a”,”b”,”c”,”d”),3) 也会报错</p><pre><code>    Can only zip RDDs with same number of elements in each partition</code></pre><h4 id="Key-Value类型"><a href="#Key-Value类型" class="headerlink" title="Key-Value类型"></a>Key-Value类型</h4><h5 id="partitionBy案例"><a href="#partitionBy案例" class="headerlink" title="partitionBy案例"></a>partitionBy案例</h5><ol><li><p>作用：对 pairRDD 进行分区操作，如果原有的 partionRDD 和现有的 partionRDD 是一致的话就不进行分区， 否则会生成 ShuffleRDD，即会产生 shuffle 过程。</p></li><li><p>需求：创建一个4个分区的RDD，对其重新分区</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"aaa"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"bbb"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"ccc"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">"ddd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）查看RDD的分区数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）对RDD重新分区</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd2 <span class="token operator">=</span> rdd<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at partitionBy at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）查看新RDD的分区数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd2<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>size——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><a href="https://github.com/Swenchao/SparkCode/blob/master/src/main/scala/com/swenchao/spark/Spark12_Oper11.scala" target="_blank" rel="noopener">案例地址</a></p><h5 id="groupByKey案例"><a href="#groupByKey案例" class="headerlink" title="groupByKey案例"></a>groupByKey案例</h5><ol><li><p>作用：groupByKey也是对每个key进行操作，但只生成一个sequence。</p></li><li><p>需求：创建一个pairRDD，将相同key对应值聚合到一个sequence中，并计算相同key对应值的相加结果。</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> words <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token string">"one"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">)</span>——<span class="token operator">></span>words<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>one<span class="token punctuation">,</span> two<span class="token punctuation">,</span> two<span class="token punctuation">,</span> three<span class="token punctuation">,</span> three<span class="token punctuation">,</span> three<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> wordPairsRDD <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>word <span class="token keyword">=></span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>wordPairsRDD<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将相同key对应值聚合到一个sequence中</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> group <span class="token operator">=</span> wordPairsRDD<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>group<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> at groupByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">28</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> group<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>two<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>one<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>three<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）计算相同key对应值的相加结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> group<span class="token punctuation">.</span>map<span class="token punctuation">(</span>t <span class="token keyword">=></span> <span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>sum<span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>res2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">31</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> res2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>two<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>one<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>three<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="reduceByKey-func-numTasks-案例"><a href="#reduceByKey-func-numTasks-案例" class="headerlink" title="reduceByKey(func, [numTasks]) 案例"></a>reduceByKey(func, [numTasks]) 案例</h5><ol><li><p>在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，reduce任务的个数可以通过第二个可选的参数来设置。</p></li><li><p>需求：创建一个pairRDD，计算相同key对应值的相加结果</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"female"</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"male"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"female"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"male"</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）计算相同key对应值的相加结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> reduce <span class="token operator">=</span> rdd<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token keyword">=></span> x<span class="token operator">+</span>y<span class="token punctuation">)</span>——<span class="token operator">></span>reduce<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span> at reduceByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> reduce<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>female<span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>male<span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="reduceByKey和groupByKey的区别"><a href="#reduceByKey和groupByKey的区别" class="headerlink" title="reduceByKey和groupByKey的区别"></a>reduceByKey和groupByKey的区别</h5><p><img src="21.png" alt></p><p>从图中可以看出，groupByKey 本来有6个数据（上面的绿框），处理之后依然有6个数据（下面的绿框），说明其在中间有一次shuffle过程；而 reduceByKey 本来有6个数据（上面的绿框），处理之后依然有3个数据（下面的绿框），说明在中间shuffle过程之前有一次合并的过程（预聚合）</p><ol><li><p>reduceByKey：按照key进行聚合，在shuffle之前有combine（预聚合）操作，返回结果是RDD[k,v].</p></li><li><p>groupByKey：按照key进行分组，直接进行shuffle。</p></li><li><p>开发指导：reduceByKey比groupByKey，建议使用。但是需要注意是否会影响业务逻辑。</p></li></ol><p><strong>注：</strong>如果shuffle过程中有预聚合操作，性能可以得到提高</p><h5 id="aggregateByKey案例"><a href="#aggregateByKey案例" class="headerlink" title="aggregateByKey案例"></a>aggregateByKey案例</h5><p>参数：(zeroValue:U,[partitioner: Partitioner]) (seqOp: (U, V) =&gt; U,combOp: (U, U) =&gt; U)</p><p>zeroValue：默认值</p><p>seqOp：分区内运算规则</p><p>combOp：分区间分区规则</p><ol><li><p>作用：在kv对的RDD中，按key将value进行分组合并，合并时，将每个value和初始值作为seq函数的参数，进行计算，返回的结果作为一个新的kv对，然后再将结果按照key进行合并，最后将每个分组的value传递给combine函数进行计算（先将前两个value进行计算，将返回结果和下一个value传给combine函数，以此类推），将key与计算结果作为一个新的kv对输出。</p></li><li><p>参数描述：</p></li></ol><p>（1）zeroValue：给每一个分区中的每一个key一个初始值；</p><p>（2）seqOp：函数用于在每一个分区中用初始值逐步迭代value；</p><p>（3）combOp：函数用于合并每个分区中的结果。</p><ol start="3"><li><p>需求：创建一个pairRDD，取出每个分区相同key对应值的最大值，然后相加</p></li><li><p>需求分析</p></li></ol><p><img src="22.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>Partitioner<span class="token punctuation">,</span> SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: aggregateByKey案例 */</span><span class="token keyword">object</span> Spark13_Oper12 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> aggRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 查看分区</span><span class="token comment" spellcheck="true">//        val glomRDD: RDD[Array[(String, Int)]] = aggRDD.glom()</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//        glomRDD.collect().foreach(s</span><span class="token comment" spellcheck="true">//            => {println(s.mkString(","))}</span><span class="token comment" spellcheck="true">//        )</span>        <span class="token comment" spellcheck="true">// 取出每个分区相同key对应值的最大值，然后相加</span>        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> aggRDD<span class="token punctuation">.</span>aggregateByKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>max<span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">)</span><span class="token punctuation">,</span> _ <span class="token operator">+</span> _<span class="token punctuation">)</span>        resRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="foldByKey案例"><a href="#foldByKey案例" class="headerlink" title="foldByKey案例"></a>foldByKey案例</h5><p>参数：(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)]</p><ol><li><p>作用：aggregateByKey的简化操作，seqop和combop相同</p></li><li><p>需求：创建一个pairRDD，计算相同key对应值的相加结果</p></li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: foldByKey案例 */</span><span class="token keyword">object</span> Spark14_Oper13 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> foldRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 查看分区</span><span class="token comment" spellcheck="true">//        val glomRDD: RDD[Array[(String, Int)]] = aggRDD.glom()</span><span class="token comment" spellcheck="true">//</span><span class="token comment" spellcheck="true">//        glomRDD.collect().foreach(s</span><span class="token comment" spellcheck="true">//            => {println(s.mkString(","))}</span><span class="token comment" spellcheck="true">//        )</span>        <span class="token comment" spellcheck="true">// 相加</span>        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> foldRDD<span class="token punctuation">.</span>foldByKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        resRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="combineByKey-C-案例"><a href="#combineByKey-C-案例" class="headerlink" title="combineByKey[C] 案例"></a>combineByKey[C] 案例</h5><p>参数：(createCombiner: V =&gt; C,  mergeValue: (C, V) =&gt; C,  mergeCombiners: (C, C) =&gt; C) </p><ol><li><p>作用：对相同K，把V合并成一个集合。</p></li><li><p>参数描述：</p></li></ol><p>（1）createCombiner: combineByKey() 会遍历分区中的所有元素，因此每个元素的键要么还没有遇到过，要么就和之前的某个元素的键相同。如果这是一个新的元素,combineByKey()会使用一个叫作createCombiner()的函数来创建那个键对应的累加器的初始值</p><p>（2）mergeValue: 如果这是一个在处理当前分区之前已经遇到的键，它会使用mergeValue()方法将该键的累加器对应的当前值与这个新的值进行合并</p><p>（3）mergeCombiners: 由于每个分区都是独立处理的， 因此对于同一个键可以有多个累加器。如果有两个或者更多的分区都有对应同一个键的累加器， 就需要使用用户提供的 mergeCombiners() 方法将各个分区的结果进行合并。</p><ol start="3"><li><p>需求：创建一个pairRDD，根据key计算每种key的均值。（先计算每个key出现的次数以及可以对应值的总和，再相除得到结果）</p></li><li><p>需求分析：</p></li></ol><p><img src="23.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: combineByKey案例 */</span><span class="token keyword">object</span> Spark15_Oper14 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 生成数据</span>        <span class="token keyword">val</span> combineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">88</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 相加</span>        <span class="token keyword">val</span> sumRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> combineRDD<span class="token punctuation">.</span>combineByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>acc<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>acc<span class="token punctuation">.</span>_1 <span class="token operator">+</span> v<span class="token punctuation">,</span> acc<span class="token punctuation">.</span>_2 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>acc1<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> acc2<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>acc1<span class="token punctuation">.</span>_1 <span class="token operator">+</span> acc2<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> acc1<span class="token punctuation">.</span>_2 <span class="token operator">+</span> acc2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>        sumRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 求平均值</span>        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sumRDD<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">.</span>_1 <span class="token operator">/</span> value<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span> <span class="token punctuation">}</span>        resRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sortByKey-ascending-numTasks-案例"><a href="#sortByKey-ascending-numTasks-案例" class="headerlink" title="sortByKey([ascending], [numTasks]) 案例"></a>sortByKey([ascending], [numTasks]) 案例</h5><ol><li><p>作用：在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD</p></li><li><p>需求：创建一个pairRDD，按照key的正序和倒序进行排序</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"aa"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token string">"cc"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"bb"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"dd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）按照key的正序</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>dd<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>bb<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>aa<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span>cc<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）按照key的倒序</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span>cc<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>aa<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>bb<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>dd<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="mapValues案例"><a href="#mapValues案例" class="headerlink" title="mapValues案例"></a>mapValues案例</h5><ol><li><p>针对于(K,V)形式的类型只对V进行操作</p></li><li><p>需求：创建一个pairRDD，并将value添加字符串”|||”</p></li></ol><p>（1）创建一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd3 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"d"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）对value添加字符串”|||”</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd3<span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>_<span class="token operator">+</span><span class="token string">"|||"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>a<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>d<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>b<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>c<span class="token operator">||</span><span class="token operator">|</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="join-otherDataset-numTasks-案例"><a href="#join-otherDataset-numTasks-案例" class="headerlink" title="join(otherDataset, [numTasks]) 案例"></a>join(otherDataset, [numTasks]) 案例</h5><ol><li><p>作用：在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD</p></li><li><p>需求：创建两个pairRDD，并将key相同的数据聚合到一个元组。</p></li></ol><p>（1）创建第一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）join操作并打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="cogroup-otherDataset-numTasks-案例"><a href="#cogroup-otherDataset-numTasks-案例" class="headerlink" title="cogroup(otherDataset, [numTasks]) 案例"></a>cogroup(otherDataset, [numTasks]) 案例</h5><ol><li><p>作用：在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable&lt;V&gt;,Iterable&lt;W&gt;))类型的RDD</p></li><li><p>需求：创建两个pairRDD，并将key相同的数据聚合到一个迭代器。</p></li></ol><p>（1）创建第一个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）创建第二个pairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）cogroup两个RDD并打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>cogroup<span class="token punctuation">(</span>rdd1<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>——<span class="token operator">></span>res6<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Iterable<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><ol><li>数据结构：时间戳，省份，城市，用户，广告，中间字段使用空格分割。</li></ol><p>样本如下：</p><pre><code>1516609143867 6 7 64 161516609143869 9 4 75 181516609143869 1 7 87 12...</code></pre><p><a href="https://github.com/Swenchao/SparkCode/blob/master/in/agent.log" target="_blank" rel="noopener">样本地址</a></p><ol start="2"><li><p>需求：统计出每一个省份广告被点击次数的TOP3</p></li><li><p>实现过程：</p></li></ol><p><img src="24.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/22 下午 10:14 * @Func: 统计出每一个省份广告被点击次数的TOP3 */</span><span class="token keyword">object</span> adTop3 <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//创建conf对象</span>        <span class="token comment" spellcheck="true">// app id对应一个应用名称</span>        <span class="token keyword">val</span> config<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"AdTop3"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建上下文对象</span>        <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>config<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取文件生成RDD</span>        <span class="token keyword">val</span> lines<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"in/agent.log"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 分解成：((Province,AD),1)</span>        <span class="token comment" spellcheck="true">// 原来样式：时间戳 省份 城市 用户 广告</span>        <span class="token keyword">val</span> provinceAD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> lines<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> details<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>            <span class="token punctuation">(</span><span class="token punctuation">(</span>details<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> details<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 检验样式：((5,10),1)</span><span class="token comment" spellcheck="true">//        provinceAD.foreach(println)</span>        <span class="token comment" spellcheck="true">// 点击次数相加</span>        <span class="token keyword">val</span> sumProvinceAD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> provinceAD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">=></span> x <span class="token operator">+</span> y<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        sumProvinceAD.foreach(println)</span>        <span class="token comment" spellcheck="true">// 改变样式 (Province,(AD,1))</span>        <span class="token keyword">val</span> provinceToADSum<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sumProvinceAD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">{</span>            <span class="token punctuation">(</span>x<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> x<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        provinceToADSum.foreach(x=>println(x._1))</span>        <span class="token comment" spellcheck="true">// 根据省份分组</span>        <span class="token keyword">val</span> provinceSum<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> provinceToADSum<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        provinceSum.foreach(println)</span>        <span class="token comment" spellcheck="true">// 排序取前三</span>        <span class="token keyword">val</span> provinceADTop3<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> provinceSum<span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">{</span>            x<span class="token punctuation">.</span>toList<span class="token punctuation">.</span>sortWith<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">=></span> x<span class="token punctuation">.</span>_2 <span class="token operator">&lt;</span> y<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        provinceADTop3<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        provinceADTop3.saveAsTextFile("output")</span>        <span class="token comment" spellcheck="true">//9.关闭与spark的连接</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Action"><a href="#Action" class="headerlink" title="Action"></a>Action</h3><h4 id="reduce-func-案例"><a href="#reduce-func-案例" class="headerlink" title="reduce(func)案例"></a>reduce(func)案例</h4><ol><li><p>作用：通过func函数聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据。</p></li><li><p>需求：创建一个RDD，将所有元素聚合得到结果。</p></li></ol><p>（1）创建一个RDD[Int]</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）聚合RDD[Int]所有元素</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd1<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）创建一个RDD[String]</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）聚合RDD[String]所有数据</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd2<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>_1 <span class="token operator">+</span> y<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>x<span class="token punctuation">.</span>_2 <span class="token operator">+</span> y<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">(</span>adca<span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="collect-案例"><a href="#collect-案例" class="headerlink" title="collect()案例"></a>collect()案例</h4><ol><li><p>作用：在驱动程序中，以数组的形式返回数据集的所有元素。</p></li><li><p>需求：创建一个RDD，并将RDD内容收集到Driver端打印</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将结果收集到Driver端</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>collect——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="count-案例"><a href="#count-案例" class="headerlink" title="count()案例"></a>count()案例</h4><ol><li><p>作用：返回RDD中元素的个数</p></li><li><p>需求：创建一个RDD，统计该RDD的条数</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>count——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">10</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="first-案例"><a href="#first-案例" class="headerlink" title="first()案例"></a>first()案例</h4><ol><li><p>作用：返回RDD中的第一个元素</p></li><li><p>需求：创建一个RDD，返回该RDD中的第一个元素</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>first——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="take-n-案例"><a href="#take-n-案例" class="headerlink" title="take(n)案例"></a>take(n)案例</h4><ol><li><p>作用：返回一个由RDD的前n个元素组成的数组</p></li><li><p>需求：创建一个RDD，统计该RDD的条数</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="takeOrdered-n-案例"><a href="#takeOrdered-n-案例" class="headerlink" title="takeOrdered(n)案例"></a>takeOrdered(n)案例</h4><ol><li><p>作用：返回该RDD<strong>排序</strong>后的前n个元素组成的数组</p></li><li><p>需求：创建一个RDD，统计该RDD的条数</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计该RDD的条数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>takeOrdered<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="aggregate案例"><a href="#aggregate案例" class="headerlink" title="aggregate案例"></a>aggregate案例</h4><ol><li><p>参数：(zeroValue: U)(seqOp: (U, T) ⇒ U, combOp: (U, U) ⇒ U)</p></li><li><p>作用：aggregate函数将每个分区里面的元素通过seqOp和初始值进行聚合，然后用combine函数将每个分区的结果和初始值(zeroValue)进行combine操作。这个函数最终返回的类型不需要和RDD中元素类型一致。</p></li><li><p>需求：创建一个RDD，将所有元素相加得到结果</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将该RDD所有元素相加得到结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>aggregate<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">,</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res5<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>此处初始值使用与 aggregateByKey 不太一样，分区内会操作一次，在分区间也会操作一次，如下：</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>aggregate<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">,</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res6<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">85</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>初始值是10，每个分区在求和的时候都是在10的基础上进行的，然后在两个分区相加的时候又会加一次：（10+1+2+3+4+5+6+7+8+9+10）+（10+1+2+3+4+5+6+7+8+9+10）+10</p><h4 id="fold-num-func-案例"><a href="#fold-num-func-案例" class="headerlink" title="fold(num)(func)案例"></a>fold(num)(func)案例</h4><ol><li><p>作用：折叠操作，aggregate的简化操作，seqop和combop一样。</p></li><li><p>需求：创建一个RDD，将所有元素相加得到结果</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将该RDD所有元素相加得到结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>fold<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>res6<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>以上两个操作可以对应 xxxByKey 操作</p><h4 id="saveAsTextFile-path"><a href="#saveAsTextFile-path" class="headerlink" title="saveAsTextFile(path)"></a>saveAsTextFile(path)</h4><p>作用：将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本</p><h4 id="saveAsSequenceFile-path"><a href="#saveAsSequenceFile-path" class="headerlink" title="saveAsSequenceFile(path)"></a>saveAsSequenceFile(path)</h4><p>作用：将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。</p><h4 id="saveAsObjectFile-path"><a href="#saveAsObjectFile-path" class="headerlink" title="saveAsObjectFile(path)"></a>saveAsObjectFile(path)</h4><p>作用：用于将RDD中的元素序列化成对象，存储到文件中。</p><h4 id="countByKey-案例"><a href="#countByKey-案例" class="headerlink" title="countByKey()案例"></a>countByKey()案例</h4><ol><li><p>作用：针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。</p></li><li><p>需求：创建一个PairRDD，统计每种key的个数</p></li></ol><p>（1）创建一个PairRDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计每种key的个数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>countByKey——<span class="token operator">></span>res1<span class="token operator">:</span> scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token number">3</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="foreach-func-案例"><a href="#foreach-func-案例" class="headerlink" title="foreach(func)案例"></a>foreach(func)案例</h4><ol><li><p>作用：在数据集的每一个元素上，运行函数func进行更新。</p></li><li><p>需求：创建一个RDD，对每个元素进行打印</p></li></ol><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">var</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）对该RDD每个元素进行打印</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span><span class="token number">3</span><span class="token number">4</span><span class="token number">5</span><span class="token number">1</span><span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RDD中的函数传递"><a href="#RDD中的函数传递" class="headerlink" title="RDD中的函数传递"></a>RDD中的函数传递</h3><p>在实际开发中我们往往需要自己定义一些对于RDD的操作，那么此时需要主要的是，初始化工作是在Driver端进行的，而实际运行程序是在Executor端进行的，这就涉及到了跨进程通信，是需要序列化的。下面我们看几个例子：</p><h4 id="传递一个方法"><a href="#传递一个方法" class="headerlink" title="传递一个方法"></a>传递一个方法</h4><p>1．创建一个搜索类</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">/** * 搜索类 * @param query */</span><span class="token keyword">class</span> Search<span class="token punctuation">(</span>query<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的数据</span>    <span class="token keyword">def</span> isMatch<span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        s<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span>    <span class="token keyword">def</span> getMatch1 <span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span>    <span class="token keyword">def</span> getMatche2<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．创建Spark主程序</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: RDD中的函数传递（序列化） */</span><span class="token keyword">object</span> Spark16_Serializable <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建search对象</span>        <span class="token keyword">val</span> search <span class="token operator">=</span> <span class="token keyword">new</span> Search<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 运用第一个过滤函数并打印结果</span>        <span class="token keyword">val</span> match1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> search<span class="token punctuation">.</span>getMatch1<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        match1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．运行程序</p><pre class="line-numbers language-scala"><code class="language-scala">Exception in thread <span class="token string">"main"</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkException<span class="token operator">:</span> Task not serializable    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>ensureSerializable<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">298</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>org$apache$spark$util$ClosureCleaner$$clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">288</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">108</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>SparkContext<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">2101</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">387</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">151</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">112</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">362</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span class="token punctuation">.</span>getMatche1<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">39</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest$<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">18</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token punctuation">)</span>Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NotSerializableException<span class="token operator">:</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．问题说明</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span><span class="token keyword">def</span> getMatch1 <span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在这个方法中所调用的方法isMatch()是定义在Search这个类中的，实际上调用的是this. isMatch()，this表示Search这个类的对象，程序在运行过程中需要将Search对象序列化以后传递到Executor端。</p><p>5．解决方案</p><p>使类继承scala.Serializable即可。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">class</span> Search<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Serializable<span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="6"><li>修改之后完整代码</li></ol><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: RDD中的函数传递（序列化） */</span><span class="token keyword">object</span> Spark16_Serializable <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建search对象</span>        <span class="token keyword">val</span> search <span class="token operator">=</span> <span class="token keyword">new</span> Search<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 运用第一个过滤函数并打印结果</span>        <span class="token keyword">val</span> match1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> search<span class="token punctuation">.</span>getMatch1<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        match1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * 搜索类（需要序列化） * @param query */</span><span class="token keyword">class</span> Search<span class="token punctuation">(</span>query<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Serializable <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的数据</span>    <span class="token keyword">def</span> isMatch<span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        s<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span>    <span class="token comment" spellcheck="true">// 此方法是要在executor中执行，而此方法是一个成员方法（来源于某个对象），因此在使用的时候，这个类也要传给executor（因此这个类也需要序列化）</span>    <span class="token keyword">def</span> getMatch1 <span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="传递一个属性"><a href="#传递一个属性" class="headerlink" title="传递一个属性"></a>传递一个属性</h4><p>1．创建Spark主程序</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/29 下午 08:57 * @Func: RDD中的函数传递（序列化） */</span><span class="token keyword">object</span> Spark16_Serializable <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建search对象</span>        <span class="token keyword">val</span> search <span class="token operator">=</span> <span class="token keyword">new</span> Search<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 运用第一个过滤函数并打印结果</span><span class="token comment" spellcheck="true">//        val match1: RDD[String] = search.getMatch1(rdd)</span><span class="token comment" spellcheck="true">//        match1.collect().foreach(println)</span>        <span class="token comment" spellcheck="true">// 运用第二个</span>        <span class="token keyword">val</span> match2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> search<span class="token punctuation">.</span>getMatche2<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        match2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．运行程序</p><pre class="line-numbers language-scala"><code class="language-scala">Exception in thread <span class="token string">"main"</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkException<span class="token operator">:</span> Task not serializable    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>ensureSerializable<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">298</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>org$apache$spark$util$ClosureCleaner$$clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">288</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ClosureCleaner$<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>ClosureCleaner<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">108</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>SparkContext<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">2101</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">387</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD$$anonfun$filter$<span class="token number">1</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">151</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDDOperationScope$<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDDOperationScope<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">112</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>withScope<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">362</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>RDD<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">386</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span class="token punctuation">.</span>getMatche1<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">39</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest$<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">18</span><span class="token punctuation">)</span>    at com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>SeriTest<span class="token punctuation">.</span>main<span class="token punctuation">(</span>SeriTest<span class="token punctuation">.</span>scala<span class="token punctuation">)</span>Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NotSerializableException<span class="token operator">:</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>Search<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．问题说明</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span><span class="token keyword">def</span> getMatche2<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在这个方法中所调用的方法query是定义在Search这个类中的字段，实际上调用的是this. query，this表示Search这个类的对象，程序在运行过程中需要将Search对象序列化以后传递到Executor端。</p><p>4．解决方案</p><p>1）使类继承scala.Serializable即可。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">class</span> Search<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Serializable<span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）将类变量query赋值给局部变量</p><p>修改getMatche2为</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//过滤出包含字符串的RDD</span><span class="token keyword">def</span> getMatche2<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> query_ <span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>query<span class="token comment" spellcheck="true">//将类变量赋值给局部变量</span>    rdd<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>query_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RDD依赖关系"><a href="#RDD依赖关系" class="headerlink" title="RDD依赖关系"></a>RDD依赖关系</h3><h4 id="Lineage"><a href="#Lineage" class="headerlink" title="Lineage"></a>Lineage</h4><p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p><p>（1）读取一个HDFS文件并将其中内容映射成一个个元组</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> wordAndOne <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"/fruit.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>wordAndOne<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）统计每一种key对应的个数</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> wordAndCount <span class="token operator">=</span> wordAndOne<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>——<span class="token operator">></span>wordAndCount<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span> at reduceByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）查看“wordAndOne”的Lineage</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndOne<span class="token punctuation">.</span>toDebugString——<span class="token operator">></span>res1<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at flatMap at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv HadoopRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）查看“wordAndCount”的Lineage</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndCount<span class="token punctuation">.</span>toDebugString——<span class="token operator">></span>res2<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span> at reduceByKey at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at flatMap at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  <span class="token operator">/</span>fruit<span class="token punctuation">.</span>tsv HadoopRDD<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> at textFile at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）查看“wordAndOne”的依赖类型</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndOne<span class="token punctuation">.</span>dependencies——<span class="token operator">></span>res3<span class="token operator">:</span> Seq<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> List<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>OneToOneDependency<span class="token annotation punctuation">@5d5db92b</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）查看“wordAndCount”的依赖类型</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> wordAndCount<span class="token punctuation">.</span>dependencies——<span class="token operator">></span>res4<span class="token operator">:</span> Seq<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> List<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>ShuffleDependency<span class="token annotation punctuation">@63f3e6a8</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>注意：</strong>RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。</p><h4 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h4><p>窄依赖指的是每一个父RDD的Partition最多被子RDD的一个Partition使用,窄依赖我们形象的比喻为独生子女（一对一）</p><p><img src="25.png" alt></p><h4 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h4><p>宽依赖指的是多个子RDD的Partition会依赖同一个父RDD的Partition，会引起shuffle,总结：宽依赖我们形象的比喻为超生（多对一）</p><p><img src="26.png" alt></p><h4 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h4><p>DAG(Directed Acyclic Graph) 叫做有向无环图，原始的 RDD 通过一系列的转换就就形成了 DAG，根据 RDD 之间的依赖关系的不同将 DAG 划分成不同的 Stage（阶段），对于窄依赖，partition的转换处理在Stage中完成计算。对于宽依赖，由于有 Shuffle 的存在，只能在 parent RDD 处理完成后，才能开始接下来的计算，因此宽依赖是划分 Stage 的依据。</p><p><img src="27.png" alt></p><p>上图可看，A与B试一个宽依赖所以分成两个stage；F与G试一个宽依赖，所以分成了两个stage。</p><h4 id="任务划分（面试重点）"><a href="#任务划分（面试重点）" class="headerlink" title="任务划分（面试重点）"></a>任务划分（面试重点）</h4><p>RDD任务切分中间分为：Application、Job、Stage和Task</p><p>1）Application：初始化一个 SparkContext 即生成一个 Application</p><p>2）Job：一个 Action 算子就会生成一个 Job</p><p>3）Stage：根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage。</p><p>4）Task：Stage是一个TaskSet，将Stage划分的结果发送到不同的Executor执行即为一个Task。</p><p>WordCount案列规划图</p><p><img src="28.png" alt></p><p><strong>注意：</strong>Application-&gt;Job（行动算子）-&gt;Stage-&gt; Task（分区）每一层都是1对n的关系。</p><p>一个应用可以多次调用行动算子（Job），而每个作业中可以有多个阶段，同时在一个阶段中有多个分区（每个分区就是一个任务）</p><p>阶段划分数量 = 1 + shuffle数量，源码分析：</p><p>[DAGScheduler.scala]</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">private</span><span class="token punctuation">[</span>scheduler<span class="token punctuation">]</span> <span class="token keyword">def</span> handleJobSubmitted<span class="token punctuation">(</span>jobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span>    finalRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">,</span>    func<span class="token operator">:</span> <span class="token punctuation">(</span>TaskContext<span class="token punctuation">,</span> Iterator<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=></span> _<span class="token punctuation">,</span>    partitions<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    callSite<span class="token operator">:</span> CallSite<span class="token punctuation">,</span>    listener<span class="token operator">:</span> JobListener<span class="token punctuation">,</span>    properties<span class="token operator">:</span> Properties<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">var</span> finalStage<span class="token operator">:</span> ResultStage <span class="token operator">=</span> <span class="token keyword">null</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// New stage creation may throw an exception if, for example, jobs are run on a</span>        <span class="token comment" spellcheck="true">// HadoopRDD whose underlying HDFS files have been deleted.</span>        <span class="token comment" spellcheck="true">// 此处便是阶段数量中的1</span>        finalStage <span class="token operator">=</span> createResultStage<span class="token punctuation">(</span>finalRDD<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitions<span class="token punctuation">,</span> jobId<span class="token punctuation">,</span> callSite<span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true">// 提交</span>        submitStage<span class="token punctuation">(</span>finalStage<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接上面 createResultStage</span><span class="token comment" spellcheck="true">/*** Create a ResultStage associated with the provided jobId.*/</span><span class="token keyword">private</span> <span class="token keyword">def</span> createResultStage<span class="token punctuation">(</span>    rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">,</span>    func<span class="token operator">:</span> <span class="token punctuation">(</span>TaskContext<span class="token punctuation">,</span> Iterator<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=></span> _<span class="token punctuation">,</span>    partitions<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    jobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span>    callSite<span class="token operator">:</span> CallSite<span class="token punctuation">)</span><span class="token operator">:</span> ResultStage <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取或创建阶段</span>        <span class="token keyword">val</span> parents <span class="token operator">=</span> getOrCreateParentStages<span class="token punctuation">(</span>rdd<span class="token punctuation">,</span> jobId<span class="token punctuation">)</span>        <span class="token keyword">val</span> id <span class="token operator">=</span> nextStageId<span class="token punctuation">.</span>getAndIncrement<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> stage <span class="token operator">=</span> <span class="token keyword">new</span> ResultStage<span class="token punctuation">(</span>id<span class="token punctuation">,</span> rdd<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitions<span class="token punctuation">,</span> parents<span class="token punctuation">,</span> jobId<span class="token punctuation">,</span> callSite<span class="token punctuation">)</span>        stageIdToStage<span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">=</span> stage        updateJobIdStageIdMaps<span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> stage<span class="token punctuation">)</span>        stage<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接上面 getOrCreateParentStages</span><span class="token comment" spellcheck="true">/*** Get or create the list of parent stages for a given RDD.  The new Stages will be created with* the provided firstJobId.*/</span><span class="token keyword">private</span> <span class="token keyword">def</span> getOrCreateParentStages<span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">,</span> firstJobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> List<span class="token punctuation">[</span>Stage<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 拿到shuffle依赖做转换</span>    getShuffleDependencies<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{</span> shuffleDep <span class="token keyword">=></span>        getOrCreateShuffleMapStage<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">,</span> firstJobId<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">.</span>toList<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接上面 getShuffleDependencies</span><span class="token keyword">private</span><span class="token punctuation">[</span>scheduler<span class="token punctuation">]</span> <span class="token keyword">def</span> getShuffleDependencies<span class="token punctuation">(</span>    rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> HashSet<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 返回值（其返回set中类型为ShuffleDependency，因此其中放的值便为shuffle）</span>        <span class="token keyword">val</span> parents <span class="token operator">=</span> <span class="token keyword">new</span> HashSet<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">val</span> visited <span class="token operator">=</span> <span class="token keyword">new</span> HashSet<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">val</span> waitingForVisit <span class="token operator">=</span> <span class="token keyword">new</span> Stack<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span>        waitingForVisit<span class="token punctuation">.</span>push<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>waitingForVisit<span class="token punctuation">.</span>nonEmpty<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> toVisit <span class="token operator">=</span> waitingForVisit<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>visited<span class="token punctuation">(</span>toVisit<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                visited <span class="token operator">+=</span> toVisit                toVisit<span class="token punctuation">.</span>dependencies<span class="token punctuation">.</span>foreach <span class="token punctuation">{</span>                    <span class="token comment" spellcheck="true">// 模式匹配，只要某个RDD的依赖是shuffle的，就加到返回的parents中</span>                    <span class="token keyword">case</span> shuffleDep<span class="token operator">:</span> ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span> <span class="token keyword">=></span>                         parents <span class="token operator">+=</span> shuffleDep                    <span class="token keyword">case</span> dependency <span class="token keyword">=></span>                        waitingForVisit<span class="token punctuation">.</span>push<span class="token punctuation">(</span>dependency<span class="token punctuation">.</span>rdd<span class="token punctuation">)</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    parents<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 在上面那个方法返回parents之后进行转换</span><span class="token comment" spellcheck="true">// 接上上面 getOrCreateShuffleMapStage</span><span class="token comment" spellcheck="true">/*** Gets a shuffle map stage if one exists in shuffleIdToMapStage. Otherwise, if the* shuffle map stage doesn't already exist, this method will create the shuffle map stage in* addition to any missing ancestor shuffle map stages.*/</span><span class="token keyword">private</span> <span class="token keyword">def</span> getOrCreateShuffleMapStage<span class="token punctuation">(</span>    shuffleDep<span class="token operator">:</span> ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">,</span>    firstJobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> ShuffleMapStage <span class="token operator">=</span> <span class="token punctuation">{</span>        shuffleIdToMapStage<span class="token punctuation">.</span>get<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">.</span>shuffleId<span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 模式匹配，若当前stage已经有了，则直接返回；</span>            <span class="token keyword">case</span> Some<span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token keyword">=></span>                stage            <span class="token comment" spellcheck="true">// 若没有则创建</span>            <span class="token keyword">case</span> None <span class="token keyword">=></span>            <span class="token comment" spellcheck="true">// Create stages for all missing ancestor shuffle dependencies.</span>                getMissingAncestorShuffleDependencies<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">.</span>rdd<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach <span class="token punctuation">{</span> dep <span class="token keyword">=></span>            <span class="token comment" spellcheck="true">// Even though getMissingAncestorShuffleDependencies only returns shuffle dependencies</span>            <span class="token comment" spellcheck="true">// that were not already in shuffleIdToMapStage, it's possible that by the time we</span>            <span class="token comment" spellcheck="true">// get to a particular dependency in the foreach loop, it's been added to</span>            <span class="token comment" spellcheck="true">// shuffleIdToMapStage by the stage creation process for an earlier dependency. See</span>            <span class="token comment" spellcheck="true">// SPARK-13902 for more information.</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>shuffleIdToMapStage<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>dep<span class="token punctuation">.</span>shuffleId<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                createShuffleMapStage<span class="token punctuation">(</span>dep<span class="token punctuation">,</span> firstJobId<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// Finally, create a stage for the given shuffle dependency.</span>        createShuffleMapStage<span class="token punctuation">(</span>shuffleDep<span class="token punctuation">,</span> firstJobId<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 接第一个最后的提交</span><span class="token comment" spellcheck="true">/** Submits stage, but first recursively submits any missing parents. */</span><span class="token keyword">private</span> <span class="token keyword">def</span> submitStage<span class="token punctuation">(</span>stage<span class="token operator">:</span> Stage<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> jobId <span class="token operator">=</span> activeJobForStage<span class="token punctuation">(</span>stage<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>jobId<span class="token punctuation">.</span>isDefined<span class="token punctuation">)</span> <span class="token punctuation">{</span>        logDebug<span class="token punctuation">(</span><span class="token string">"submitStage("</span> <span class="token operator">+</span> stage <span class="token operator">+</span> <span class="token string">")"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>waitingStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>runningStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>failedStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">val</span> missing <span class="token operator">=</span> getMissingParentStages<span class="token punctuation">(</span>stage<span class="token punctuation">)</span><span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span>            logDebug<span class="token punctuation">(</span><span class="token string">"missing: "</span> <span class="token operator">+</span> missing<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>missing<span class="token punctuation">.</span>isEmpty<span class="token punctuation">)</span> <span class="token punctuation">{</span>                logInfo<span class="token punctuation">(</span><span class="token string">"Submitting "</span> <span class="token operator">+</span> stage <span class="token operator">+</span> <span class="token string">" ("</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>rdd <span class="token operator">+</span> <span class="token string">"), which has no missing parents"</span><span class="token punctuation">)</span>                submitMissingTasks<span class="token punctuation">(</span>stage<span class="token punctuation">,</span> jobId<span class="token punctuation">.</span>get<span class="token punctuation">)</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span>parent <span class="token keyword">&lt;-</span> missing<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    submitStage<span class="token punctuation">(</span>parent<span class="token punctuation">)</span>                <span class="token punctuation">}</span>                waitingStages <span class="token operator">+=</span> stage            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        abortStage<span class="token punctuation">(</span>stage<span class="token punctuation">,</span> <span class="token string">"No active job for stage "</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> None<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala">  <span class="token comment" spellcheck="true">// 接上面的 submitMissingTasks（这只是其中一部分）</span>  <span class="token comment" spellcheck="true">/** Called when stage's parents are available and we can now do its task. */</span>  <span class="token keyword">private</span> <span class="token keyword">def</span> submitMissingTasks<span class="token punctuation">(</span>stage<span class="token operator">:</span> Stage<span class="token punctuation">,</span> jobId<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">val</span> tasks<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Task<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token punctuation">{</span>      stage <span class="token keyword">match</span> <span class="token punctuation">{</span>        <span class="token keyword">case</span> stage<span class="token operator">:</span> ShuffleMapStage <span class="token keyword">=></span>          <span class="token comment" spellcheck="true">// 根据分区计算任务</span>          partitionsToCompute<span class="token punctuation">.</span>map <span class="token punctuation">{</span> id <span class="token keyword">=></span>            <span class="token keyword">val</span> locs <span class="token operator">=</span> taskIdToLocations<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token keyword">val</span> part <span class="token operator">=</span> stage<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">// 最后返回为一个task</span>            <span class="token keyword">new</span> ShuffleMapTask<span class="token punctuation">(</span>stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptId<span class="token punctuation">,</span>              taskBinary<span class="token punctuation">,</span> part<span class="token punctuation">,</span> locs<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>taskMetrics<span class="token punctuation">,</span> properties<span class="token punctuation">,</span> Option<span class="token punctuation">(</span>jobId<span class="token punctuation">)</span><span class="token punctuation">,</span>              Option<span class="token punctuation">(</span>sc<span class="token punctuation">.</span>applicationId<span class="token punctuation">)</span><span class="token punctuation">,</span> sc<span class="token punctuation">.</span>applicationAttemptId<span class="token punctuation">)</span>          <span class="token punctuation">}</span>        <span class="token keyword">case</span> stage<span class="token operator">:</span> ResultStage <span class="token keyword">=></span>          partitionsToCompute<span class="token punctuation">.</span>map <span class="token punctuation">{</span> id <span class="token keyword">=></span>            <span class="token keyword">val</span> p<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> stage<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token keyword">val</span> part <span class="token operator">=</span> stage<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span>p<span class="token punctuation">)</span>            <span class="token keyword">val</span> locs <span class="token operator">=</span> taskIdToLocations<span class="token punctuation">(</span>id<span class="token punctuation">)</span>            <span class="token keyword">new</span> ResultTask<span class="token punctuation">(</span>stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptId<span class="token punctuation">,</span>              taskBinary<span class="token punctuation">,</span> part<span class="token punctuation">,</span> locs<span class="token punctuation">,</span> id<span class="token punctuation">,</span> properties<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>taskMetrics<span class="token punctuation">,</span>              Option<span class="token punctuation">(</span>jobId<span class="token punctuation">)</span><span class="token punctuation">,</span> Option<span class="token punctuation">(</span>sc<span class="token punctuation">.</span>applicationId<span class="token punctuation">)</span><span class="token punctuation">,</span> sc<span class="token punctuation">.</span>applicationAttemptId<span class="token punctuation">)</span>          <span class="token punctuation">}</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>tasks<span class="token punctuation">.</span>size <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      logInfo<span class="token punctuation">(</span><span class="token string">"Submitting "</span> <span class="token operator">+</span> tasks<span class="token punctuation">.</span>size <span class="token operator">+</span> <span class="token string">" missing tasks from "</span> <span class="token operator">+</span> stage <span class="token operator">+</span> <span class="token string">" ("</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>rdd <span class="token operator">+</span> <span class="token string">")"</span><span class="token punctuation">)</span>      stage<span class="token punctuation">.</span>pendingPartitions <span class="token operator">++</span><span class="token operator">=</span> tasks<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>partitionId<span class="token punctuation">)</span>      logDebug<span class="token punctuation">(</span><span class="token string">"New pending partitions: "</span> <span class="token operator">+</span> stage<span class="token punctuation">.</span>pendingPartitions<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">// 将所有信息封装成一个TaskSet进行提交</span>      taskScheduler<span class="token punctuation">.</span>submitTasks<span class="token punctuation">(</span><span class="token keyword">new</span> TaskSet<span class="token punctuation">(</span>        tasks<span class="token punctuation">.</span>toArray<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptId<span class="token punctuation">,</span> jobId<span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">)</span>      stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>submissionTime <span class="token operator">=</span> Some<span class="token punctuation">(</span>clock<span class="token punctuation">.</span>getTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RDD缓存"><a href="#RDD缓存" class="headerlink" title="RDD缓存"></a>RDD缓存</h3><p>RDD通过persist方法或cache方法可以将前面的计算结果缓存，默认情况下 persist() 会把数据以序列化的形式缓存在 JVM 的堆空间中。 </p><p>但是并不是这两个方法被调用时立即缓存，而是触发后面的action时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> persist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> persist<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过查看源码发现cache最终也是调用了persist方法，默认的存储级别都是仅在内存存储一份，Spark的存储级别还有好多种，存储级别在object StorageLevel中定义的。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">object</span> StorageLevel <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 不缓存</span>    <span class="token keyword">val</span> NONE <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 只缓存到磁盘</span>    <span class="token keyword">val</span> DISK_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 缓存盘2份副本</span>    <span class="token keyword">val</span> DISK_ONLY_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 只缓存到内存</span>    <span class="token keyword">val</span> MEMORY_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_ONLY_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 缓存到内存序列化</span>    <span class="token keyword">val</span> MEMORY_ONLY_SER <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_ONLY_SER_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK_SER <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> MEMORY_AND_DISK_SER_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 堆外内存（JVM里面的内存是堆内，不是其中的内存叫堆外）</span>    <span class="token keyword">val</span> OFF_HEAP <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在存储级别的末尾加上“_2”来把持久化数据存为两份 </p><p><img src="29.png" alt></p><p>缓存有可能丢失，或者存储存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p><p>（1）创建一个RDD</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">"bigData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>——<span class="token operator">></span>rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）将RDD转换为携带当前时间戳不做缓存</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 后面加上一个时间戳</span>scala<span class="token operator">></span> <span class="token keyword">val</span> nocache <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>toString<span class="token operator">+</span>System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">)</span>——<span class="token operator">></span>nocache<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）多次打印结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> nocache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728101126<span class="token punctuation">)</span>scala<span class="token operator">></span> nocache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728114573<span class="token punctuation">)</span>scala<span class="token operator">></span> nocache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728141278<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）将RDD转换为携带当前时间戳并做缓存</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> <span class="token keyword">val</span> cache <span class="token operator">=</span>  rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>toString<span class="token operator">+</span>System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">)</span><span class="token punctuation">.</span>cache——<span class="token operator">></span>cache<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）多次打印做了缓存的结果</p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> cache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728208803<span class="token punctuation">)</span>                               scala<span class="token operator">></span> cache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728208803<span class="token punctuation">)</span>scala<span class="token operator">></span> cache<span class="token punctuation">.</span>collect——<span class="token operator">></span>res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>bigData1601728208803<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> cache<span class="token punctuation">.</span>toDebugStringres8<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at map at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">26</span> <span class="token punctuation">[</span>Memory Deserialized 1x Replicated<span class="token punctuation">]</span> <span class="token operator">|</span>       CachedPartitions<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">;</span> MemorySize<span class="token operator">:</span> <span class="token number">104.0</span> B<span class="token punctuation">;</span> ExternalBlockStoreSize<span class="token operator">:</span> <span class="token number">0.0</span> B<span class="token punctuation">;</span> DiskSize<span class="token operator">:</span> <span class="token number">0.0</span> B <span class="token operator">|</span>  ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">></span><span class="token operator">:</span><span class="token number">24</span> <span class="token punctuation">[</span>Memory Deserialized 1x Replicated<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>debug之后可以看出，其在依赖关系中间加了一个缓存步骤</p><h3 id="RDD-CheckPoint"><a href="#RDD-CheckPoint" class="headerlink" title="RDD CheckPoint"></a>RDD CheckPoint</h3><p>Spark中对于数据的保存除了持久化操作之外，还提供了一种检查点的机制，检查点（本质是通过将RDD写入Disk做检查点）是为了通过lineage做容错的辅助，lineage过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的RDD开始重做Lineage，就会减少开销。检查点通过将数据写入到HDFS文件系统实现了RDD的检查点功能。</p><p>为当前RDD设置检查点。该函数将会创建一个二进制的文件，并存储到checkpoint目录中，该目录是用SparkContext.setCheckpointDir()设置的。在checkpoint的过程中，该RDD的所有依赖于父RDD中的信息将全部被移除。对RDD进行checkpoint操作并不会马上被执行，必须执行Action操作才能触发。</p><p>案例实操：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/10/03 下午 08:25 * @Func: 检查点（设置检查点就是将血缘关系保存成文件） */</span><span class="token keyword">object</span> Spark17_Checkpoint <span class="token punctuation">{</span>    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建Spark上下文对象</span>        <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 设定检查点保存目录</span>        sc<span class="token punctuation">.</span>setCheckpointDir<span class="token punctuation">(</span><span class="token string">"CheckPoint"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 构造rdd</span>        <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 进行简单处理</span>        <span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">val</span> reduceRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 设置检查点</span>        reduceRDD<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 输出查看</span>        reduceRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 血缘关系</span>        println<span class="token punctuation">(</span>reduceRDD<span class="token punctuation">.</span>toDebugString<span class="token punctuation">)</span>        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果差距（运行两遍，查看血缘关系的变化）</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 运行第一遍</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at reduceByKey at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">27</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at map at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">26</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">|</span>  ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at makeRDD at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">23</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">// 运行第二遍</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span> ShuffledRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at reduceByKey at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">27</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span>  ReliableCheckpointRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at foreach at Spark17_Checkpoint<span class="token punctuation">.</span>scala<span class="token operator">:</span><span class="token number">33</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>RDD编程全部更新完了，这一模块基本就结束了。同时SparkCore的大头也就基本结束了，还剩键值对RDD数据分区器、数据读取与保存。</p><blockquote><p>希望这个假期如自己所愿，心愿节后能够实现<br>屁屁一切顺利</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkCore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-SparkCore-概述（SparkCore系列一）</title>
      <link href="2020/09/24/spark-sparkcore-gai-shu-sparkcore-xi-lie-yi/"/>
      <url>2020/09/24/spark-sparkcore-gai-shu-sparkcore-xi-lie-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h1><h2 id="JAVA-IO"><a href="#JAVA-IO" class="headerlink" title="JAVA IO"></a>JAVA IO</h2><p>输入 输出——&gt;字节 字符</p><p>输入输出文件通过字节还是字符要看文件存的什么类型内容（文件格式），比如：</p><p>txt文件一般是使用字符流，因为其中存的一般是一些文字信息，是一些字符串，而字符串又恰恰是由一个个字符组成的。</p><p>rar、zip、png这些文件一般是使用字节流的。</p><h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a>字节流</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 文件输入流</span>InputStream in <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>若像上面那么操作，效率并不是很高，因为是按字节来操作（一个字节一个字节来读取，速度会很慢），因此应该加个缓冲流</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 缓冲流（其中new FileInputStream("test.txt")就相当于上面文件输入流的 in）</span>InputStream bufferIn <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Java中的IO就体现了装饰者设计模式（功能扩招——本来没这个功能，包装一下就有了这个功能）</p><p><img src="8.png" alt></p><p>从上面可以看出，FileInputStream（in）首先从文件中读取数据，然后通过 channel（通道）写入到 BufferedInputStream（缓冲区）中，然后当 BufferedInputStream 中数据达到一定数量的时候，统一往外写出。</p><p>因此，其实读取文件的其实依然是FileInputStream（in）而不是 BufferedInputStream 对象。这就相当于是对 BufferedInputStream 对象的一个功能的补充，也就是装饰者模式。</p><h3 id="字符流"><a href="#字符流" class="headerlink" title="字符流"></a>字符流</h3><p>按行读取文件需要用到字符流）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 文件输入流</span>InputStream in <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 字符流读取一行数据（之所以要传"UTF-8"是因为BufferedReader不知道如何将字节组合成字符，因为不同编码方式其组合方式是不同的）</span>Reader reader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">InputSteamReader</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="9.png" alt></p><p>其中并不是一开始便开始执行，而是从最后的readLine开始，当发起readLine请求，才一步步往前推开始执行</p><h2 id="RDD概述"><a href="#RDD概述" class="headerlink" title="RDD概述"></a>RDD概述</h2><h3 id="RDD中的装饰者模式"><a href="#RDD中的装饰者模式" class="headerlink" title="RDD中的装饰者模式"></a>RDD中的装饰者模式</h3><p><img src="10.png" alt></p><p>其中textFile将数据读取之后自己没法处理，因此在其外面包了一层新的类来对数据进行切分（flatMap）；然后发现切分后没法统计，因此又包了一层来对数据进行分别统计（map）；统计后又没法整合，因此又包了一层（reduceByKey）</p><p>其与JAVA IO的区别在于RDD从属于分布式的集群操作以及RDD是将数据处理逻辑进行了封装，而JAVA IO是封装的类。</p><p>另外RDD每层封装数据并没发生变化，始终都是都进来的那些数据。</p><h3 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h3><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据（逻辑）抽象。代码中是一个抽象类，它代表一个不可变、可分区（并行）、里面的元素可并行计算的集合。</p><h3 id="RDD的属性"><a href="#RDD的属性" class="headerlink" title="RDD的属性"></a>RDD的属性</h3><p><img src="7.png" alt></p><p>1) 一组分区（Partition），即数据集的基本组成单位;</p><p>2) 一个计算每个分区的函数;</p><p>3) RDD之间的依赖关系（逻辑不断嵌套，依赖关系越来越长）;</p><p>4) 一个Partitioner，即RDD的分片函数;</p><p>5) 一个列表，存储存取每个P  artition的优先位置（preferred location）。</p><p><img src="11.png" alt></p><p>从上图可看出Driver要将当前任务分发给哪个Executor执行取决于当前任务所需要数据在哪个DN上（因为Executor就是部署在DN上的），而数据所在DN就是其优先位置，也就是列表中所存的。</p><h3 id="RDD特点"><a href="#RDD特点" class="headerlink" title="RDD特点"></a>RDD特点</h3><p>RDD表示只读的分区的数据集，对RDD进行改动，只能通过RDD的转换操作，由一个RDD得到一个新的RDD，新的RDD包含了从其他RDD衍生所必需的信息。RDD之间存在依赖，RDD的执行是按照血缘关系延时计算的。如果血缘关系较长，可以通过持久化RDD来切断血缘关系。</p><p>延时计算：当用到的时候才会去计算，就像RDD中的装饰者模式中给出的图，其中只有在执行collect的时候，才会一步步往前推产生计算关系。</p><h4 id="分区——便于并行计算"><a href="#分区——便于并行计算" class="headerlink" title="分区——便于并行计算"></a>分区——便于并行计算</h4><p>RDD逻辑上是分区的，每个分区的数据是抽象存在的，计算的时候会通过一个compute函数得到每个分区的数据。如果RDD是通过已有的文件系统构建，则compute函数是读取指定文件系统中的数据，如果RDD是通过其他RDD转换而来，则compute函数是执行转换逻辑将其他RDD的数据进行转换。</p><p><img src="1.png" alt></p><h4 id="只读"><a href="#只读" class="headerlink" title="只读"></a>只读</h4><p>RDD是只读的，要想改变RDD中的数据，只能在现有的RDD基础上创建新的RDD。</p><p><img src="2.png" alt></p><p>由一个RDD转换到另一个RDD，可以通过丰富的操作算子实现，不再像MapReduce那样只能写map和reduce了，如图</p><p><img src="3.png" alt></p><p>算子：从认知心理学角度讲，解决问题其实是将问题的初始状态通过一系列的操作（算子、Operate）对问题的状态进行转换，然后达到完成（解决）状态。Spark中方法就是算子。</p><p>RDD的操作算子包括两类，一类叫做transformations（转换算子），它是用来将RDD进行转化，构建RDD的血缘关系；另一类叫做actions（行动算子），它是用来触发RDD的计算，得到RDD的相关计算结果或者将RDD保存的文件系统中。下图是RDD所支持的操作算子列表。</p><p>transformations（转换算子）：只转换数据的结构——textFile、flatMap、map、reduceByKey</p><p>actions（行动算子）：触发数据计算——collect</p><h4 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h4><p>RDD通过操作算子进行转换，转换得到的新RDD包含了从其他RDD衍生所必需的信息，RDD之间维护着这种血缘关系，也称之为依赖。如下图，依赖包括两种，一种是窄依赖，RDD之间分区是一一对应的，另一种是宽依赖，下游RDD的每个分区与上游RDD(也称之为父RDD)的每个分区都有关，是多对多的关系。</p><p><img src="4.png" alt></p><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>如果在应用程序中多次使用同一个RDD，可以将该RDD缓存起来，该RDD只有在第一次计算的时候会根据血缘关系得到分区的数据，在后续其他地方用到该RDD的时候，会直接从缓存处取而不用再根据血缘关系计算，这样就加速后期的重用。如下图所示，RDD-1经过一系列的转换后得到RDD-n并保存到hdfs，RDD-1在这一过程中会有个中间结果，如果将其缓存到内存，那么在随后的RDD-1转换到RDD-m这一过程中，就不会计算其之前的RDD-0了。</p><p><img src="5.png" alt></p><h4 id="CheckPoint"><a href="#CheckPoint" class="headerlink" title="CheckPoint"></a>CheckPoint</h4><p>虽然RDD的血缘关系天然地可以实现容错，当RDD的某个分区数据失败或丢失，可以通过血缘关系重建。但是对于长时间迭代型应用来说，随着迭代的进行，RDD之间的血缘关系会越来越长，一旦在后续迭代过程中出错，则需要通过非常长的血缘关系去重建，势必影响性能。为此，RDD支持checkpoint将数据保存到持久化的存储中，这样就可以切断之前的血缘关系，因为checkpoint后的RDD不需要知道它的父RDDs了，它可以从checkpoint处拿到数据。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SparkCore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark运行模式</title>
      <link href="2020/09/21/spark-yun-xing-mo-shi-spark-xi-lie-er/"/>
      <url>2020/09/21/spark-yun-xing-mo-shi-spark-xi-lie-er/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="Spark-运行模式"><a href="#Spark-运行模式" class="headerlink" title="Spark 运行模式"></a>Spark 运行模式</h2><h3 id="Spark-安装地址"><a href="#Spark-安装地址" class="headerlink" title="Spark 安装地址"></a>Spark 安装地址</h3><ol><li><p><a href="http://spark.apache.org/" target="_blank" rel="noopener">官网地址</a></p></li><li><p><a href="https://spark.apache.org/docs/2.1.1/" target="_blank" rel="noopener">文档查看地址</a></p></li><li><p><a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">下载地址</a></p></li></ol><h3 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h3><ol><li>Master 和 Worker（若用Yarn，则未必会有）</li></ol><p>（1）Master</p><p>Spark 特有资源调度系统的 Leader。掌管着整个集群的资源信息，类似于 Yarn 框架中的 ResourceManager，主要功能：</p><p>1）监听 Worker，看 Worker 是否正常工作；</p><p>2）Master 对 Worker、Application 等的管理(接收 Worker 的注册并管理所有的Worker，接收 Client 提交的 Application，调度等待的 Application 并向Worker 提交)。</p><p>（2）Worker</p><p>Spark 特有资源调度系统的 Slave，有多个。每个 Slave 掌管着所在节点的资源信息，类似于 Yarn 框架中的 NodeManager，主要功能：</p><p>1）通过 RegisterWorker 注册到 Master；</p><p>2）定时发送心跳给 Master；</p><p>3）根据 Master 发送的 Application 配置进程环境，并启动 ExecutorBackend(执行 Task 所需的临时进程)</p><ol start="2"><li>Driver和Executor</li></ol><p>（1）Driver（驱动器）——管理</p><p>Spark 的驱动器是执行开发程序中的 main 方法的线程。</p><p>它负责开发人员编写的用来创建SparkContext、创建RDD，以及进行RDD的转化操作和行动操作代码的执行。如果你是用Spark Shell，那么当你启动Spark shell的时候，系统后台自启了一个Spark驱动器程序，就是在Spark shell中预加载的一个叫作 sc 的SparkContext对象。如果驱动器程序终止，那么Spark应用也就结束了。主要负责：</p><p>1）将用户程序转化为作业（Job）；</p><p>2）在Executor之间调度任务（Task）；</p><p>3）跟踪Executor的执行情况；通过UI展示查询运行情况。</p><p>（2）Executor（执行器）——计算</p><p>Spark Executor是一个工作节点，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。主要负责：</p><p>1）运行组成 Spark 应用的任务，并将状态信息返回给驱动器程序；</p><p>2）通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD提供内存式存储。RDD是直接缓存在Executor内的，因此任务可以在运行时充分利用缓存数据加速运算。</p><h3 id="Local-模式"><a href="#Local-模式" class="headerlink" title="Local 模式"></a>Local 模式</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置Master。</p><p>local: 所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式;</p><p>local[K]: 指定使用几个线程来运行计算，比如local[4]就是运行4个Worker线程。通常我们的Cpu有几个Core，就指定几个线程，最大化利用Cpu的计算能力;</p><p>local[*]: 这种模式直接帮你按照Cpu最多Cores来设置线程数了。</p><h4 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h4><p>1）上传并解压spark 安装包</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 sorfware]$ tar -zxvf spark-2.1.1-binhadoop2.7.tgz -C /opt/module/# 改名方便以后操作[user_test@hadoop102 module]$ mv spark-2.1.1-bin-hadoop2.7 spark<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）官方求PI（圆周率）案例</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --executor-memory 1G --total-executor-cores 2 ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>前面带”–”的参数，是可有可无的，可以互换位置的。</p><p>（1）基本语法</p><pre class="line-numbers language-shell"><code class="language-shell">bin/spark-submit \--class <main-class>--master <master-url> \--deploy-mode <deploy-mode> \--conf <key>=<value> \... # other options<application-jar> \<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）参数说明：</p><p>–master：指定Master 的地址，默认为Local</p><p>–class: 你的应用的启动类你的应用的启动类 (如如 org.apache.spark.examples.SparkPi)</p><p>–deploy-mode: 是否发布你的驱动到是否发布你的驱动到worker节点节点(cluster) 或者作为一个本地客户端或者作为一个本地客户端 (client) (default: client)*</p><p>–conf: 任意的任意的Spark配置属性配置属性，， 格式格式key=value. 如果值包含空格如果值包含空格，，可以加引号可以加引号“key=value”</p><p>application-jar: 打包好的应用打包好的应用jar,包含依赖包含依赖. 这个这个URL在集群中全局可见。在集群中全局可见。 比如比如hdfs:// 共享存储系统，共享存储系统， 如果是如果是 file:// path，， 那么所有的节点的那么所有的节点的path都包含同样的都包含同样的jar</p><p>application-arguments: 传给传给main()方法的参数方法的参数</p><p>–executor-memory 1G 指定每个指定每个executor可用内存为可用内存为1G</p><p>–total-executor-cores 2 指定每个指定每个executor使用的使用的cup核数为核数为2个个</p><p>3）结果展示</p><p><img src="2.png" alt></p><p>4）准备文件 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ mkdir input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在input下创建2个文件1.txt和2.txt，并输入以下内容</p><p>[1.txt]</p><pre><code>Hello WorldHello Scala</code></pre><p>[2.txt]</p><pre><code>Hello BigDataHello Spark</code></pre><p>5）启动spark-shell </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-shell <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>出现以下界面就说明环境成功了</p><p><img src="3.png" alt></p><p>开启另一个窗口 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ jps ——>3627 SparkSubmit4047 Jps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可登录 <a href="http://hadoop102:4040" target="_blank" rel="noopener">http://hadoop102:4040</a> (hadoop102:4040) 查看程序运行，其中地址在3.png中可以看到</p><p><img src="4.png" alt></p><p>6）运行WordCount程序 </p><p>分析</p><p><img src="6.png" alt></p><p><img src="7.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>Hello<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>World<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Scala<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>BigData<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Spark<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可登录hadoop102:4040查看程序运行</p><h4 id="提交流程提交流程"><a href="#提交流程提交流程" class="headerlink" title="提交流程提交流程"></a>提交流程提交流程</h4><p>1）提交任务分析：</p><p><strong>Spark通用运行简易流程</strong></p><p><img src="5.png" alt></p><p>重要角色：</p><p>Driver（驱动器）</p><p>Spark 的驱动器是执行开发程序中的main 方法的进程。它负责开发人员编写的用来创建SparkContext、创建RDD，以及进行RDD 的转化操作和行动操作代码的执行。如果你是用spark shell，那么当你启动Spark shell 的时候，系统后台自启了一个Spark 驱动器程序，就是在Spark shell 中预加载的一个叫作 sc 的SparkContext 对象。如果驱动器程序终止，那么Spark 应用也就结束了。主要负责：</p><p>1）把用户程序转为任务</p><p>2）跟踪Executor 的运行状况</p><p>3）为执行器节点调度任务</p><p>4）UI 展示应用运行状况</p><p>Executor（执行器）</p><p>Spark Executor 是一个工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor 节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor 节点上继续运行。主要负责：</p><p>1）负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程；</p><p>2）通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD 提供内存式存储。RDD 是直接缓存在Executor 进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p><h4 id="数据流程"><a href="#数据流程" class="headerlink" title="数据流程"></a>数据流程</h4><p>textFile(“input”)：读取本地文件input 文件夹数据（按行读取）；</p><p>flatMap(_.split(“ “))：压平操作，按照空格分割符将一行数据映射成一个个单词；</p><p>map((_,1))：对每一个元素操作，将单词映射为元组；</p><p>reduceByKey(<em>+</em>)：按照key 将值进行聚合，相加；</p><p>collect：将数据收集到Driver 端展示。</p><p><strong>WordCount案例分析</strong></p><p><img src="8.png" alt></p><h3 id="Standalone-模式"><a href="#Standalone-模式" class="headerlink" title="Standalone 模式"></a>Standalone 模式</h3><p>只用spark独立部署，不用其他的（资源调度也用spark，那么就没有RM和NM，相应替换成了master和worker）</p><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>构建一个由Master+Slave 构成的Spark 集群，Spark 运行在集群中。</p><p><img src="9.png" alt></p><p>Master &lt;——&gt; ResourceManager<br>Worker &lt;——&gt; NodeManager</p><h4 id="安装使用-1"><a href="#安装使用-1" class="headerlink" title="安装使用"></a>安装使用</h4><p>1）进入spark 安装目录下的conf 文件夹</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 module]$ cd spark/conf/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）修改配置文件名称</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ mv slaves.template slaves# 若以下已经修改则不用重复修改[user_test@hadoop102 conf]$ mv spark-env.sh.template spark-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3）修改slave 文件，添加work 节点：</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim slaves<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容</p><pre><code>hadoop102hadoop103hadoop104</code></pre><p>4）修改spark-env.sh 文件，添加如下配置：</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>写入以下内容</p><pre><code>SPARK_MASTER_HOST=hadoop102SPARK_MASTER_PORT=7077</code></pre><p>5）分发spark 包</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 module]$ xsync spark/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）启动</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/start-all.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可执行jps来进行查看</p><p>网页查看：</p><p>hadoop102:8080</p><p><strong>注意：</strong>如果遇到 “JAVA_HOME not set” 异常 可以在 sbin目录下的 spark-config.sh 文件中加入如下配置：</p><pre><code>export JAVA_HOME=XXXX</code></pre><p>其中JAVA_HOME可以通过如下命令获得</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ echo $JAVA_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）官方求 PI案例</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop102:7077 --executor-memory 1G --total-executor-cores 2 ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）启动 spark shell </p><pre class="line-numbers language-shell"><code class="language-shell">/opt/module/spark/bin/spark-shell --master spark://hadoop 102:7077 --executor-memory 1g --total-executor-cores 2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：–master spark://hadoop102:7077指定要连接的集群的 master</p><p>执行WordCount程序</p><pre class="line-numbers language-shell"><code class="language-shell">scala> sc.textFile("input").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect——>res2: Array[(String, Int)] = Array((Hello,4), (World,1), (Scala,1), (BigData,1), (Spark,1))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="JobHistoryServer配置"><a href="#JobHistoryServer配置" class="headerlink" title="JobHistoryServer配置"></a>JobHistoryServer配置</h4><p>1）修改 spark-default.conf.template名称</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ mv spark-defaults.conf.template spark-defaults.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）修改 spark-default.conf文件，开启 Log</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-defaults.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改以下内容</p><pre><code>    spark.eventLog.enabled    true     spark.eventLog.dir    hdfs://hadoop102:9000/directory </code></pre><p><strong>注：</strong>HDFS 上的目录需要提前存在。</p><p>3）修改 spark-env.sh 文件，添加如下配置： </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>export SPARK_HISTORY_OPTS=&quot;-Dspark.history.ui.port=18080  -Dspark.history.retainedApplications=30  -Dspark.history.fs.logDirectory=hdfs://hadoop102:9000/directory&quot; </code></pre><p>参数描述： </p><p>spark.eventLog.dir：Application 在运行过程中所有的信息均记录在该属性指定的路径下 </p><p>spark.history.ui.port=18080   WEBUI 访问的端口号为 18080 </p><p>spark.history.fs.logDirectory=hdfs://hadoop102:9000/directory 配置了该属性后，在 start-history-server.sh 时就无需再显式的指定路径，Spark History Server 页面只展示该指定路径下的信息 </p><p>spark.history.retainedApplications=30 指定保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。 </p><p>4）分发配置文件 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ xsync spark-defaults.conf [user_test@hadoop102 conf]$ xsync spark-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）启动历史服务 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/start-history-server.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）再次执行任务 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit \ --class org.apache.spark.examples.SparkPi \ --master spark://hadoop102:7077 \ --executor-memory 1G \ --total-executor-cores 2 \ ./examples/jars/spark-examples_2.11-2.1.1.jar \ 100 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）网页查看历史服务</p><p>hadoop102:18080</p><h3 id="Yarn-模式"><a href="#Yarn-模式" class="headerlink" title="Yarn 模式"></a>Yarn 模式</h3><h4 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h4><p>Spark 客户端直接连接Yarn，不需要额外构建Spark 集群。有yarnclient和yarn-cluster 两种模式，主要区别在于：Driver 程序的运行节点。</p><p>yarn-client：Driver 程序运行在客户端，适用于交互、调试，希望立即看到app 的输出</p><p>yarn-cluster：Driver 程序运行在由RM（ResourceManager）启动的AP（APPMaster）适用于生产环境。</p><p><img src="10.png" alt></p><p>更通俗的一幅画</p><p><img src="11.png" alt></p><h4 id="安装使用-2"><a href="#安装使用-2" class="headerlink" title="安装使用"></a>安装使用</h4><p>1）修改hadoop 配置文件yarn-site.xml,添加如下内容：</p><p>[user_test@hadoop102 hadoop]$ vim yarn-site.xml</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）修改 spark-env.sh，添加如下配置</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>    YARN_CONF_DIR= DIR=/opt/module/hadoop-2.7.2/etc/hadoop</code></pre><p><strong>注：</strong>在添加以上内容时，要把之前Standalone模式下的配置注释掉，即：</p><pre><code># SPARK_MASTER_HOST=hadoop102# SPARK_MASTER_PORT=7077</code></pre><p>spark本地运行运行是不需要任何配置的，现在是要跟yarn结合所以要加上配置。其中上面的 /opt/module/hadoop-2.7.2 就是我们 yarn 的地址（注意自己的修改）</p><p>3）分发配置文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ xsync /opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xml[user_test@hadoop102 module]$ xsync spark<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这里需要分发一下spark，使集群上没个机器都有，不然后面会很麻烦。</p><p>4）执行一个程序</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注意：</strong>在提交任务之前需启动HDFS以及 YARN集群；ResourceManager在哪，就在哪执行程序。</p><h4 id="日志查看"><a href="#日志查看" class="headerlink" title="日志查看"></a>日志查看</h4><p>1）修改配置文件 spark-defaults.conf</p><p>添加如下内容</p><pre><code>    spark.yarn.historyServer.address=hadoop102:18080    spark.history.ui.port=18080</code></pre><p>2）重启 spark历史服务</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/stop-history-server.sh[user_test@hadoop102 spark]$ sbin/start-history-server.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）提交任务到 Yarn执行</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）Web页面查看日志</p><h2 id="WordCount案例"><a href="#WordCount案例" class="headerlink" title="WordCount案例"></a>WordCount案例</h2><p>Spark Shell仅在测试和验证我们的程序时使用的较多，在生产环境中，通常会在 IDE中编制程序，然后打成 jar包，然后提交到集群，最常用的是创建一个 Maven项目，利用<br>Maven来管理 jar包的依赖。</p><h3 id="编写-WordCount程序"><a href="#编写-WordCount程序" class="headerlink" title="编写 WordCount程序"></a>编写 WordCount程序</h3><p><strong>注：</strong>在编写程序之前要在idea中配置好scala环境（下载scala配置环境——&gt;在idea中安装scala插件（建议下载好插件包，选择从磁盘安装）——&gt;新建maven项目之后右击选择add framework support——&gt;选中scala——&gt;根据自己情况配置）</p><p>1）创建一个Maven项目WordCount并导入依赖</p><pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-core_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>finalName</span><span class="token punctuation">></span></span>WordCount<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>finalName</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">></span></span>WordCount<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）编写代码</p><p><strong>此处创建的是 scala object</strong> </p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/22 下午 10:14 * @Func: WordCount */</span>object WordCount <span class="token punctuation">{</span>    def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// local模式</span>        <span class="token comment" spellcheck="true">//创建conf对象</span>        <span class="token comment" spellcheck="true">// 设定计算框架运行（部署）环境</span>        <span class="token comment" spellcheck="true">// app id对应一个应用名称</span>        val config<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建上下文对象</span>        val sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取文件,将文件内容按行读取</span>        <span class="token comment" spellcheck="true">// 路径查找位置默认从当前部署环境中查找</span>        <span class="token comment" spellcheck="true">// 如需从本地查找 file:///opt/module/spark/in</span>        val lines<span class="token operator">:</span> RDD<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">"in/word.txt"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 分解成单词</span>        val words<span class="token operator">:</span> RDD<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> lines<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 将单词数据进行结构转换</span>        val wordToOne<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> words<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 分组聚合</span>        val wordToSum<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordToOne<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印结果</span>        val res <span class="token operator">=</span> wordToSum<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        println(res)</span>        res<span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）打包插件上传到集群</p><p>4）集群测试</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class com.swenchao.spark.WordCount WordCount-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>屁屁工作顺利~<br>找到自己满意的新的sx</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark完整版笔记</title>
      <link href="2020/09/21/spark-wan-zheng-bi-ji/"/>
      <url>2020/09/21/spark-wan-zheng-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="Spark概述"><a href="#Spark概述" class="headerlink" title="Spark概述"></a>Spark概述</h2><h3 id="什么是-Spark"><a href="#什么是-Spark" class="headerlink" title="什么是 Spark"></a>什么是 Spark</h3><p>Spark 是一个快速(基于内存), 通用, 可扩展的集群计算引擎</p><p>并且 Spark 目前已经成为 Apache 最活跃的开源项目, 有超过 1000 个活跃的贡献者.</p><p><strong>历史</strong></p><p>2009 年，Spark 诞生于 UC Berkeley(加州大学伯克利分校, CAL) 的 AMP 实验室, 项目采用 Scala 编程语言编写。</p><p>2010 年, Spark 正式对外开源</p><p>2013 年 6 月, 进入 Apache 孵化器</p><p>2014 年, 成为 Apache 的顶级项目.</p><p>目前最新的版本是 2.4.0</p><p>参考: <a href="http://spark.apache.org/history.html" target="_blank" rel="noopener">http://spark.apache.org/history.html</a></p><h3 id="Spark-内置模块介绍"><a href="#Spark-内置模块介绍" class="headerlink" title="Spark 内置模块介绍"></a>Spark 内置模块介绍</h3><p><img src="1.png" alt></p><p>独立调度器：Spark自己的<br>YARN：HAdoop的</p><h4 id="集群管理器-Cluster-Manager"><a href="#集群管理器-Cluster-Manager" class="headerlink" title="集群管理器(Cluster Manager)"></a>集群管理器(Cluster Manager)</h4><p>Spark 设计为可以高效地在一个计算节点到数千个计算节点之间伸缩计算。</p><p>为了实现这样的要求，同时获得最大灵活性，Spark 支持在各种集群管理器(Cluster Manager)上运行，目前 Spark 支持 3 种集群管理器:</p><ol><li><p>Hadoop YARN(在国内使用最广泛)</p></li><li><p>Apache Mesos(国内使用较少, 国外使用较多)</p></li><li><p>Standalone(Spark 自带的资源调度器, 需要在集群中的每台节点上配置 Spark)</p></li></ol><h4 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h4><p>实现了 Spark 的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。SparkCore 中还包含了对弹性分布式数据集(Resilient Distributed DataSet，简称RDD)的API定义。</p><h4 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h4><p>是 Spark 用来操作结构化数据的程序包。通过SparkSql，我们可以使用 SQL或者Apache Hive 版本的 SQL 方言(HQL)来查询数据。Spark SQL 支持多种数据源，比如 Hive 表、Parquet 以及 JSON 等。</p><h4 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h4><p>是 Spark 提供的对实时数据进行流式计算的组件。提供了用来操作数据流的 API，并且与 Spark Core 中的 RDD API 高度对应。</p><h4 id="Spark-MLlib"><a href="#Spark-MLlib" class="headerlink" title="Spark MLlib"></a>Spark MLlib</h4><p>提供常见的机器学习 (ML) 功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据导入等额外的支持功能。</p><p>Spark 得到了众多大数据公司的支持，这些公司包括 Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。</p><p>当前百度的 Spark 已应用于大搜索、直达号、百度大数据等业务；阿里利用 GraphX 构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到 8000 台的规模，是当前已知的世界上最大的 Spark 集群。</p><h3 id="Spark-特点"><a href="#Spark-特点" class="headerlink" title="Spark 特点"></a>Spark 特点</h3><p>Spark特点</p><p>1）快：与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。计算的中间结果是存在于内存中的。</p><p>2）易用：Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的Shell，可以非常方便地在这些Shell中使用Spark集群来验证解决问题的方法。</p><p>3）通用：Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。减少了开发和维护的人力成本和部署平台的物力成本。</p><p>4）兼容性：Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。</p><h2 id="Spark-运行模式"><a href="#Spark-运行模式" class="headerlink" title="Spark 运行模式"></a>Spark 运行模式</h2><h3 id="Spark-安装地址"><a href="#Spark-安装地址" class="headerlink" title="Spark 安装地址"></a>Spark 安装地址</h3><ol><li><p><a href="http://spark.apache.org/" target="_blank" rel="noopener">官网地址</a></p></li><li><p><a href="https://spark.apache.org/docs/2.1.1/" target="_blank" rel="noopener">文档查看地址</a></p></li><li><p><a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">下载地址</a></p></li></ol><h3 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h3><ol><li>Master 和 Worker（若用Yarn，则未必会有）</li></ol><p>（1）Master</p><p>Spark 特有资源调度系统的 Leader。掌管着整个集群的资源信息，类似于 Yarn 框架中的 ResourceManager，主要功能：</p><p>1）监听 Worker，看 Worker 是否正常工作；</p><p>2）Master 对 Worker、Application 等的管理(接收 Worker 的注册并管理所有的Worker，接收 Client 提交的 Application，调度等待的 Application 并向Worker 提交)。</p><p>（2）Worker</p><p>Spark 特有资源调度系统的 Slave，有多个。每个 Slave 掌管着所在节点的资源信息，类似于 Yarn 框架中的 NodeManager，主要功能：</p><p>1）通过 RegisterWorker 注册到 Master；</p><p>2）定时发送心跳给 Master；</p><p>3）根据 Master 发送的 Application 配置进程环境，并启动 ExecutorBackend(执行 Task 所需的临时进程)</p><ol start="2"><li>Driver和Executor</li></ol><p>（1）Driver（驱动器）——管理</p><p>Spark 的驱动器是执行开发程序中的 main 方法的线程。</p><p>它负责开发人员编写的用来创建SparkContext、创建RDD，以及进行RDD的转化操作和行动操作代码的执行。如果你是用Spark Shell，那么当你启动Spark shell的时候，系统后台自启了一个Spark驱动器程序，就是在Spark shell中预加载的一个叫作 sc 的SparkContext对象。如果驱动器程序终止，那么Spark应用也就结束了。主要负责：</p><p>1）将用户程序转化为作业（Job）；</p><p>2）在Executor之间调度任务（Task）；</p><p>3）跟踪Executor的执行情况；通过UI展示查询运行情况。</p><p>（2）Executor（执行器）——计算</p><p>Spark Executor是一个工作节点，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。主要负责：</p><p>1）运行组成 Spark 应用的任务，并将状态信息返回给驱动器程序；</p><p>2）通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD提供内存式存储。RDD是直接缓存在Executor内的，因此任务可以在运行时充分利用缓存数据加速运算。</p><h3 id="Local-模式"><a href="#Local-模式" class="headerlink" title="Local 模式"></a>Local 模式</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置Master。</p><p>local: 所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式;</p><p>local[K]: 指定使用几个线程来运行计算，比如local[4]就是运行4个Worker线程。通常我们的Cpu有几个Core，就指定几个线程，最大化利用Cpu的计算能力;</p><p>local[*]: 这种模式直接帮你按照Cpu最多Cores来设置线程数了。</p><h4 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h4><p>1）上传并解压spark 安装包</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 sorfware]$ tar -zxvf spark-2.1.1-binhadoop2.7.tgz -C /opt/module/# 改名方便以后操作[user_test@hadoop102 module]$ mv spark-2.1.1-bin-hadoop2.7 spark<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）官方求PI（圆周率）案例</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --executor-memory 1G --total-executor-cores 2 ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>前面带”–”的参数，是可有可无的，可以互换位置的。</p><p>（1）基本语法</p><pre class="line-numbers language-shell"><code class="language-shell">bin/spark-submit \--class <main-class>--master <master-url> \--deploy-mode <deploy-mode> \--conf <key>=<value> \... # other options<application-jar> \<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）参数说明：</p><p>–master：指定Master 的地址，默认为Local</p><p>–class: 你的应用的启动类你的应用的启动类 (如如 org.apache.spark.examples.SparkPi)</p><p>–deploy-mode: 是否发布你的驱动到是否发布你的驱动到worker节点节点(cluster) 或者作为一个本地客户端或者作为一个本地客户端 (client) (default: client)*</p><p>–conf: 任意的任意的Spark配置属性配置属性，， 格式格式key=value. 如果值包含空格如果值包含空格，，可以加引号可以加引号“key=value”</p><p>application-jar: 打包好的应用打包好的应用jar,包含依赖包含依赖. 这个这个URL在集群中全局可见。在集群中全局可见。 比如比如hdfs:// 共享存储系统，共享存储系统， 如果是如果是 file:// path，， 那么所有的节点的那么所有的节点的path都包含同样的都包含同样的jar</p><p>application-arguments: 传给传给main()方法的参数方法的参数</p><p>–executor-memory 1G 指定每个指定每个executor可用内存为可用内存为1G</p><p>–total-executor-cores 2 指定每个指定每个executor使用的使用的cup核数为核数为2个个</p><p>3）结果展示</p><p><img src="2.png" alt></p><p>4）准备文件 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ mkdir input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在input下创建2个文件1.txt和2.txt，并输入以下内容</p><p>[1.txt]</p><pre><code>Hello WorldHello Scala</code></pre><p>[2.txt]</p><pre><code>Hello BigDataHello Spark</code></pre><p>5）启动spark-shell </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-shell <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>出现以下界面就说明环境成功了</p><p><img src="3.png" alt></p><p>开启另一个窗口 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ jps ——>3627 SparkSubmit4047 Jps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可登录 <a href="http://hadoop102:4040" target="_blank" rel="noopener">http://hadoop102:4040</a> (hadoop102:4040) 查看程序运行，其中地址在3.png中可以看到</p><p><img src="4.png" alt></p><p>6）运行WordCount程序 </p><p>分析</p><p><img src="6.png" alt></p><p><img src="7.png" alt></p><pre class="line-numbers language-scala"><code class="language-scala">scala<span class="token operator">></span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect——<span class="token operator">></span>res2<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>Hello<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>World<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Scala<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>BigData<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Spark<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可登录hadoop102:4040查看程序运行</p><h4 id="提交流程提交流程"><a href="#提交流程提交流程" class="headerlink" title="提交流程提交流程"></a>提交流程提交流程</h4><p>1）提交任务分析：</p><p><strong>Spark通用运行简易流程</strong></p><p><img src="5.png" alt></p><p>重要角色：</p><p>Driver（驱动器）</p><p>Spark 的驱动器是执行开发程序中的main 方法的进程。它负责开发人员编写的用来创建SparkContext、创建RDD，以及进行RDD 的转化操作和行动操作代码的执行。如果你是用spark shell，那么当你启动Spark shell 的时候，系统后台自启了一个Spark 驱动器程序，就是在Spark shell 中预加载的一个叫作 sc 的SparkContext 对象。如果驱动器程序终止，那么Spark 应用也就结束了。主要负责：</p><p>1）把用户程序转为任务</p><p>2）跟踪Executor 的运行状况</p><p>3）为执行器节点调度任务</p><p>4）UI 展示应用运行状况</p><p>Executor（执行器）</p><p>Spark Executor 是一个工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor 节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor 节点上继续运行。主要负责：</p><p>1）负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程；</p><p>2）通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD 提供内存式存储。RDD 是直接缓存在Executor 进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p><h4 id="数据流程"><a href="#数据流程" class="headerlink" title="数据流程"></a>数据流程</h4><p>textFile(“input”)：读取本地文件input 文件夹数据（按行读取）；</p><p>flatMap(_.split(“ “))：压平操作，按照空格分割符将一行数据映射成一个个单词；</p><p>map((_,1))：对每一个元素操作，将单词映射为元组；</p><p>reduceByKey(<em>+</em>)：按照key 将值进行聚合，相加；</p><p>collect：将数据收集到Driver 端展示。</p><p><strong>WordCount案例分析</strong></p><p><img src="8.png" alt></p><h3 id="Standalone-模式"><a href="#Standalone-模式" class="headerlink" title="Standalone 模式"></a>Standalone 模式</h3><p>只用spark独立部署，不用其他的（资源调度也用spark，那么就没有RM和NM，相应替换成了master和worker）</p><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>构建一个由Master+Slave 构成的Spark 集群，Spark 运行在集群中。</p><p><img src="9.png" alt></p><p>Master &lt;——&gt; ResourceManager<br>Worker &lt;——&gt; NodeManager</p><h4 id="安装使用-1"><a href="#安装使用-1" class="headerlink" title="安装使用"></a>安装使用</h4><p>1）进入spark 安装目录下的conf 文件夹</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 module]$ cd spark/conf/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）修改配置文件名称</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ mv slaves.template slaves# 若以下已经修改则不用重复修改[user_test@hadoop102 conf]$ mv spark-env.sh.template spark-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3）修改slave 文件，添加work 节点：</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim slaves<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容</p><pre><code>hadoop102hadoop103hadoop104</code></pre><p>4）修改spark-env.sh 文件，添加如下配置：</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>写入以下内容</p><pre><code>SPARK_MASTER_HOST=hadoop102SPARK_MASTER_PORT=7077</code></pre><p>5）分发spark 包</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 module]$ xsync spark/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）启动</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/start-all.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可执行jps来进行查看</p><p>网页查看：</p><p>hadoop102:8080</p><p><strong>注意：</strong>如果遇到 “JAVA_HOME not set” 异常 可以在 sbin目录下的 spark-config.sh 文件中加入如下配置：</p><pre><code>export JAVA_HOME=XXXX</code></pre><p>其中JAVA_HOME可以通过如下命令获得</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ echo $JAVA_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）官方求 PI案例</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop102:7077 --executor-memory 1G --total-executor-cores 2 ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）启动 spark shell </p><pre class="line-numbers language-shell"><code class="language-shell">/opt/module/spark/bin/spark-shell --master spark://hadoop 102:7077 --executor-memory 1g --total-executor-cores 2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数：–master spark://hadoop102:7077指定要连接的集群的 master</p><p>执行WordCount程序</p><pre class="line-numbers language-shell"><code class="language-shell">scala> sc.textFile("input").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect——>res2: Array[(String, Int)] = Array((Hello,4), (World,1), (Scala,1), (BigData,1), (Spark,1))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="JobHistoryServer配置"><a href="#JobHistoryServer配置" class="headerlink" title="JobHistoryServer配置"></a>JobHistoryServer配置</h4><p>1）修改 spark-default.conf.template名称</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ mv spark-defaults.conf.template spark-defaults.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）修改 spark-default.conf文件，开启 Log</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-defaults.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改以下内容</p><pre><code>    spark.eventLog.enabled    true     spark.eventLog.dir    hdfs://hadoop102:9000/directory </code></pre><p><strong>注：</strong>HDFS 上的目录需要提前存在。</p><p>3）修改 spark-env.sh 文件，添加如下配置： </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>export SPARK_HISTORY_OPTS=&quot;-Dspark.history.ui.port=18080  -Dspark.history.retainedApplications=30  -Dspark.history.fs.logDirectory=hdfs://hadoop102:9000/directory&quot; </code></pre><p>参数描述： </p><p>spark.eventLog.dir：Application 在运行过程中所有的信息均记录在该属性指定的路径下 </p><p>spark.history.ui.port=18080   WEBUI 访问的端口号为 18080 </p><p>spark.history.fs.logDirectory=hdfs://hadoop102:9000/directory 配置了该属性后，在 start-history-server.sh 时就无需再显式的指定路径，Spark History Server 页面只展示该指定路径下的信息 </p><p>spark.history.retainedApplications=30 指定保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。 </p><p>4）分发配置文件 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ xsync spark-defaults.conf [user_test@hadoop102 conf]$ xsync spark-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）启动历史服务 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/start-history-server.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）再次执行任务 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop102:7077 --executor-memory 1G --total-executor-cores 2  ./examples/jars/spark-examples_2.11-2.1.1.jar 100 <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）网页查看历史服务</p><p>hadoop102:18080</p><h4 id="HA配置"><a href="#HA配置" class="headerlink" title="HA配置"></a>HA配置</h4><p><img src="12.png" alt></p><p>1）zookeeper 正常安装并启动 </p><p>2）修改 spark-env.sh 文件添加如下配置： </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注释掉如下内容： </p><pre><code>    #SPARK_MASTER_HOST=hadoop102     #SPARK_MASTER_PORT=7077 </code></pre><p>添加上如下内容： </p><pre><code>export SPARK_DAEMON_JAVA_OPTS=&quot; -Dspark.deploy.recoveryMode=ZOOKEEPER  -Dspark.deploy.zookeeper.url=hadoop101,hadoop102,hadoop103 -Dspark.deploy.zookeeper.dir=/spark&quot; </code></pre><p>3）分发配置文件 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ xsync spark-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）在 hadoop102 上启动全部节点 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/start-all.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）在 hadoop103 上单独启动 master 节点 </p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop103 spark]$ sbin/start-master.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）spark HA 集群访问 </p><pre class="line-numbers language-shell"><code class="language-shell">/opt/module/spark/bin/spark-shell \ --master spark://hadoop101:7077,hadoop102:7077 \ --executor-memory 2g \ --total-executor-cores 2 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Yarn-模式"><a href="#Yarn-模式" class="headerlink" title="Yarn 模式"></a>Yarn 模式</h3><h4 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h4><p>Spark 客户端直接连接Yarn，不需要额外构建Spark 集群。有yarnclient和yarn-cluster 两种模式，主要区别在于：Driver 程序的运行节点。</p><p>yarn-client：Driver 程序运行在客户端，适用于交互、调试，希望立即看到app 的输出</p><p>yarn-cluster：Driver 程序运行在由RM（ResourceManager）启动的AP（APPMaster）适用于生产环境。</p><p><img src="10.png" alt></p><p>更通俗的一幅画</p><p><img src="11.png" alt></p><h4 id="安装使用-2"><a href="#安装使用-2" class="headerlink" title="安装使用"></a>安装使用</h4><p>1）修改hadoop 配置文件yarn-site.xml,添加如下内容：</p><p>[user_test@hadoop102 hadoop]$ vim yarn-site.xml</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）修改 spark-env.sh，添加如下配置</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ vim spark env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>    YARN_CONF_DIR= DIR=/opt/module/hadoop-2.7.2/etc/hadoop</code></pre><p><strong>注：</strong>在添加以上内容时，要把之前Standalone模式下的配置注释掉，即：</p><pre><code># SPARK_MASTER_HOST=hadoop102# SPARK_MASTER_PORT=7077</code></pre><p>spark本地运行运行是不需要任何配置的，现在是要跟yarn结合所以要加上配置。其中上面的 /opt/module/hadoop-2.7.2 就是我们 yarn 的地址（注意自己的修改）</p><p>3）分发配置文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 conf]$ xsync /opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xml[user_test@hadoop102 module]$ xsync spark<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这里需要分发一下spark，使集群上没个机器都有，不然后面会很麻烦。</p><p>4）执行一个程序</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注意：</strong>在提交任务之前需启动HDFS以及 YARN集群；ResourceManager在哪，就在哪执行程序。</p><h4 id="日志查看"><a href="#日志查看" class="headerlink" title="日志查看"></a>日志查看</h4><p>1）修改配置文件 spark-defaults.conf</p><p>添加如下内容</p><pre><code>    spark.yarn.historyServer.address=hadoop102:18080    spark.history.ui.port=18080</code></pre><p>2）重启 spark历史服务</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ sbin/stop-history-server.sh[user_test@hadoop102 spark]$ sbin/start-history-server.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）提交任务到 Yarn执行</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.1.1.jar 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）Web页面查看日志</p><h3 id="集中模式对比"><a href="#集中模式对比" class="headerlink" title="集中模式对比"></a>集中模式对比</h3><table><thead><tr><th>模式</th><th>Spark安装机器数</th><th>需启动的进程</th><th>所属者</th></tr></thead><tbody><tr><td>Local</td><td>1</td><td>无</td><td>Spark</td></tr><tr><td>Standalone</td><td>3</td><td>Master 及 Worker</td><td>Spark</td></tr><tr><td>Yarn</td><td>1</td><td>Yarn 及 HDFS</td><td>Hadoop</td></tr></tbody></table><h2 id="WordCount案例"><a href="#WordCount案例" class="headerlink" title="WordCount案例"></a>WordCount案例</h2><p>Spark Shell仅在测试和验证我们的程序时使用的较多，在生产环境中，通常会在 IDE中编制程序，然后打成 jar包，然后提交到集群，最常用的是创建一个 Maven项目，利用<br>Maven来管理 jar包的依赖。</p><h3 id="编写-WordCount程序"><a href="#编写-WordCount程序" class="headerlink" title="编写 WordCount程序"></a>编写 WordCount程序</h3><p><strong>注：</strong>在编写程序之前要在idea中配置好scala环境（下载scala配置环境——&gt;在idea中安装scala插件（建议下载好插件包，选择从磁盘安装）——&gt;新建maven项目之后右击选择add framework support——&gt;选中scala——&gt;根据自己情况配置）</p><p>1）创建一个Maven项目WordCount并导入依赖</p><pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-core_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>finalName</span><span class="token punctuation">></span></span>WordCount<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>finalName</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">></span></span>WordCount<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）编写代码</p><p><strong>此处创建的是 scala object</strong> </p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>spark<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/22 下午 10:14 * @Func: WordCount */</span>object WordCount <span class="token punctuation">{</span>    def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> Unit <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// local模式</span>        <span class="token comment" spellcheck="true">//创建conf对象</span>        <span class="token comment" spellcheck="true">// 设定计算框架运行（部署）环境</span>        <span class="token comment" spellcheck="true">// app id对应一个应用名称</span>        val config<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 创建上下文对象</span>        val sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 读取文件,将文件内容按行读取</span>        <span class="token comment" spellcheck="true">// 路径查找位置默认从当前部署环境中查找</span>        <span class="token comment" spellcheck="true">// 如需从本地查找 file:///opt/module/spark/in</span>        val lines<span class="token operator">:</span> RDD<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">"in/word.txt"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 分解成单词</span>        val words<span class="token operator">:</span> RDD<span class="token punctuation">[</span>String<span class="token punctuation">]</span> <span class="token operator">=</span> lines<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 将单词数据进行结构转换</span>        val wordToOne<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> words<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 分组聚合</span>        val wordToSum<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String<span class="token punctuation">,</span> Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordToOne<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 打印结果</span>        val res <span class="token operator">=</span> wordToSum<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//        println(res)</span>        res<span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>println<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）打包插件上传到集群</p><p>4）集群测试</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 spark]$ bin/spark-submit --class com.swenchao.spark.WordCount WordCount-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark概述（Spark系列一）</title>
      <link href="2020/09/21/spark-gai-shu-spark-xi-lie-yi/"/>
      <url>2020/09/21/spark-gai-shu-spark-xi-lie-yi/</url>
      
        <content type="html"><![CDATA[<p>要开始学习Spark了，准备开启新的一系列了，一切顺利呀~</p><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="Spark概述"><a href="#Spark概述" class="headerlink" title="Spark概述"></a>Spark概述</h2><h3 id="什么是-Spark"><a href="#什么是-Spark" class="headerlink" title="什么是 Spark"></a>什么是 Spark</h3><p>Spark 是一个快速(基于内存), 通用, 可扩展的集群计算引擎</p><p>并且 Spark 目前已经成为 Apache 最活跃的开源项目, 有超过 1000 个活跃的贡献者.</p><p><strong>历史</strong></p><p>2009 年，Spark 诞生于 UC Berkeley(加州大学伯克利分校, CAL) 的 AMP 实验室, 项目采用 Scala 编程语言编写。</p><p>2010 年, Spark 正式对外开源</p><p>2013 年 6 月, 进入 Apache 孵化器</p><p>2014 年, 成为 Apache 的顶级项目.</p><p>目前最新的版本是 2.4.0</p><p>参考: <a href="http://spark.apache.org/history.html" target="_blank" rel="noopener">http://spark.apache.org/history.html</a></p><h3 id="Spark-内置模块介绍"><a href="#Spark-内置模块介绍" class="headerlink" title="Spark 内置模块介绍"></a>Spark 内置模块介绍</h3><p><img src="1.png" alt></p><p>独立调度器：Spark自己的<br>YARN：HAdoop的</p><h4 id="集群管理器-Cluster-Manager"><a href="#集群管理器-Cluster-Manager" class="headerlink" title="集群管理器(Cluster Manager)"></a>集群管理器(Cluster Manager)</h4><p>Spark 设计为可以高效地在一个计算节点到数千个计算节点之间伸缩计算。</p><p>为了实现这样的要求，同时获得最大灵活性，Spark 支持在各种集群管理器(Cluster Manager)上运行，目前 Spark 支持 3 种集群管理器:</p><ol><li><p>Hadoop YARN(在国内使用最广泛)</p></li><li><p>Apache Mesos(国内使用较少, 国外使用较多)</p></li><li><p>Standalone(Spark 自带的资源调度器, 需要在集群中的每台节点上配置 Spark)</p></li></ol><h4 id="SparkCore"><a href="#SparkCore" class="headerlink" title="SparkCore"></a>SparkCore</h4><p>实现了 Spark 的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。SparkCore 中还包含了对弹性分布式数据集(Resilient Distributed DataSet，简称RDD)的API定义。</p><h4 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h4><p>是 Spark 用来操作结构化数据的程序包。通过SparkSql，我们可以使用 SQL或者Apache Hive 版本的 SQL 方言(HQL)来查询数据。Spark SQL 支持多种数据源，比如 Hive 表、Parquet 以及 JSON 等。</p><h4 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h4><p>是 Spark 提供的对实时数据进行流式计算的组件。提供了用来操作数据流的 API，并且与 Spark Core 中的 RDD API 高度对应。</p><h4 id="Spark-MLlib"><a href="#Spark-MLlib" class="headerlink" title="Spark MLlib"></a>Spark MLlib</h4><p>提供常见的机器学习 (ML) 功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据导入等额外的支持功能。</p><p>Spark 得到了众多大数据公司的支持，这些公司包括 Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。</p><p>当前百度的 Spark 已应用于大搜索、直达号、百度大数据等业务；阿里利用 GraphX 构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到 8000 台的规模，是当前已知的世界上最大的 Spark 集群。</p><h3 id="Spark-特点"><a href="#Spark-特点" class="headerlink" title="Spark 特点"></a>Spark 特点</h3><p>Spark特点</p><p>1）快：与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。计算的中间结果是存在于内存中的。</p><p>2）易用：Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的Shell，可以非常方便地在这些Shell中使用Spark集群来验证解决问题的方法。</p><p>3）通用：Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。减少了开发和维护的人力成本和部署平台的物力成本。</p><p>4）兼容性：Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。</p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>Spark运行模式</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-Yarn资源调度</title>
      <link href="2020/09/17/hadoop-yarn-zi-yuan-diao-du/"/>
      <url>2020/09/17/hadoop-yarn-zi-yuan-diao-du/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Yarn资源调度器"><a href="#Yarn资源调度器" class="headerlink" title="Yarn资源调度器"></a>Yarn资源调度器</h2><p>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。</p><h3 id="Yarn基本架构"><a href="#Yarn基本架构" class="headerlink" title="Yarn基本架构"></a>Yarn基本架构</h3><p>YARN主要由ResourceManager、NodeManager、ApplicationMaster和Container等组件构成，如图:</p><p><img src="66.png" alt></p><p>ResourceManager：整个集群老大<br>NodeManager：某个节点老大<br>ApplicationMaster：job老大<br>Container：虚拟化资源分配</p><h3 id="Yarn工作机制"><a href="#Yarn工作机制" class="headerlink" title="Yarn工作机制"></a>Yarn工作机制</h3><p>1．Yarn运行机制，如图：</p><p><img src="67.png" alt></p><p>2．工作机制详解</p><p>（1）MR程序提交到客户端所在的节点。</p><p>（2）YarnRunner向ResourceManager申请一个Application。</p><p>（3）RM将该应用程序的资源路径返回给YarnRunner。</p><p>（4）该程序将运行所需资源提交到HDFS上。</p><p>（5）程序资源提交完毕后，申请运行mrAppMaster。</p><p>（6）RM将用户的请求初始化成一个Task。</p><p>（7）其中一个NodeManager领取到Task任务。</p><p>（8）该NodeManager创建容器Container，并产生MRAppmaster。</p><p>（9）Container从HDFS上拷贝资源到本地。</p><p>（10）MRAppmaster向RM 申请运行MapTask资源。</p><p>（11）RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p><p>（12）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</p><p>（13）MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</p><p>（14）ReduceTask向MapTask获取相应分区的数据。</p><p>（15）程序运行完毕后，MR会向RM申请注销自己。</p><h3 id="作业提交全过程"><a href="#作业提交全过程" class="headerlink" title="作业提交全过程"></a>作业提交全过程</h3><p>1．作业提交过程之YARN，如图：</p><p><img src="67.png" alt></p><p>Map过程：read（读取）——&gt;map（分）——&gt;collect（收集）——&gt;spill（溢写）——&gt;merge（合并）</p><p>Reduce过程：copy（拷贝map过程的数据）——&gt;merge+sort（归并排序）——&gt;reduce</p><p>作业提交全过程详解</p><p>（1）作业提交</p><p>第1步：Client调用job.waitForCompletion方法，向整个集群提交MapReduce作业。</p><p>第2步：Client向RM申请一个作业id。</p><p>第3步：RM给Client返回该job资源的提交路径和作业id。</p><p>第4步：Client提交jar包、切片信息和配置文件到指定的资源提交路径。</p><p>第5步：Client提交完资源后，向RM申请运行MrAppMaster。</p><p>（2）作业初始化</p><p>第6步：当RM收到Client的请求后，将该job添加到容量调度器中。</p><p>第7步：某一个空闲的NM领取到该Job。</p><p>第8步：该NM创建Container，并产生MRAppmaster。</p><p>第9步：下载Client提交的资源到本地。</p><p>（3）任务分配</p><p>第10步：MrAppMaster向RM申请运行多个MapTask任务资源。</p><p>第11步：RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p><p>（4）任务运行</p><p>第12步：MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</p><p>第13步：MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</p><p>第14步：ReduceTask向MapTask获取相应分区的数据。</p><p>第15步：程序运行完毕后，MR会向RM申请注销自己。</p><p>（5）进度和状态更新</p><p>YARN中的任务将其进度和状态(包括counter)返回给应用管理器, 客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新, 展示给用户。</p><p>（6）作业完成</p><p>除了向应用管理器请求作业进度外, 客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后, 应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</p><p>2．作业提交过程之MapReduce，如图：</p><p><img src="68.png" alt></p><p>其中HDFS文件操作中就牵扯到了NameNode和Secondary NameNode相等问题（日志+2NN=NN）</p><h3 id="资源调度器（作业提交过程中任务队列）"><a href="#资源调度器（作业提交过程中任务队列）" class="headerlink" title="资源调度器（作业提交过程中任务队列）"></a>资源调度器（作业提交过程中任务队列）</h3><p>目前，Hadoop作业调度器主要有三种：FIFO、Capacity Scheduler和Fair Scheduler。Hadoop2.7.2默认的资源调度器是Capacity Scheduler。</p><p>[yarn-default.xml]</p><pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>            The class to use as the resource scheduler.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.scheduler.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>            org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>1．先进先出调度器（FIFO）</p><p><img src="69.png" alt></p><p>其中分配多少个task，得看现在可用资源有多少。其中可能一下分配很多个task。</p><p>2．容量调度器（Capacity Scheduler）</p><p><img src="70.png" alt></p><p>多个FIFO调度器的总和</p><p>3．公平调度器（Fair Scheduler）</p><p><img src="71.png" alt></p><p>容量调度器中，作业并不是公平享有，得按一定规则排好序，然后按优先级来获取资源。</p><p>如果机器性能高，想要并发度，可以采用第三种；若机器性能差点，还想要并发度，可以采用第二种；第一种完全没有并发度。</p><h3 id="任务的推测执行"><a href="#任务的推测执行" class="headerlink" title="任务的推测执行"></a>任务的推测执行</h3><p>1．作业完成时间取决于最慢的任务完成时间</p><p>一个作业由若干个Map任务和Reduce任务构成。因硬件老化、软件Bug等，某些任务可能运行非常慢。</p><p>2．推测执行机制</p><p>发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。</p><p>3．执行推测任务的前提条件</p><p>（1）每个Task只能有一个备份任务</p><p>（2）当前Job已完成的Task必须不小于0.05（5%）</p><p>（3）开启推测执行参数设置。mapred-site.xml文件中默认是打开的。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.map.speculative<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>If true, then multiple instances of some map tasks may be executed in parallel.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.reduce.speculative<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>If true, then multiple instances of some reduce tasks may be executed in parallel.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．不能启用推测执行机制情况</p><p>（1）任务间存在严重的负载倾斜；</p><p>（2）特殊任务，比如任务向数据库中写数据。</p><p>5．算法原理，如图</p><p><img src="72.png" alt></p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>Hadoop先告一段落了，准备再学习下Spark，希望将要有好事发生~</p><blockquote><p>希望屁屁在剩下的这一年中不会太忙，加班越来越少，工资越来越高<br>希望接下来一切顺利，好事发生~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-Yarn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-数据压缩（MApReduce系列四）</title>
      <link href="2020/09/17/hadoop-shu-ju-ya-suo-mapreduce-xi-lie-si/"/>
      <url>2020/09/17/hadoop-shu-ju-ya-suo-mapreduce-xi-lie-si/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Hadoop数据压缩"><a href="#Hadoop数据压缩" class="headerlink" title="Hadoop数据压缩"></a>Hadoop数据压缩</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><img src="59.png" alt></p><h3 id="MR支持的压缩编码"><a href="#MR支持的压缩编码" class="headerlink" title="MR支持的压缩编码"></a>MR支持的压缩编码</h3><table><thead><tr><th>压缩格式</th><th>hadoop自带</th><th>算法</th><th>文件扩展名</th><th>是否可切分</th><th>换成压缩格式后，原来的程序是否需要修改</th></tr></thead><tbody><tr><td>DEFLATE</td><td>是，直接使用</td><td>DEFLATE</td><td>.deflate</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>Gzip</td><td>是，直接使用</td><td>DEFLATE</td><td>.gz</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>bzip2</td><td>是，直接使用</td><td>bzip2</td><td>.bz2</td><td>是</td><td>和文本处理一样，不需要修改</td></tr><tr><td>LZO</td><td>否，需要安装</td><td>LZO</td><td>.lzo</td><td>是</td><td>需要建索引，还需要指定输入格式</td></tr><tr><td>Snappy</td><td>否，需要安装</td><td>Snappy</td><td>.snappy</td><td>否</td><td>和文本处理一样，不需要修改</td></tr></tbody></table><p>其中是否可切分代表压缩后是否还可以切分。若不可切分，则其处理数据不要在mapper之前。</p><p>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示。</p><table><thead><tr><th>压缩格式</th><th>对应编码/解码器</th></tr></thead><tbody><tr><td>DEFLATE</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>gzip</td><td>org.apache.hadoop.io.compress.GzipCodec</td></tr><tr><td>bzip2</td><td>org.apache.hadoop.io.compress.BZip2Codec</td></tr><tr><td>LZO</td><td>com.hadoop.compression.lzo.LzopCodec</td></tr><tr><td>Snappy</td><td>org.apache.hadoop.io.compress.SnappyCode</td></tr></tbody></table><p>压缩性能的比较</p><table><thead><tr><th>压缩算法</th><th>原始文件大小</th><th>压缩文件大小</th><th>压缩速度</th><th>解压速度</th></tr></thead><tbody><tr><td>gzip</td><td>8.3GB</td><td>1.8GB</td><td>17.5MB/s</td><td>58MB/s</td></tr><tr><td>bzip2</td><td>8.3GB</td><td>1.1GB</td><td>2.4MB/s</td><td>9.5MB/s</td></tr><tr><td>LZO</td><td>8.3GB</td><td>2.9GB</td><td>49.3MB/s</td><td>74.6MB/s</td></tr></tbody></table><p><a href="http://google.github.io/snappy/" target="_blank" rel="noopener">http://google.github.io/snappy/</a></p><p>On a single core of a Core i7 processor in 64-bit mode, Snappy compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more.</p><h3 id="压缩方式选择"><a href="#压缩方式选择" class="headerlink" title="压缩方式选择"></a>压缩方式选择</h3><h4 id="Gzip压缩"><a href="#Gzip压缩" class="headerlink" title="Gzip压缩"></a>Gzip压缩</h4><p><img src="60.png" alt></p><h4 id="Bzip2压缩"><a href="#Bzip2压缩" class="headerlink" title="Bzip2压缩"></a>Bzip2压缩</h4><p><img src="61.png" alt></p><h4 id="Lzo压缩"><a href="#Lzo压缩" class="headerlink" title="Lzo压缩"></a>Lzo压缩</h4><p><img src="62.png" alt></p><h4 id="Snappy压缩"><a href="#Snappy压缩" class="headerlink" title="Snappy压缩"></a>Snappy压缩</h4><p><img src="63.png" alt></p><h3 id="压缩位置选择"><a href="#压缩位置选择" class="headerlink" title="压缩位置选择"></a>压缩位置选择</h3><p>压缩可以在MapReduce作用的任意阶段启用，如图</p><p><img src="64.png" alt></p><p>shuffle是最应该使用压缩技术的阶段（Map和Reduce之间）</p><h3 id="压缩参数配置"><a href="#压缩参数配置" class="headerlink" title="压缩参数配置"></a>压缩参数配置</h3><p>要在Hadoop中启用压缩，可以配置如下参数：</p><table><thead><tr><th>参数</th><th>默认值</th><th>阶段</th><th>建议</th></tr></thead><tbody><tr><td>io.compression.codecs（在core-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec</td><td>输入压缩</td><td>Hadoop使用文件扩展名判断是否支持某种编解码器</td></tr><tr><td>mapreduce.map.output.compress（在mapred-site.xml中配置）</td><td>false</td><td>mapper输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.map.output.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec</td><td>mapper输出</td><td>企业多使用LZO或Snappy编解码器在此阶段压缩数据</td></tr><tr><td>mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）</td><td>false</td><td>reducer输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress. DefaultCodec</td><td>reducer输出</td><td>使用标准工具或者编解码器，如gzip和bzip2</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）</td><td>RECORD</td><td>reducer输出</td><td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td></tr></tbody></table><h3 id="压缩实操案例"><a href="#压缩实操案例" class="headerlink" title="压缩实操案例"></a>压缩实操案例</h3><h4 id="数据流的压缩和解压缩"><a href="#数据流的压缩和解压缩" class="headerlink" title="数据流的压缩和解压缩"></a>数据流的压缩和解压缩</h4><p><img src="65.png" alt></p><p>测试一下如下压缩方式：</p><p>| DEFLATE | org.apache.hadoop.io.compress.DefaultCodec |<br>| gzip | org.apache.hadoop.io.compress.GzipCodec |<br>| bzip2 | org.apache.hadoop.io.compress.BZip2Codec |</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>compress<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodecFactory<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ReflectionUtils<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/17 上午 10:54 * @Func: 压缩 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestCompress</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 压缩（可以更换不同压缩方式）</span>        <span class="token function">compress</span><span class="token punctuation">(</span><span class="token string">"D:/scwri/Desktop/inputWeb/web.log"</span><span class="token punctuation">,</span><span class="token string">"org.apache.hadoop.io.compress.BZip2Codec"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 解压缩</span>        <span class="token function">decompress</span><span class="token punctuation">(</span><span class="token string">"d:/scwri/Desktop/inputWeb/web.log.bz2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">decompress</span><span class="token punctuation">(</span>String fileName<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 压缩方式检查</span>        CompressionCodecFactory factory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">CompressionCodecFactory</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionCodec codec <span class="token operator">=</span> factory<span class="token punctuation">.</span><span class="token function">getCodec</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>codec <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"can not process"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 获取输入流</span>        FileInputStream fis <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionInputStream cis <span class="token operator">=</span> codec<span class="token punctuation">.</span><span class="token function">createInputStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取输出流</span>        FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName <span class="token operator">+</span> <span class="token string">".decode"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 流的对拷</span>        IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>cis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>cis<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">compress</span><span class="token punctuation">(</span>String fileName<span class="token punctuation">,</span> String method<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//获取输入流</span>        FileInputStream fis <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Class<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span> theClass <span class="token operator">=</span> Class<span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span>method<span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionCodec codec <span class="token operator">=</span> <span class="token punctuation">(</span>CompressionCodec<span class="token punctuation">)</span> ReflectionUtils<span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span>theClass<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取输出流(需要一个压缩后的扩展名)</span>        FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName <span class="token operator">+</span> codec<span class="token punctuation">.</span><span class="token function">getDefaultExtension</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionOutputStream cos <span class="token operator">=</span> codec<span class="token punctuation">.</span><span class="token function">createOutputStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//流的对拷(参数：输入流、输出流、缓冲区（自己设置）、最后是否关闭输入流和输出流)</span>        IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> cos<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>cos<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Map输出端采用压缩"><a href="#Map输出端采用压缩" class="headerlink" title="Map输出端采用压缩"></a>Map输出端采用压缩</h4><p>即使你的Ma pReduce的输入输出文件都是未压缩的文件，你仍然可以对Map任务的中间结果输出做压缩，因为它要写在硬盘并且通过网络传输到Reduce节点，对其压缩可以提高很多性能，这些工作只要设置两个属性即可，我们来看下代码怎么设置。</p><p>1．给大家提供的Hadoop源码支持的压缩格式有：BZip2Codec 、DefaultCodec</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>BZip2Codec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>CombineTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_words/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 开启map端输出压缩</span>        conf<span class="token punctuation">.</span><span class="token function">setBoolean</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress"</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置map端输出压缩方式</span>        conf<span class="token punctuation">.</span><span class="token function">setClass</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress.codec"</span><span class="token punctuation">,</span> BZip2Codec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> CompressionCodec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联map和reduce</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper阶段输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入路径和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．Mapper保持不变</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * map阶段 * @author swenchao */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．Reducer保持不变</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * reduce阶段 * @author swenchao */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span> <span class="token punctuation">{</span>    IntWritable value <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 累加求和</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>IntWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        value<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Reduce输出端采用压缩"><a href="#Reduce输出端采用压缩" class="headerlink" title="Reduce输出端采用压缩"></a>Reduce输出端采用压缩</h4><p>基于WordCount案例处理。</p><p>1．修改驱动</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>BZip2Codec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>CombineTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_words/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 开启map端输出压缩</span>        conf<span class="token punctuation">.</span><span class="token function">setBoolean</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress"</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置map端输出压缩方式</span>        conf<span class="token punctuation">.</span><span class="token function">setClass</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress.codec"</span><span class="token punctuation">,</span> BZip2Codec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> CompressionCodec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置reduce端输出压缩开启</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setCompressOutput</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置压缩的方式</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputCompressorClass</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> BZip2Codec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联map和reduce</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入路径和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．Mapper和Reducer保持不变（跟之前 WordCount 一样）</p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>接下来是Yarn马上就接近尾声了，开心~</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-MapReduce-MapReduce框架原理（MapReduce系列三）</title>
      <link href="2020/09/09/hadoop-mapreduce-mapreduce-kuang-jia-yuan-li-mapreduce-xi-lie-san/"/>
      <url>2020/09/09/hadoop-mapreduce-mapreduce-kuang-jia-yuan-li-mapreduce-xi-lie-san/</url>
      
        <content type="html"><![CDATA[<h2 id="MapReduce框架原理"><a href="#MapReduce框架原理" class="headerlink" title="MapReduce框架原理"></a>MapReduce框架原理</h2><h3 id="InputFormat数据输入"><a href="#InputFormat数据输入" class="headerlink" title="InputFormat数据输入"></a>InputFormat数据输入</h3><h4 id="切片与MapTask并行度决定机制"><a href="#切片与MapTask并行度决定机制" class="headerlink" title="切片与MapTask并行度决定机制"></a>切片与MapTask并行度决定机制</h4><p>1．问题引出</p><p>MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个Job的处理速度。</p><p><strong>思考：1G的数据，启动8个MapTask，可以提高集群的并发处理能力。那么1K的数据，也启动8个MapTask，会提高集群性能吗？MapTask并行任务是否越多越好呢？哪些因素影响了MapTask并行度？</strong> </p><p>2．MapTask并行度决定机制</p><p>数据块：Block是HDFS物理上把数据分成一块一块。</p><p>数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。</p><p><img src="14.png" alt></p><p>其中4）是说，假如在ss.avi与ss2.avi一块到来时，每个文件单独切片。不会合在一块切，即使刚好能凑成一个整数块的大小。</p><h4 id="Job提交流程源码和切片源码详解（主要源码）"><a href="#Job提交流程源码和切片源码详解（主要源码）" class="headerlink" title="Job提交流程源码和切片源码详解（主要源码）"></a>Job提交流程源码和切片源码详解（主要源码）</h4><p>1．Job提交流程源码详解，如下：</p><p><img src="15.png" alt></p><pre class="line-numbers language-java"><code class="language-java"><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 其下面还有一些打印信息的代码</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">/*在这中间有一个是判断状态的，一个是设置新的api的*/</span><span class="token comment" spellcheck="true">// 1建立连接</span><span class="token function">connect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1）创建提交Job的代理</span>    <span class="token keyword">new</span> <span class="token class-name">Cluster</span><span class="token punctuation">(</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// （1）判断是本地yarn还是远程（主要工作）</span>        <span class="token function">initialize</span><span class="token punctuation">(</span>jobTrackAddr<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 2 提交job</span>submitter<span class="token punctuation">.</span><span class="token function">submitJobInternal</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> cluster<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 1）创建给集群提交数据的Stag路径（每个任务在本地都会创建一个，提交之后就会删除）</span>    Path jobStagingArea <span class="token operator">=</span> JobSubmissionFiles<span class="token punctuation">.</span><span class="token function">getStagingDir</span><span class="token punctuation">(</span>cluster<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2）获取jobid ，并创建Job路径</span>    JobID jobId <span class="token operator">=</span> submitClient<span class="token punctuation">.</span><span class="token function">getNewJobID</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3）拷贝jar包到集群（集群会走这块）</span><span class="token function">copyAndConfigureFiles</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        rUploader<span class="token punctuation">.</span><span class="token function">uploadFiles</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> jobSubmitDir<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 4）计算切片，生成切片规划文件</span><span class="token function">writeSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        maps <span class="token operator">=</span> <span class="token function">writeNewSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> jobSubmitDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        input<span class="token punctuation">.</span><span class="token function">getSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 5）向Stag路径写XML配置文件</span><span class="token function">writeConf</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> submitJobFile<span class="token punctuation">)</span><span class="token punctuation">;</span>    conf<span class="token punctuation">.</span><span class="token function">writeXml</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 6）提交Job,返回提交状态</span>status <span class="token operator">=</span> submitClient<span class="token punctuation">.</span><span class="token function">submitJob</span><span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> job<span class="token punctuation">.</span><span class="token function">getCredentials</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．FileInputFormat切片源码解析(input.getSplits(job))</p><p><img src="16.png" alt></p><h4 id="FileInputFormat切片机制"><a href="#FileInputFormat切片机制" class="headerlink" title="FileInputFormat切片机制"></a>FileInputFormat切片机制</h4><p><img src="17.png" alt></p><p><img src="18.png" alt></p><p>从代码中可以看到，本地运行的话，块的大小是32m。</p><p>文件大小/切片大小，如果大于1.1，则要进行切片，否则不用切。<br><strong>在集群上，若一个文件129m，则要存在两个块上，但是只切一片</strong></p><h4 id="CombineTextInputFormat切片机制"><a href="#CombineTextInputFormat切片机制" class="headerlink" title="CombineTextInputFormat切片机制"></a>CombineTextInputFormat切片机制</h4><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。</p><p>1、应用场景：</p><p>CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p><p>2、虚拟存储切片最大值设置</p><p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</p><p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p><p>3、切片机制</p><p>生成切片过程包括：虚拟存储过程和切片过程二部分。</p><p>（1）虚拟存储过程：</p><p>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</p><p>例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p><p>（2）切片过程：</p><p>（a）判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。</p><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p><p>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：</p><p>1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）</p><p>最终会形成3个切片，大小分别为：</p><p>（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p><p>若有一个10m的文件来切分的话，则会切成4+3+3，三个文件</p><p><img src="19.png" alt></p><h4 id="CombineTextInputFormat案例实操"><a href="#CombineTextInputFormat案例实操" class="headerlink" title="CombineTextInputFormat案例实操"></a>CombineTextInputFormat案例实操</h4><p>1．需求</p><p>将输入的大量小文件合并成一个切片统一处理。</p><p>（1）输入数据</p><p>准备4个小文件</p><p>（2）期望</p><p>期望一个切片处理4个文件</p><p>2．实现过程</p><p>（1）不做任何处理，运行1.6节的WordCount案例程序，观察切片个数为4。</p><p>number of splits : 4</p><p>（2）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为3。</p><p>（a）驱动类中添加代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span>job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//虚拟存储切片最大值设置4m</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token function">setMaxInputSplitSize</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">4194304</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）运行如果为3个切片。</p><p>number of splits : 3</p><p>（3）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为1。</p><p>（a）驱动中添加代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span>job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//虚拟存储切片最大值设置20m</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token function">setMaxInputSplitSize</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">20971520</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）运行如果为1个切片。</p><p>number of splits : 1</p><h4 id="FileInputFormat实现类"><a href="#FileInputFormat实现类" class="headerlink" title="FileInputFormat实现类"></a>FileInputFormat实现类</h4><p><img src="20.png" alt></p><p><img src="21.png" alt></p><p><img src="22.png" alt></p><p><img src="23.png" alt></p><h4 id="KeyValueTextInputFormat使用案例"><a href="#KeyValueTextInputFormat使用案例" class="headerlink" title="KeyValueTextInputFormat使用案例"></a>KeyValueTextInputFormat使用案例</h4><p>1．需求</p><p>统计输入文件中每一行的第一个单词相同的行数。</p><p>（1）输入数据</p><pre><code>apple ni haobigdata hadoop apple hellobigdata orange hadoop</code></pre><p>（2）期望结果数据</p><pre><code>apple    2bigdata    2</code></pre><p>2．需求分析</p><p><img src="24.png" alt></p><p>3．代码实现</p><p>（1）编写Mapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>kv<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KVTextMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">// 1 设置value</span>   LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>            <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span><span class="token comment" spellcheck="true">// banzhang ni hao</span>        <span class="token comment" spellcheck="true">// 2 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Reducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>kv<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KVTextReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span>    LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>LongWritable<span class="token operator">></span> values<span class="token punctuation">,</span>    Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>         <span class="token keyword">long</span> sum <span class="token operator">=</span> 0L<span class="token punctuation">;</span>           <span class="token comment" spellcheck="true">// 1 汇总统计</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>LongWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>              sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token punctuation">}</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment" spellcheck="true">// 2 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Driver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>kv<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueLineRecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KVTextDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置切割符</span>    conf<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>KeyValueLineRecordReader<span class="token punctuation">.</span>KEY_VALUE_SEPERATOR<span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置jar包位置，关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>KVTextDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>KVTextMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>KVTextReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 设置map输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入输出数据路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入格式</span>    job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>KeyValueTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输出数据路径</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交job</span>        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="NLineInputFormat使用案例"><a href="#NLineInputFormat使用案例" class="headerlink" title="NLineInputFormat使用案例"></a>NLineInputFormat使用案例</h4><p>1．需求</p><p>对每个单词进行个数统计，要求根据每个输入文件的行数来规定输出多少个切片。此案例要求每三行放入一个切片中。</p><p>（1）输入数据</p><pre><code>apple ni haoorange hadoop appleapple ni haoorange hadoop appleapple ni haoorange hadoop appleapple ni haoorange hadoop appleapple ni haoorange hadoop apple apple ni haoorange hadoop apple</code></pre><p>（2）期望输出数据</p><p>Number of splits:4</p><p>2．需求分析</p><p><img src="25.png" alt></p><p>3．代码实现</p><p>（1）编写Mapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>nline<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">NLineMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span>    <span class="token keyword">private</span> Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 遍历</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span><span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Reducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>nline<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">NLineReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span>    LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>    Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 求和</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>LongWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Driver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>nline<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URISyntaxException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>NLineInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">NLineDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输入输出路径</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job对象</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7设置每个切片InputSplit中划分三条记录（三行一片）</span>        NLineInputFormat<span class="token punctuation">.</span><span class="token function">setNumLinesPerSplit</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 8使用NLineInputFormat处理记录数</span>        job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>NLineInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment" spellcheck="true">// 2设置jar包位置，关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>NLineDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>NLineMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>NLineReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment" spellcheck="true">// 3设置map输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment" spellcheck="true">// 4设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment" spellcheck="true">// 5设置输入输出数据路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment" spellcheck="true">// 6提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="自定义InputFormat"><a href="#自定义InputFormat" class="headerlink" title="自定义InputFormat"></a>自定义InputFormat</h4><p><img src="26.png" alt></p><h4 id="自定义InputFormat案例使用"><a href="#自定义InputFormat案例使用" class="headerlink" title="自定义InputFormat案例使用"></a>自定义InputFormat案例使用</h4><p>无论HDFS还是MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义InputFormat实现小文件的合并。</p><p>1．需求</p><p>将多个小文件合并成一个SequenceFile文件（SequenceFile文件是Hadoop用来存储二进制形式的key-value对的文件格式），SequenceFile里面存储着多个文件，存储的形式为文件路径+名称为key，文件内容为value。</p><p>输入数据</p><p>文件1</p><pre><code>apple orange bananapear pineapple grape</code></pre><p>文件2</p><pre><code>Blackberry Blueberry CherryCrabapple Cranberry CumquatBlackberry Blueberry CherryCrabapple Cranberry Cumquat</code></pre><p>文件3</p><pre><code>zhangsan wangwu zhaoliulisi qianqi sunba</code></pre><p>2．需求分析</p><p><img src="27.png" alt></p><p>3．程序实现</p><p>（1）自定义InputFromat</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>InputSplit<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 03:13 * @Func: 自定义Inputformat类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInput</span> <span class="token keyword">extends</span> <span class="token class-name">FileInputFormat</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> RecordReader<span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token function">createRecordReader</span><span class="token punctuation">(</span>InputSplit inputSplit<span class="token punctuation">,</span> TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        SelfInputRecordReder recordReder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SelfInputRecordReder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        recordReder<span class="token punctuation">.</span><span class="token function">initialize</span><span class="token punctuation">(</span>inputSplit<span class="token punctuation">,</span> taskAttemptContext<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> recordReder<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）自定义SelfInputRecordReder类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FileSystem<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileSplit<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>InputSplit<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 03:19 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputRecordReder</span> <span class="token keyword">extends</span> <span class="token class-name">RecordReader</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    FileSplit split<span class="token punctuation">;</span>    Configuration conf<span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    BytesWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BytesWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">boolean</span> isProgress <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span>InputSplit inputSplit<span class="token punctuation">,</span> TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 初始化</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>split <span class="token operator">=</span> <span class="token punctuation">(</span>FileSplit<span class="token punctuation">)</span>inputSplit<span class="token punctuation">;</span>        conf <span class="token operator">=</span> taskAttemptContext<span class="token punctuation">.</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">nextKeyValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 业务逻辑处理(封装最终结果)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>isProgress<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">byte</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>split<span class="token punctuation">.</span><span class="token function">getLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            FileSystem fs <span class="token operator">=</span> null<span class="token punctuation">;</span>            FSDataInputStream fis <span class="token operator">=</span> null<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 获取fs对象（每个切片都能拿到相应的路径）</span>            Path path<span class="token operator">=</span> split<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            fs <span class="token operator">=</span> path<span class="token punctuation">.</span><span class="token function">getFileSystem</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 获取输入流</span>            fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 拷贝(将fis信息读取到buf中；0是从哪开始读；buf.length读取长度)</span>            IOUtils<span class="token punctuation">.</span><span class="token function">readFully</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> buf<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 写入v</span>            v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> buf<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 封装k</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>path<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 关闭集群</span>            IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>            isProgress <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Text <span class="token function">getCurrentKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>       <span class="token keyword">return</span> k<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> BytesWritable <span class="token function">getCurrentValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">return</span> v<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 获取正在处理进程     * @return     * @throws IOException     * @throws InterruptedException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">float</span> <span class="token function">getProgress</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写SelfInputMapper类处理流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>sun<span class="token punctuation">.</span>crypto<span class="token punctuation">.</span>provider<span class="token punctuation">.</span>HmacPKCS12PBESHA1<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 08:20 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> BytesWritable value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写SelfInputReducer类处理流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 08:20 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>BytesWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>BytesWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写SelfInputDriver类处理流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>SequenceFileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 08:20 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>SelfInputDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>SelfInputMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>SelfInputReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>SelfInput<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputFormatClass</span><span class="token punctuation">(</span>SequenceFileOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>BytesWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>BytesWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">boolean</span> res <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>res <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>FileInputFormat常见接口实现总结</strong></p><table><thead><tr><th>FileInputFormat常见接口</th><th>切片方式</th><th>默认key</th><th>默认value</th></tr></thead><tbody><tr><td>TextInputFormat</td><td>按块（block）的大小来切</td><td>LongWritable（偏移量）</td><td>Text（一行的内容，按行读取）</td></tr><tr><td>KeyValueTextInputFormat</td><td>按块（block）的大小来切</td><td>切完后的第一列</td><td>切完后的剩余列</td></tr><tr><td>NLineTextInputFormat</td><td>按行来切</td><td>LongWritable（偏移量）</td><td>Text（内容）</td></tr><tr><td>CombineTextInputFormat</td><td>跟设置的最大值有关（大于最大值，小于两倍的最大值）</td><td>LongWritable（偏移量）</td><td>Text（一行的内容，按行读取）</td></tr><tr><td>自定义InputFormat</td><td>按块（block）的大小来切</td><td>跟我们自定义有关</td><td>跟我们自定义有关</td></tr></tbody></table><p>4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序</p><p>5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据</p><p>6）ReduceTask会取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</p><p>7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</p><p>3．注意</p><p>Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</p><p>缓冲区的大小可以通过参数调整，参数：io.sort.mb默认100M。</p><h3 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h3><h4 id="Shuffle机制-1"><a href="#Shuffle机制-1" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h4><p>Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle，如图</p><p><img src="30.png" alt></p><h4 id="Partition分区"><a href="#Partition分区" class="headerlink" title="Partition分区"></a>Partition分区</h4><p><img src="31.png" alt></p><p><strong>(key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks</strong></p><p>(1) 默认分区是hashPartition</p><p>(2) 其中numReduceTasks默认是1。</p><p>(3) key.hashCode() &amp; Integer.MAX_VALUE 就是规定key.hashCode() &lt;= x &lt;= Integer.MAX_VALUE 这么一个范围（因为 Integer.MAX_VALUE 是11111…. 那么它跟谁进行与操作都是最大是Integer.MAX_VALUE，所以规定了一个最大值）</p><p><img src="32.png" alt></p><p><img src="33.png" alt></p><h4 id="Partition分区案例"><a href="#Partition分区案例" class="headerlink" title="Partition分区案例"></a>Partition分区案例</h4><p>1．需求</p><p>将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p><p>（1）输入数据</p><pre><code>    1    13736230513    192.196.100.1    www.baidu.com    2481    24681    200    2    13846544121    192.196.100.2            264    0    200    3     13956435636    192.196.100.3            132    1512    200    4     13966251146    192.168.100.1            240    0    404    5     18271575951    192.168.100.2    www.bilibili.com    1527    2106    200    6     84188413    192.168.100.3    www.baidu.com    4116    1432    200    7     13590439668    192.168.100.4            1116    954    200    8     15910133277    192.168.100.5    www.hao123.com    3156    2936    200    9     13729199489    192.168.100.6            240    0    200    10     13630577991    192.168.100.7    www.shouhu.com    6960    690    200    11     15043685818    192.168.100.8    www.baidu.com    3659    3538    200    12     15959002129    192.168.100.9    www.baidu.com    1938    180    500    13     13560439638    192.168.100.10            918    4938    200    14     13470253144    192.168.100.11            180    180    200    15     13682846555    192.168.100.12    www.qq.com    1938    2910    200    16     13992314666    192.168.100.13    www.gaga.com    3008    3720    200    17     13509468723    192.168.100.14    www.sogou.com    7335    110349    404    18     18390173782    192.168.100.15    www.sogou.com    9531    2412    200    19     13975057813    192.168.100.16    www.baidu.com    11058    48243    200    20     13768778790    192.168.100.17            120    120    200    21     13568436656    192.168.100.18    www.alibaba.com    2481    24681    200    22     13568436656    192.168.100.19            1116    954    200</code></pre><p>（2）期望输出数据</p><p>手机号136、137、138、139开头都分别放到4个独立的文件中，其他开头的放到一个文件中。</p><p>2．需求分析</p><p><img src="34.png" alt></p><p>3．在第二章序列化案例（求电话流量）的基础上，增加一个分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Partitioner<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 03:54 * @Func: 自定义分区类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>Text text<span class="token punctuation">,</span> FlowBean flowBean<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// k是手机号  v是流量信息</span>        <span class="token comment" spellcheck="true">// 获取手机号前三位（截取左闭右开）</span>        String prePhoneNum <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 根据前三位进行分区</span>        <span class="token keyword">int</span> partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"136"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>  <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"137"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"138"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"139"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．在驱动函数中增加自定义数据分区设置和ReduceTask设置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueLineRecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/7 11:45 * @Func: driver类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowSumDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_phone/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output1"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置jar路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowSumDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置分区和分区数</span>        job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 设置分区和分区数</span>job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>若定义的分区类是5，在驱动中设置的分区数如果是1或者是大于5的数都不会报错，但是其他数就会报错。</p><p>(1) 若设置分区数为1，则最终会生成1个文件并且所有数据都在1个文件里</p><p>(2) 若设置分区数为6，则最终会生成6个文件并且所有数据都在前5个文件里</p><p><img src="33.png" alt></p><h4 id="WritableComparable排序"><a href="#WritableComparable排序" class="headerlink" title="WritableComparable排序"></a>WritableComparable排序</h4><ol><li>排序概述</li></ol><p><img src="35.png" alt></p><p><img src="36.png" alt></p><ol start="2"><li>排序的分类</li></ol><p><img src="37.png" alt></p><ol start="3"><li>自定义排序WritableComparable</li></ol><p>（1）原理分析</p><p>bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowBean o<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> result<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 按照总流量大小，倒序排列</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>        result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="WritableComparable排序案例实操（全排序）"><a href="#WritableComparable排序案例实操（全排序）" class="headerlink" title="WritableComparable排序案例实操（全排序）"></a>WritableComparable排序案例实操（全排序）</h4><p>1．需求</p><p>根据之前手机流量求和案例，对总流量进行排序。</p><p>（1）输入数据</p><pre><code>    13470253144    180    180    360    13509468723    7335    110349    117684    13560439638    918    4938    5856    13568436656    3597    25635    29232    13590439668    1116    954    2070    13630577991    6960    690    7650    13682846555    1938    2910    4848    13729199489    240    0    240    13736230513    2481    24681    27162    13768778790    120    120    240    13846544121    264    0    264    13956435636    132    1512    1644    13966251146    240    0    240    13975057813    11058    48243    59301    13992314666    3008    3720    6728    15043685818    3659    3538    7197    15910133277    3156    2936    6092    15959002129    1938    180    2118    18271575951    1527    2106    3633    18390173782    9531    2412    11943    84188413    4116    1432    5548</code></pre><p>（2）期望输出数据</p><pre><code>    13509468723    7335    110349    117684    13736230513    2481    24681    27162    13956435636    132        1512    1644    13846544121    264        0        264    ...</code></pre><p>2．需求分析</p><p><img src="38.png" alt></p><p>3．代码实现</p><p>（1）FlowSortBean对象在在之前的基础上增加了比较功能</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 07:42 * @Func: 自己定义的FlowBean对象 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowSortBean</span> <span class="token keyword">implements</span> <span class="token class-name">WritableComparable</span><span class="token operator">&lt;</span>FlowSortBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**上行流量*/</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> upFlow<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**下行流量*/</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**总流量*/</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> sumFlow<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">FlowSortBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">FlowSortBean</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 排序比较     * @param bean     * @return res     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowSortBean bean<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> res<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 比较逻辑</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            res <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            res <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            res <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> res<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 序列化     * @param dataOutput     * @throws IOException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput dataOutput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 反序列化     * @param dataInput     * @throws IOException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput dataInput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        upFlow <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        downFlow <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        sumFlow <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> sumFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> downFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Mapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 08:13 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowSortBean<span class="token punctuation">,</span> Text<span class="token operator">></span><span class="token punctuation">{</span>    FlowSortBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowSortBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 截取</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 封装对象</span>        String phoneNbr <span class="token operator">=</span> fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> upFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> downFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> sumFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">,</span> downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>phoneNbr<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>bean<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Reducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 08:13 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>FlowSortBean<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowSortBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>FlowSortBean key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>Text<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Text value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写Driver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 08:13 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_phone/phone_sum.txt"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output1"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置jar路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowCountSortDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountSortMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountSortReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>FlowSortBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>FlowSortBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="WritableComparable排序案例实操（区内排序）"><a href="#WritableComparable排序案例实操（区内排序）" class="headerlink" title="WritableComparable排序案例实操（区内排序）"></a>WritableComparable排序案例实操（区内排序）</h4><p>1．需求</p><p>要求之前整理的每个前缀手机号输出的文件中按照总流量内部排序。</p><p>2．需求分析</p><p>基于上一个需求，增加自定义分区类，分区按照省份手机号设置。</p><p><img src="39.png" alt></p><p>3．案例实操</p><p>（1）增加自定义分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Partitioner<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 09:37 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token operator">&lt;</span>FlowSortBean<span class="token punctuation">,</span> Text<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>FlowSortBean flowSortBean<span class="token punctuation">,</span> Text text<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 按照手机号前三位分区</span>        <span class="token comment" spellcheck="true">// 获取前三位</span>        String prePhoneNum <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 根据前三位进行分区</span>        <span class="token keyword">int</span> partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"136"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"137"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"138"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"139"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在驱动类中添加分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 加载自定义分区类</span>job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 设置Reducetask个数</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Combiner合并"><a href="#Combiner合并" class="headerlink" title="Combiner合并"></a>Combiner合并</h4><p><img src="40.png" alt></p><p>combiner不适用于求平均一类操作，只适用于汇总一类的工作。</p><p>（6）自定义Combiner实现步骤</p><p>（a）自定义一个Combiner继承Reducer，重写Reduce方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 汇总操作</span>        <span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable v <span class="token operator">:</span>values<span class="token punctuation">)</span><span class="token punctuation">{</span>            count <span class="token operator">+=</span> v<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 2 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）在Job驱动类中设置：  </p><pre class="line-numbers language-java"><code class="language-java">job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountCombiner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Combiner合并案例实操"><a href="#Combiner合并案例实操" class="headerlink" title="Combiner合并案例实操"></a>Combiner合并案例实操</h4><ol><li>需求</li></ol><p>统计过程中对每一个MapTask的输出进行局部汇总，以减小网络传输量即采用Combiner功能。</p><p>（1）数据输入 </p><pre><code>apple spark hibigdata hadoop apple hello hibigdata orange hadoop</code></pre><p>（2）期望输出数据</p><p>期望：Combine输入数据多，输出时经过合并，输出数据降低。</p><ol start="2"><li>需求分析</li></ol><p>对每一个MapTask的输出进行局部汇总</p><p><img src="41.png" alt></p><ol start="3"><li>方案一</li></ol><p>1）增加一个WordcountCombiner类继承Reducer</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 上午 10:12 * @Func: Combiner类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span> <span class="token punctuation">{</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 累加求和</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）在WordcountDriver驱动类中指定Combiner</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 指定需要使用combiner，以及用哪个类作为combiner的逻辑</span>job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountCombiner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4．案例实操-方案二</p><p>1）将WordcountReducer作为Combiner在WordcountDriver驱动类中进行绑定</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 指定需要使用Combiner，以及用哪个类作为Combiner的逻辑</span>job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>运行程序结果对比</p><p>使用前</p><p><img src="42.jpg" alt></p><p>使用后</p><p><img src="43.jpg" alt></p><p>可以看出其中combiner就在mapper与reducer之间。其中使用之后，reducer的输入明显减少，这就说明已经进行了一次汇总。</p><h4 id="GroupingComparator分组（辅助排序）"><a href="#GroupingComparator分组（辅助排序）" class="headerlink" title="GroupingComparator分组（辅助排序）"></a>GroupingComparator分组（辅助排序）</h4><p>对Reduce阶段的数据根据某一个或几个字段进行分组。</p><p>分组排序步骤：</p><p>（1）自定义类继承WritableComparator</p><p>（2）重写compare()方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compare</span><span class="token punctuation">(</span>WritableComparable a<span class="token punctuation">,</span> WritableComparable b<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 比较的业务逻辑</span>    <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建一个构造将比较对象的类传给父类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">protected</span> <span class="token function">OrderGroupingComparator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="GroupingComparator分组案例"><a href="#GroupingComparator分组案例" class="headerlink" title="GroupingComparator分组案例"></a>GroupingComparator分组案例</h4><p>1．需求</p><p>有如下订单数据</p><table>    <tr>        <th>订单id</th>        <th>商品id</th>        <th>成交金额</th>      </tr>    <tr>        <td rowspan="2">0000001</td>        <td>Pdt_01</td>        <td>222.8</td>    </tr>    <tr>        <td>Pdt_02</td>        <td>33.8</td>    </tr>    <tr>        <td rowspan="3">0000002</td>        <td>Pdt_03</td>        <td>522.8</td>    </tr>    <tr>        <td>Pdt_04</td>        <td>122.4</td>    </tr>    <tr>        <td>Pdt_05</td>        <td>722.4</td>    </tr>    <tr>        <td rowspan="2">0000003</td>        <td>Pdt_06</td>        <td>232.8</td>    </tr>    <tr>        <td>Pdt_02</td>        <td>33.8</td>    </tr></table><p>现在需要求出每一个订单中最贵的商品。</p><p>（1）输入数据</p><pre><code>0000001 Pdt_01 222.80000002    Pdt_05 722.40000001    Pdt_02 33.80000003    Pdt_06 232.80000003    Pdt_02 33.80000002    Pdt_03 522.80000002    Pdt_04 122.4</code></pre><p>（2）期望输出数据</p><pre><code>1    222.82    722.43    232.8</code></pre><p>2．需求分析</p><p>（1）利用“订单id和成交金额”作为key，可以将Map阶段读取到的所有订单数据按照id升序排序，如果id相同再按照金额降序排序，发送到Reduce。</p><p>（2）在Reduce端利用groupingComparator将订单id相同的kv聚合成组，然后取第一个即是该订单中最贵商品，如图</p><p><img src="44.png" alt></p><p>3．代码实现</p><p>（1）定义订单信息OrderBean类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 01:47 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderBean</span> <span class="token keyword">implements</span> <span class="token class-name">WritableComparable</span><span class="token operator">&lt;</span>OrderBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**订单id*/</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> orderId<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**价格*/</span>    <span class="token keyword">private</span> <span class="token keyword">double</span> price<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">OrderBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">OrderBean</span><span class="token punctuation">(</span><span class="token keyword">int</span> orderId<span class="token punctuation">,</span> <span class="token keyword">int</span> price<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>orderId <span class="token operator">=</span> orderId<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>price <span class="token operator">=</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> orderId<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setOrderId</span><span class="token punctuation">(</span><span class="token keyword">int</span> orderId<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>orderId <span class="token operator">=</span> orderId<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getPrice</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setPrice</span><span class="token punctuation">(</span><span class="token keyword">double</span> price<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>price <span class="token operator">=</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>OrderBean bean<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 先按id升序排序，如果相同再降序排序</span>        <span class="token keyword">int</span> result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>orderId <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>orderId <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>price <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getPrice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>price <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getPrice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> result<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput dataOutput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeInt</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeDouble</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput dataInput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        orderId <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        price <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readDouble</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> orderId <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写OrderMapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 02:11 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> OrderBean<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//    0000001 Pdt_01 222.8</span>    OrderBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OrderBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 切割取价格</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> details <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> orderId <span class="token operator">=</span> Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>details<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">double</span> price <span class="token operator">=</span> Double<span class="token punctuation">.</span><span class="token function">parseDouble</span><span class="token punctuation">(</span>details<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">setOrderId</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">setPrice</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>bean<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写OrderSortGroupingComparator类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">.</span>OrderBean<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparator<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 04:32 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderSortGroupingComparator</span> <span class="token keyword">extends</span> <span class="token class-name">WritableComparator</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token function">OrderSortGroupingComparator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compare</span><span class="token punctuation">(</span>WritableComparable a<span class="token punctuation">,</span> WritableComparable b<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 只要id相同就判定为相同key(当为0的时候就会返回同一个分组)</span>        OrderBean aBean <span class="token operator">=</span> <span class="token punctuation">(</span>OrderBean<span class="token punctuation">)</span> a<span class="token punctuation">;</span>        OrderBean bBean <span class="token operator">=</span> <span class="token punctuation">(</span>OrderBean<span class="token punctuation">)</span> b<span class="token punctuation">;</span>        <span class="token keyword">int</span> result<span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>aBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> bBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>aBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> bBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> result<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写OrderReducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 02:11 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>OrderBean<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span> OrderBean<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>OrderBean key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>NullWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写OrderDriver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">.</span>OrderSortGroupingComparator<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span>WordcountDriver<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span>WordcountMapper<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span>WordcountReducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>CombineTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 02:11 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_order/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置jar存储路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>OrderDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联map和reduce</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>OrderMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>OrderReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper阶段输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入路径和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置reduce分组</span>        job<span class="token punctuation">.</span><span class="token function">setGroupingComparatorClass</span><span class="token punctuation">(</span>OrderSortGroupingComparator<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MapTask工作机制"><a href="#MapTask工作机制" class="headerlink" title="MapTask工作机制"></a>MapTask工作机制</h3><p><img src="45.png" alt></p><p>（1）Read阶段：MapTask通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。</p><p>（2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p><p>（3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p><p>（4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p><p>溢写阶段详情：</p><p>步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p><p>步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p><p>步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p><p>（5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p><p>当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。</p><p>在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p><p>让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p><h3 id="ReduceTask工作机制"><a href="#ReduceTask工作机制" class="headerlink" title="ReduceTask工作机制"></a>ReduceTask工作机制</h3><p>1．ReduceTask工作机制</p><p><img src="46.png" alt></p><p>（1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p><p>（2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p><p>（3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p><p>（4）Reduce阶段：reduce()函数将计算结果写到HDFS上。</p><p>2．设置ReduceTask并行度（个数）</p><p>ReduceTask的并行度同样影响整个Job的执行并发度和执行效率，但与MapTask的并发数由切片数决定不同，ReduceTask数量的决定是可以直接手动设置：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 默认值是1，手动设置为4</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3．实验：测试ReduceTask多少合适（据说是IBM工程师做的实验）</p><p>（1）实验环境：1个Master节点，16个Slave节点：CPU:8GHZ，内存: 2G</p><p>（2）实验结论：</p><p>改变ReduceTask （数据量为1GB）</p><table>    <tr>        <th colspan="11">MapTask =16</th>    </tr>    <tr>        <td>ReduceTask</td>        <td>1</td>        <td>5</td>        <td>10</td>        <td>15</td>        <td>16</td>        <td>20</td>        <td>25</td>        <td>30</td>        <td>45</td>        <td>60</td>    </tr>    <tr>        <td>总时间</td>        <td>892</td>        <td>146</td>        <td>110</td>        <td>92</td>        <td>88</td>        <td>100</td>        <td>128</td>        <td>101</td>        <td>145</td>        <td>104</td>    </tr></table><p>4．注意事项</p><p><img src="47.png" alt></p><p>数据倾斜：如果有三个ReduceTask，若其中①里面有1亿条数据，②里面有100条数据，③里面有1条数据，那么这就负载不够均衡，①会压力特别大。这种情况就叫数据倾斜。</p><p><strong>注：</strong>以上两节合起来便是之前讲过的MapReduce工作流程</p><h3 id="OutputFormat数据输出"><a href="#OutputFormat数据输出" class="headerlink" title="OutputFormat数据输出"></a>OutputFormat数据输出</h3><h4 id="OutputFormat接口实现类"><a href="#OutputFormat接口实现类" class="headerlink" title="OutputFormat接口实现类"></a>OutputFormat接口实现类</h4><p><img src="48.png" alt></p><h4 id="自定义OutputFormat"><a href="#自定义OutputFormat" class="headerlink" title="自定义OutputFormat"></a>自定义OutputFormat</h4><p><img src="49.png" alt></p><h4 id="自定义OutputFormat案例实操"><a href="#自定义OutputFormat案例实操" class="headerlink" title="自定义OutputFormat案例实操"></a>自定义OutputFormat案例实操</h4><p>1．需求</p><p>过滤输入的log日志，包含百度的网站输出到/baidu.log，不包含百度的网站输出到/other.log。</p><p>（1）输入数据</p><pre><code>    http://www.baidu.com    http://www.google.com    http://cn.bing.com    http://www.github.com    http://www.sohu.com    http://www.sina.com    http://www.sin2a.com    http://www.sin2desa.com    http://www.sindsafa.com</code></pre><p>（2）期望输出数据</p><p>[/baidu.log]</p><pre><code>    http://www.baidu.com</code></pre><p>[/other.log]</p><pre><code>    http://www.google.com    http://cn.bing.com    http://www.github.com    http://www.sohu.com    http://www.sina.com    http://www.sin2a.com    http://www.sin2desa.com    http://www.sindsafa.com</code></pre><p>3．案例</p><p>（1）编写FilterMapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: Mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写FilterReducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: Reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>NullWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        String line <span class="token operator">=</span> key<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        line <span class="token operator">+=</span> <span class="token string">"\r\n"</span><span class="token punctuation">;</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）自定义一个OutputFormat类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: 自定义OutputFormat */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterOutputFormat</span> <span class="token keyword">extends</span> <span class="token class-name">FileOutputFormat</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> RecordWriter<span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token function">getRecordWriter</span><span class="token punctuation">(</span>TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">FRecordWrite</span><span class="token punctuation">(</span>taskAttemptContext<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写FRecordWrite类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FileSystem<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 05:21 * @Func: 自定义 RecordWrite */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FRecordWrite</span> <span class="token keyword">extends</span> <span class="token class-name">RecordWriter</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    FSDataOutputStream fosBaidu<span class="token punctuation">;</span>    FSDataOutputStream fosOther<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">FRecordWrite</span><span class="token punctuation">(</span>TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获取文件系统</span>            FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>taskAttemptContext<span class="token punctuation">.</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 创建输出到baidu.log输出流</span>            fosBaidu <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"baidu.log"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 创建输出到other.log输出流</span>            fosOther <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"other.log"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>Text text<span class="token punctuation">,</span> NullWritable nullWritable<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 判断key中是否有baidu，分别写入</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"baidu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            fosBaidu<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            fosOther<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span>TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 结束关掉资源</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fosBaidu<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fosOther<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写FilterDriver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: 驱动类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token punctuation">{</span> <span class="token string">"D:/scwri/Desktop/inputoutputformat"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span> <span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FilterDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FilterMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FilterReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 要将自定义的输出格式组件设置到job中</span>        job<span class="token punctuation">.</span><span class="token function">setOutputFormatClass</span><span class="token punctuation">(</span>FilterOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat</span>        <span class="token comment" spellcheck="true">// 而fileoutputformat要输出一个_SUCCESS文件，所以，在这还得指定一个输出目录</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Join多种应用"><a href="#Join多种应用" class="headerlink" title="Join多种应用"></a>Join多种应用</h3><h4 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h4><p><img src="50.png" alt></p><h4 id="Reduce-Join案例实操"><a href="#Reduce-Join案例实操" class="headerlink" title="Reduce Join案例实操"></a>Reduce Join案例实操</h4><ol><li>需求</li></ol><p>[订单数据表 order.txt]</p><table><thead><tr><th>id</th><th>pid</th><th>amount</th></tr></thead><tbody><tr><td>1001</td><td>01</td><td>1</td></tr><tr><td>1002</td><td>02</td><td>2</td></tr><tr><td>1003</td><td>03</td><td>3</td></tr><tr><td>1004</td><td>04</td><td>4</td></tr><tr><td>1005</td><td>05</td><td>5</td></tr><tr><td>1006</td><td>06</td><td>6</td></tr></tbody></table><p>[商品信息表 product.txt]</p><table><thead><tr><th>pid</th><th>name</th></tr></thead><tbody><tr><td>01</td><td>小米</td></tr><tr><td>02</td><td>华为</td></tr><tr><td>03</td><td>格力</td></tr></tbody></table><p>将商品信息表中数据根据商品pid合并到订单数据表中。</p><p>[最终数据形式]</p><table><thead><tr><th>id</th><th>pname</th><th>amount</th></tr></thead><tbody><tr><td>1001</td><td>小米</td><td>1</td></tr><tr><td>1004</td><td>小米</td><td>4</td></tr><tr><td>1002</td><td>华为</td><td>2</td></tr><tr><td>1005</td><td>华为</td><td>5</td></tr><tr><td>1003</td><td>格力</td><td>3</td></tr><tr><td>1006</td><td>格力</td><td>6</td></tr></tbody></table><ol start="2"><li>需求分析</li></ol><p>通过将关联条件作为Map输出的key，将两表满足Join条件的数据并携带数据所来源的文件信息，发往同一个ReduceTask，在Reduce中进行数据的串联，如图4-20所示。</p><p><img src="51.png" alt></p><ol start="3"><li>代码实现</li></ol><p>1）创建商品和订合并后的Bean类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Writable<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:03 * @Func: 表的bean类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableBean</span> <span class="token keyword">implements</span> <span class="token class-name">Writable</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**订单id*/</span>    <span class="token keyword">private</span> String id<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**产品id*/</span>    <span class="token keyword">private</span> String pid<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**数量*/</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> amount<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**产品名称*/</span>    <span class="token keyword">private</span> String pname<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**标记（订单还是产品）*/</span>    <span class="token keyword">private</span> String flag<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">TableBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">TableBean</span><span class="token punctuation">(</span>String id<span class="token punctuation">,</span> String pid<span class="token punctuation">,</span> <span class="token keyword">int</span> amount<span class="token punctuation">,</span> String pname<span class="token punctuation">,</span> String flag<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>id <span class="token operator">=</span> id<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pid <span class="token operator">=</span> pid<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>amount <span class="token operator">=</span> amount<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pname <span class="token operator">=</span> pname<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>flag <span class="token operator">=</span> flag<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput dataOutput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>pid<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeInt</span><span class="token punctuation">(</span>amount<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>pname<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>flag<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput dataInput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        id <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        pid <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        amount <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        pname <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        flag <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> id<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setId</span><span class="token punctuation">(</span>String id<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>id <span class="token operator">=</span> id<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getPid</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> pid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setPid</span><span class="token punctuation">(</span>String pid<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pid <span class="token operator">=</span> pid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getAmount</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> amount<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setAmount</span><span class="token punctuation">(</span><span class="token keyword">int</span> amount<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>amount <span class="token operator">=</span> amount<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getPname</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> pname<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setPname</span><span class="token punctuation">(</span>String pname<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pname <span class="token operator">=</span> pname<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getFlag</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> flag<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setFlag</span><span class="token punctuation">(</span>String flag<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>flag <span class="token operator">=</span> flag<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> id <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> amount <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> pname<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）编写TableMapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileSplit<span class="token punctuation">;</span><span class="token keyword">import</span> javax<span class="token punctuation">.</span>swing<span class="token punctuation">.</span>text<span class="token punctuation">.</span>TabExpander<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:55 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> TableBean<span class="token operator">></span> <span class="token punctuation">{</span>    String name<span class="token punctuation">;</span>    TableBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TableBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//    </span><span class="token comment" spellcheck="true">/**因为在一开始要拿到它的文件信息来做区分，所以重写此方法*/</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">setup</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取文件名称</span>        FileSplit inputSplit <span class="token operator">=</span> <span class="token punctuation">(</span>FileSplit<span class="token punctuation">)</span> context<span class="token punctuation">.</span><span class="token function">getInputSplit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        name <span class="token operator">=</span> inputSplit<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>name<span class="token punctuation">.</span><span class="token function">startsWith</span><span class="token punctuation">(</span><span class="token string">"order"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setId</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPid</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setAmount</span><span class="token punctuation">(</span>Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setFlag</span><span class="token punctuation">(</span><span class="token string">"order"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPname</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setId</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPid</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setAmount</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setFlag</span><span class="token punctuation">(</span><span class="token string">"pd"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPname</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> bean<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）编写TableReducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>commons<span class="token punctuation">.</span>beanutils<span class="token punctuation">.</span>BeanUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>InvocationTargetException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:55 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> TableBean<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span> TableBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>TableBean<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        ArrayList<span class="token operator">&lt;</span>TableBean<span class="token operator">></span> orderBeans <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/**标记是否获得pname*/</span>        <span class="token keyword">boolean</span> isGetPname <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        String pName <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>TableBean bean <span class="token operator">:</span>values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"order"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>bean<span class="token punctuation">.</span><span class="token function">getFlag</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                TableBean tableBean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TableBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">try</span> <span class="token punctuation">{</span>                    BeanUtils<span class="token punctuation">.</span><span class="token function">copyProperties</span><span class="token punctuation">(</span>tableBean<span class="token punctuation">,</span> bean<span class="token punctuation">)</span><span class="token punctuation">;</span>                    orderBeans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>tableBean<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IllegalAccessException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">InvocationTargetException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>isGetPname<span class="token punctuation">)</span> <span class="token punctuation">{</span>                pName <span class="token operator">+=</span> bean<span class="token punctuation">.</span><span class="token function">getPname</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                isGetPname <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>TableBean tableBean <span class="token operator">:</span> orderBeans<span class="token punctuation">)</span><span class="token punctuation">{</span>            tableBean<span class="token punctuation">.</span><span class="token function">setPname</span><span class="token punctuation">(</span>pName<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tableBean<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）编写TableDriver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:55 * @Func: 驱动类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/inputTable/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息，或者job对象实例</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 指定本程序的jar包所在的本地路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>TableDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 指定本业务job要使用的Mapper/Reducer业务类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>TableMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>TableReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 指定Mapper输出数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>TableBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 指定最终输出的数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>TableBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 指定job的输入原始文件所在目录</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>测试</li></ol><p>运行程序查看结果</p><pre><code>    1004    4    小米    1001    1    小米    1005    5    华为    1002    2    华为    1006    6    格力    1003    3    格力</code></pre><ol start="5"><li>总结</li></ol><p><img src="52.png" alt></p><h4 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h4><ol><li>使用场景</li></ol><p>Map Join适用于一张表十分小、一张表很大的场景。</p><ol start="2"><li>优点</li></ol><p><strong>思考：在Reduce端处理过多的表，非常容易产生数据倾斜。怎么办？</strong></p><p>在Map端缓存多张表，提前处理业务逻辑，这样增加Map端业务，减少Reduce端数据的压力，尽可能的减少数据倾斜。</p><ol start="3"><li>具体办法：采用DistributedCache</li></ol><p>（1）在Mapper的setup阶段，将文件读取到缓存集合中。</p><p>（2）在驱动函数中加载缓存。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 缓存普通文件到Task运行节点。</span>job<span class="token punctuation">.</span><span class="token function">addCacheFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"file://d:/pd.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="Map-Join案例"><a href="#Map-Join案例" class="headerlink" title="Map Join案例"></a>Map Join案例</h4><ol><li>需求（同上）</li></ol><p>将商品信息表中数据根据商品pid合并到订单数据表中。</p><ol start="2"><li>需求分析</li></ol><p>MapJoin适用于关联表中有小表的情形。</p><p><img src="53.png" alt></p><ol start="3"><li>实现代码</li></ol><p>（1）在驱动模块中添加缓存文件</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>cache<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URI<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URISyntaxException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/15 上午 09:17 * @Func: 驱动 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DistributedCacheDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 0 根据自己电脑路径重新配置</span><span class="token comment" spellcheck="true">//        args = new String[]{"e:/input/inputtable2", "e:/output1"};</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/inputTable/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job信息</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置加载jar包路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>DistributedCacheDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联map</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>DistributedCacheMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出数据类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 加载缓存数据</span>        job<span class="token punctuation">.</span><span class="token function">addCacheFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"file:///d:/scwri/Desktop/cache/pd.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 8 提交</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）读取缓存的文件数据</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>cache<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">.</span>TableBean<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>commons<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>StringUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BufferedReader<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FileInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>InputStreamReader<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URI<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HashMap<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/15 上午 09:24 * @Func: 缓存mapper */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DistributedCacheMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> pdMap <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">setup</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 缓存小表</span>        URI<span class="token punctuation">[</span><span class="token punctuation">]</span> cacheFiles <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">getCacheFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String path <span class="token operator">=</span> cacheFiles<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        BufferedReader reader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">InputStreamReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String line<span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>StringUtils<span class="token punctuation">.</span><span class="token function">isNotEmpty</span><span class="token punctuation">(</span>line <span class="token operator">=</span> reader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获取数据不为空，进行切割</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            pdMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>reader<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 拿到一行进行切割</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从map里面获取pName</span>        String pid <span class="token operator">=</span> detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        String pName <span class="token operator">=</span> pdMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>pid<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 封装</span>        line <span class="token operator">=</span> line <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> pName<span class="token punctuation">;</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="计数器应用"><a href="#计数器应用" class="headerlink" title="计数器应用"></a>计数器应用</h3><p><img src="54.png" alt></p><h3 id="数据清洗（ETL）"><a href="#数据清洗（ETL）" class="headerlink" title="数据清洗（ETL）"></a>数据清洗（ETL）</h3><p>在运行核心业务MapReduce程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。清理的过程往往只需要运行Mapper程序，不需要运行Reduce程序。</p><h4 id="数据清洗案例-简单解析版"><a href="#数据清洗案例-简单解析版" class="headerlink" title="数据清洗案例-简单解析版"></a>数据清洗案例-简单解析版</h4><ol><li>需求</li></ol><p>去除日志中字段长度小于等于11的日志。</p><p>（1）输入数据 （非常多，但是跟下面类似）</p><pre><code>    194.237.142.21 - - [18/Sep/2013:06:49:18 +0000] &quot;GET /wp-content/uploads/2013/07/rstudio-git3.png HTTP/1.1&quot; 304 0 &quot;-&quot; &quot;Mozilla/4.0 (compatible;)&quot;    183.49.46.228 - - [18/Sep/2013:06:49:23 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;    163.177.71.12 - - [18/Sep/2013:06:49:33 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    163.177.71.12 - - [18/Sep/2013:06:49:36 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    101.226.68.137 - - [18/Sep/2013:06:49:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    101.226.68.137 - - [18/Sep/2013:06:49:45 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;    ...</code></pre><p>（2）期望输出数据</p><p>每行字段长度都大于11。</p><ol start="2"><li>需求分析</li></ol><p>需要在Map阶段对输入的数据根据规则进行过滤清洗。</p><ol start="3"><li>实现代码</li></ol><p>（1）编写LogMapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/16 下午 04:23 * @Func: Mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">logMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 解析数据</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> <span class="token function">parseLog</span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>result<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> <span class="token function">parseLog</span><span class="token punctuation">(</span>String line<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>detail<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">getCounter</span><span class="token punctuation">(</span><span class="token string">"map"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">increment</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">getCounter</span><span class="token punctuation">(</span><span class="token string">"map"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">increment</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写LogDriver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/16 下午 04:23 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">logDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/inputWeb/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job信息</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 加载jar包</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>logDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联map</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>logMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置reducetask个数为0</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 提交</span>        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="数据清洗案例实操-复杂解析版"><a href="#数据清洗案例实操-复杂解析版" class="headerlink" title="数据清洗案例实操-复杂解析版"></a>数据清洗案例实操-复杂解析版</h4><p>1．需求</p><p>对Web访问日志中的各字段识别切分，去除日志中不合法的记录。根据清洗规则，输出过滤后的数据。</p><p>（1）输入数据</p><p>同上</p><p>（2）期望输出数据</p><p>都是合法的数据</p><p>2．实现代码</p><p>（1）定义一个bean，用来记录日志数据中的各数据字段（除了信息还有）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogBean</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> String remote_addr<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录客户端的ip地址</span>    <span class="token keyword">private</span> String remote_user<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录客户端用户名称,忽略属性"-"</span>    <span class="token keyword">private</span> String time_local<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录访问时间与时区</span>    <span class="token keyword">private</span> String request<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录请求的url与http协议</span>    <span class="token keyword">private</span> String status<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录请求状态；成功是200</span>    <span class="token keyword">private</span> String body_bytes_sent<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录发送给客户端文件主体内容大小</span>    <span class="token keyword">private</span> String http_referer<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 用来记录从那个页面链接访问过来的</span>    <span class="token keyword">private</span> String http_user_agent<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录客户浏览器的相关信息</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> valid <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 判断数据是否合法</span>    <span class="token keyword">public</span> String <span class="token function">getRemote_addr</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> remote_addr<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setRemote_addr</span><span class="token punctuation">(</span>String remote_addr<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>remote_addr <span class="token operator">=</span> remote_addr<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getRemote_user</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> remote_user<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setRemote_user</span><span class="token punctuation">(</span>String remote_user<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>remote_user <span class="token operator">=</span> remote_user<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getTime_local</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> time_local<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setTime_local</span><span class="token punctuation">(</span>String time_local<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>time_local <span class="token operator">=</span> time_local<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getRequest</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> request<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setRequest</span><span class="token punctuation">(</span>String request<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>request <span class="token operator">=</span> request<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> status<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setStatus</span><span class="token punctuation">(</span>String status<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>status <span class="token operator">=</span> status<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getBody_bytes_sent</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> body_bytes_sent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setBody_bytes_sent</span><span class="token punctuation">(</span>String body_bytes_sent<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>body_bytes_sent <span class="token operator">=</span> body_bytes_sent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getHttp_referer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> http_referer<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setHttp_referer</span><span class="token punctuation">(</span>String http_referer<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>http_referer <span class="token operator">=</span> http_referer<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getHttp_user_agent</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> http_user_agent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setHttp_user_agent</span><span class="token punctuation">(</span>String http_user_agent<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>http_user_agent <span class="token operator">=</span> http_user_agent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isValid</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> valid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setValid</span><span class="token punctuation">(</span><span class="token keyword">boolean</span> valid<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>valid <span class="token operator">=</span> valid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        StringBuilder sb <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>valid<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 使用特殊字段（"\001"）拼接，因为其他的可能原来字符串中就可能有</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>remote_addr<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>remote_user<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>time_local<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>status<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>body_bytes_sent<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>http_referer<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>http_user_agent<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> sb<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写LogMapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span><span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取1行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 解析日志是否合法</span>        LogBean bean <span class="token operator">=</span> <span class="token function">parseLog</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>bean<span class="token punctuation">.</span><span class="token function">isValid</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>bean<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 解析日志</span>    <span class="token keyword">private</span> LogBean <span class="token function">parseLog</span><span class="token punctuation">(</span>String line<span class="token punctuation">)</span> <span class="token punctuation">{</span>        LogBean logBean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LogBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 截取</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>fields<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">11</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 2封装数据</span>            logBean<span class="token punctuation">.</span><span class="token function">setRemote_addr</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setRemote_user</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setTime_local</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setRequest</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setStatus</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setBody_bytes_sent</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setHttp_referer</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>fields<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">12</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                logBean<span class="token punctuation">.</span><span class="token function">setHttp_user_agent</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span><span class="token operator">+</span> fields<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>                logBean<span class="token punctuation">.</span><span class="token function">setHttp_user_agent</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">// 大于400，HTTP错误</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>logBean<span class="token punctuation">.</span><span class="token function">getStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">400</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                logBean<span class="token punctuation">.</span><span class="token function">setValid</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            logBean<span class="token punctuation">.</span><span class="token function">setValid</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> logBean<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写LogDriver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span><span class="token comment" spellcheck="true">// 1 获取job信息</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 加载jar包</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>LogDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联map</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>LogMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 提交</span>        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MapReduce开发总结"><a href="#MapReduce开发总结" class="headerlink" title="MapReduce开发总结"></a>MapReduce开发总结</h3><p>在编写MapReduce程序时，需要考虑如下几个方面：</p><p><img src="55.png" alt></p><p><img src="56.png" alt></p><p><img src="57.png" alt></p><p><img src="58.png" alt></p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>MapReduce的工作原理终于弄完了，这是比较重要一章吧，感觉面试基本都会问（不过现在好像mr用的不是那么多了，Spark好像挺多的）。</p><p>接下来是Hadoop数据压缩</p><blockquote><p>屁屁好像要进入每年中的加班时间段了，希望她不会太累<br>希望自己能尽快找到一个更好的自己喜欢的sx，不断进步~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-MapReduce-序列化（MapReduce系列二）</title>
      <link href="2020/09/07/hadoop-mapreduce-xu-lie-hua-mapreduce-xi-lie-er/"/>
      <url>2020/09/07/hadoop-mapreduce-xu-lie-hua-mapreduce-xi-lie-er/</url>
      
        <content type="html"><![CDATA[<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="Hadoop序列化"><a href="#Hadoop序列化" class="headerlink" title="Hadoop序列化"></a>Hadoop序列化</h2><h3 id="序列化概述"><a href="#序列化概述" class="headerlink" title="序列化概述"></a>序列化概述</h3><p><img src="11.png" alt></p><p><img src="12.png" alt></p><p>内存中对象有：数组、集合等</p><h3 id="自定义bean对象实现序列化接口（Writable）"><a href="#自定义bean对象实现序列化接口（Writable）" class="headerlink" title="自定义bean对象实现序列化接口（Writable）"></a>自定义bean对象实现序列化接口（Writable）</h3><p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在Hadoop框架内部传递一个bean对象，那么该对象就需要实现序列化接口。</p><p>具体实现bean对象序列化步骤如下7步。</p><p>（1）必须实现Writable接口</p><p>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）重写序列化方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput out<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>    out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）重写反序列化方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput in<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>    upFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    downFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    sumFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）<strong>注意反序列化的顺序和序列化的顺序完全一致（序列化先操作的upFlow，则反序列化应该也是先操作upFlow,其他同理）</strong></p><p>比如说两个服务器A，B，要从A服务器将其传递到B。这就相当于是一个队列，A中序列化顺序为upFlow-&gt;downFlow-&gt;sumFlow，则在B中反序列化存储时，就应该先进先出来操作。</p><p>（6）要想把结果显示在文件中，需要重写toString()，可用”\t”分开，方便后续用。</p><p>（7）如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为MapReduce框中的Shuffle过程要求对key必须能排序。详见后面排序案例。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowBean o<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 倒序排列，从大到小</span>    <span class="token keyword">return</span> <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">></span> o<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="序列化案例实操"><a href="#序列化案例实操" class="headerlink" title="序列化案例实操"></a>序列化案例实操</h3><ol><li>需求</li></ol><p>统计每一个手机号耗费的总上行流量、下行流量、总流量</p><p>（1）输入数据（文件内容）</p><pre><code>1    13736230513    192.196.100.1    www.baidu.com    2481    24681    2002    13846544121    192.196.100.2            264    0    2003     13956435636    192.196.100.3            132    1512    2004     13966251146    192.168.100.1            240    0    4045     18271575951    192.168.100.2    www.bilibili.com    1527    2106    2006     84188413    192.168.100.3    www.baidu.com    4116    1432    2007     13590439668    192.168.100.4            1116    954    2008     15910133277    192.168.100.5    www.hao123.com    3156    2936    2009     13729199489    192.168.100.6            240    0    20010     13630577991    192.168.100.7    www.shouhu.com    6960    690    20011     15043685818    192.168.100.8    www.baidu.com    3659    3538    20012     15959002129    192.168.100.9    www.baidu.com    1938    180    50013     13560439638    192.168.100.10            918    4938    20014     13470253144    192.168.100.11            180    180    20015     13682846555    192.168.100.12    www.qq.com    1938    2910    20016     13992314666    192.168.100.13    www.gaga.com    3008    3720    20017     13509468723    192.168.100.14    www.sogou.com    7335    110349    40418     18390173782    192.168.100.15    www.sogou.com    9531    2412    20019     13975057813    192.168.100.16    www.baidu.com    11058    48243    20020     13768778790    192.168.100.17            120    120    20021     13568436656    192.168.100.18    www.alibaba.com    2481    24681    20022     13568436656    192.168.100.19            1116    954    200</code></pre><p>（2）输入数据格式：</p><table><thead><tr><th>id</th><th>手机号码</th><th>网络ip</th><th>上行流量</th><th>下行流量</th><th>网络状态码</th></tr></thead><tbody><tr><td>7</td><td>13560436666</td><td>120.196.100.99</td><td>1116</td><td>954</td><td>200</td></tr></tbody></table><p>（3）期望输出数据格式</p><table><thead><tr><th>手机号码</th><th>上行流量</th><th>下行流量</th><th>总流量</th></tr></thead><tbody><tr><td>13560436666</td><td>1116</td><td>954</td><td>2070</td></tr></tbody></table><ol start="2"><li>需求分析</li></ol><p><img src="13.png" alt></p><ol start="3"><li>编写MapReduce程序</li></ol><p>（1）编写流量统计的Bean对象</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Writable<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 1 实现writable接口</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowBean</span> <span class="token keyword">implements</span> <span class="token class-name">Writable</span><span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> upFlow<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 上行流量</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 下行流量</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> sumFlow<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 总流量</span>    <span class="token comment" spellcheck="true">//2  反射调用空参构造函数</span>    <span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//3  写序列化方法</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput out<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//4 反序列化方法</span>    <span class="token comment" spellcheck="true">//5 反序列化方法读顺序必须和写序列化方法的写顺序必须一致</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput in<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow  <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 6 编写toString方法，方便后续打印到文本</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> downFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> sumFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Mapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span><span class="token punctuation">{</span>    FlowBean v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割字段</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 封装对象</span>        <span class="token comment" spellcheck="true">// 取出手机号码</span>        String phoneNum <span class="token operator">=</span> fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 取出上行流量和下行流量</span>        <span class="token keyword">long</span> upFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span>fields<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> downFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span>fields<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>phoneNum<span class="token punctuation">)</span><span class="token punctuation">;</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">,</span> upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Reducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> FlowBean<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>FlowBean<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span><span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">long</span> sum_upFlow <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> sum_downFlow <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 遍历所用bean，将其中的上行流量，下行流量分别累加</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>FlowBean flowBean <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum_upFlow <span class="token operator">+=</span> flowBean<span class="token punctuation">.</span><span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            sum_downFlow <span class="token operator">+=</span> flowBean<span class="token punctuation">.</span><span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 2 封装对象</span>        FlowBean resultBean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span>sum_upFlow<span class="token punctuation">,</span> sum_downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> resultBean<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写Driver驱动类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowsumDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IllegalArgumentException<span class="token punctuation">,</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span><span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input/test.txt"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息，或者job对象实例</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 指定本程序的jar包所在的本地路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowsumDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 指定本业务job要使用的mapper/Reducer业务类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 指定mapper输出数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 指定最终输出的数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 指定job的输入原始文件所在目录</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-MapReduce-概述（MapReduce系列一）</title>
      <link href="2020/09/06/hadoop-mapreduce-gai-shu-mapreduce-xi-lie-yi/"/>
      <url>2020/09/06/hadoop-mapreduce-gai-shu-mapreduce-xi-lie-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="MapReduce概述"><a href="#MapReduce概述" class="headerlink" title="MapReduce概述"></a>MapReduce概述</h2><h3 id="MapReduce定义"><a href="#MapReduce定义" class="headerlink" title="MapReduce定义"></a>MapReduce定义</h3><p><img src="1.png" alt></p><h3 id="MapReduce优缺点"><a href="#MapReduce优缺点" class="headerlink" title="MapReduce优缺点"></a>MapReduce优缺点</h3><p>优点</p><p><img src="2.png" alt></p><p><img src="3.png" alt></p><p>缺点</p><p><img src="4.png" alt></p><h3 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h3><p><img src="5.png" alt></p><p>分布式的运算程序往往需要分成至少2个阶段。</p><p>1）第一个阶段的MapTask并发实例，完全并行运行，互不相干。</p><p>2）第二个阶段的ReduceTask并发实例互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出。</p><p>3）MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，串行运行(前一个MapReduce模型输出作为后一个MapReduce模型的输入)。</p><p>总结：分析WordCount数据流走向深入理解MapReduce核心思想。</p><h3 id="MapReduce进程"><a href="#MapReduce进程" class="headerlink" title="MapReduce进程"></a>MapReduce进程</h3><p><img src="6.png" alt></p><p>通俗点讲，AppMaster相当于一个job的老大，ResourceManager相当于所有的老大，NodeManager相当于单个节点的老大。</p><h3 id="官方WordCount源码"><a href="#官方WordCount源码" class="headerlink" title="官方WordCount源码"></a>官方WordCount源码</h3><p>采用反编译工具反编译源码，发现WordCount案例有Map类、Reduce类和驱动类。且数据的类型是Hadoop自身封装的序列化类型。</p><h3 id="常用数据序列化类型"><a href="#常用数据序列化类型" class="headerlink" title="常用数据序列化类型"></a>常用数据序列化类型</h3><table><thead><tr><th>Java类型</th><th>Hadoop Write 类型</th></tr></thead><tbody><tr><td>boolean</td><td>BooleanWritable</td></tr><tr><td>byte</td><td>ByteWritable</td></tr><tr><td>int</td><td>IntWritable</td></tr><tr><td>float</td><td>FloatWritable</td></tr><tr><td>long</td><td>LongWritable</td></tr><tr><td>double</td><td>DoubleWritable</td></tr><tr><td>String</td><td>Text</td></tr><tr><td>map</td><td>MapWritable</td></tr><tr><td>array</td><td>ArrayWritable</td></tr></tbody></table><h3 id="MapReduce编程规范"><a href="#MapReduce编程规范" class="headerlink" title="MapReduce编程规范"></a>MapReduce编程规范</h3><p>用户编写的程序分成三个部分：Mapper、Reducer和Driver。</p><p><img src="7.png" alt></p><p><img src="8.png" alt></p><p><img src="9.png" alt></p><h3 id="WordCount案例实操"><a href="#WordCount案例实操" class="headerlink" title="WordCount案例实操"></a>WordCount案例实操</h3><p>1．需求</p><p>在给定的文本文件中统计输出每一个单词出现的总次数</p><p>2．需求分析</p><p>按照MapReduce编程规范，分别编写Mapper，Reducer，Driver</p><p>Mapper，Reducer工作已经了解，下面是Driver工作</p><p><img src="9.png" alt></p><p>3．环境准备</p><p>（1）创建maven工程</p><p>（2）在pom.xml文件中添加如下依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>RELEASE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.8.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-hdfs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入。</p><pre class="line-numbers language-properties"><code class="language-properties"><span class="token attr-name">log4j.rootLogger</span><span class="token punctuation">=</span><span class="token attr-value">INFO, stdout</span><span class="token attr-name">log4j.appender.stdout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.ConsoleAppender</span><span class="token attr-name">log4j.appender.stdout.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.stdout.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d %p [%c] - %m%n</span><span class="token attr-name">log4j.appender.logfile</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.FileAppender</span><span class="token attr-name">log4j.appender.logfile.File</span><span class="token punctuation">=</span><span class="token attr-value">target/spring.log</span><span class="token attr-name">log4j.appender.logfile.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.logfile.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d %p [%c] - %m%n</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．编写程序<br>（1）编写Mapper类</p><p>LongWritable：KEYIN 输入数据的key（读取游标）<br>Text：VALUEIN 输入数据value（输入文本）<br>输出数据类型 &lt;sc, 1&gt;, &lt;ss, 2&gt;…<br>Text：KEYOUT 输出数据key类型<br>IntWritable：VALUEOUT 输出数据value类型</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Reducer类</p><p>map阶段输出的kv</p><p>Text：KEYIN<br>IntWritable： VALUEIN</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token punctuation">{</span><span class="token keyword">int</span> sum<span class="token punctuation">;</span>IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 累加求和</span>        sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>IntWritable count <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum <span class="token operator">+=</span> count<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 2 输出</span>       v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Driver驱动类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息以及封装任务</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置jar加载路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 设置map和reduce类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置map输出</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5．本地测试</p><p>（1）如果电脑系统是win7的就将win7的hadoop jar包解压到非中文路径，并在Windows环境上配置HADOOP_HOME环境变量。如果是电脑win10操作系统，就解压win10的hadoop jar包，并配置HADOOP_HOME环境变量。</p><p><strong>注意：win8电脑和win10家庭版操作系统可能有问题，需要重新编译源码或者更改操作系统。</strong></p><p>（2）在Idea上运行程序</p><p>注意在运行添加arguments时，输出路径(args[1])要定位到一个现在还没有的<strong>路径</strong>，而不是一个文件（比如：d:/scwri/Desktop/output，其中output是现在并不存在的一个路径）</p><p>6．集群上测试</p><p>（0）用maven打jar包，需要添加的打包插件依赖</p><p>注意：标记红颜色的部分需要替换为自己工程主类</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.3.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">></span></span>com.atguigu.mr.WordcountDriver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果maven修改后，有红叉。则可以将maven设置成自动导入，点击file再点settings，然后搜多maven 如下：</p><p><img src="10.png" alt></p><p>（1）将程序打成jar包，然后拷贝到Hadoop集群中</p><p>[exlipse]</p><p>步骤：右键 -&gt; Run as -&gt; maven install。等待编译完成就会在项目的target文件夹中生成jar包。如果看不到。在项目上右键-》Refresh，即可看到。修改不带依赖的jar包名称为wc.jar，并拷贝该jar包到Hadoop集群。</p><p>[idea]</p><p>步骤：右键项目 -&gt; Run Maven -&gt; install。然后就跟上面一样的操作。</p><p>（2）启动Hadoop集群</p><p>（3）执行WordCount程序</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop jar  wc.jar com.swenchao.mr.wordcount.WordcountDriver /user/test/input/test.txt /user/atguigu/output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>其中输出路径（/user/atguigu/output）必须是之前不存在的；输入文件（test.txt）是已经上传的。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-MapReduce-完整版笔记</title>
      <link href="2020/09/06/hadoop-mapreduce-wan-zheng-ban-bi-ji/"/>
      <url>2020/09/06/hadoop-mapreduce-wan-zheng-ban-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="MapReduce-概述"><a href="#MapReduce-概述" class="headerlink" title="MapReduce 概述"></a>MapReduce 概述</h2><h3 id="MapReduce-定义"><a href="#MapReduce-定义" class="headerlink" title="MapReduce 定义"></a>MapReduce 定义</h3><p><img src="1.png" alt></p><h3 id="MapReduce-优缺点"><a href="#MapReduce-优缺点" class="headerlink" title="MapReduce 优缺点"></a>MapReduce 优缺点</h3><p>优点</p><p><img src="2.png" alt></p><p><img src="3.png" alt></p><p>缺点</p><p><img src="4.png" alt></p><h3 id="MapReduce-核心思想"><a href="#MapReduce-核心思想" class="headerlink" title="MapReduce 核心思想"></a>MapReduce 核心思想</h3><p><img src="5.png" alt></p><p>分布式的运算程序往往需要分成至少 2 个阶段。</p><p>1）第一个阶段的 MapTask 并发实例，完全并行运行，互不相干。</p><p>2）第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段的所有 MapTask 并发实例的输出。</p><p>3）MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行(前一个 MapReduce 模型输出作为后一个 MapReduce 模型的输入)。</p><p>总结：分析 WordCount 数据流走向深入理解 MapReduce 核心思想。</p><h3 id="MapReduce-进程"><a href="#MapReduce-进程" class="headerlink" title="MapReduce 进程"></a>MapReduce 进程</h3><p><img src="6.png" alt></p><p>通俗点讲，AppMaster 相当于一个 job 的老大，ResourceManager 相当于所有的老大，NodeManager 相当于单个节点的老大。</p><h3 id="官方-WordCount-源码"><a href="#官方-WordCount-源码" class="headerlink" title="官方 WordCount 源码"></a>官方 WordCount 源码</h3><p>采用反编译工具反编译源码，发现 WordCount 案例有 Map 类、Reduce 类和驱动类。且数据的类型是 Hadoop 自身封装的序列化类型。</p><h3 id="常用数据序列化类型"><a href="#常用数据序列化类型" class="headerlink" title="常用数据序列化类型"></a>常用数据序列化类型</h3><table><thead><tr><th>Java 类型</th><th>Hadoop Write 类型</th></tr></thead><tbody><tr><td>boolean</td><td>BooleanWritable</td></tr><tr><td>byte</td><td>ByteWritable</td></tr><tr><td>int</td><td>IntWritable</td></tr><tr><td>float</td><td>FloatWritable</td></tr><tr><td>long</td><td>LongWritable</td></tr><tr><td>double</td><td>DoubleWritable</td></tr><tr><td>String</td><td>Text</td></tr><tr><td>map</td><td>MapWritable</td></tr><tr><td>array</td><td>ArrayWritable</td></tr></tbody></table><h3 id="MapReduce-编程规范"><a href="#MapReduce-编程规范" class="headerlink" title="MapReduce 编程规范"></a>MapReduce 编程规范</h3><p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。</p><p><img src="7.png" alt></p><p><img src="8.png" alt></p><p><img src="9.png" alt></p><h3 id="WordCount-案例实操"><a href="#WordCount-案例实操" class="headerlink" title="WordCount 案例实操"></a>WordCount 案例实操</h3><p>1．需求</p><p>在给定的文本文件中统计输出每一个单词出现的总次数</p><p>2．需求分析</p><p>按照 MapReduce 编程规范，分别编写 Mapper，Reducer，Driver</p><p>Mapper，Reducer 工作已经了解，下面是 Driver 工作</p><p><img src="9.png" alt></p><p>3．环境准备</p><p>（1）创建 maven 工程</p><p>（2）在 pom.xml 文件中添加如下依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>RELEASE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.8.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-hdfs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在项目的 src/main/resources 目录下，新建一个文件，命名为“log4j.properties”，在文件中填入。</p><pre class="line-numbers language-properties"><code class="language-properties"><span class="token attr-name">log4j.rootLogger</span><span class="token punctuation">=</span><span class="token attr-value">INFO, stdout</span><span class="token attr-name">log4j.appender.stdout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.ConsoleAppender</span><span class="token attr-name">log4j.appender.stdout.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.stdout.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d %p [%c] - %m%n</span><span class="token attr-name">log4j.appender.logfile</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.FileAppender</span><span class="token attr-name">log4j.appender.logfile.File</span><span class="token punctuation">=</span><span class="token attr-value">target/spring.log</span><span class="token attr-name">log4j.appender.logfile.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.logfile.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d %p [%c] - %m%n</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．编写程序<br>（1）编写 Mapper 类</p><p>LongWritable：KEYIN 输入数据的 key（读取游标）<br>Text：VALUEIN 输入数据 value（输入文本）<br>输出数据类型 &lt;sc, 1&gt;, &lt;ss, 2&gt;…<br>Text：KEYOUT 输出数据 key 类型<br>IntWritable：VALUEOUT 输出数据 value 类型</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 Reducer 类</p><p>map 阶段输出的 kv</p><p>Text：KEYIN<br>IntWritable： VALUEIN</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token punctuation">{</span><span class="token keyword">int</span> sum<span class="token punctuation">;</span>IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 累加求和</span>        sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>IntWritable count <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum <span class="token operator">+=</span> count<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 2 输出</span>       v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 Driver 驱动类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息以及封装任务</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置jar加载路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 设置map和reduce类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置map输出</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5．本地测试</p><p>（1）如果电脑系统是 win7 的就将 win7 的 hadoop jar 包解压到非中文路径，并在 Windows 环境上配置 HADOOP_HOME 环境变量。如果是电脑 win10 操作系统，就解压 win10 的 hadoop jar 包，并配置 HADOOP_HOME 环境变量。</p><p><strong>注意：win8 电脑和 win10 家庭版操作系统可能有问题，需要重新编译源码或者更改操作系统。</strong></p><p>（2）在 Idea 上运行程序</p><p>注意在运行添加 arguments 时，输出路径(args[1])要定位到一个现在还没有的<strong>路径</strong>，而不是一个文件（比如：d:/scwri/Desktop/output，其中 output 是现在并不存在的一个路径）</p><p>6．集群上测试</p><p>（0）用 maven 打 jar 包，需要添加的打包插件依赖</p><p>注意：标记红颜色的部分需要替换为自己工程主类</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.3.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">></span></span>com.atguigu.mr.WordcountDriver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果 maven 修改后，有红叉。则可以将 maven 设置成自动导入，点击 file 再点 settings，然后搜多 maven 如下：</p><p><img src="10.png" alt></p><p>（1）将程序打成 jar 包，然后拷贝到 Hadoop 集群中</p><p>[exlipse]</p><p>步骤：右键 -&gt; Run as -&gt; maven install。等待编译完成就会在项目的 target 文件夹中生成 jar 包。如果看不到。在项目上右键-》Refresh，即可看到。修改不带依赖的 jar 包名称为 wc.jar，并拷贝该 jar 包到 Hadoop 集群。</p><p>[idea]</p><p>步骤：右键项目 -&gt; Run Maven -&gt; install。然后就跟上面一样的操作。</p><p>（2）启动 Hadoop 集群</p><p>（3）执行 WordCount 程序</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop jar  wc.jar com.swenchao.mr.wordcount.WordcountDriver /user/test/input/test.txt /user/atguigu/output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注：</strong>其中输出路径（/user/atguigu/output）必须是之前不存在的；输入文件（test.txt）是已经上传的。</p><h2 id="Hadoop-序列化"><a href="#Hadoop-序列化" class="headerlink" title="Hadoop 序列化"></a>Hadoop 序列化</h2><h3 id="序列化概述"><a href="#序列化概述" class="headerlink" title="序列化概述"></a>序列化概述</h3><p><img src="11.png" alt></p><p><img src="12.png" alt></p><p>内存中对象有：数组、集合等</p><h3 id="自定义-bean-对象实现序列化接口（Writable）"><a href="#自定义-bean-对象实现序列化接口（Writable）" class="headerlink" title="自定义 bean 对象实现序列化接口（Writable）"></a>自定义 bean 对象实现序列化接口（Writable）</h3><p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在 Hadoop 框架内部传递一个 bean 对象，那么该对象就需要实现序列化接口。</p><p>具体实现 bean 对象序列化步骤如下 7 步。</p><p>（1）必须实现 Writable 接口</p><p>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）重写序列化方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput out<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>    out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）重写反序列化方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput in<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>    upFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    downFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    sumFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）<strong>注意反序列化的顺序和序列化的顺序完全一致（序列化先操作的 upFlow，则反序列化应该也是先操作 upFlow,其他同理）</strong></p><p>比如说两个服务器 A，B，要从 A 服务器将其传递到 B。这就相当于是一个队列，A 中序列化顺序为 upFlow-&gt;downFlow-&gt;sumFlow，则在 B 中反序列化存储时，就应该先进先出来操作。</p><p>（6）要想把结果显示在文件中，需要重写 toString()，可用”\t”分开，方便后续用。</p><p>（7）如果需要将自定义的 bean 放在 key 中传输，则还需要实现 Comparable 接口，因为 MapReduce 框中的 Shuffle 过程要求对 key 必须能排序。详见后面排序案例。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowBean o<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 倒序排列，从大到小</span>    <span class="token keyword">return</span> <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">></span> o<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="序列化案例实操"><a href="#序列化案例实操" class="headerlink" title="序列化案例实操"></a>序列化案例实操</h3><ol><li>需求</li></ol><p>统计每一个手机号耗费的总上行流量、下行流量、总流量</p><p>（1）输入数据（文件内容）</p><pre><code>1    13736230513    192.196.100.1    www.baidu.com    2481    24681    2002    13846544121    192.196.100.2            264    0    2003     13956435636    192.196.100.3            132    1512    2004     13966251146    192.168.100.1            240    0    4045     18271575951    192.168.100.2    www.bilibili.com    1527    2106    2006     84188413    192.168.100.3    www.baidu.com    4116    1432    2007     13590439668    192.168.100.4            1116    954    2008     15910133277    192.168.100.5    www.hao123.com    3156    2936    2009     13729199489    192.168.100.6            240    0    20010     13630577991    192.168.100.7    www.shouhu.com    6960    690    20011     15043685818    192.168.100.8    www.baidu.com    3659    3538    20012     15959002129    192.168.100.9    www.baidu.com    1938    180    50013     13560439638    192.168.100.10            918    4938    20014     13470253144    192.168.100.11            180    180    20015     13682846555    192.168.100.12    www.qq.com    1938    2910    20016     13992314666    192.168.100.13    www.gaga.com    3008    3720    20017     13509468723    192.168.100.14    www.sogou.com    7335    110349    40418     18390173782    192.168.100.15    www.sogou.com    9531    2412    20019     13975057813    192.168.100.16    www.baidu.com    11058    48243    20020     13768778790    192.168.100.17            120    120    20021     13568436656    192.168.100.18    www.alibaba.com    2481    24681    20022     13568436656    192.168.100.19            1116    954    200</code></pre><p>（2）输入数据格式：</p><table><thead><tr><th>id</th><th>手机号码</th><th>网络 ip</th><th>上行流量</th><th>下行流量</th><th>网络状态码</th></tr></thead><tbody><tr><td>7</td><td>13560436666</td><td>120.196.100.99</td><td>1116</td><td>954</td><td>200</td></tr></tbody></table><p>（3）期望输出数据格式</p><table><thead><tr><th>手机号码</th><th>上行流量</th><th>下行流量</th><th>总流量</th></tr></thead><tbody><tr><td>13560436666</td><td>1116</td><td>954</td><td>2070</td></tr></tbody></table><ol start="2"><li>需求分析</li></ol><p><img src="13.png" alt></p><ol start="3"><li>编写 MapReduce 程序</li></ol><p>（1）编写流量统计的 Bean 对象</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Writable<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 1 实现writable接口</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowBean</span> <span class="token keyword">implements</span> <span class="token class-name">Writable</span><span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> upFlow<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 上行流量</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 下行流量</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> sumFlow<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 总流量</span>    <span class="token comment" spellcheck="true">//2  反射调用空参构造函数</span>    <span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//3  写序列化方法</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput out<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//4 反序列化方法</span>    <span class="token comment" spellcheck="true">//5 反序列化方法读顺序必须和写序列化方法的写顺序必须一致</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput in<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow  <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 6 编写toString方法，方便后续打印到文本</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> downFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> sumFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 Mapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span><span class="token punctuation">{</span>    FlowBean v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割字段</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 封装对象</span>        <span class="token comment" spellcheck="true">// 取出手机号码</span>        String phoneNum <span class="token operator">=</span> fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 取出上行流量和下行流量</span>        <span class="token keyword">long</span> upFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span>fields<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> downFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span>fields<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>phoneNum<span class="token punctuation">)</span><span class="token punctuation">;</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">,</span> upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 Reducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> FlowBean<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>FlowBean<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span><span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">long</span> sum_upFlow <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> sum_downFlow <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 遍历所用bean，将其中的上行流量，下行流量分别累加</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>FlowBean flowBean <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum_upFlow <span class="token operator">+=</span> flowBean<span class="token punctuation">.</span><span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            sum_downFlow <span class="token operator">+=</span> flowBean<span class="token punctuation">.</span><span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 2 封装对象</span>        FlowBean resultBean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span>sum_upFlow<span class="token punctuation">,</span> sum_downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> resultBean<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写 Driver 驱动类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowsumDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IllegalArgumentException<span class="token punctuation">,</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span><span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input/test.txt"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息，或者job对象实例</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 指定本程序的jar包所在的本地路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowsumDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 指定本业务job要使用的mapper/Reducer业务类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 指定mapper输出数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 指定最终输出的数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 指定job的输入原始文件所在目录</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="MapReduce-框架原理"><a href="#MapReduce-框架原理" class="headerlink" title="MapReduce 框架原理"></a>MapReduce 框架原理</h2><h3 id="InputFormat-数据输入"><a href="#InputFormat-数据输入" class="headerlink" title="InputFormat 数据输入"></a>InputFormat 数据输入</h3><h4 id="切片与-MapTask-并行度决定机制"><a href="#切片与-MapTask-并行度决定机制" class="headerlink" title="切片与 MapTask 并行度决定机制"></a>切片与 MapTask 并行度决定机制</h4><p>1．问题引出</p><p>MapTask 的并行度决定 Map 阶段的任务处理并发度，进而影响到整个 Job 的处理速度。</p><p><strong>思考：1G 的数据，启动 8 个 MapTask，可以提高集群的并发处理能力。那么 1K 的数据，也启动 8 个 MapTask，会提高集群性能吗？MapTask 并行任务是否越多越好呢？哪些因素影响了 MapTask 并行度？</strong></p><p>2．MapTask 并行度决定机制</p><p>数据块：Block 是 HDFS 物理上把数据分成一块一块。</p><p>数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。</p><p><img src="14.png" alt></p><p>其中 4）是说，假如在 ss.avi 与 ss2.avi 一块到来时，每个文件单独切片。不会合在一块切，即使刚好能凑成一个整数块的大小。</p><h4 id="Job-提交流程源码和切片源码详解（主要源码）"><a href="#Job-提交流程源码和切片源码详解（主要源码）" class="headerlink" title="Job 提交流程源码和切片源码详解（主要源码）"></a>Job 提交流程源码和切片源码详解（主要源码）</h4><p>1．Job 提交流程源码详解，如下：</p><p><img src="15.png" alt></p><pre class="line-numbers language-java"><code class="language-java"><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 其下面还有一些打印信息的代码</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">/*在这中间有一个是判断状态的，一个是设置新的api的*/</span><span class="token comment" spellcheck="true">// 1建立连接</span><span class="token function">connect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 1）创建提交Job的代理</span>    <span class="token keyword">new</span> <span class="token class-name">Cluster</span><span class="token punctuation">(</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// （1）判断是本地yarn还是远程（主要工作）</span>        <span class="token function">initialize</span><span class="token punctuation">(</span>jobTrackAddr<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 2 提交job</span>submitter<span class="token punctuation">.</span><span class="token function">submitJobInternal</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> cluster<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 1）创建给集群提交数据的Stag路径（每个任务在本地都会创建一个，提交之后就会删除）</span>    Path jobStagingArea <span class="token operator">=</span> JobSubmissionFiles<span class="token punctuation">.</span><span class="token function">getStagingDir</span><span class="token punctuation">(</span>cluster<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2）获取jobid ，并创建Job路径</span>    JobID jobId <span class="token operator">=</span> submitClient<span class="token punctuation">.</span><span class="token function">getNewJobID</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3）拷贝jar包到集群（集群会走这块）</span><span class="token function">copyAndConfigureFiles</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">)</span><span class="token punctuation">;</span>    rUploader<span class="token punctuation">.</span><span class="token function">uploadFiles</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> jobSubmitDir<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 4）计算切片，生成切片规划文件</span><span class="token function">writeSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        maps <span class="token operator">=</span> <span class="token function">writeNewSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> jobSubmitDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        input<span class="token punctuation">.</span><span class="token function">getSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 5）向Stag路径写XML配置文件</span><span class="token function">writeConf</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> submitJobFile<span class="token punctuation">)</span><span class="token punctuation">;</span>    conf<span class="token punctuation">.</span><span class="token function">writeXml</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 6）提交Job,返回提交状态</span>status <span class="token operator">=</span> submitClient<span class="token punctuation">.</span><span class="token function">submitJob</span><span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> job<span class="token punctuation">.</span><span class="token function">getCredentials</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．FileInputFormat 切片源码解析(input.getSplits(job))</p><p><img src="16.png" alt></p><h4 id="FileInputFormat-切片机制"><a href="#FileInputFormat-切片机制" class="headerlink" title="FileInputFormat 切片机制"></a>FileInputFormat 切片机制</h4><p><img src="17.png" alt></p><p><img src="18.png" alt></p><p>从代码中可以看到，本地运行的话，块的大小是 32m。</p><p>文件大小/切片大小，如果大于 1.1，则要进行切片，否则不用切。<br><strong>在集群上，若一个文件 129m，则要存在两个块上，但是只切一片</strong></p><h4 id="CombineTextInputFormat-切片机制"><a href="#CombineTextInputFormat-切片机制" class="headerlink" title="CombineTextInputFormat 切片机制"></a>CombineTextInputFormat 切片机制</h4><p>框架默认的 TextInputFormat 切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的 MapTask，处理效率极其低下。</p><p>1、应用场景：</p><p>CombineTextInputFormat 用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个 MapTask 处理。</p><p>2、虚拟存储切片最大值设置</p><p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</p><p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p><p>3、切片机制</p><p>生成切片过程包括：虚拟存储过程和切片过程二部分。</p><p>（1）虚拟存储过程：</p><p>将输入目录下所有文件大小，依次和设置的 setMaxInputSplitSize 值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值 2 倍，此时将文件均分成 2 个虚拟存储块（防止出现太小切片）。</p><p>例如 setMaxInputSplitSize 值为 4M，输入文件大小为 8.02M，则先逻辑上分成一个 4M。剩余的大小为 4.02M，如果按照 4M 逻辑划分，就会出现 0.02M 的小的虚拟存储文件，所以将剩余的 4.02M 文件切分成（2.01M 和 2.01M）两个文件。</p><p>（2）切片过程：</p><p>（a）判断虚拟存储的文件大小是否大于 setMaxInputSplitSize 值，大于等于则单独形成一个切片。</p><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p><p>（c）测试举例：有 4 个小文件大小分别为 1.7M、5.1M、3.4M 以及 6.8M 这四个小文件，则虚拟存储之后形成 6 个文件块，大小分别为：</p><p>1.7M，（2.55M、2.55M），3.4M 以及（3.4M、3.4M）</p><p>最终会形成 3 个切片，大小分别为：</p><p>（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p><p>若有一个 10m 的文件来切分的话，则会切成 4+3+3，三个文件</p><p><img src="19.png" alt></p><h4 id="CombineTextInputFormat-案例实操"><a href="#CombineTextInputFormat-案例实操" class="headerlink" title="CombineTextInputFormat 案例实操"></a>CombineTextInputFormat 案例实操</h4><p>1．需求</p><p>将输入的大量小文件合并成一个切片统一处理。</p><p>（1）输入数据</p><p>准备 4 个小文件</p><p>（2）期望</p><p>期望一个切片处理 4 个文件</p><p>2．实现过程</p><p>（1）不做任何处理，运行 1.6 节的 WordCount 案例程序，观察切片个数为 4。</p><p>number of splits : 4</p><p>（2）在 WordcountDriver 中增加如下代码，运行程序，并观察运行的切片个数为 3。</p><p>（a）驱动类中添加代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span>job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//虚拟存储切片最大值设置4m</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token function">setMaxInputSplitSize</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">4194304</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）运行如果为 3 个切片。</p><p>number of splits : 3</p><p>（3）在 WordcountDriver 中增加如下代码，运行程序，并观察运行的切片个数为 1。</p><p>（a）驱动中添加代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span>job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//虚拟存储切片最大值设置20m</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token function">setMaxInputSplitSize</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">20971520</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）运行如果为 1 个切片。</p><p>number of splits : 1</p><h4 id="FileInputFormat-实现类"><a href="#FileInputFormat-实现类" class="headerlink" title="FileInputFormat 实现类"></a>FileInputFormat 实现类</h4><p><img src="20.png" alt></p><p><img src="21.png" alt></p><p><img src="22.png" alt></p><p><img src="23.png" alt></p><h4 id="KeyValueTextInputFormat-使用案例"><a href="#KeyValueTextInputFormat-使用案例" class="headerlink" title="KeyValueTextInputFormat 使用案例"></a>KeyValueTextInputFormat 使用案例</h4><p>1．需求</p><p>统计输入文件中每一行的第一个单词相同的行数。</p><p>（1）输入数据</p><pre><code>apple ni haobigdata hadoopapple hellobigdata orange hadoop</code></pre><p>（2）期望结果数据</p><pre><code>apple    2bigdata    2</code></pre><p>2．需求分析</p><p><img src="24.png" alt></p><p>3．代码实现</p><p>（1）编写 Mapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>kv<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KVTextMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">// 1 设置value</span>   LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>            <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span><span class="token comment" spellcheck="true">// banzhang ni hao</span>        <span class="token comment" spellcheck="true">// 2 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 Reducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>kv<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KVTextReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span>    LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>LongWritable<span class="token operator">></span> values<span class="token punctuation">,</span>    Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>         <span class="token keyword">long</span> sum <span class="token operator">=</span> 0L<span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">// 1 汇总统计</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>LongWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 Driver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>kv<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueLineRecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KVTextDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置切割符</span>    conf<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>KeyValueLineRecordReader<span class="token punctuation">.</span>KEY_VALUE_SEPERATOR<span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置jar包位置，关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>KVTextDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>KVTextMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>KVTextReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 设置map输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入输出数据路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入格式</span>    job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>KeyValueTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输出数据路径</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交job</span>        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="NLineInputFormat-使用案例"><a href="#NLineInputFormat-使用案例" class="headerlink" title="NLineInputFormat 使用案例"></a>NLineInputFormat 使用案例</h4><p>1．需求</p><p>对每个单词进行个数统计，要求根据每个输入文件的行数来规定输出多少个切片。此案例要求每三行放入一个切片中。</p><p>（1）输入数据</p><pre><code>apple ni haoorange hadoop appleapple ni haoorange hadoop appleapple ni haoorange hadoop appleapple ni haoorange hadoop appleapple ni haoorange hadoop apple apple ni haoorange hadoop apple</code></pre><p>（2）期望输出数据</p><p>Number of splits:4</p><p>2．需求分析</p><p><img src="25.png" alt></p><p>3．代码实现</p><p>（1）编写 Mapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>nline<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">NLineMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span>    <span class="token keyword">private</span> Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 遍历</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span><span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 Reducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>nline<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">NLineReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> LongWritable<span class="token operator">></span><span class="token punctuation">{</span>    LongWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LongWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>    Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 求和</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>LongWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 Driver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>nline<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URISyntaxException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>NLineInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">NLineDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输入输出路径</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job对象</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7设置每个切片InputSplit中划分三条记录（三行一片）</span>        NLineInputFormat<span class="token punctuation">.</span><span class="token function">setNumLinesPerSplit</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 8使用NLineInputFormat处理记录数</span>        job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>NLineInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2设置jar包位置，关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>NLineDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>NLineMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>NLineReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3设置map输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>LongWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5设置输入输出数据路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="自定义-InputFormat"><a href="#自定义-InputFormat" class="headerlink" title="自定义 InputFormat"></a>自定义 InputFormat</h4><p><img src="26.png" alt></p><h4 id="自定义-InputFormat-案例使用"><a href="#自定义-InputFormat-案例使用" class="headerlink" title="自定义 InputFormat 案例使用"></a>自定义 InputFormat 案例使用</h4><p>无论 HDFS 还是 MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义 InputFormat 实现小文件的合并。</p><p>1．需求</p><p>将多个小文件合并成一个 SequenceFile 文件（SequenceFile 文件是 Hadoop 用来存储二进制形式的 key-value 对的文件格式），SequenceFile 里面存储着多个文件，存储的形式为文件路径+名称为 key，文件内容为 value。</p><p>输入数据</p><p>文件 1</p><pre><code>apple orange bananapear pineapple grape</code></pre><p>文件 2</p><pre><code>Blackberry Blueberry CherryCrabapple Cranberry CumquatBlackberry Blueberry CherryCrabapple Cranberry Cumquat</code></pre><p>文件 3</p><pre><code>zhangsan wangwu zhaoliulisi qianqi sunba</code></pre><p>2．需求分析</p><p><img src="27.png" alt></p><p>3．程序实现</p><p>（1）自定义 InputFromat</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>InputSplit<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 03:13 * @Func: 自定义Inputformat类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInput</span> <span class="token keyword">extends</span> <span class="token class-name">FileInputFormat</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> RecordReader<span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token function">createRecordReader</span><span class="token punctuation">(</span>InputSplit inputSplit<span class="token punctuation">,</span> TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        SelfInputRecordReder recordReder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SelfInputRecordReder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        recordReder<span class="token punctuation">.</span><span class="token function">initialize</span><span class="token punctuation">(</span>inputSplit<span class="token punctuation">,</span> taskAttemptContext<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> recordReder<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）自定义 SelfInputRecordReder 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FileSystem<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileSplit<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>InputSplit<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 03:19 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputRecordReder</span> <span class="token keyword">extends</span> <span class="token class-name">RecordReader</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    FileSplit split<span class="token punctuation">;</span>    Configuration conf<span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    BytesWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BytesWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">boolean</span> isProgress <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span>InputSplit inputSplit<span class="token punctuation">,</span> TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 初始化</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>split <span class="token operator">=</span> <span class="token punctuation">(</span>FileSplit<span class="token punctuation">)</span>inputSplit<span class="token punctuation">;</span>        conf <span class="token operator">=</span> taskAttemptContext<span class="token punctuation">.</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">nextKeyValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 业务逻辑处理(封装最终结果)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>isProgress<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">byte</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>split<span class="token punctuation">.</span><span class="token function">getLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            FileSystem fs <span class="token operator">=</span> null<span class="token punctuation">;</span>            FSDataInputStream fis <span class="token operator">=</span> null<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 获取fs对象（每个切片都能拿到相应的路径）</span>            Path path<span class="token operator">=</span> split<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            fs <span class="token operator">=</span> path<span class="token punctuation">.</span><span class="token function">getFileSystem</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 获取输入流</span>            fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 拷贝(将fis信息读取到buf中；0是从哪开始读；buf.length读取长度)</span>            IOUtils<span class="token punctuation">.</span><span class="token function">readFully</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> buf<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 写入v</span>            v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> buf<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 封装k</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>path<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 关闭集群</span>            IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>            isProgress <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Text <span class="token function">getCurrentKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>       <span class="token keyword">return</span> k<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> BytesWritable <span class="token function">getCurrentValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">return</span> v<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 获取正在处理进程     * @return     * @throws IOException     * @throws InterruptedException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">float</span> <span class="token function">getProgress</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 SelfInputMapper 类处理流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>sun<span class="token punctuation">.</span>crypto<span class="token punctuation">.</span>provider<span class="token punctuation">.</span>HmacPKCS12PBESHA1<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 08:20 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> BytesWritable value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写 SelfInputReducer 类处理流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 08:20 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> BytesWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> BytesWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>BytesWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>BytesWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写 SelfInputDriver 类处理流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>selfInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BytesWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>SequenceFileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/8 下午 08:20 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SelfInputDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>SelfInputDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>SelfInputMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>SelfInputReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>SelfInput<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputFormatClass</span><span class="token punctuation">(</span>SequenceFileOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>BytesWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>BytesWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">boolean</span> res <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>res <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>FileInputFormat 常见接口实现总结</strong></p><table><thead><tr><th>FileInputFormat 常见接口</th><th>切片方式</th><th>默认 key</th><th>默认 value</th></tr></thead><tbody><tr><td>TextInputFormat</td><td>按块（block）的大小来切</td><td>LongWritable（偏移量）</td><td>Text（一行的内容，按行读取）</td></tr><tr><td>KeyValueTextInputFormat</td><td>按块（block）的大小来切</td><td>切完后的第一列</td><td>切完后的剩余列</td></tr><tr><td>NLineTextInputFormat</td><td>按行来切</td><td>LongWritable（偏移量）</td><td>Text（内容）</td></tr><tr><td>CombineTextInputFormat</td><td>跟设置的最大值有关（大于最大值，小于两倍的最大值）</td><td>LongWritable（偏移量）</td><td>Text（一行的内容，按行读取）</td></tr><tr><td>自定义 InputFormat</td><td>按块（block）的大小来切</td><td>跟我们自定义有关</td><td>跟我们自定义有关</td></tr></tbody></table><h3 id="MapReduce-工作流程"><a href="#MapReduce-工作流程" class="headerlink" title="MapReduce 工作流程"></a>MapReduce 工作流程</h3><ol><li>流程示意图，如图:</li></ol><p><img src="28.png" alt></p><p>(1) 其中第 2 步就相当于是切片</p><p>(2) outputController 往环形缓冲区写数据，其中一边是数据一边是数据索引，在数据写到 80%，则将数据全部写入磁盘（本来是在内存中），然后在索引与数据中间位置往回写，如此往复。</p><p>(3) 分区排序中对 key 进行排序用的是快排（这一步是在写入达到 80%才开始或者整个文件写完次才排序）</p><p><img src="29.png" alt></p><p>启动多少个 MapTask 取决于切片多少，启动多少个 ReduceTask 取决于有多少个分区。</p><p>一次读取一组就是，将 key 相同的一块读取出来。</p><p>2．流程详解</p><p>上面的流程是整个 MapReduce 最全工作流程，但是 Shuffle 过程只是从第 7 步开始到第 16 步结束，具体 Shuffle 过程如下：</p><p>1）MapTask 收集我们的 map()方法输出的 kv 对，放到内存缓冲区中</p><p>2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p><p>3）多个溢出文件会被合并成大的溢出文件</p><p>4）在溢出过程及合并的过程中，都要调用 Partitioner 进行分区和针对 key 进行排序</p><p>5）ReduceTask 根据自己的分区号，去各个 MapTask 机器上取相应的结果分区数据</p><p>6）ReduceTask 会取到同一个分区的来自不同 MapTask 的结果文件，ReduceTask 会将这些文件再进行合并（归并排序）</p><p>7）合并成大文件后，Shuffle 的过程也就结束了，后面进入 ReduceTask 的逻辑运算过程（从文件中取出一个一个的键值对 Group，调用用户自定义的 reduce()方法）</p><p>3．注意</p><p>Shuffle 中的缓冲区大小会影响到 MapReduce 程序的执行效率，原则上说，缓冲区越大，磁盘 io 的次数越少，执行速度就越快。</p><p>缓冲区的大小可以通过参数调整，参数：io.sort.mb 默认 100M。</p><h3 id="Shuffle-机制"><a href="#Shuffle-机制" class="headerlink" title="Shuffle 机制"></a>Shuffle 机制</h3><h4 id="Shuffle-机制-1"><a href="#Shuffle-机制-1" class="headerlink" title="Shuffle 机制"></a>Shuffle 机制</h4><p>Map 方法之后，Reduce 方法之前的数据处理过程称之为 Shuffle，如图</p><p><img src="30.png" alt></p><h4 id="Partition-分区"><a href="#Partition-分区" class="headerlink" title="Partition 分区"></a>Partition 分区</h4><p><img src="31.png" alt></p><p><strong>(key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks</strong></p><p>(1) 默认分区是 hashPartition</p><p>(2) 其中 numReduceTasks 默认是 1。</p><p>(3) key.hashCode() &amp; Integer.MAX_VALUE 就是规定 key.hashCode() &lt;= x &lt;= Integer.MAX_VALUE 这么一个范围（因为 Integer.MAX_VALUE 是 11111…. 那么它跟谁进行与操作都是最大是 Integer.MAX_VALUE，所以规定了一个最大值）</p><p><img src="32.png" alt></p><p><img src="33.png" alt></p><h4 id="Partition-分区案例"><a href="#Partition-分区案例" class="headerlink" title="Partition 分区案例"></a>Partition 分区案例</h4><p>1．需求</p><p>将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p><p>（1）输入数据</p><pre><code>1    13736230513    192.196.100.1    www.baidu.com    2481    24681    2002    13846544121    192.196.100.2            264    0    2003     13956435636    192.196.100.3            132    1512    2004     13966251146    192.168.100.1            240    0    4045     18271575951    192.168.100.2    www.bilibili.com    1527    2106    2006     84188413    192.168.100.3    www.baidu.com    4116    1432    2007     13590439668    192.168.100.4            1116    954    2008     15910133277    192.168.100.5    www.hao123.com    3156    2936    2009     13729199489    192.168.100.6            240    0    20010     13630577991    192.168.100.7    www.shouhu.com    6960    690    20011     15043685818    192.168.100.8    www.baidu.com    3659    3538    20012     15959002129    192.168.100.9    www.baidu.com    1938    180    50013     13560439638    192.168.100.10            918    4938    20014     13470253144    192.168.100.11            180    180    20015     13682846555    192.168.100.12    www.qq.com    1938    2910    20016     13992314666    192.168.100.13    www.gaga.com    3008    3720    20017     13509468723    192.168.100.14    www.sogou.com    7335    110349    40418     18390173782    192.168.100.15    www.sogou.com    9531    2412    20019     13975057813    192.168.100.16    www.baidu.com    11058    48243    20020     13768778790    192.168.100.17            120    120    20021     13568436656    192.168.100.18    www.alibaba.com    2481    24681    20022     13568436656    192.168.100.19            1116    954    200</code></pre><p>（2）期望输出数据</p><p>手机号 136、137、138、139 开头都分别放到 4 个独立的文件中，其他开头的放到一个文件中。</p><p>2．需求分析</p><p><img src="34.png" alt></p><p>3．在第二章序列化案例（求电话流量）的基础上，增加一个分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Partitioner<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 03:54 * @Func: 自定义分区类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>Text text<span class="token punctuation">,</span> FlowBean flowBean<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// k是手机号  v是流量信息</span>        <span class="token comment" spellcheck="true">// 获取手机号前三位（截取左闭右开）</span>        String prePhoneNum <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 根据前三位进行分区</span>        <span class="token keyword">int</span> partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"136"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>  <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"137"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"138"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"139"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．在驱动函数中增加自定义数据分区设置和 ReduceTask 设置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueLineRecordReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>KeyValueTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/7 11:45 * @Func: driver类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowSumDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_phone/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output1"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置jar路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowSumDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置分区和分区数</span>        job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 设置分区和分区数</span>job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>若定义的分区类是 5，在驱动中设置的分区数如果是 1 或者是大于 5 的数都不会报错，但是其他数就会报错。</p><p>(1) 若设置分区数为 1，则最终会生成 1 个文件并且所有数据都在 1 个文件里</p><p>(2) 若设置分区数为 6，则最终会生成 6 个文件并且所有数据都在前 5 个文件里</p><p><img src="33.png" alt></p><h4 id="WritableComparable-排序"><a href="#WritableComparable-排序" class="headerlink" title="WritableComparable 排序"></a>WritableComparable 排序</h4><ol><li>排序概述</li></ol><p><img src="35.png" alt></p><p><img src="36.png" alt></p><ol start="2"><li>排序的分类</li></ol><p><img src="37.png" alt></p><ol start="3"><li>自定义排序 WritableComparable</li></ol><p>（1）原理分析</p><p>bean 对象做为 key 传输，需要实现 WritableComparable 接口重写 compareTo 方法，就可以实现排序。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowBean o<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> result<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 按照总流量大小，倒序排列</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>        result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="WritableComparable-排序案例实操（全排序）"><a href="#WritableComparable-排序案例实操（全排序）" class="headerlink" title="WritableComparable 排序案例实操（全排序）"></a>WritableComparable 排序案例实操（全排序）</h4><p>1．需求</p><p>根据之前手机流量求和案例，对总流量进行排序。</p><p>（1）输入数据</p><pre><code>13470253144    180    180    36013509468723    7335    110349    11768413560439638    918    4938    585613568436656    3597    25635    2923213590439668    1116    954    207013630577991    6960    690    765013682846555    1938    2910    484813729199489    240    0    24013736230513    2481    24681    2716213768778790    120    120    24013846544121    264    0    26413956435636    132    1512    164413966251146    240    0    24013975057813    11058    48243    5930113992314666    3008    3720    672815043685818    3659    3538    719715910133277    3156    2936    609215959002129    1938    180    211818271575951    1527    2106    363318390173782    9531    2412    1194384188413    4116    1432    5548</code></pre><p>（2）期望输出数据</p><pre><code>13509468723    7335    110349    11768413736230513    2481    24681    2716213956435636    132        1512    164413846544121    264        0        264...</code></pre><p>2．需求分析</p><p><img src="38.png" alt></p><p>3．代码实现</p><p>（1）FlowSortBean 对象在在之前的基础上增加了比较功能</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 07:42 * @Func: 自己定义的FlowBean对象 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowSortBean</span> <span class="token keyword">implements</span> <span class="token class-name">WritableComparable</span><span class="token operator">&lt;</span>FlowSortBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**上行流量*/</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> upFlow<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**下行流量*/</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**总流量*/</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> sumFlow<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">FlowSortBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">FlowSortBean</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 排序比较     * @param bean     * @return res     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowSortBean bean<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> res<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 比较逻辑</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            res <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            res <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            res <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> res<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 序列化     * @param dataOutput     * @throws IOException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput dataOutput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 反序列化     * @param dataInput     * @throws IOException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput dataInput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        upFlow <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        downFlow <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        sumFlow <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> sumFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> upFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> downFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> sumFlow<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 Mapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 08:13 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowSortBean<span class="token punctuation">,</span> Text<span class="token operator">></span><span class="token punctuation">{</span>    FlowSortBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowSortBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 截取</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 封装对象</span>        String phoneNbr <span class="token operator">=</span> fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> upFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> downFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> sumFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">,</span> downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>phoneNbr<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>bean<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 Reducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 08:13 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>FlowSortBean<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowSortBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>FlowSortBean key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>Text<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Text value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写 Driver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 08:13 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_phone/phone_sum.txt"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output1"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置jar路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowCountSortDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联mapper和reducer</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountSortMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountSortReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>FlowSortBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>FlowSortBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="WritableComparable-排序案例实操（区内排序）"><a href="#WritableComparable-排序案例实操（区内排序）" class="headerlink" title="WritableComparable 排序案例实操（区内排序）"></a>WritableComparable 排序案例实操（区内排序）</h4><p>1．需求</p><p>要求之前整理的每个前缀手机号输出的文件中按照总流量内部排序。</p><p>2．需求分析</p><p>基于上一个需求，增加自定义分区类，分区按照省份手机号设置。</p><p><img src="39.png" alt></p><p>3．案例实操</p><p>（1）增加自定义分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Partitioner<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/9 下午 09:37 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token operator">&lt;</span>FlowSortBean<span class="token punctuation">,</span> Text<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>FlowSortBean flowSortBean<span class="token punctuation">,</span> Text text<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 按照手机号前三位分区</span>        <span class="token comment" spellcheck="true">// 获取前三位</span>        String prePhoneNum <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 根据前三位进行分区</span>        <span class="token keyword">int</span> partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"136"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"137"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"138"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>prePhoneNum<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"139"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在驱动类中添加分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 加载自定义分区类</span>job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 设置Reducetask个数</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Combiner-合并"><a href="#Combiner-合并" class="headerlink" title="Combiner 合并"></a>Combiner 合并</h4><p><img src="40.png" alt></p><p>combiner 不适用于求平均一类操作，只适用于汇总一类的工作。</p><p>（6）自定义 Combiner 实现步骤</p><p>（a）自定义一个 Combiner 继承 Reducer，重写 Reduce 方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 汇总操作</span>        <span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable v <span class="token operator">:</span>values<span class="token punctuation">)</span><span class="token punctuation">{</span>            count <span class="token operator">+=</span> v<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 2 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）在 Job 驱动类中设置：</p><pre class="line-numbers language-java"><code class="language-java">job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountCombiner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Combiner-合并案例实操"><a href="#Combiner-合并案例实操" class="headerlink" title="Combiner 合并案例实操"></a>Combiner 合并案例实操</h4><ol><li>需求</li></ol><p>统计过程中对每一个 MapTask 的输出进行局部汇总，以减小网络传输量即采用 Combiner 功能。</p><p>（1）数据输入</p><pre><code>apple spark hibigdata hadoopapple hello hibigdata orange hadoop</code></pre><p>（2）期望输出数据</p><p>期望：Combine 输入数据多，输出时经过合并，输出数据降低。</p><ol start="2"><li>需求分析</li></ol><p>对每一个 MapTask 的输出进行局部汇总</p><p><img src="41.png" alt></p><ol start="3"><li>方案一</li></ol><p>1）增加一个 WordcountCombiner 类继承 Reducer</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 上午 10:12 * @Func: Combiner类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span> <span class="token punctuation">{</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 累加求和</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）在 WordcountDriver 驱动类中指定 Combiner</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 指定需要使用combiner，以及用哪个类作为combiner的逻辑</span>job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountCombiner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4．案例实操-方案二</p><p>1）将 WordcountReducer 作为 Combiner 在 WordcountDriver 驱动类中进行绑定</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 指定需要使用Combiner，以及用哪个类作为Combiner的逻辑</span>job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>运行程序结果对比</p><p>使用前</p><p><img src="42.jpg" alt></p><p>使用后</p><p><img src="43.jpg" alt></p><p>可以看出其中 combiner 就在 mapper 与 reducer 之间。其中使用之后，reducer 的输入明显减少，这就说明已经进行了一次汇总。</p><h4 id="GroupingComparator-分组（辅助排序）"><a href="#GroupingComparator-分组（辅助排序）" class="headerlink" title="GroupingComparator 分组（辅助排序）"></a>GroupingComparator 分组（辅助排序）</h4><p>对 Reduce 阶段的数据根据某一个或几个字段进行分组。</p><p>分组排序步骤：</p><p>（1）自定义类继承 WritableComparator</p><p>（2）重写 compare()方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compare</span><span class="token punctuation">(</span>WritableComparable a<span class="token punctuation">,</span> WritableComparable b<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 比较的业务逻辑</span>    <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建一个构造将比较对象的类传给父类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">protected</span> <span class="token function">OrderGroupingComparator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="GroupingComparator-分组案例"><a href="#GroupingComparator-分组案例" class="headerlink" title="GroupingComparator 分组案例"></a>GroupingComparator 分组案例</h4><p>1．需求</p><p>有如下订单数据</p><table>    <tr>        <th>订单id</th>        <th>商品id</th>        <th>成交金额</th>      </tr>    <tr>        <td rowspan="2">0000001</td>        <td>Pdt_01</td>        <td>222.8</td>    </tr>    <tr>        <td>Pdt_02</td>        <td>33.8</td>    </tr>    <tr>        <td rowspan="3">0000002</td>        <td>Pdt_03</td>        <td>522.8</td>    </tr>    <tr>        <td>Pdt_04</td>        <td>122.4</td>    </tr>    <tr>        <td>Pdt_05</td>        <td>722.4</td>    </tr>    <tr>        <td rowspan="2">0000003</td>        <td>Pdt_06</td>        <td>232.8</td>    </tr>    <tr>        <td>Pdt_02</td>        <td>33.8</td>    </tr></table><p>现在需要求出每一个订单中最贵的商品。</p><p>（1）输入数据</p><pre><code>0000001 Pdt_01 222.80000002    Pdt_05 722.40000001    Pdt_02 33.80000003    Pdt_06 232.80000003    Pdt_02 33.80000002    Pdt_03 522.80000002    Pdt_04 122.4</code></pre><p>（2）期望输出数据</p><pre><code>1    222.82    722.43    232.8</code></pre><p>2．需求分析</p><p>（1）利用“订单 id 和成交金额”作为 key，可以将 Map 阶段读取到的所有订单数据按照 id 升序排序，如果 id 相同再按照金额降序排序，发送到 Reduce。</p><p>（2）在 Reduce 端利用 groupingComparator 将订单 id 相同的 kv 聚合成组，然后取第一个即是该订单中最贵商品，如图</p><p><img src="44.png" alt></p><p>3．代码实现</p><p>（1）定义订单信息 OrderBean 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 01:47 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderBean</span> <span class="token keyword">implements</span> <span class="token class-name">WritableComparable</span><span class="token operator">&lt;</span>OrderBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**订单id*/</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> orderId<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**价格*/</span>    <span class="token keyword">private</span> <span class="token keyword">double</span> price<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">OrderBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">OrderBean</span><span class="token punctuation">(</span><span class="token keyword">int</span> orderId<span class="token punctuation">,</span> <span class="token keyword">int</span> price<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>orderId <span class="token operator">=</span> orderId<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>price <span class="token operator">=</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> orderId<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setOrderId</span><span class="token punctuation">(</span><span class="token keyword">int</span> orderId<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>orderId <span class="token operator">=</span> orderId<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getPrice</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setPrice</span><span class="token punctuation">(</span><span class="token keyword">double</span> price<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>price <span class="token operator">=</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>OrderBean bean<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 先按id升序排序，如果相同再降序排序</span>        <span class="token keyword">int</span> result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>orderId <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>orderId <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>price <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getPrice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>price <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getPrice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> result<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput dataOutput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeInt</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeDouble</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput dataInput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        orderId <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        price <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readDouble</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> orderId <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 OrderMapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 02:11 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> OrderBean<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//    0000001 Pdt_01 222.8</span>    OrderBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OrderBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 切割取价格</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> details <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> orderId <span class="token operator">=</span> Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>details<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">double</span> price <span class="token operator">=</span> Double<span class="token punctuation">.</span><span class="token function">parseDouble</span><span class="token punctuation">(</span>details<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">setOrderId</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">setPrice</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>bean<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 OrderSortGroupingComparator 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">.</span>OrderBean<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparator<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 04:32 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderSortGroupingComparator</span> <span class="token keyword">extends</span> <span class="token class-name">WritableComparator</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token function">OrderSortGroupingComparator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compare</span><span class="token punctuation">(</span>WritableComparable a<span class="token punctuation">,</span> WritableComparable b<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 只要id相同就判定为相同key(当为0的时候就会返回同一个分组)</span>        OrderBean aBean <span class="token operator">=</span> <span class="token punctuation">(</span>OrderBean<span class="token punctuation">)</span> a<span class="token punctuation">;</span>        OrderBean bBean <span class="token operator">=</span> <span class="token punctuation">(</span>OrderBean<span class="token punctuation">)</span> b<span class="token punctuation">;</span>        <span class="token keyword">int</span> result<span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>aBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> bBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>aBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> bBean<span class="token punctuation">.</span><span class="token function">getOrderId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> result<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写 OrderReducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 02:11 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>OrderBean<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span> OrderBean<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>OrderBean key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>NullWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写 OrderDriver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>order<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>sort<span class="token punctuation">.</span>OrderSortGroupingComparator<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span>WordcountDriver<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span>WordcountMapper<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">.</span>WordcountReducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>CombineTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/10 下午 02:11 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OrderDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_order/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置jar存储路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>OrderDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联map和reduce</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>OrderMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>OrderReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper阶段输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>OrderBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入路径和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置reduce分组</span>        job<span class="token punctuation">.</span><span class="token function">setGroupingComparatorClass</span><span class="token punctuation">(</span>OrderSortGroupingComparator<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MapTask-工作机制"><a href="#MapTask-工作机制" class="headerlink" title="MapTask 工作机制"></a>MapTask 工作机制</h3><p><img src="45.png" alt></p><p>（1）Read 阶段：MapTask 通过用户编写的 RecordReader，从输入 InputSplit 中解析出一个个 key/value。</p><p>（2）Map 阶段：该节点主要是将解析出的 key/value 交给用户编写 map()函数处理，并产生一系列新的 key/value。</p><p>（3）Collect 收集阶段：在用户编写 map()函数中，当数据处理完成后，一般会调用 OutputCollector.collect()输出结果。在该函数内部，它会将生成的 key/value 分区（调用 Partitioner），并写入一个环形内存缓冲区中。</p><p>（4）Spill 阶段：即“溢写”，当环形缓冲区满后，MapReduce 会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p><p>溢写阶段详情：</p><p>步骤 1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号 Partition 进行排序，然后按照 key 进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照 key 有序。</p><p>步骤 2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件 output/spillN.out（N 表示当前溢写次数）中。如果用户设置了 Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p><p>步骤 3：将分区数据的元信息写到内存索引数据结构 SpillRecord 中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过 1MB，则将内存索引写到文件 output/spillN.out.index 中。</p><p>（5）Combine 阶段：当所有数据处理完成后，MapTask 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p><p>当所有数据处理完后，MapTask 会将所有临时文件合并成一个大文件，并保存到文件 output/file.out 中，同时生成相应的索引文件 output/file.out.index。</p><p>在进行文件合并过程中，MapTask 以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并 io.sort.factor（默认 10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p><p>让每个 MapTask 最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p><h3 id="ReduceTask-工作机制"><a href="#ReduceTask-工作机制" class="headerlink" title="ReduceTask 工作机制"></a>ReduceTask 工作机制</h3><p>1．ReduceTask 工作机制</p><p><img src="46.png" alt></p><p>（1）Copy 阶段：ReduceTask 从各个 MapTask 上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p><p>（2）Merge 阶段：在远程拷贝数据的同时，ReduceTask 启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p><p>（3）Sort 阶段：按照 MapReduce 语义，用户编写 reduce()函数输入数据是按 key 进行聚集的一组数据。为了将 key 相同的数据聚在一起，Hadoop 采用了基于排序的策略。由于各个 MapTask 已经实现对自己的处理结果进行了局部排序，因此，ReduceTask 只需对所有数据进行一次归并排序即可。</p><p>（4）Reduce 阶段：reduce()函数将计算结果写到 HDFS 上。</p><p>2．设置 ReduceTask 并行度（个数）</p><p>ReduceTask 的并行度同样影响整个 Job 的执行并发度和执行效率，但与 MapTask 的并发数由切片数决定不同，ReduceTask 数量的决定是可以直接手动设置：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 默认值是1，手动设置为4</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3．实验：测试 ReduceTask 多少合适（据说是 IBM 工程师做的实验）</p><p>（1）实验环境：1 个 Master 节点，16 个 Slave 节点：CPU:8GHZ，内存: 2G</p><p>（2）实验结论：</p><p>改变 ReduceTask （数据量为 1GB）</p><table>    <tr>        <th colspan="11">MapTask =16</th>    </tr>    <tr>        <td>ReduceTask</td>        <td>1</td>        <td>5</td>        <td>10</td>        <td>15</td>        <td>16</td>        <td>20</td>        <td>25</td>        <td>30</td>        <td>45</td>        <td>60</td>    </tr>    <tr>        <td>总时间</td>        <td>892</td>        <td>146</td>        <td>110</td>        <td>92</td>        <td>88</td>        <td>100</td>        <td>128</td>        <td>101</td>        <td>145</td>        <td>104</td>    </tr></table><p>4．注意事项</p><p><img src="47.png" alt></p><p>数据倾斜：如果有三个 ReduceTask，若其中 ① 里面有 1 亿条数据，② 里面有 100 条数据，③ 里面有 1 条数据，那么这就负载不够均衡，① 会压力特别大。这种情况就叫数据倾斜。</p><p><strong>注：</strong>以上两节合起来便是之前讲过的 MapReduce 工作流程</p><h3 id="OutputFormat-数据输出"><a href="#OutputFormat-数据输出" class="headerlink" title="OutputFormat 数据输出"></a>OutputFormat 数据输出</h3><h4 id="OutputFormat-接口实现类"><a href="#OutputFormat-接口实现类" class="headerlink" title="OutputFormat 接口实现类"></a>OutputFormat 接口实现类</h4><p><img src="48.png" alt></p><h4 id="自定义-OutputFormat"><a href="#自定义-OutputFormat" class="headerlink" title="自定义 OutputFormat"></a>自定义 OutputFormat</h4><p><img src="49.png" alt></p><h4 id="自定义-OutputFormat-案例实操"><a href="#自定义-OutputFormat-案例实操" class="headerlink" title="自定义 OutputFormat 案例实操"></a>自定义 OutputFormat 案例实操</h4><p>1．需求</p><p>过滤输入的 log 日志，包含百度的网站输出到/baidu.log，不包含百度的网站输出到/other.log。</p><p>（1）输入数据</p><pre><code>    http://www.baidu.com    http://www.google.com    http://cn.bing.com    http://www.github.com    http://www.sohu.com    http://www.sina.com    http://www.sin2a.com    http://www.sin2desa.com    http://www.sindsafa.com</code></pre><p>（2）期望输出数据</p><p>[/baidu.log]</p><pre><code>    http://www.baidu.com</code></pre><p>[/other.log]</p><pre><code>    http://www.google.com    http://cn.bing.com    http://www.github.com    http://www.sohu.com    http://www.sina.com    http://www.sin2a.com    http://www.sin2desa.com    http://www.sindsafa.com</code></pre><p>3．案例</p><p>（1）编写 FilterMapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: Mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 FilterReducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: Reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>NullWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        String line <span class="token operator">=</span> key<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        line <span class="token operator">+=</span> <span class="token string">"\r\n"</span><span class="token punctuation">;</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）自定义一个 OutputFormat 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: 自定义OutputFormat */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterOutputFormat</span> <span class="token keyword">extends</span> <span class="token class-name">FileOutputFormat</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> RecordWriter<span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token function">getRecordWriter</span><span class="token punctuation">(</span>TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">FRecordWrite</span><span class="token punctuation">(</span>taskAttemptContext<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写 FRecordWrite 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FileSystem<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 05:21 * @Func: 自定义 RecordWrite */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FRecordWrite</span> <span class="token keyword">extends</span> <span class="token class-name">RecordWriter</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    FSDataOutputStream fosBaidu<span class="token punctuation">;</span>    FSDataOutputStream fosOther<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">FRecordWrite</span><span class="token punctuation">(</span>TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获取文件系统</span>            FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>taskAttemptContext<span class="token punctuation">.</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 创建输出到baidu.log输出流</span>            fosBaidu <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"baidu.log"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 创建输出到other.log输出流</span>            fosOther <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"other.log"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>Text text<span class="token punctuation">,</span> NullWritable nullWritable<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 判断key中是否有baidu，分别写入</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"baidu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            fosBaidu<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            fosOther<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span>TaskAttemptContext taskAttemptContext<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 结束关掉资源</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fosBaidu<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fosOther<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写 FilterDriver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>outputFormt<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/12 下午 04:59 * @Func: 驱动类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FilterDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token punctuation">{</span> <span class="token string">"D:/scwri/Desktop/inputoutputformat"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span> <span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FilterDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FilterMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FilterReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 要将自定义的输出格式组件设置到job中</span>        job<span class="token punctuation">.</span><span class="token function">setOutputFormatClass</span><span class="token punctuation">(</span>FilterOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat</span>        <span class="token comment" spellcheck="true">// 而fileoutputformat要输出一个_SUCCESS文件，所以，在这还得指定一个输出目录</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Join-多种应用"><a href="#Join-多种应用" class="headerlink" title="Join 多种应用"></a>Join 多种应用</h3><h4 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h4><p><img src="50.png" alt></p><h4 id="Reduce-Join-案例实操"><a href="#Reduce-Join-案例实操" class="headerlink" title="Reduce Join 案例实操"></a>Reduce Join 案例实操</h4><ol><li>需求</li></ol><p>[订单数据表 order.txt]</p><table><thead><tr><th>id</th><th>pid</th><th>amount</th></tr></thead><tbody><tr><td>1001</td><td>01</td><td>1</td></tr><tr><td>1002</td><td>02</td><td>2</td></tr><tr><td>1003</td><td>03</td><td>3</td></tr><tr><td>1004</td><td>04</td><td>4</td></tr><tr><td>1005</td><td>05</td><td>5</td></tr><tr><td>1006</td><td>06</td><td>6</td></tr></tbody></table><p>[商品信息表 product.txt]</p><table><thead><tr><th>pid</th><th>name</th></tr></thead><tbody><tr><td>01</td><td>小米</td></tr><tr><td>02</td><td>华为</td></tr><tr><td>03</td><td>格力</td></tr></tbody></table><p>将商品信息表中数据根据商品 pid 合并到订单数据表中。</p><p>[最终数据形式]</p><table><thead><tr><th>id</th><th>pname</th><th>amount</th></tr></thead><tbody><tr><td>1001</td><td>小米</td><td>1</td></tr><tr><td>1004</td><td>小米</td><td>4</td></tr><tr><td>1002</td><td>华为</td><td>2</td></tr><tr><td>1005</td><td>华为</td><td>5</td></tr><tr><td>1003</td><td>格力</td><td>3</td></tr><tr><td>1006</td><td>格力</td><td>6</td></tr></tbody></table><ol start="2"><li>需求分析</li></ol><p>通过将关联条件作为 Map 输出的 key，将两表满足 Join 条件的数据并携带数据所来源的文件信息，发往同一个 ReduceTask，在 Reduce 中进行数据的串联，如图 4-20 所示。</p><p><img src="51.png" alt></p><ol start="3"><li>代码实现</li></ol><p>1）创建商品和订合并后的 Bean 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Writable<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:03 * @Func: 表的bean类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableBean</span> <span class="token keyword">implements</span> <span class="token class-name">Writable</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**订单id*/</span>    <span class="token keyword">private</span> String id<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**产品id*/</span>    <span class="token keyword">private</span> String pid<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**数量*/</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> amount<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**产品名称*/</span>    <span class="token keyword">private</span> String pname<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**标记（订单还是产品）*/</span>    <span class="token keyword">private</span> String flag<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">TableBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">TableBean</span><span class="token punctuation">(</span>String id<span class="token punctuation">,</span> String pid<span class="token punctuation">,</span> <span class="token keyword">int</span> amount<span class="token punctuation">,</span> String pname<span class="token punctuation">,</span> String flag<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>id <span class="token operator">=</span> id<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pid <span class="token operator">=</span> pid<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>amount <span class="token operator">=</span> amount<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pname <span class="token operator">=</span> pname<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>flag <span class="token operator">=</span> flag<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput dataOutput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>pid<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeInt</span><span class="token punctuation">(</span>amount<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>pname<span class="token punctuation">)</span><span class="token punctuation">;</span>        dataOutput<span class="token punctuation">.</span><span class="token function">writeUTF</span><span class="token punctuation">(</span>flag<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput dataInput<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        id <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        pid <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        amount <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        pname <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        flag <span class="token operator">=</span> dataInput<span class="token punctuation">.</span><span class="token function">readUTF</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> id<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setId</span><span class="token punctuation">(</span>String id<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>id <span class="token operator">=</span> id<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getPid</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> pid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setPid</span><span class="token punctuation">(</span>String pid<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pid <span class="token operator">=</span> pid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getAmount</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> amount<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setAmount</span><span class="token punctuation">(</span><span class="token keyword">int</span> amount<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>amount <span class="token operator">=</span> amount<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getPname</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> pname<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setPname</span><span class="token punctuation">(</span>String pname<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>pname <span class="token operator">=</span> pname<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getFlag</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> flag<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setFlag</span><span class="token punctuation">(</span>String flag<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>flag <span class="token operator">=</span> flag<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> id <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> amount <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> pname<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）编写 TableMapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileSplit<span class="token punctuation">;</span><span class="token keyword">import</span> javax<span class="token punctuation">.</span>swing<span class="token punctuation">.</span>text<span class="token punctuation">.</span>TabExpander<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:55 * @Func: mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> TableBean<span class="token operator">></span> <span class="token punctuation">{</span>    String name<span class="token punctuation">;</span>    TableBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TableBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//    </span><span class="token comment" spellcheck="true">/**因为在一开始要拿到它的文件信息来做区分，所以重写此方法*/</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">setup</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取文件名称</span>        FileSplit inputSplit <span class="token operator">=</span> <span class="token punctuation">(</span>FileSplit<span class="token punctuation">)</span> context<span class="token punctuation">.</span><span class="token function">getInputSplit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        name <span class="token operator">=</span> inputSplit<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>name<span class="token punctuation">.</span><span class="token function">startsWith</span><span class="token punctuation">(</span><span class="token string">"order"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setId</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPid</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setAmount</span><span class="token punctuation">(</span>Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setFlag</span><span class="token punctuation">(</span><span class="token string">"order"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPname</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setId</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPid</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setAmount</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setFlag</span><span class="token punctuation">(</span><span class="token string">"pd"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bean<span class="token punctuation">.</span><span class="token function">setPname</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> bean<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）编写 TableReducer 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>commons<span class="token punctuation">.</span>beanutils<span class="token punctuation">.</span>BeanUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>InvocationTargetException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:55 * @Func: reducer类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> TableBean<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span> TableBean<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>TableBean<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        ArrayList<span class="token operator">&lt;</span>TableBean<span class="token operator">></span> orderBeans <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/**标记是否获得pname*/</span>        <span class="token keyword">boolean</span> isGetPname <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        String pName <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>TableBean bean <span class="token operator">:</span>values<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"order"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>bean<span class="token punctuation">.</span><span class="token function">getFlag</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                TableBean tableBean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TableBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">try</span> <span class="token punctuation">{</span>                    BeanUtils<span class="token punctuation">.</span><span class="token function">copyProperties</span><span class="token punctuation">(</span>tableBean<span class="token punctuation">,</span> bean<span class="token punctuation">)</span><span class="token punctuation">;</span>                    orderBeans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>tableBean<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IllegalAccessException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">InvocationTargetException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>isGetPname<span class="token punctuation">)</span> <span class="token punctuation">{</span>                pName <span class="token operator">+=</span> bean<span class="token punctuation">.</span><span class="token function">getPname</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                isGetPname <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>TableBean tableBean <span class="token operator">:</span> orderBeans<span class="token punctuation">)</span><span class="token punctuation">{</span>            tableBean<span class="token punctuation">.</span><span class="token function">setPname</span><span class="token punctuation">(</span>pName<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tableBean<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）编写 TableDriver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/14 下午 03:55 * @Func: 驱动类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/inputTable/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息，或者job对象实例</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 指定本程序的jar包所在的本地路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>TableDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 指定本业务job要使用的Mapper/Reducer业务类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>TableMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>TableReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 指定Mapper输出数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>TableBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 指定最终输出的数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>TableBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 指定job的输入原始文件所在目录</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>测试</li></ol><p>运行程序查看结果</p><pre><code>    1004    4    小米    1001    1    小米    1005    5    华为    1002    2    华为    1006    6    格力    1003    3    格力</code></pre><ol start="5"><li>总结</li></ol><p><img src="52.png" alt></p><h4 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h4><ol><li>使用场景</li></ol><p>Map Join 适用于一张表十分小、一张表很大的场景。</p><ol start="2"><li>优点</li></ol><p><strong>思考：在 Reduce 端处理过多的表，非常容易产生数据倾斜。怎么办？</strong></p><p>在 Map 端缓存多张表，提前处理业务逻辑，这样增加 Map 端业务，减少 Reduce 端数据的压力，尽可能的减少数据倾斜。</p><ol start="3"><li>具体办法：采用 DistributedCache</li></ol><p>（1）在 Mapper 的 setup 阶段，将文件读取到缓存集合中。</p><p>（2）在驱动函数中加载缓存。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 缓存普通文件到Task运行节点。</span>job<span class="token punctuation">.</span><span class="token function">addCacheFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"file://d:/pd.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="Map-Join-案例"><a href="#Map-Join-案例" class="headerlink" title="Map Join 案例"></a>Map Join 案例</h4><ol><li>需求（同上）</li></ol><p>将商品信息表中数据根据商品 pid 合并到订单数据表中。</p><ol start="2"><li>需求分析</li></ol><p>MapJoin 适用于关联表中有小表的情形。</p><p><img src="53.png" alt></p><ol start="3"><li>实现代码</li></ol><p>（1）在驱动模块中添加缓存文件</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>cache<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URI<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URISyntaxException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/15 上午 09:17 * @Func: 驱动 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DistributedCacheDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 0 根据自己电脑路径重新配置</span><span class="token comment" spellcheck="true">//        args = new String[]{"e:/input/inputtable2", "e:/output1"};</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/inputTable/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job信息</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置加载jar包路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>DistributedCacheDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联map</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>DistributedCacheMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出数据类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 加载缓存数据</span>        job<span class="token punctuation">.</span><span class="token function">addCacheFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"file:///d:/scwri/Desktop/cache/pd.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 8 提交</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）读取缓存的文件数据</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>cache<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>joinTable<span class="token punctuation">.</span>TableBean<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>commons<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>StringUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BufferedReader<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FileInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>InputStreamReader<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URI<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HashMap<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/15 上午 09:24 * @Func: 缓存mapper */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DistributedCacheMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> pdMap <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">setup</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 缓存小表</span>        URI<span class="token punctuation">[</span><span class="token punctuation">]</span> cacheFiles <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">getCacheFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String path <span class="token operator">=</span> cacheFiles<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        BufferedReader reader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">InputStreamReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String line<span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>StringUtils<span class="token punctuation">.</span><span class="token function">isNotEmpty</span><span class="token punctuation">(</span>line <span class="token operator">=</span> reader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获取数据不为空，进行切割</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            pdMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>reader<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 拿到一行进行切割</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 从map里面获取pName</span>        String pid <span class="token operator">=</span> detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        String pName <span class="token operator">=</span> pdMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>pid<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 封装</span>        line <span class="token operator">=</span> line <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> pName<span class="token punctuation">;</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="计数器应用"><a href="#计数器应用" class="headerlink" title="计数器应用"></a>计数器应用</h3><p><img src="54.png" alt></p><h3 id="数据清洗（ETL）"><a href="#数据清洗（ETL）" class="headerlink" title="数据清洗（ETL）"></a>数据清洗（ETL）</h3><p>在运行核心业务 MapReduce 程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。清理的过程往往只需要运行 Mapper 程序，不需要运行 Reduce 程序。</p><h4 id="数据清洗案例实操-简单解析版"><a href="#数据清洗案例实操-简单解析版" class="headerlink" title="数据清洗案例实操-简单解析版"></a>数据清洗案例实操-简单解析版</h4><ol><li>需求</li></ol><p>去除日志中字段长度小于等于 11 的日志。</p><p>（1）输入数据 （非常多，但是跟下面类似）</p><pre><code>    194.237.142.21 - - [18/Sep/2013:06:49:18 +0000] &quot;GET /wp-content/uploads/2013/07/rstudio-git3.png HTTP/1.1&quot; 304 0 &quot;-&quot; &quot;Mozilla/4.0 (compatible;)&quot;    183.49.46.228 - - [18/Sep/2013:06:49:23 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;    163.177.71.12 - - [18/Sep/2013:06:49:33 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    163.177.71.12 - - [18/Sep/2013:06:49:36 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    101.226.68.137 - - [18/Sep/2013:06:49:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    101.226.68.137 - - [18/Sep/2013:06:49:45 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;    60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;    ...</code></pre><p>（2）期望输出数据</p><p>每行字段长度都大于 11。</p><ol start="2"><li>需求分析</li></ol><p>需要在 Map 阶段对输入的数据根据规则进行过滤清洗。</p><ol start="3"><li>实现代码</li></ol><p>（1）编写 LogMapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/16 下午 04:23 * @Func: Mapper类 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">logMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 解析数据</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> <span class="token function">parseLog</span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>result<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> <span class="token function">parseLog</span><span class="token punctuation">(</span>String line<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> detail <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>detail<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">getCounter</span><span class="token punctuation">(</span><span class="token string">"map"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">increment</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            context<span class="token punctuation">.</span><span class="token function">getCounter</span><span class="token punctuation">(</span><span class="token string">"map"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">increment</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 LogDriver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/16 下午 04:23 * @Func: */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">logDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/inputWeb/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取job信息</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 加载jar包</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>logDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联map</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>logMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置reducetask个数为0</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 提交</span>        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="数据清洗案例实操-复杂解析版"><a href="#数据清洗案例实操-复杂解析版" class="headerlink" title="数据清洗案例实操-复杂解析版"></a>数据清洗案例实操-复杂解析版</h4><p>1．需求</p><p>对 Web 访问日志中的各字段识别切分，去除日志中不合法的记录。根据清洗规则，输出过滤后的数据。</p><p>（1）输入数据</p><p>同上</p><p>（2）期望输出数据</p><p>都是合法的数据</p><p>2．实现代码</p><p>（1）定义一个 bean，用来记录日志数据中的各数据字段（除了信息还有）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogBean</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> String remote_addr<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录客户端的ip地址</span>    <span class="token keyword">private</span> String remote_user<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录客户端用户名称,忽略属性"-"</span>    <span class="token keyword">private</span> String time_local<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录访问时间与时区</span>    <span class="token keyword">private</span> String request<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录请求的url与http协议</span>    <span class="token keyword">private</span> String status<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录请求状态；成功是200</span>    <span class="token keyword">private</span> String body_bytes_sent<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录发送给客户端文件主体内容大小</span>    <span class="token keyword">private</span> String http_referer<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 用来记录从那个页面链接访问过来的</span>    <span class="token keyword">private</span> String http_user_agent<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 记录客户浏览器的相关信息</span>    <span class="token keyword">private</span> <span class="token keyword">boolean</span> valid <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 判断数据是否合法</span>    <span class="token keyword">public</span> String <span class="token function">getRemote_addr</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> remote_addr<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setRemote_addr</span><span class="token punctuation">(</span>String remote_addr<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>remote_addr <span class="token operator">=</span> remote_addr<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getRemote_user</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> remote_user<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setRemote_user</span><span class="token punctuation">(</span>String remote_user<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>remote_user <span class="token operator">=</span> remote_user<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getTime_local</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> time_local<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setTime_local</span><span class="token punctuation">(</span>String time_local<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>time_local <span class="token operator">=</span> time_local<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getRequest</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> request<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setRequest</span><span class="token punctuation">(</span>String request<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>request <span class="token operator">=</span> request<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> status<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setStatus</span><span class="token punctuation">(</span>String status<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>status <span class="token operator">=</span> status<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getBody_bytes_sent</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> body_bytes_sent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setBody_bytes_sent</span><span class="token punctuation">(</span>String body_bytes_sent<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>body_bytes_sent <span class="token operator">=</span> body_bytes_sent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getHttp_referer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> http_referer<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setHttp_referer</span><span class="token punctuation">(</span>String http_referer<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>http_referer <span class="token operator">=</span> http_referer<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getHttp_user_agent</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> http_user_agent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setHttp_user_agent</span><span class="token punctuation">(</span>String http_user_agent<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>http_user_agent <span class="token operator">=</span> http_user_agent<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isValid</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> valid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setValid</span><span class="token punctuation">(</span><span class="token keyword">boolean</span> valid<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>valid <span class="token operator">=</span> valid<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        StringBuilder sb <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>valid<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 使用特殊字段（"\001"）拼接，因为其他的可能原来字符串中就可能有</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>remote_addr<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>remote_user<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>time_local<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>status<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>body_bytes_sent<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>http_referer<span class="token punctuation">)</span><span class="token punctuation">;</span>        sb<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>http_user_agent<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> sb<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写 LogMapper 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span><span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取1行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 解析日志是否合法</span>        LogBean bean <span class="token operator">=</span> <span class="token function">parseLog</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>bean<span class="token punctuation">.</span><span class="token function">isValid</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>bean<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 解析日志</span>    <span class="token keyword">private</span> LogBean <span class="token function">parseLog</span><span class="token punctuation">(</span>String line<span class="token punctuation">)</span> <span class="token punctuation">{</span>        LogBean logBean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LogBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 截取</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>fields<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">11</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 2封装数据</span>            logBean<span class="token punctuation">.</span><span class="token function">setRemote_addr</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setRemote_user</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setTime_local</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setRequest</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setStatus</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setBody_bytes_sent</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            logBean<span class="token punctuation">.</span><span class="token function">setHttp_referer</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>fields<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">12</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                logBean<span class="token punctuation">.</span><span class="token function">setHttp_user_agent</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">" "</span><span class="token operator">+</span> fields<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>                logBean<span class="token punctuation">.</span><span class="token function">setHttp_user_agent</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">// 大于400，HTTP错误</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>logBean<span class="token punctuation">.</span><span class="token function">getStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">400</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                logBean<span class="token punctuation">.</span><span class="token function">setValid</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            logBean<span class="token punctuation">.</span><span class="token function">setValid</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> logBean<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写 LogDriver 类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>log<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span><span class="token comment" spellcheck="true">// 1 获取job信息</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 加载jar包</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>LogDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联map</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>LogMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置最终输出类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 提交</span>        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MapReduce-开发总结"><a href="#MapReduce-开发总结" class="headerlink" title="MapReduce 开发总结"></a>MapReduce 开发总结</h3><p>在编写 MapReduce 程序时，需要考虑如下几个方面：</p><p><img src="55.png" alt></p><p><img src="56.png" alt></p><p><img src="57.png" alt></p><p><img src="58.png" alt></p><h2 id="Hadoop-数据压缩"><a href="#Hadoop-数据压缩" class="headerlink" title="Hadoop 数据压缩"></a>Hadoop 数据压缩</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><img src="59.png" alt></p><h3 id="MR-支持的压缩编码"><a href="#MR-支持的压缩编码" class="headerlink" title="MR 支持的压缩编码"></a>MR 支持的压缩编码</h3><table><thead><tr><th>压缩格式</th><th>hadoop 自带</th><th>算法</th><th>文件扩展名</th><th>是否可切分</th><th>换成压缩格式后，原来的程序是否需要修改</th></tr></thead><tbody><tr><td>DEFLATE</td><td>是，直接使用</td><td>DEFLATE</td><td>.deflate</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>Gzip</td><td>是，直接使用</td><td>DEFLATE</td><td>.gz</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>bzip2</td><td>是，直接使用</td><td>bzip2</td><td>.bz2</td><td>是</td><td>和文本处理一样，不需要修改</td></tr><tr><td>LZO</td><td>否，需要安装</td><td>LZO</td><td>.lzo</td><td>是</td><td>需要建索引，还需要指定输入格式</td></tr><tr><td>Snappy</td><td>否，需要安装</td><td>Snappy</td><td>.snappy</td><td>否</td><td>和文本处理一样，不需要修改</td></tr></tbody></table><p>其中是否可切分代表压缩后是否还可以切分。若不可切分，则其处理数据不要在 mapper 之前。</p><p>为了支持多种压缩/解压缩算法，Hadoop 引入了编码/解码器，如下表所示。</p><table><thead><tr><th>压缩格式</th><th>对应编码/解码器</th></tr></thead><tbody><tr><td>DEFLATE</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>gzip</td><td>org.apache.hadoop.io.compress.GzipCodec</td></tr><tr><td>bzip2</td><td>org.apache.hadoop.io.compress.BZip2Codec</td></tr><tr><td>LZO</td><td>com.hadoop.compression.lzo.LzopCodec</td></tr><tr><td>Snappy</td><td>org.apache.hadoop.io.compress.SnappyCode</td></tr></tbody></table><p>压缩性能的比较</p><table><thead><tr><th>压缩算法</th><th>原始文件大小</th><th>压缩文件大小</th><th>压缩速度</th><th>解压速度</th></tr></thead><tbody><tr><td>gzip</td><td>8.3GB</td><td>1.8GB</td><td>17.5MB/s</td><td>58MB/s</td></tr><tr><td>bzip2</td><td>8.3GB</td><td>1.1GB</td><td>2.4MB/s</td><td>9.5MB/s</td></tr><tr><td>LZO</td><td>8.3GB</td><td>2.9GB</td><td>49.3MB/s</td><td>74.6MB/s</td></tr></tbody></table><p><a href="http://google.github.io/snappy/" target="_blank" rel="noopener">http://google.github.io/snappy/</a></p><p>On a single core of a Core i7 processor in 64-bit mode, Snappy compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more.</p><h3 id="压缩方式选择"><a href="#压缩方式选择" class="headerlink" title="压缩方式选择"></a>压缩方式选择</h3><h4 id="Gzip-压缩"><a href="#Gzip-压缩" class="headerlink" title="Gzip 压缩"></a>Gzip 压缩</h4><p><img src="60.png" alt></p><h4 id="Bzip2-压缩"><a href="#Bzip2-压缩" class="headerlink" title="Bzip2 压缩"></a>Bzip2 压缩</h4><p><img src="61.png" alt></p><h4 id="Lzo-压缩"><a href="#Lzo-压缩" class="headerlink" title="Lzo 压缩"></a>Lzo 压缩</h4><p><img src="62.png" alt></p><h4 id="Snappy-压缩"><a href="#Snappy-压缩" class="headerlink" title="Snappy 压缩"></a>Snappy 压缩</h4><p><img src="63.png" alt></p><h3 id="压缩位置选择"><a href="#压缩位置选择" class="headerlink" title="压缩位置选择"></a>压缩位置选择</h3><p>压缩可以在 MapReduce 作用的任意阶段启用，如图</p><p><img src="64.png" alt></p><p>shuffle 是最应该使用压缩技术的阶段（Map 和 Reduce 之间）</p><h3 id="压缩参数配置"><a href="#压缩参数配置" class="headerlink" title="压缩参数配置"></a>压缩参数配置</h3><p>要在 Hadoop 中启用压缩，可以配置如下参数：</p><table><thead><tr><th>参数</th><th>默认值</th><th>阶段</th><th>建议</th></tr></thead><tbody><tr><td>io.compression.codecs（在 core-site.xml 中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec</td><td>输入压缩</td><td>Hadoop 使用文件扩展名判断是否支持某种编解码器</td></tr><tr><td>mapreduce.map.output.compress（在 mapred-site.xml 中配置）</td><td>false</td><td>mapper 输出</td><td>这个参数设为 true 启用压缩</td></tr><tr><td>mapreduce.map.output.compress.codec（在 mapred-site.xml 中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec</td><td>mapper 输出</td><td>企业多使用 LZO 或 Snappy 编解码器在此阶段压缩数据</td></tr><tr><td>mapreduce.output.fileoutputformat.compress（在 mapred-site.xml 中配置）</td><td>false</td><td>reducer 输出</td><td>这个参数设为 true 启用压缩</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec（在 mapred-site.xml 中配置）</td><td>org.apache.hadoop.io.compress. DefaultCodec</td><td>reducer 输出</td><td>使用标准工具或者编解码器，如 gzip 和 bzip2</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type（在 mapred-site.xml 中配置）</td><td>RECORD</td><td>reducer 输出</td><td>SequenceFile 输出使用的压缩类型：NONE 和 BLOCK</td></tr></tbody></table><h3 id="压缩实操案例"><a href="#压缩实操案例" class="headerlink" title="压缩实操案例"></a>压缩实操案例</h3><h4 id="数据流的压缩和解压缩"><a href="#数据流的压缩和解压缩" class="headerlink" title="数据流的压缩和解压缩"></a>数据流的压缩和解压缩</h4><p><img src="65.png" alt></p><p>测试一下如下压缩方式：</p><p>| DEFLATE | org.apache.hadoop.io.compress.DefaultCodec |<br>| gzip | org.apache.hadoop.io.compress.GzipCodec |<br>| bzip2 | org.apache.hadoop.io.compress.BZip2Codec |</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>compress<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodecFactory<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ReflectionUtils<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * @Author: Swenchao * @Date: 2020/9/17 上午 10:54 * @Func: 压缩 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestCompress</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 压缩（可以更换不同压缩方式）</span>        <span class="token function">compress</span><span class="token punctuation">(</span><span class="token string">"D:/scwri/Desktop/inputWeb/web.log"</span><span class="token punctuation">,</span><span class="token string">"org.apache.hadoop.io.compress.BZip2Codec"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 解压缩</span>        <span class="token function">decompress</span><span class="token punctuation">(</span><span class="token string">"d:/scwri/Desktop/inputWeb/web.log.bz2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">decompress</span><span class="token punctuation">(</span>String fileName<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 压缩方式检查</span>        CompressionCodecFactory factory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">CompressionCodecFactory</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionCodec codec <span class="token operator">=</span> factory<span class="token punctuation">.</span><span class="token function">getCodec</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>codec <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"can not process"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 获取输入流</span>        FileInputStream fis <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionInputStream cis <span class="token operator">=</span> codec<span class="token punctuation">.</span><span class="token function">createInputStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取输出流</span>        FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName <span class="token operator">+</span> <span class="token string">".decode"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 流的对拷</span>        IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>cis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>cis<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">compress</span><span class="token punctuation">(</span>String fileName<span class="token punctuation">,</span> String method<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//获取输入流</span>        FileInputStream fis <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Class<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span> theClass <span class="token operator">=</span> Class<span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span>method<span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionCodec codec <span class="token operator">=</span> <span class="token punctuation">(</span>CompressionCodec<span class="token punctuation">)</span> ReflectionUtils<span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span>theClass<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取输出流(需要一个压缩后的扩展名)</span>        FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>fileName <span class="token operator">+</span> codec<span class="token punctuation">.</span><span class="token function">getDefaultExtension</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        CompressionOutputStream cos <span class="token operator">=</span> codec<span class="token punctuation">.</span><span class="token function">createOutputStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//流的对拷(参数：输入流、输出流、缓冲区（自己设置）、最后是否关闭输入流和输出流)</span>        IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> cos<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关闭资源</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>cos<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Map-输出端采用压缩"><a href="#Map-输出端采用压缩" class="headerlink" title="Map 输出端采用压缩"></a>Map 输出端采用压缩</h4><p>即使你的 Ma pReduce 的输入输出文件都是未压缩的文件，你仍然可以对 Map 任务的中间结果输出做压缩，因为它要写在硬盘并且通过网络传输到 Reduce 节点，对其压缩可以提高很多性能，这些工作只要设置两个属性即可，我们来看下代码怎么设置。</p><p>1．给大家提供的 Hadoop 源码支持的压缩格式有：BZip2Codec 、DefaultCodec</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>BZip2Codec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>CombineTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_words/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 开启map端输出压缩</span>        conf<span class="token punctuation">.</span><span class="token function">setBoolean</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress"</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置map端输出压缩方式</span>        conf<span class="token punctuation">.</span><span class="token function">setClass</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress.codec"</span><span class="token punctuation">,</span> BZip2Codec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> CompressionCodec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联map和reduce</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置mapper阶段输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入路径和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．Mapper 保持不变</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * map阶段 * @author swenchao */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token punctuation">{</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3．Reducer 保持不变</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * reduce阶段 * @author swenchao */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span> <span class="token punctuation">{</span>    IntWritable value <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 累加求和</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>IntWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span><span class="token punctuation">{</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        value<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Reduce-输出端采用压缩"><a href="#Reduce-输出端采用压缩" class="headerlink" title="Reduce 输出端采用压缩"></a>Reduce 输出端采用压缩</h4><p>基于 WordCount 案例处理。</p><p>1．修改驱动</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>swenchao<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>BZip2Codec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>CompressionCodec<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>CombineTextInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token punctuation">{</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span><span class="token string">"D:/scwri/Desktop/input_words/"</span><span class="token punctuation">,</span> <span class="token string">"D:/scwri/Desktop/output"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 开启map端输出压缩</span>        conf<span class="token punctuation">.</span><span class="token function">setBoolean</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress"</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置map端输出压缩方式</span>        conf<span class="token punctuation">.</span><span class="token function">setClass</span><span class="token punctuation">(</span><span class="token string">"mapreduce.map.output.compress.codec"</span><span class="token punctuation">,</span> BZip2Codec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> CompressionCodec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取job对象</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置reduce端输出压缩开启</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setCompressOutput</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置压缩的方式</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputCompressorClass</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> BZip2Codec<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 关联map和reduce</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置最终输出数据的k 和 v类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置输入路径和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．Mapper 和 Reducer 保持不变（跟之前 WordCount 一样）</p><h2 id="Yarn-资源调度器"><a href="#Yarn-资源调度器" class="headerlink" title="Yarn 资源调度器"></a>Yarn 资源调度器</h2><p>Yarn 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而 MapReduce 等运算程序则相当于运行于操作系统之上的应用程序。</p><h3 id="Yarn-基本架构"><a href="#Yarn-基本架构" class="headerlink" title="Yarn 基本架构"></a>Yarn 基本架构</h3><p>YARN 主要由 ResourceManager、NodeManager、ApplicationMaster 和 Container 等组件构成，如图:</p><p><img src="66.png" alt></p><p>ResourceManager：整个集群老大<br>NodeManager：某个节点老大<br>ApplicationMaster：job 老大<br>Container：虚拟化资源分配</p><h3 id="Yarn-工作机制"><a href="#Yarn-工作机制" class="headerlink" title="Yarn 工作机制"></a>Yarn 工作机制</h3><p>1．Yarn 运行机制，如图：</p><p><img src="67.png" alt></p><p>2．工作机制详解</p><p>（1）MR 程序提交到客户端所在的节点。</p><p>（2）YarnRunner 向 ResourceManager 申请一个 Application。</p><p>（3）RM 将该应用程序的资源路径返回给 YarnRunner。</p><p>（4）该程序将运行所需资源提交到 HDFS 上。</p><p>（5）程序资源提交完毕后，申请运行 mrAppMaster。</p><p>（6）RM 将用户的请求初始化成一个 Task。</p><p>（7）其中一个 NodeManager 领取到 Task 任务。</p><p>（8）该 NodeManager 创建容器 Container，并产生 MRAppmaster。</p><p>（9）Container 从 HDFS 上拷贝资源到本地。</p><p>（10）MRAppmaster 向 RM 申请运行 MapTask 资源。</p><p>（11）RM 将运行 MapTask 任务分配给另外两个 NodeManager，另两个 NodeManager 分别领取任务并创建容器。</p><p>（12）MR 向两个接收到任务的 NodeManager 发送程序启动脚本，这两个 NodeManager 分别启动 MapTask，MapTask 对数据分区排序。</p><p>（13）MrAppMaster 等待所有 MapTask 运行完毕后，向 RM 申请容器，运行 ReduceTask。</p><p>（14）ReduceTask 向 MapTask 获取相应分区的数据。</p><p>（15）程序运行完毕后，MR 会向 RM 申请注销自己。</p><h3 id="作业提交全过程"><a href="#作业提交全过程" class="headerlink" title="作业提交全过程"></a>作业提交全过程</h3><p>1．作业提交过程之 YARN，如图：</p><p><img src="67.png" alt></p><p>Map 过程：read（读取）——&gt;map（分）——&gt;collect（收集）——&gt;spill（溢写）——&gt;merge（合并）</p><p>Reduce 过程：copy（拷贝 map 过程的数据）——&gt;merge+sort（归并排序）——&gt;reduce</p><p>作业提交全过程详解</p><p>（1）作业提交</p><p>第 1 步：Client 调用 job.waitForCompletion 方法，向整个集群提交 MapReduce 作业。</p><p>第 2 步：Client 向 RM 申请一个作业 id。</p><p>第 3 步：RM 给 Client 返回该 job 资源的提交路径和作业 id。</p><p>第 4 步：Client 提交 jar 包、切片信息和配置文件到指定的资源提交路径。</p><p>第 5 步：Client 提交完资源后，向 RM 申请运行 MrAppMaster。</p><p>（2）作业初始化</p><p>第 6 步：当 RM 收到 Client 的请求后，将该 job 添加到容量调度器中。</p><p>第 7 步：某一个空闲的 NM 领取到该 Job。</p><p>第 8 步：该 NM 创建 Container，并产生 MRAppmaster。</p><p>第 9 步：下载 Client 提交的资源到本地。</p><p>（3）任务分配</p><p>第 10 步：MrAppMaster 向 RM 申请运行多个 MapTask 任务资源。</p><p>第 11 步：RM 将运行 MapTask 任务分配给另外两个 NodeManager，另两个 NodeManager 分别领取任务并创建容器。</p><p>（4）任务运行</p><p>第 12 步：MR 向两个接收到任务的 NodeManager 发送程序启动脚本，这两个 NodeManager 分别启动 MapTask，MapTask 对数据分区排序。</p><p>第 13 步：MrAppMaster 等待所有 MapTask 运行完毕后，向 RM 申请容器，运行 ReduceTask。</p><p>第 14 步：ReduceTask 向 MapTask 获取相应分区的数据。</p><p>第 15 步：程序运行完毕后，MR 会向 RM 申请注销自己。</p><p>（5）进度和状态更新</p><p>YARN 中的任务将其进度和状态(包括 counter)返回给应用管理器, 客户端每秒(通过 mapreduce.client.progressmonitor.pollinterval 设置)向应用管理器请求进度更新, 展示给用户。</p><p>（6）作业完成</p><p>除了向应用管理器请求作业进度外, 客户端每 5 秒都会通过调用 waitForCompletion()来检查作业是否完成。时间间隔可以通过 mapreduce.client.completion.pollinterval 来设置。作业完成之后, 应用管理器和 Container 会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</p><p>2．作业提交过程之 MapReduce，如图：</p><p><img src="68.png" alt></p><p>其中 HDFS 文件操作中就牵扯到了 NameNode 和 Secondary NameNode 相等问题（日志+2NN=NN）</p><h3 id="资源调度器（作业提交过程中任务队列）"><a href="#资源调度器（作业提交过程中任务队列）" class="headerlink" title="资源调度器（作业提交过程中任务队列）"></a>资源调度器（作业提交过程中任务队列）</h3><p>目前，Hadoop 作业调度器主要有三种：FIFO、Capacity Scheduler 和 Fair Scheduler。Hadoop2.7.2 默认的资源调度器是 Capacity Scheduler。</p><p>[yarn-default.xml]</p><pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>            The class to use as the resource scheduler.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.scheduler.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>            org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>1．先进先出调度器（FIFO）</p><p><img src="69.png" alt></p><p>其中分配多少个 task，得看现在可用资源有多少。其中可能一下分配很多个 task。</p><p>2．容量调度器（Capacity Scheduler）</p><p><img src="70.png" alt></p><p>多个 FIFO 调度器的总和</p><p>3．公平调度器（Fair Scheduler）</p><p><img src="71.png" alt></p><p>容量调度器中，作业并不是公平享有，得按一定规则排好序，然后按优先级来获取资源。</p><p>如果机器性能高，想要并发度，可以采用第三种；若机器性能差点，还想要并发度，可以采用第二种；第一种完全没有并发度。</p><h3 id="任务的推测执行"><a href="#任务的推测执行" class="headerlink" title="任务的推测执行"></a>任务的推测执行</h3><p>1．作业完成时间取决于最慢的任务完成时间</p><p>一个作业由若干个 Map 任务和 Reduce 任务构成。因硬件老化、软件 Bug 等，某些任务可能运行非常慢。</p><p>2．推测执行机制</p><p>发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。</p><p>3．执行推测任务的前提条件</p><p>（1）每个 Task 只能有一个备份任务</p><p>（2）当前 Job 已完成的 Task 必须不小于 0.05（5%）</p><p>（3）开启推测执行参数设置。mapred-site.xml 文件中默认是打开的。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.map.speculative<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>If true, then multiple instances of some map tasks may be executed in parallel.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.reduce.speculative<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>If true, then multiple instances of some reduce tasks may be executed in parallel.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4．不能启用推测执行机制情况</p><p>（1）任务间存在严重的负载倾斜；</p><p>（2）特殊任务，比如任务向数据库中写数据。</p><p>5．算法原理，如图</p><p><img src="72.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS完整版笔记</title>
      <link href="2020/09/03/hadoop-hdfs-wan-zheng-ban-bi-ji/"/>
      <url>2020/09/03/hadoop-hdfs-wan-zheng-ban-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>感觉不是很重要，文件块大小那节要明白，其他稍微了解下就可以了~</p><h3 id="产生背景及定义"><a href="#产生背景及定义" class="headerlink" title="产生背景及定义"></a>产生背景及定义</h3><p><img src="d:%5Cscwri%5CDesktop%5C1.png" alt></p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><img src="d:%5Cscwri%5CDesktop%5C2.png" alt="优点"></p><p><img src="d:%5Cscwri%5CDesktop%5C3.png" alt="缺点"></p><h3 id="组成架构（之前概述讲过-）"><a href="#组成架构（之前概述讲过-）" class="headerlink" title="组成架构（之前概述讲过 ）"></a>组成架构（之前概述讲过 ）</h3><p><img src="d:%5Cscwri%5CDesktop%5C4.png" alt></p><p><img src="d:%5Cscwri%5CDesktop%5C5.png" alt></p><h3 id="文件块大小"><a href="#文件块大小" class="headerlink" title="文件块大小"></a>文件块大小</h3><p><img src="d:%5Cscwri%5CDesktop%5C6.png" alt></p><p><strong>注：文件块不能设置太小也不能设置太大。因为如果设置太小，会增加寻址时间，程序会一直在寻找块开始的位置；若块设置太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。HDFS块的大小设置主要取决于磁盘的传输速率</strong></p><h2 id="HDFS-的-Shell-操作"><a href="#HDFS-的-Shell-操作" class="headerlink" title="HDFS 的 Shell 操作"></a>HDFS 的 Shell 操作</h2><p>1．基本语法</p><pre><code>bin/hadoop fs 具体命令   OR  bin/hdfs dfs 具体命令</code></pre><p>dfs是fs的实现类。</p><p>2．命令大全</p><p>可通过如下命令进行查看</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3．常用命令实操</p><p>（1）启动Hadoop集群（方便后续的测试）</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh    [user_test@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）-help：查询命令参数及功能</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -help rm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）-ls: 显示目录信息</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -ls /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>递归查看</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr /    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -ls -R /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）-mkdir：在HDFS上创建目录</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mkdir -p /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）-moveFromLocal：从本地剪切粘贴到HDFS</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ touch test.txt    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs  -moveFromLocal test.txt  /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>往 test.txt 文件中输入任意内容，等会测试追加</p><p>（6）-appendToFile：追加一个文件到已经存在的文件末尾</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ touch testAppend.txt    [user_test@hadoop102 hadoop-2.7.2]$ vim testAppend.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入任意内容</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -appendToFile testAppend.txt /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）-cat：显示文件内容</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -cat /user/test/input/kongtest.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（8）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs  -chmod  666 /user/test/input/test.txt[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs  -chown  user_test:user   /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（9）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -copyFromLocal README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（10）-copyToLocal：从HDFS拷贝到本地</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -copyToLocal /user/test/input/test.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（11）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -cp /user/test/input/test.txt /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（12）-mv：在HDFS目录中移动文件</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mv /user/test/input/test.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（13）-get：等同于copyToLocal，就是从HDFS下载文件到本地</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -get /user/test/input/test.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（14）-getmerge：合并下载多个文件，比如HDFS的目录 /user/user_test/test下有多个文件:log.1, log.2,log.3,…</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -getmerge /user/user_test/test/* ./merge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（15）-put：等同于copyFromLocal</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -put ./merge.txt /user/test/input/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（16）-tail：显示一个文件的末尾</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -tail /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（17）-rm：删除文件或文件夹</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -rm /user/test/input/merge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（18）-rmdir：删除空目录</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mkdir /test_null    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -rmdir /test_null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（19）-du统计文件夹的大小信息</p><p>统计整个文件大小</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -du -s -h /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>——&gt; 2.7 K</code></pre><p>分别列出大小</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -du -h /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>——&gt;2.1.3 K  /user/test/input/README.txt15     /user/test/input/jinlian.txt1.4 K  /user/test/input/zaiyiqi.txt</code></pre><p>（20）-setrep：设置HDFS中文件的副本数量</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -setrep 10 /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</strong></p><h2 id="HDFS客户端环境"><a href="#HDFS客户端环境" class="headerlink" title="HDFS客户端环境"></a>HDFS客户端环境</h2><h3 id="HDFS客户端环境准备"><a href="#HDFS客户端环境准备" class="headerlink" title="HDFS客户端环境准备"></a>HDFS客户端环境准备</h3><p>1．根据自己电脑的操作系统选择对应的编译后的hadoop jar包保存到非中文路径下（例如：D:\nonblank\hadoop-2.7.2）</p><p>2．配置HADOOP_HOME环境变量</p><p><img src="1.png" alt></p><ol start="3"><li>配置Path环境变量</li></ol><p><img src="2.png" alt></p><p>4．创建一个Maven工程HdfsClientDemo</p><p>5．导入相应的依赖并添加日志</p><p>（1）导入依赖</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span>dependencies<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>junit<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>junit<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span>RELEASE<span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>log4j<span class="token operator">-</span>core<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.8</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>hadoop<span class="token operator">-</span>common<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>hadoop<span class="token operator">-</span>client<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>hadoop<span class="token operator">-</span>hdfs<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>jdk<span class="token punctuation">.</span>tools<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>jdk<span class="token punctuation">.</span>tools<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">1.8</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>        <span class="token operator">&lt;</span>scope<span class="token operator">></span>system<span class="token operator">&lt;</span><span class="token operator">/</span>scope<span class="token operator">></span>        <span class="token operator">&lt;</span>systemPath<span class="token operator">></span>$<span class="token punctuation">{</span>JAVA_HOME<span class="token punctuation">}</span><span class="token operator">/</span>lib<span class="token operator">/</span>tools<span class="token punctuation">.</span>jar<span class="token operator">&lt;</span><span class="token operator">/</span>systemPath<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>dependencies<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）添加日志相关</p><p>在src/main/resources目录下，新建一个文件，命名为“log4j.properties”，填写如下内容：</p><pre><code>log4j.rootLogger=INFO, stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%nlog4j.appender.logfile=org.apache.log4j.FileAppenderlog4j.appender.logfile.File=target/spring.loglog4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</code></pre><p>6．创建包名：bigdata.hadoop.hdfs</p><p>7．创建HdfsClient类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClient</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testMkdirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 配置在集群上运行(方式1)</span>        <span class="token comment" spellcheck="true">// configuration.set("fs.defaultFS", "hdfs://hadoop102:9000");</span>        <span class="token comment" spellcheck="true">// FileSystem fs = FileSystem.get(configuration);</span>        <span class="token comment" spellcheck="true">// 方式2(其中user_test为用户名)</span>        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 创建目录</span>        fs<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/user_test/test/sc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关闭资源</span>        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>8．执行程序</p><p>方式1运行时需要配置用户名称</p><p><img src="3.png" alt></p><p><img src="4.png" alt></p><p>客户端去操作HDFS时，是有一个用户身份的。默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=user_test，user_test为用户名称。</p><h3 id="HDFS的API操作"><a href="#HDFS的API操作" class="headerlink" title="HDFS的API操作"></a>HDFS的API操作</h3><h4 id="HDFS文件上传（测试参数优先级）"><a href="#HDFS文件上传（测试参数优先级）" class="headerlink" title="HDFS文件上传（测试参数优先级）"></a>HDFS文件上传（测试参数优先级）</h4><p>1．编写源代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyFromLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"dfs.replication"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 上传文件（第一个地址为本地的，第二个为hdfs上的地址）</span>    fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"over"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．将hdfs-site.xml拷贝到项目的根目录下（配置文件设置备份数量——这里是1）</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>*<em>注：<br>参数优先级排序：（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）服务器的默认配置<br>*</em></p><h4 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyToLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 执行下载操作(第一个地址是hdfs地址，第二个为本地地址)</span>    <span class="token comment" spellcheck="true">//可选参数</span>    <span class="token comment" spellcheck="true">// boolean delSrc 指是否将原文件删除</span>    <span class="token comment" spellcheck="true">// Path src 指要下载的文件路径</span>    <span class="token comment" spellcheck="true">// Path dst 指将文件下载到的路径</span>    <span class="token comment" spellcheck="true">// boolean useRawLocalFileSystem 是否开启文件校验（若不开启就会产生一个crc的校验文件）</span>    fs<span class="token punctuation">.</span><span class="token function">copyToLocalFile</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件夹删除"><a href="#HDFS文件夹删除" class="headerlink" title="HDFS文件夹删除"></a>HDFS文件夹删除</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDelete</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 执行删除(第一个是要删除的地址；若是删除的是个路径，则第二个必须为true，文件则无所谓)</span>    fs<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/test"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件名更改"><a href="#HDFS文件名更改" class="headerlink" title="HDFS文件名更改"></a>HDFS文件名更改</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testRename</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 2 修改文件名称(第一个为源文件名称，第二个为新文件名称)</span>    fs<span class="token punctuation">.</span><span class="token function">rename</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/newTest.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件详情查看"><a href="#HDFS文件详情查看" class="headerlink" title="HDFS文件详情查看"></a>HDFS文件详情查看</h4><p>查看文件名称、权限、长度、块信息</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 2 获取文件详情(第二个参数为递归查看)</span>    RemoteIterator<span class="token operator">&lt;</span>LocatedFileStatus<span class="token operator">></span> listFiles <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 遍历迭代器</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>listFiles<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        LocatedFileStatus status <span class="token operator">=</span> listFiles<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 输出详情</span>        <span class="token comment" spellcheck="true">// 文件名称</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 长度</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 权限</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 分组</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取存储的块信息</span>        BlockLocation<span class="token punctuation">[</span><span class="token punctuation">]</span> blockLocations <span class="token operator">=</span> status<span class="token punctuation">.</span><span class="token function">getBlockLocations</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>BlockLocation blockLocation <span class="token operator">:</span> blockLocations<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获取块存储的主机节点</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> hosts <span class="token operator">=</span> blockLocation<span class="token punctuation">.</span><span class="token function">getHosts</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>String host <span class="token operator">:</span> hosts<span class="token punctuation">)</span> <span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>host<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"------------------------"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件和文件夹判断"><a href="#HDFS文件和文件夹判断" class="headerlink" title="HDFS文件和文件夹判断"></a>HDFS文件和文件夹判断</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件配置信息</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 判断是文件还是文件夹</span>    FileStatus<span class="token punctuation">[</span><span class="token punctuation">]</span> listStatus <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>FileStatus fileStatus <span class="token operator">:</span> listStatus<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 如果是文件</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>fileStatus<span class="token punctuation">.</span><span class="token function">isFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"f:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"d:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="HDFS的I-O流操作"><a href="#HDFS的I-O流操作" class="headerlink" title="HDFS的I/O流操作"></a>HDFS的I/O流操作</h3><p>上面api都是框架封装好的。现在可以尝试自己实现（我们可以采用IO流的方式实现数据的上传和下载）</p><h4 id="HDFS文件上传"><a href="#HDFS文件上传" class="headerlink" title="HDFS文件上传"></a>HDFS文件上传</h4><p>1．需求：把本地的test.txt文件上传到HDFS根目录</p><p>2．编写代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">putFileToHDFS</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 创建输入流</span>    FileInputStream fis <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 获取输出流</span>    FSDataOutputStream fos <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 流对拷</span>    IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 5 关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件下载-1"><a href="#HDFS文件下载-1" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h4><p>1．需求：从HDFS上下载test.txt文件到本地</p><p>2．编写代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 文件下载</span><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">getFileFromHDFS</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 输入流：写出的；输出流：写入的——在这个里面本地就是输出流，hdfs就是输出流</span>    <span class="token comment" spellcheck="true">// 2 获取输入流</span>    FSDataInputStream fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 获取输出流</span>    FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 流的对拷</span>    IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 5 关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="文件定位读取"><a href="#文件定位读取" class="headerlink" title="文件定位读取"></a>文件定位读取</h4><p>1．需求：分块读取HDFS上的大文件，比如根目录下的/hadoop-2.7.2.tar.gz（首先手动将文件上传到hdfs——分成两块）</p><p>2．编写代码</p><pre class="line-numbers language-java"><code class="language-java">（<span class="token number">1</span>）下载第一块<span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFileSeek1</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 获取输入流</span>    FSDataInputStream fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 创建输出流</span>    FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz.part1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 流的拷贝（若还用copyBytes来拷贝，则是拷贝的全部）</span>    <span class="token comment" spellcheck="true">// 相当与1k</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">byte</span><span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 读取128M</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">128</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        fis<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>buf<span class="token punctuation">)</span><span class="token punctuation">;</span>        fos<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>buf<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 5关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java"><code class="language-java">（<span class="token number">2</span>）下载第二块<span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFileSeek2</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 打开输入流</span>    FSDataInputStream fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 定位输入数据位置(128M位置处)</span>    fis<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 创建输出流</span>    FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz.part2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 5 流的对拷</span>    IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 6 关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）合并文件</p><p>在Window命令窗口中进入到下载文件目录下，然后执行命令，进行数据合并</p><pre class="line-numbers language-shell"><code class="language-shell">    type hadoop-2.7.2.tar.gz.part2 >> hadoop-2.7.2.tar.gz.part1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>合并完成后，将hadoop-2.7.2.tar.gz.part1重新命名为hadoop-2.7.2.tar.gz。</p><h2 id="HDFS的数据流（面试重点）"><a href="#HDFS的数据流（面试重点）" class="headerlink" title="HDFS的数据流（面试重点）"></a>HDFS的数据流（面试重点）</h2><h3 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h3><h4 id="剖析文件写入"><a href="#剖析文件写入" class="headerlink" title="剖析文件写入"></a>剖析文件写入</h4><p>HDFS写数据流程，如下</p><p><img src="1.png" alt></p><p>1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p><p>2）NameNode返回是否可以上传。</p><p>3）客户端请求第一个 Block上传到哪几个DataNode服务器上。</p><p>4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3（备份）。</p><p>5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p><p>6）dn1、dn2、dn3逐级应答客户端。</p><p>7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3（这个过程是通过内存缓存来传的，因为速度快）；dn1每传一个packet会放入一个应答队列等待应答。</p><p>8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p><h4 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h4><p>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。</p><p><strong>节点距离：两个节点到达最近的共同祖先的距离总和。</strong></p><p><img src="2.png" alt></p><h4 id="机架感知（副本存储节点选择）"><a href="#机架感知（副本存储节点选择）" class="headerlink" title="机架感知（副本存储节点选择）"></a>机架感知（副本存储节点选择）</h4><ol><li>官方ip地址</li></ol><p>机架感知说明</p><p><a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication</a></p><p>For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.</p><ol start="2"><li>Hadoop2.7.2副本节点选择</li></ol><p><img src="3.png" alt></p><h3 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h3><p><img src="1.png" alt></p><p>其中 ss.avi 有三个副本，每个副本有两块。</p><p>1）客户端通过 Distributed FileSystem 向 NameNode 请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p><p>2）挑选一台 DataNode 服务器（就近原则），请求读取数据。若数据损坏，则选择一个副本来进行读取。</p><p>3）DataNode 开始传输数据给客户端（从磁盘里面读取数据输入流，以 Packet 为单位来做校验）。</p><p>4）客户端以 Packet 为单位接收，先在本地缓存，然后写入目标文件。</p><h2 id="NameNode和SecondaryNameNode（面试开发重点）"><a href="#NameNode和SecondaryNameNode（面试开发重点）" class="headerlink" title="NameNode和SecondaryNameNode（面试开发重点）"></a>NameNode和SecondaryNameNode（面试开发重点）</h2><h3 id="NN和2NN工作机制"><a href="#NN和2NN工作机制" class="headerlink" title="NN和2NN工作机制"></a>NN和2NN工作机制</h3><p><strong>思考：NameNode中的元数据是存储在哪里的？</strong></p><p>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。</p><p>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。</p><p>但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。</p><p>NN和2NN工作机制，如下：</p><p><img src="2.png" alt></p><ol><li>第一阶段：NameNode启动</li></ol><p>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p><p>（2）客户端对元数据进行增删改的请求。</p><p>（3）NameNode记录操作日志，更新滚动日志。</p><p>（4）NameNode在内存中对数据进行增删改。</p><p><strong>之所以先更新日志再进行操作，是因为如果先操作数据，未写日志突然断电，那么数据操作有可能丢失，无法还原。</strong></p><ol start="2"><li>第二阶段：Secondary NameNode工作</li></ol><p>（1）Secondary NameNode 询问NameNode是否需要 CheckPoint。直接带回NameNode是否检查结果。<br>CheckPoint是一个检查点，检测是否需要合并日志文件和 fsimage 然后再序列化到 fsimge 中。</p><p>（2）若触发条件满足了，则 Secondary NameNode 请求执行CheckPoint。</p><p>（3）NameNode滚动正在编写的Edits日志，避免在合并的时候没法继续编写操作（001为原来的，然后新的日志先写到002中）。</p><p>（4）将滚动前的编辑日志和镜像文件拷贝到 Secondary NameNode。</p><p>（5）Secondary NameNode 加载编辑日志和镜像文件到内存，并合并。</p><p>（6）生成新的镜像文件 fsimage.chkpoint。</p><p>（7）拷贝 fsimage.chkpoint 到 NameNode。</p><p>（8）NameNode 将 fsimage.chkpoint 重新命名成 fsimage（现在情况是002和新的镜像文件fsimage合起来就是当前内存中最新的内容）。</p><p><strong>NN和2NN工作机制详解</strong></p><p>Fsimage：NameNode内存中元数据序列化后形成的文件。</p><p>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。</p><p>NameNode 启动时，先滚动Edits并生成一个空的 edits.inprogress，然后加载Edits和Fsimage 到内存中，此时 NameNode 内存就持有最新的元数据信息。</p><p>Client 开始对NameNode 发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress 中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时 NameNode 挂掉，重启后会从 Edits 中读取元数据的信息。然后，NameNode 会在内存中执行元数据的增删改的操作。</p><p>由于 Edits 中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对 Edits 和 Fsimage 进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。</p><p>SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。<br>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。</p><p>NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p><h3 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h3><ol><li>概念</li></ol><p><img src="3.png" alt></p><ol start="2"><li>oiv查看Fsimage文件</li></ol><p>（1）查看oiv和oev命令</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 current]$ hdfs——>...oiv        apply the offline fsimage viewer to an fsimageoev        pply the offline edits viewer to an edits file...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）基本语法</p><pre class="line-numbers language-shell"><code class="language-shell">hdfs oiv -p （要将 fsimage 转化成的格式） -i （镜像文件） -o （转换后文件输出路径）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）案例实操（其中文件名称可能有区别）</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 current]$ pwd——>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current[user_test@hadoop102 current]$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-2.7.2/fsimage.xml[user_test@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/fsimage.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将显示的xml文件内容拷贝到idea中创建的xml文件中，并格式化。部分显示结果如下（代码信息会有所区别）。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16386<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>DIRECTORY<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512722284477<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>user_test:supergroup:rwxr-xr-x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nsquota</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dsquota</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16387<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>DIRECTORY<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512790549080<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>user_test:supergroup:rwxr-xr-x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nsquota</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dsquota</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16389<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>FILE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>wc.input<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>replication</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>replication</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512722322219<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>atime</span><span class="token punctuation">></span></span>1512722321610<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>atime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>perferredBlockSize</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>perferredBlockSize</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>user_test:supergroup:rw-r--r--<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>blocks</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>block</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>1073741825<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>genstamp</span><span class="token punctuation">></span></span>1001<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>genstamp</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>numBytes</span><span class="token punctuation">></span></span>59<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>numBytes</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>block</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>blocks</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>思考：可以看出，Fsimage中没有记录块所对应DataNode，为什么？</strong></p><p>在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。（datanode运行机制会详细说）</p><ol start="3"><li>oev查看Edits文件</li></ol><p>（1）基本语法</p><pre class="line-numbers language-shell"><code class="language-shell">hdfs oev -p （要将 fsimage 转化成的格式） -i （镜像文件） -o （转换后文件输出路径）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）案例实操</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 current]$ hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-2.7.2/edits.xml[user_test@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/edits.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>将显示的xml文件内容拷贝到 idea 中创建的xml文件中，并格式化。显示结果如下。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EDITS</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EDITS_VERSION</span><span class="token punctuation">></span></span>-63<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>EDITS_VERSION</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_START_LOG_SEGMENT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>129<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ADD<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>130<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LENGTH</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LENGTH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>INODEID</span><span class="token punctuation">></span></span>16407<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>INODEID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>REPLICATION</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>REPLICATION</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MTIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MTIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ATIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ATIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCKSIZE</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCKSIZE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_NAME</span><span class="token punctuation">></span></span>DFSClient_NONMAPREDUCE_-1544295051_1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_NAME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>192.168.1.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OVERWRITE</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OVERWRITE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>USERNAME</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>USERNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GROUPNAME</span><span class="token punctuation">></span></span>supergroup<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GROUPNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MODE</span><span class="token punctuation">></span></span>420<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MODE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>908eafd4-9aec-4288-96f1-e8011d181561<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CALLID</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CALLID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ALLOCATE_BLOCK_ID<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>131<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_SET_GENSTAMP_V2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>132<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMPV2</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMPV2</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ADD_BLOCK<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>133<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>NUM_BYTES</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>NUM_BYTES</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMP</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMP</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CLIENTID</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CALLID</span><span class="token punctuation">></span></span>-2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CALLID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_CLOSE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>134<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LENGTH</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LENGTH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>INODEID</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>INODEID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>REPLICATION</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>REPLICATION</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MTIME</span><span class="token punctuation">></span></span>1512943608761<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MTIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ATIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ATIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCKSIZE</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCKSIZE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_NAME</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_NAME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OVERWRITE</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OVERWRITE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>NUM_BYTES</span><span class="token punctuation">></span></span>25<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>NUM_BYTES</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMP</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMP</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>USERNAME</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>USERNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GROUPNAME</span><span class="token punctuation">></span></span>supergroup<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GROUPNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MODE</span><span class="token punctuation">></span></span>420<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MODE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>EDITS</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>说明：</strong></p><pre><code>OP_START_LOG_SEGMENT：日志开始OP_MKDIR：创建路径OP_ADD：上传文件OP_ALLOCATE_BLOCK_ID：分配块 idOP_SET_GENSTAMP_V2：创建时间戳OP_ADD_BLOCK：添加块信息OP_CLOSE：操作结束OP_RENAME_OLD：重命名原来复制的文件</code></pre><p><strong>思考：NameNode如何确定下次开机启动的时候合并哪些Edits？</strong></p><p>根据 seen_txid 文件中数据来合并，其中记录了最新的。</p><h3 id="CheckPoint时间设置"><a href="#CheckPoint时间设置" class="headerlink" title="CheckPoint时间设置"></a>CheckPoint时间设置</h3><p>（1）通常情况下，SecondaryNameNodec每隔一小时执行一次(3600秒)。</p><p>配置文件：hdfs-default.xml</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>3600<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode 执行一次。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.txns<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1000000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>操作动作次数<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.check.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>60<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span> 1分钟检查一次操作次数<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="NameNode故障处理"><a href="#NameNode故障处理" class="headerlink" title="NameNode故障处理"></a>NameNode故障处理</h3><p>NameNode故障后，可以采用如下两种方法恢复数据。</p><h4 id="方法一：将-SecondaryNameNode-中数据拷贝到-NameNode-中进行数据备份或恢复；"><a href="#方法一：将-SecondaryNameNode-中数据拷贝到-NameNode-中进行数据备份或恢复；" class="headerlink" title="方法一：将 SecondaryNameNode 中数据拷贝到 NameNode 中进行数据备份或恢复；"></a>方法一：将 SecondaryNameNode 中数据拷贝到 NameNode 中进行数据备份或恢复；</h4><ol><li><p>kill -9 NameNode进程号</p></li><li><p>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>拷贝SecondaryNameNode中数据到原NameNode存储数据目录</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 dfs]$ scp -r user_test@hadoop104:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* ./name/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>重新启动NameNode</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="方法二：使用-importCheckpoint-选项启动-NameNode-守护进程，从而将-SecondaryNameNode-中数据拷贝到-NameNode-目录中。"><a href="#方法二：使用-importCheckpoint-选项启动-NameNode-守护进程，从而将-SecondaryNameNode-中数据拷贝到-NameNode-目录中。" class="headerlink" title="方法二：使用 -importCheckpoint 选项启动 NameNode 守护进程，从而将 SecondaryNameNode 中数据拷贝到 NameNode 目录中。"></a>方法二：使用 -importCheckpoint 选项启动 NameNode 守护进程，从而将 SecondaryNameNode 中数据拷贝到 NameNode 目录中。</h4><ol><li>修改hdfs-site.xml中的（因为原来的3600秒时间太长了，所以改成120）</li></ol><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>120<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-2.7.2/data/tmp/dfs/name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li><p>kill -9 NameNode 进程</p></li><li><p>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>如果 SecondaryNameNode 不和 NameNode 在一个主机节点上，需要将 SecondaryNameNode 存储数据的目录拷贝到 NameNode 存储数据的平级目录，并删除 in_use.lock 文件</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 dfs]$ scp -r user_test@hadoop104:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary ./[user_test@hadoop102 namesecondary]$ rm -rf in_use.lock[user_test@hadoop102 dfs]$ pwd/opt/module/hadoop-2.7.2/data/tmp/dfs[user_test@hadoop102 dfs]$ lsdata  name  namesecondary<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>导入检查点数据（等待一会ctrl+c结束掉）</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -importCheckpoint<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>启动NameNode</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="集群安全模式"><a href="#集群安全模式" class="headerlink" title="集群安全模式"></a>集群安全模式</h3><ol><li>概述</li></ol><p><img src="4.png" alt></p><ol start="2"><li>基本语法</li></ol><p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p><pre class="line-numbers language-shell"><code class="language-shell">    （1）bin/hdfs dfsadmin -safemode get        （查看安全模式状态）    （2）bin/hdfs dfsadmin -safemode enter      （进入安全模式状态）    （3）bin/hdfs dfsadmin -safemode leave    （离开安全模式状态）    （4）bin/hdfs dfsadmin -safemode wait        （等待安全模式状态）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>案例</li></ol><p>模拟等待安全模式（在安全模式时间内，来了任务，需要让其等待安全模式结束，然后立即执行。比如：银行对账时，在凌晨进行，在对账这个过程中，是不允许进行任何交易的，因此需要等待对账结束，然后）</p><p>（1）查看当前模式</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -safemode get——>Safe mode is OFF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）先进入安全模式</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs dfsadmin -safemode enter——>Safe mode is ON<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>上传文件进行测试</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs dfs -put sc.txt /loadFile/——>put: Cannot create file/loadFile/sc.txt._COPYING_. Name node is in safe mode.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）创建并执行下面的脚本</p><p>在/opt/module/hadoop-2.7.2路径上，创建一个脚本safemode.sh</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ touch safemode.sh[user_test@hadoop102 hadoop-2.7.2]$ vim safemode.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入内容</p><pre class="line-numbers language-xml"><code class="language-xml">#!/bin/bashhdfs dfsadmin -safemode waithdfs dfs -put /opt/module/hadoop-2.7.2/README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ chmod 777 safemode.sh[user_test@hadoop102 hadoop-2.7.2]$ bash safemode.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）再打开一个窗口，执行</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs dfsadmin -safemode leave<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）观察</p><p>（a）再观察上一个窗口</p><p>Safe mode is OFF</p><p>（b）HDFS集群上已经有上传的数据了。</p><h3 id="NameNode多目录配置"><a href="#NameNode多目录配置" class="headerlink" title="NameNode多目录配置"></a>NameNode多目录配置</h3><ol><li><p>NameNode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性</p></li><li><p>具体配置如下</p></li></ol><p>（1）在hdfs-site.xml文件中增加如下内容</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）停止集群，删除data和logs中所有数据。</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ rm -rf data/ logs/[user_test@hadoop103 hadoop-2.7.2]$ rm -rf data/ logs/[user_test@hadoop104 hadoop-2.7.2]$ rm -rf data/ logs/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）格式化集群并启动。</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode –format[user_test@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看结果</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 dfs]$ ll——>总用量 12drwx------. 3 user_test user_test 4096 12月 11 08:03 datadrwxrwxr-x. 3 user_test user_test 4096 12月 11 08:03 name1drwxrwxr-x. 3 user_test user_test 4096 12月 11 08:03 name2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="DataNode（面试开发重点）"><a href="#DataNode（面试开发重点）" class="headerlink" title="DataNode（面试开发重点）"></a>DataNode（面试开发重点）</h2><h3 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h3><p><img src="1.png" alt></p><p>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</p><p>1）DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。</p><p>2）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令（如复制块数据到另一台机器，或删除某个数据块）。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</p><p>3）集群运行中可以安全加入和退出一些机器。</p><h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><p><strong>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？</strong></p><p>如下是DataNode节点保证数据完整性的方法。</p><p>1）当DataNode读取Block的时候，它会计算CheckSum。</p><p>2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</p><p>3）Client读取其他DataNode上的Block。</p><p>4）DataNode在其文件创建后周期验证CheckSum，如图：</p><p><img src="2.png" alt></p><h3 id="掉线时限参数设置"><a href="#掉线时限参数设置" class="headerlink" title="掉线时限参数设置"></a>掉线时限参数设置</h3><p><img src="4.png" alt></p><p>需要注意的是hdfs-site.xml 配置文件中的 heartbeat.recheck.interval 的单位为毫秒，dfs.heartbeat.interval 的单位为秒。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.heartbeat.recheck-interval<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>300000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.heartbeat.interval<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="服役新数据节点"><a href="#服役新数据节点" class="headerlink" title="服役新数据节点"></a>服役新数据节点</h3><ol start="0"><li><p>需求<br>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。</p></li><li><p>环境准备</p></li></ol><p>（1）在hadoop104主机上再克隆一台hadoop105主机</p><p>（2）修改IP地址和主机名称</p><p>（3）删除原来HDFS文件系统留存的文件（/opt/module/hadoop-2.7.2/data和log）</p><p>（4）source一下配置文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ source /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>服役新节点具体步骤</li></ol><p>（1）直接启动DataNode，即可关联到集群</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode[user_test@hadoop105 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="5.png" alt></p><p>（2）在hadoop105上上传文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ hadoop fs -put /opt/module/hadoop-2.7.2/LICENSE.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）如果数据不均衡，可以用命令实现集群的再平衡</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 sbin]$ ./start-balancer.sh——>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-balancer-hadoop102.outTime Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="退役旧数据节点"><a href="#退役旧数据节点" class="headerlink" title="退役旧数据节点"></a>退役旧数据节点</h3><h4 id="添加白名单"><a href="#添加白名单" class="headerlink" title="添加白名单"></a>添加白名单</h4><p>添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。</p><p>配置白名单的具体步骤如下：</p><p>（1）在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts文件，添加以下内容</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop]$ pwd——>/opt/module/hadoop-2.7.2/etc/hadoop[user_test@hadoop102 hadoop]$ touch dfs.hosts[user_test@hadoop102 hadoop]$ vi dfs.hosts<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>添加如下主机名称（不添加hadoop105）<br>hadoop102<br>hadoop103<br>hadoop104</p><p>（2）在NameNode的hdfs-site.xml配置文件中增加dfs.hosts属性</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）配置文件分发</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop]$ xsync hdfs-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）刷新NameNode</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes——>Refresh nodes successful<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）更新ResourceManager节点</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop103 hadoop-2.7.2]$ yarn rmadmin -refreshNodes——>17/06/24 14:17:11 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）在web浏览器上查看</p><p><img src="6.png" alt></p><ol start="4"><li>如果数据不均衡，可以用命令实现集群的再平衡</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 sbin]$ ./start-balancer.sh——>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-balancer-hadoop102.outTime Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="黑名单退役"><a href="#黑名单退役" class="headerlink" title="黑名单退役"></a>黑名单退役</h4><p><strong>在做以下操作时，要注意退回到上一节操作之前状态</strong></p><p>在黑名单上面的主机都会被强制退出。</p><p>1.在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts.exclude文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop]$ pwd/opt/module/hadoop-2.7.2/etc/hadoop[user_test@hadoop102 hadoop]$ touch dfs.hosts.exclude[user_test@hadoop102 hadoop]$ vi dfs.hosts.exclude<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>添加如下主机名称（要退役的节点）<br>hadoop105</p><p>2．在NameNode的hdfs-site.xml配置文件中增加dfs.hosts.exclude属性</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.hosts.exclude<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3．刷新NameNode、刷新ResourceManager</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes——>Refresh nodes successful[user_test@hadoop102 hadoop-2.7.2]$ yarn rmadmin -refreshNodes——>17/06/24 14:55:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>检查Web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点，如图:</li></ol><p><img src="7.png" alt></p><ol start="5"><li>等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役，如图:</li></ol><p><img src="8.png" alt></p><p>可以看到hadoop105仍然还在页面上，但是里面Last contact是随着时间推移而增大的。这就表示上次连接时间与现在的间隔。</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode——>stopping datanode[user_test@hadoop105 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager——>stopping nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li>如果数据不均衡，可以用命令实现集群的再平衡</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ sbin/start-balancer.sh ——>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-balancer-hadoop102.outTime Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：不允许白名单和黑名单中同时出现同一个主机名称。</strong></p><h3 id="Datanode多目录配置"><a href="#Datanode多目录配置" class="headerlink" title="Datanode多目录配置"></a>Datanode多目录配置</h3><ol><li>DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本</li></ol><p>2．具体配置如下</p><p>hdfs-site.xml</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:///${hadoop.tmp.dir}/dfs/data1,file:///${hadoop.tmp.dir}/dfs/data2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="HDFS-2-X新特性"><a href="#HDFS-2-X新特性" class="headerlink" title="HDFS 2.X新特性"></a>HDFS 2.X新特性</h2><h3 id="集群间数据拷贝"><a href="#集群间数据拷贝" class="headerlink" title="集群间数据拷贝"></a>集群间数据拷贝</h3><p>1．scp实现两个远程主机之间的文件复制</p><pre class="line-numbers language-shell"><code class="language-shell">scp -r hello.txt root@hadoop103:/user/atguigu/hello.txt        // 推 pushscp -r root@hadoop103:/user/atguigu/hello.txt  hello.txt        // 拉 pullscp -r root@hadoop103:/user/atguigu/hello.txt root@hadoop104:/user/atguigu   //是通过本地主机中转实现两个远程主机的文件复制；如果在两个远程主机之间ssh没有配置的情况下可以使用该方式。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．采用distcp命令实现两个Hadoop集群之间的递归数据复制</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$  bin/hadoop distcphdfs://haoop102:9000/user/atguigu/hello.txt hdfs://hadoop103:9000/user/atguigu/hello.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>其中第一个地址为文件源地址，第二个为文件目的地址</p><h3 id="小文件存档"><a href="#小文件存档" class="headerlink" title="小文件存档"></a>小文件存档</h3><p><img src="1.png" alt></p><p>HAR文件就是HDFS归档文件，只是文件形式是这个。</p><p>3．案例实操</p><p>（1）需要启动YARN进程</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）归档文件</p><p>把/user/test/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/test/output路径下。（以上几个路径都得自己新建来测试）</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop archive -archiveName input.har –p  /user/atguigu/input   /user/atguigu/output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中 input.har 为要生成的har文件；-p后面第一个地址是源地址，第二个地址为将要生成存储的地址</p><p>（3）查看归档</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr /user/atguigu/output/input.har[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr har:///user/atguigu/output/input.har<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>第二个就会看到其中内容</p><p>（4）解归档文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -cp har:/// user/test/output/input.har/*    /user/test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="回收站"><a href="#回收站" class="headerlink" title="回收站"></a>回收站</h3><p>开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用。</p><p>1．回收站参数设置及工作机制</p><p><img src="2.png" alt></p><p>其中两个参数单位都是分钟</p><p>2．启用回收站</p><p>修改core-site.xml，配置垃圾回收时间为1分钟。</p><pre class="line-numbers language-shell"><code class="language-shell"><property>    <name>fs.trash.interval</name>    <value>1</value></property><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3．查看回收站</p><p>回收站在集群中的路径：/user/atguigu/.Trash/….</p><p>这样会说权限不够，因此需要下一步来配置权限</p><p>4．修改访问垃圾回收站用户名称</p><p>进入垃圾回收站用户名称，默认是dr.who，修改为user_test用户</p><p>[core-site.xml]</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站</li></ol><p>Trash trash = New Trash(conf);<br>trash.moveToTrash(path);</p><ol start="5"><li>恢复回收站数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mv/user/user_test/.Trash/Current/user/test/input    /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="6"><li>清空回收站</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -expunge<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>并不是跟windows一样全部清空，二十重新打一个包，放起来。</p><h3 id="快照管理"><a href="#快照管理" class="headerlink" title="快照管理"></a>快照管理</h3><p><img src="3.png" alt></p><p>禁用快照功能的时候，要先删除已有快照</p><p>2．案例实操</p><p>（1）开启/禁用指定目录的快照功能</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -allowSnapshot /user/test/input[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -disallowSnapshot /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）对目录创建快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -createSnapshot /user/test/input——>Created snapshot /user/test/input/.snapshot/s20200903-165659.207[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -lsr /user/test/input/.snapshot/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>快照放在一个隐藏文件之中</p><p><img src="4.png" alt></p><p>（3）指定名称创建快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -createSnapshot /user/atguigu/input  scSnapshot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）重命名快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -renameSnapshot /user/atguigu/input/  scSnapshot sc20200903<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）列出当前用户所有可快照目录</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs lsSnapshottableDir<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）比较两个快照目录的不同之处</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs snapshotDiff /user/test/input/  .  .snapshot/sc20200903    ——>Difference between current directory and snapshot s20200903-165659.207 under directory /user/test/input:M       .-       ./README.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>- ./README.txt </code></pre><p>这句就表示了，现有快照比现在文件少了一个 readme.txt 文件</p><p>（7）恢复快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -cp/user/atguigu/input/.snapshot/s20170708-134303.027 /user<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-HDFS2.X新特性（系列十三）</title>
      <link href="2020/09/03/hadoop-hdfs-hdfs2-x-xin-te-xing-xi-lie-shi-san/"/>
      <url>2020/09/03/hadoop-hdfs-hdfs2-x-xin-te-xing-xi-lie-shi-san/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS-2-X新特性"><a href="#HDFS-2-X新特性" class="headerlink" title="HDFS 2.X新特性"></a>HDFS 2.X新特性</h2><h3 id="集群间数据拷贝"><a href="#集群间数据拷贝" class="headerlink" title="集群间数据拷贝"></a>集群间数据拷贝</h3><p>1．scp实现两个远程主机之间的文件复制</p><pre class="line-numbers language-shell"><code class="language-shell">scp -r hello.txt root@hadoop103:/user/atguigu/hello.txt        // 推 pushscp -r root@hadoop103:/user/atguigu/hello.txt  hello.txt        // 拉 pullscp -r root@hadoop103:/user/atguigu/hello.txt root@hadoop104:/user/atguigu   //是通过本地主机中转实现两个远程主机的文件复制；如果在两个远程主机之间ssh没有配置的情况下可以使用该方式。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．采用distcp命令实现两个Hadoop集群之间的递归数据复制</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$  bin/hadoop distcphdfs://haoop102:9000/user/atguigu/hello.txt hdfs://hadoop103:9000/user/atguigu/hello.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>其中第一个地址为文件源地址，第二个为文件目的地址</p><h3 id="小文件存档"><a href="#小文件存档" class="headerlink" title="小文件存档"></a>小文件存档</h3><p><img src="1.png" alt></p><p>HAR文件就是HDFS归档文件，只是文件形式是这个。</p><p>3．案例实操</p><p>（1）需要启动YARN进程</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）归档文件</p><p>把/user/test/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/test/output路径下。（以上几个路径都得自己新建来测试）</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop archive -archiveName input.har –p  /user/atguigu/input   /user/atguigu/output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中 input.har 为要生成的har文件；-p后面第一个地址是源地址，第二个地址为将要生成存储的地址</p><p>（3）查看归档</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr /user/atguigu/output/input.har[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr har:///user/atguigu/output/input.har<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>第二个就会看到其中内容</p><p>（4）解归档文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -cp har:/// user/test/output/input.har/*    /user/test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="回收站"><a href="#回收站" class="headerlink" title="回收站"></a>回收站</h3><p>开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用。</p><p>1．回收站参数设置及工作机制</p><p><img src="2.png" alt></p><p>其中两个参数单位都是分钟</p><p>2．启用回收站</p><p>修改core-site.xml，配置垃圾回收时间为1分钟。</p><pre class="line-numbers language-shell"><code class="language-shell"><property>    <name>fs.trash.interval</name>    <value>1</value></property><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3．查看回收站</p><p>回收站在集群中的路径：/user/atguigu/.Trash/….</p><p>这样会说权限不够，因此需要下一步来配置权限</p><p>4．修改访问垃圾回收站用户名称</p><p>进入垃圾回收站用户名称，默认是dr.who，修改为user_test用户</p><p>[core-site.xml]</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站</li></ol><p>Trash trash = New Trash(conf);<br>trash.moveToTrash(path);</p><ol start="5"><li>恢复回收站数据</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mv/user/user_test/.Trash/Current/user/test/input    /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="6"><li>清空回收站</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -expunge<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>并不是跟windows一样全部清空，二十重新打一个包，放起来。</p><h3 id="快照管理"><a href="#快照管理" class="headerlink" title="快照管理"></a>快照管理</h3><p><img src="3.png" alt></p><p>禁用快照功能的时候，要先删除已有快照</p><p>2．案例实操</p><p>（1）开启/禁用指定目录的快照功能</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -allowSnapshot /user/test/input[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -disallowSnapshot /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）对目录创建快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -createSnapshot /user/test/input——>Created snapshot /user/test/input/.snapshot/s20200903-165659.207[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -lsr /user/test/input/.snapshot/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>快照放在一个隐藏文件之中</p><p><img src="4.png" alt></p><p>（3）指定名称创建快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -createSnapshot /user/atguigu/input  scSnapshot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）重命名快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -renameSnapshot /user/atguigu/input/  scSnapshot sc20200903<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）列出当前用户所有可快照目录</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs lsSnapshottableDir<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）比较两个快照目录的不同之处</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs snapshotDiff /user/test/input/  .  .snapshot/sc20200903    ——>Difference between current directory and snapshot s20200903-165659.207 under directory /user/test/input:M       .-       ./README.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>- ./README.txt </code></pre><p>这句就表示了，现有快照比现在文件少了一个 readme.txt 文件</p><p>（7）恢复快照</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -cp/user/atguigu/input/.snapshot/s20170708-134303.027 /user<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>HDFS部分暂时要告一段落了，接下来是MapReduce了，还有好长的路要走~<br>稍后会把HDFS一个合订版放上来。</p><blockquote><p>一切顺利，有所收获~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-DataNode相关（系列十二）</title>
      <link href="2020/09/01/hadoop-hdfs-datanode-xiang-guan-xi-lie-shi-er/"/>
      <url>2020/09/01/hadoop-hdfs-datanode-xiang-guan-xi-lie-shi-er/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="DataNode（面试开发重点）"><a href="#DataNode（面试开发重点）" class="headerlink" title="DataNode（面试开发重点）"></a>DataNode（面试开发重点）</h2><h3 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h3><p><img src="1.png" alt></p><p>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</p><p>1）DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。</p><p>2）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令（如复制块数据到另一台机器，或删除某个数据块）。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</p><p>3）集群运行中可以安全加入和退出一些机器。</p><h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><p><strong>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？</strong></p><p>如下是DataNode节点保证数据完整性的方法。</p><p>1）当DataNode读取Block的时候，它会计算CheckSum。</p><p>2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</p><p>3）Client读取其他DataNode上的Block。</p><p>4）DataNode在其文件创建后周期验证CheckSum，如图：</p><p><img src="2.png" alt></p><h3 id="掉线时限参数设置"><a href="#掉线时限参数设置" class="headerlink" title="掉线时限参数设置"></a>掉线时限参数设置</h3><p><img src="4.png" alt></p><p>需要注意的是hdfs-site.xml 配置文件中的 heartbeat.recheck.interval 的单位为毫秒，dfs.heartbeat.interval 的单位为秒。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.heartbeat.recheck-interval<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>300000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.heartbeat.interval<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="服役新数据节点"><a href="#服役新数据节点" class="headerlink" title="服役新数据节点"></a>服役新数据节点</h3><ol start="0"><li><p>需求<br>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。</p></li><li><p>环境准备</p></li></ol><p>（1）在hadoop104主机上再克隆一台hadoop105主机</p><p>（2）修改IP地址和主机名称</p><p>（3）删除原来HDFS文件系统留存的文件（/opt/module/hadoop-2.7.2/data和log）</p><p>（4）source一下配置文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ source /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>服役新节点具体步骤</li></ol><p>（1）直接启动DataNode，即可关联到集群</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode[user_test@hadoop105 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="5.png" alt></p><p>（2）在hadoop105上上传文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ hadoop fs -put /opt/module/hadoop-2.7.2/LICENSE.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）如果数据不均衡，可以用命令实现集群的再平衡</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 sbin]$ ./start-balancer.sh——>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-balancer-hadoop102.outTime Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="退役旧数据节点"><a href="#退役旧数据节点" class="headerlink" title="退役旧数据节点"></a>退役旧数据节点</h3><h4 id="添加白名单"><a href="#添加白名单" class="headerlink" title="添加白名单"></a>添加白名单</h4><p>添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。</p><p>配置白名单的具体步骤如下：</p><p>（1）在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts文件，添加以下内容</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop]$ pwd——>/opt/module/hadoop-2.7.2/etc/hadoop[user_test@hadoop102 hadoop]$ touch dfs.hosts[user_test@hadoop102 hadoop]$ vi dfs.hosts<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>添加如下主机名称（不添加hadoop105）<br>hadoop102<br>hadoop103<br>hadoop104</p><p>（2）在NameNode的hdfs-site.xml配置文件中增加dfs.hosts属性</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）配置文件分发</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop]$ xsync hdfs-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）刷新NameNode</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes——>Refresh nodes successful<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）更新ResourceManager节点</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop103 hadoop-2.7.2]$ yarn rmadmin -refreshNodes——>17/06/24 14:17:11 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）在web浏览器上查看</p><p><img src="6.png" alt></p><ol start="4"><li>如果数据不均衡，可以用命令实现集群的再平衡</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 sbin]$ ./start-balancer.sh——>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-balancer-hadoop102.outTime Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="黑名单退役"><a href="#黑名单退役" class="headerlink" title="黑名单退役"></a>黑名单退役</h4><p><strong>在做以下操作时，要注意退回到上一节操作之前状态</strong></p><p>在黑名单上面的主机都会被强制退出。</p><p>1.在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts.exclude文件</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop]$ pwd/opt/module/hadoop-2.7.2/etc/hadoop[user_test@hadoop102 hadoop]$ touch dfs.hosts.exclude[user_test@hadoop102 hadoop]$ vi dfs.hosts.exclude<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>添加如下主机名称（要退役的节点）<br>hadoop105</p><p>2．在NameNode的hdfs-site.xml配置文件中增加dfs.hosts.exclude属性</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.hosts.exclude<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3．刷新NameNode、刷新ResourceManager</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes——>Refresh nodes successful[user_test@hadoop102 hadoop-2.7.2]$ yarn rmadmin -refreshNodes——>17/06/24 14:55:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>检查Web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点，如图:</li></ol><p><img src="7.png" alt></p><ol start="5"><li>等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役，如图:</li></ol><p><img src="8.png" alt></p><p>可以看到hadoop105仍然还在页面上，但是里面Last contact是随着时间推移而增大的。这就表示上次连接时间与现在的间隔。</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop105 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode——>stopping datanode[user_test@hadoop105 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager——>stopping nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="6"><li>如果数据不均衡，可以用命令实现集群的再平衡</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ sbin/start-balancer.sh ——>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-balancer-hadoop102.outTime Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：不允许白名单和黑名单中同时出现同一个主机名称。</strong></p><h3 id="Datanode多目录配置"><a href="#Datanode多目录配置" class="headerlink" title="Datanode多目录配置"></a>Datanode多目录配置</h3><ol><li>DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本</li></ol><p>2．具体配置如下</p><p>hdfs-site.xml</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:///${hadoop.tmp.dir}/dfs/data1,file:///${hadoop.tmp.dir}/dfs/data2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>HDFS 2.X的一些新特性（集群间数据拷贝、小文件存档、回收站、快照管理）</p><blockquote><p>这次DataNode相关直接一块推上去了，感觉这样会好点，吸取教训下次整块推。另外今天一个同学告诉我收到了某公司offer，也是自己比较中意的公司还是大数据开发相关的。嗯。真的不错，替他高兴，感觉他准备挺充分的，向他学习吧，希望一切顺利，到时候秋招我也能跟他一样~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-NameNode多目录配置（HDFS系列十一）</title>
      <link href="2020/08/26/hadoop-hdfs-namenode-duo-mu-lu-pei-zhi-hdfs-xi-lie-shi-yi/"/>
      <url>2020/08/26/hadoop-hdfs-namenode-duo-mu-lu-pei-zhi-hdfs-xi-lie-shi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="NameNode和SecondaryNameNode（面试开发重点）"><a href="#NameNode和SecondaryNameNode（面试开发重点）" class="headerlink" title="NameNode和SecondaryNameNode（面试开发重点）"></a>NameNode和SecondaryNameNode（面试开发重点）</h2><h3 id="NameNode多目录配置"><a href="#NameNode多目录配置" class="headerlink" title="NameNode多目录配置"></a>NameNode多目录配置</h3><ol><li><p>NameNode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性</p></li><li><p>具体配置如下</p></li></ol><p>（1）在hdfs-site.xml文件中增加如下内容</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）停止集群，删除data和logs中所有数据。</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ rm -rf data/ logs/[user_test@hadoop103 hadoop-2.7.2]$ rm -rf data/ logs/[user_test@hadoop104 hadoop-2.7.2]$ rm -rf data/ logs/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）格式化集群并启动。</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode –format[user_test@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看结果</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 dfs]$ ll——>总用量 12drwx------. 3 user_test user_test 4096 12月 11 08:03 datadrwxrwxr-x. 3 user_test user_test 4096 12月 11 08:03 name1drwxrwxr-x. 3 user_test user_test 4096 12月 11 08:03 name2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>DataNode 相关（工作机制——&gt;数据完整性——&gt;掉线时限参数设置——&gt;服役新数据节点——&gt;退役旧数据节点）</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-集群安全模式（HDFS系列十）</title>
      <link href="2020/08/25/hadoop-hdfs-ji-qun-an-quan-mo-shi-hdfs-xi-lie-shi/"/>
      <url>2020/08/25/hadoop-hdfs-ji-qun-an-quan-mo-shi-hdfs-xi-lie-shi/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="NameNode和SecondaryNameNode（面试开发重点）"><a href="#NameNode和SecondaryNameNode（面试开发重点）" class="headerlink" title="NameNode和SecondaryNameNode（面试开发重点）"></a>NameNode和SecondaryNameNode（面试开发重点）</h2><h3 id="集群安全模式"><a href="#集群安全模式" class="headerlink" title="集群安全模式"></a>集群安全模式</h3><ol><li>概述</li></ol><p><img src="4.png" alt></p><ol start="2"><li>基本语法</li></ol><p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p><pre class="line-numbers language-shell"><code class="language-shell">    （1）bin/hdfs dfsadmin -safemode get        （查看安全模式状态）    （2）bin/hdfs dfsadmin -safemode enter      （进入安全模式状态）    （3）bin/hdfs dfsadmin -safemode leave    （离开安全模式状态）    （4）bin/hdfs dfsadmin -safemode wait        （等待安全模式状态）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>案例</li></ol><p>模拟等待安全模式（在安全模式时间内，来了任务，需要让其等待安全模式结束，然后立即执行。比如：银行对账时，在凌晨进行，在对账这个过程中，是不允许进行任何交易的，因此需要等待对账结束，然后）</p><p>（1）查看当前模式</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -safemode get——>Safe mode is OFF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）先进入安全模式</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs dfsadmin -safemode enter——>Safe mode is ON<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>上传文件进行测试</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs dfs -put sc.txt /loadFile/——>put: Cannot create file/loadFile/sc.txt._COPYING_. Name node is in safe mode.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）创建并执行下面的脚本</p><p>在/opt/module/hadoop-2.7.2路径上，创建一个脚本safemode.sh</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ touch safemode.sh[user_test@hadoop102 hadoop-2.7.2]$ vim safemode.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入内容</p><pre class="line-numbers language-xml"><code class="language-xml">#!/bin/bashhdfs dfsadmin -safemode waithdfs dfs -put /opt/module/hadoop-2.7.2/README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ chmod 777 safemode.sh[user_test@hadoop102 hadoop-2.7.2]$ bash safemode.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）再打开一个窗口，执行</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs dfsadmin -safemode leave<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）观察</p><p>a）再观察上一个窗口</p><p>Safe mode is OFF</p><p>b）HDFS集群上已经有上传的数据了。</p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>NameNode多目录配置</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-时间点设置以及NN故障处理</title>
      <link href="2020/08/24/hadoop-hdfs-shi-jian-dian-she-zhi-yi-ji-nn-gu-zhang-chu-li-hdfs-xi-lie-jiu/"/>
      <url>2020/08/24/hadoop-hdfs-shi-jian-dian-she-zhi-yi-ji-nn-gu-zhang-chu-li-hdfs-xi-lie-jiu/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="NameNode和SecondaryNameNode（面试开发重点）"><a href="#NameNode和SecondaryNameNode（面试开发重点）" class="headerlink" title="NameNode和SecondaryNameNode（面试开发重点）"></a>NameNode和SecondaryNameNode（面试开发重点）</h2><h3 id="CheckPoint时间设置"><a href="#CheckPoint时间设置" class="headerlink" title="CheckPoint时间设置"></a>CheckPoint时间设置</h3><p>（1）通常情况下，SecondaryNameNodec每隔一小时执行一次(3600秒)。</p><p>配置文件：hdfs-default.xml</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>3600<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode 执行一次。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.txns<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1000000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>操作动作次数<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.check.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>60<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span> 1分钟检查一次操作次数<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="NameNode故障处理"><a href="#NameNode故障处理" class="headerlink" title="NameNode故障处理"></a>NameNode故障处理</h3><p>NameNode故障后，可以采用如下两种方法恢复数据。</p><h4 id="方法一：将-SecondaryNameNode-中数据拷贝到-NameNode-中进行数据备份或恢复；"><a href="#方法一：将-SecondaryNameNode-中数据拷贝到-NameNode-中进行数据备份或恢复；" class="headerlink" title="方法一：将 SecondaryNameNode 中数据拷贝到 NameNode 中进行数据备份或恢复；"></a>方法一：将 SecondaryNameNode 中数据拷贝到 NameNode 中进行数据备份或恢复；</h4><ol><li><p>kill -9 NameNode进程号</p></li><li><p>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>拷贝SecondaryNameNode中数据到原NameNode存储数据目录</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 dfs]$ scp -r user_test@hadoop104:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* ./name/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>重新启动NameNode</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="方法二：使用-importCheckpoint-选项启动-NameNode-守护进程，从而将-SecondaryNameNode-中数据拷贝到-NameNode-目录中。"><a href="#方法二：使用-importCheckpoint-选项启动-NameNode-守护进程，从而将-SecondaryNameNode-中数据拷贝到-NameNode-目录中。" class="headerlink" title="方法二：使用 -importCheckpoint 选项启动 NameNode 守护进程，从而将 SecondaryNameNode 中数据拷贝到 NameNode 目录中。"></a>方法二：使用 -importCheckpoint 选项启动 NameNode 守护进程，从而将 SecondaryNameNode 中数据拷贝到 NameNode 目录中。</h4><ol><li>修改hdfs-site.xml中的（因为原来的3600秒时间太长了，所以改成120）</li></ol><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>120<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-2.7.2/data/tmp/dfs/name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li><p>kill -9 NameNode 进程</p></li><li><p>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p></li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>如果 SecondaryNameNode 不和 NameNode 在一个主机节点上，需要将 SecondaryNameNode 存储数据的目录拷贝到 NameNode 存储数据的平级目录，并删除 in_use.lock 文件</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 dfs]$ scp -r user_test@hadoop104:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary ./[user_test@hadoop102 namesecondary]$ rm -rf in_use.lock[user_test@hadoop102 dfs]$ pwd/opt/module/hadoop-2.7.2/data/tmp/dfs[user_test@hadoop102 dfs]$ lsdata  name  namesecondary<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li>导入检查点数据（等待一会ctrl+c结束掉）</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -importCheckpoint<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>启动NameNode</li></ol><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>集群安全模式</p><blockquote><p>顺顺利利，有自己满意结果~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-NameNode和SecondaryNameNode（HDFS系列八）</title>
      <link href="2020/08/23/hadoop-hdfs-namenode-he-secondarynamenode-hdfs-xi-lie-ba/"/>
      <url>2020/08/23/hadoop-hdfs-namenode-he-secondarynamenode-hdfs-xi-lie-ba/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="NameNode和SecondaryNameNode（面试开发重点）"><a href="#NameNode和SecondaryNameNode（面试开发重点）" class="headerlink" title="NameNode和SecondaryNameNode（面试开发重点）"></a>NameNode和SecondaryNameNode（面试开发重点）</h2><h3 id="NN和2NN工作机制"><a href="#NN和2NN工作机制" class="headerlink" title="NN和2NN工作机制"></a>NN和2NN工作机制</h3><p><strong>思考：NameNode中的元数据是存储在哪里的？</strong></p><p>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。</p><p>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。</p><p>但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。</p><p>NN和2NN工作机制，如下：</p><p><img src="1.png" alt></p><ol><li>第一阶段：NameNode启动</li></ol><p>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p><p>（2）客户端对元数据进行增删改的请求。</p><p>（3）NameNode记录操作日志，更新滚动日志。</p><p>（4）NameNode在内存中对数据进行增删改。</p><p><strong>之所以先更新日志再进行操作，是因为如果先操作数据，未写日志突然断电，那么数据操作有可能丢失，无法还原。</strong></p><ol start="2"><li>第二阶段：Secondary NameNode工作</li></ol><p>（1）Secondary NameNode 询问NameNode是否需要 CheckPoint。直接带回NameNode是否检查结果。<br>CheckPoint是一个检查点，检测是否需要合并日志文件和 fsimage 然后再序列化到 fsimge 中。</p><p>（2）若触发条件满足了，则 Secondary NameNode 请求执行CheckPoint。</p><p>（3）NameNode滚动正在编写的Edits日志，避免在合并的时候没法继续编写操作（001为原来的，然后新的日志先写到002中）。</p><p>（4）将滚动前的编辑日志和镜像文件拷贝到 Secondary NameNode。</p><p>（5）Secondary NameNode 加载编辑日志和镜像文件到内存，并合并。</p><p>（6）生成新的镜像文件 fsimage.chkpoint。</p><p>（7）拷贝 fsimage.chkpoint 到 NameNode。</p><p>（8）NameNode 将 fsimage.chkpoint 重新命名成 fsimage（现在情况是002和新的镜像文件fsimage合起来就是当前内存中最新的内容）。</p><p><strong>NN和2NN工作机制详解</strong></p><p>Fsimage：NameNode内存中元数据序列化后形成的文件。</p><p>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。</p><p>NameNode 启动时，先滚动Edits并生成一个空的 edits.inprogress，然后加载Edits和Fsimage 到内存中，此时 NameNode 内存就持有最新的元数据信息。</p><p>Client 开始对NameNode 发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress 中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时 NameNode 挂掉，重启后会从 Edits 中读取元数据的信息。然后，NameNode 会在内存中执行元数据的增删改的操作。</p><p>由于 Edits 中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对 Edits 和 Fsimage 进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。</p><p>SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。<br>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。</p><p>NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p><h3 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h3><ol><li>概念</li></ol><p><img src="2.png" alt></p><ol start="2"><li>oiv查看Fsimage文件</li></ol><p>（1）查看oiv和oev命令</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 current]$ hdfs——>...oiv        apply the offline fsimage viewer to an fsimageoev        pply the offline edits viewer to an edits file...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）基本语法</p><pre class="line-numbers language-shell"><code class="language-shell">hdfs oiv -p （要将 fsimage 转化成的格式） -i （镜像文件） -o （转换后文件输出路径）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）案例实操（其中文件名称可能有区别）</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 current]$ pwd——>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current[user_test@hadoop102 current]$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-2.7.2/fsimage.xml[user_test@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/fsimage.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将显示的xml文件内容拷贝到idea中创建的xml文件中，并格式化。部分显示结果如下（代码信息会有所区别）。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16386<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>DIRECTORY<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512722284477<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>user_test:supergroup:rwxr-xr-x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nsquota</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dsquota</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16387<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>DIRECTORY<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512790549080<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>user_test:supergroup:rwxr-xr-x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nsquota</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dsquota</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16389<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>FILE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>wc.input<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>replication</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>replication</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512722322219<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>atime</span><span class="token punctuation">></span></span>1512722321610<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>atime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>perferredBlockSize</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>perferredBlockSize</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>user_test:supergroup:rw-r--r--<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>blocks</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>block</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>1073741825<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>genstamp</span><span class="token punctuation">></span></span>1001<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>genstamp</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>numBytes</span><span class="token punctuation">></span></span>59<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>numBytes</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>block</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>blocks</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>思考：可以看出，Fsimage中没有记录块所对应DataNode，为什么？</strong></p><p>在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。（datanode运行机制会详细说）</p><ol start="3"><li>oev查看Edits文件</li></ol><p>（1）基本语法</p><pre class="line-numbers language-shell"><code class="language-shell">hdfs oev -p （要将 fsimage 转化成的格式） -i （镜像文件） -o （转换后文件输出路径）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）案例实操</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 current]$ hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-2.7.2/edits.xml[user_test@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/edits.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>将显示的xml文件内容拷贝到 idea 中创建的xml文件中，并格式化。显示结果如下。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EDITS</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EDITS_VERSION</span><span class="token punctuation">></span></span>-63<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>EDITS_VERSION</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_START_LOG_SEGMENT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>129<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ADD<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>130<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LENGTH</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LENGTH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>INODEID</span><span class="token punctuation">></span></span>16407<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>INODEID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>REPLICATION</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>REPLICATION</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MTIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MTIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ATIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ATIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCKSIZE</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCKSIZE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_NAME</span><span class="token punctuation">></span></span>DFSClient_NONMAPREDUCE_-1544295051_1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_NAME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>192.168.1.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OVERWRITE</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OVERWRITE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>USERNAME</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>USERNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GROUPNAME</span><span class="token punctuation">></span></span>supergroup<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GROUPNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MODE</span><span class="token punctuation">></span></span>420<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MODE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>908eafd4-9aec-4288-96f1-e8011d181561<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CALLID</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CALLID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ALLOCATE_BLOCK_ID<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>131<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_SET_GENSTAMP_V2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>132<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMPV2</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMPV2</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ADD_BLOCK<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>133<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>NUM_BYTES</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>NUM_BYTES</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMP</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMP</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CLIENTID</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CALLID</span><span class="token punctuation">></span></span>-2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CALLID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_CLOSE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>134<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LENGTH</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LENGTH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>INODEID</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>INODEID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>REPLICATION</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>REPLICATION</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MTIME</span><span class="token punctuation">></span></span>1512943608761<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MTIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ATIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ATIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCKSIZE</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCKSIZE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_NAME</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_NAME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OVERWRITE</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OVERWRITE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>NUM_BYTES</span><span class="token punctuation">></span></span>25<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>NUM_BYTES</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMP</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMP</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>USERNAME</span><span class="token punctuation">></span></span>user_test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>USERNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GROUPNAME</span><span class="token punctuation">></span></span>supergroup<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GROUPNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MODE</span><span class="token punctuation">></span></span>420<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MODE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>EDITS</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>说明：</strong></p><pre><code>OP_START_LOG_SEGMENT：日志开始OP_MKDIR：创建路径OP_ADD：上传文件OP_ALLOCATE_BLOCK_ID：分配块 idOP_SET_GENSTAMP_V2：创建时间戳OP_ADD_BLOCK：添加块信息OP_CLOSE：操作结束OP_RENAME_OLD：重命名原来复制的文件</code></pre><p><strong>思考：NameNode如何确定下次开机启动的时候合并哪些Edits？</strong></p><p>根据 seen_txid 文件中数据来合并，其中记录了最新的。</p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>CheckPoint时间点设置以及NN故障处理</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-数据流（文件读取）（HDFS系列七）</title>
      <link href="2020/08/21/hadoop-hdfs-shu-ju-liu-wen-jian-du-qu-hdfs-xi-lie-qi/"/>
      <url>2020/08/21/hadoop-hdfs-shu-ju-liu-wen-jian-du-qu-hdfs-xi-lie-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS的数据流（面试重点）"><a href="#HDFS的数据流（面试重点）" class="headerlink" title="HDFS的数据流（面试重点）"></a>HDFS的数据流（面试重点）</h2><h3 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h3><p><img src="1.png" alt></p><p>其中 ss.avi 有三个副本，每个副本有两块。</p><p>1）客户端通过 Distributed FileSystem 向 NameNode 请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p><p>2）挑选一台 DataNode 服务器（就近原则），请求读取数据。若数据损坏，则选择一个副本来进行读取。</p><p>3）DataNode 开始传输数据给客户端（从磁盘里面读取数据输入流，以 Packet 为单位来做校验）。</p><p>4）客户端以 Packet 为单位接收，先在本地缓存，然后写入目标文件。</p><h1 id="待续"><a href="#待续" class="headerlink" title="待续"></a>待续</h1><p>接下来就是 NameNode 和 SecondaryNameNode 相关（首先是工作机制然后是时间点设置再就是 NN 故障处理）</p><blockquote><p>顺顺利利不挨批，收获多多~<br>屁屁明天也顺利</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-数据流（文件写入、网络拓扑）（HDFS系列六）</title>
      <link href="2020/08/20/hadoop-hdfs-shu-ju-liu-wen-jian-xie-ru-wang-luo-tuo-bu-hdfs-xi-lie-liu/"/>
      <url>2020/08/20/hadoop-hdfs-shu-ju-liu-wen-jian-xie-ru-wang-luo-tuo-bu-hdfs-xi-lie-liu/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS的数据流（面试重点）"><a href="#HDFS的数据流（面试重点）" class="headerlink" title="HDFS的数据流（面试重点）"></a>HDFS的数据流（面试重点）</h2><h3 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h3><h4 id="剖析文件写入"><a href="#剖析文件写入" class="headerlink" title="剖析文件写入"></a>剖析文件写入</h4><p>HDFS写数据流程，如下</p><p><img src="1.png" alt></p><p>1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p><p>2）NameNode返回是否可以上传。</p><p>3）客户端请求第一个 Block上传到哪几个DataNode服务器上。</p><p>4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3（备份）。</p><p>5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p><p>6）dn1、dn2、dn3逐级应答客户端。</p><p>7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3（这个过程是通过内存缓存来传的，因为速度快）；dn1每传一个packet会放入一个应答队列等待应答。</p><p>8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p><h4 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h4><p>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。</p><p><strong>节点距离：两个节点到达最近的共同祖先的距离总和。</strong></p><p><img src="2.png" alt></p><h4 id="机架感知（副本存储节点选择）"><a href="#机架感知（副本存储节点选择）" class="headerlink" title="机架感知（副本存储节点选择）"></a>机架感知（副本存储节点选择）</h4><ol><li>官方ip地址</li></ol><p>机架感知说明</p><p><a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication</a></p><p>For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.</p><ol start="2"><li>Hadoop2.7.2副本节点选择</li></ol><p><img src="3.png" alt></p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>接下来就是HDFS读数据流程了</p><blockquote><p>明天顺顺利利<br>屁屁团建开心，工作顺利~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-IO流操作（HDFS系列五）</title>
      <link href="2020/08/20/hadoop-hdfs-io-liu-cao-zuo-hdfs-xi-lie-wu/"/>
      <url>2020/08/20/hadoop-hdfs-io-liu-cao-zuo-hdfs-xi-lie-wu/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS客户端相关"><a href="#HDFS客户端相关" class="headerlink" title="HDFS客户端相关"></a>HDFS客户端相关</h2><h3 id="HDFS的I-O流操作"><a href="#HDFS的I-O流操作" class="headerlink" title="HDFS的I/O流操作"></a>HDFS的I/O流操作</h3><p>上面api都是框架封装好的。现在可以尝试自己实现（我们可以采用IO流的方式实现数据的上传和下载）</p><h4 id="HDFS文件上传"><a href="#HDFS文件上传" class="headerlink" title="HDFS文件上传"></a>HDFS文件上传</h4><p>1．需求：把本地的test.txt文件上传到HDFS根目录</p><p>2．编写代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">putFileToHDFS</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 创建输入流</span>    FileInputStream fis <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 获取输出流</span>    FSDataOutputStream fos <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 流对拷</span>    IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 5 关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h4><p>1．需求：从HDFS上下载test.txt文件到本地</p><p>2．编写代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 文件下载</span><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">getFileFromHDFS</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 输入流：写出的；输出流：写入的——在这个里面本地就是输出流，hdfs就是输出流</span>    <span class="token comment" spellcheck="true">// 2 获取输入流</span>    FSDataInputStream fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 获取输出流</span>    FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 流的对拷</span>    IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 5 关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="文件定位读取"><a href="#文件定位读取" class="headerlink" title="文件定位读取"></a>文件定位读取</h4><p>1．需求：分块读取HDFS上的大文件，比如根目录下的/hadoop-2.7.2.tar.gz（首先手动将文件上传到hdfs——分成两块）</p><p>2．编写代码</p><pre class="line-numbers language-java"><code class="language-java">（<span class="token number">1</span>）下载第一块<span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFileSeek1</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 获取输入流</span>    FSDataInputStream fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 创建输出流</span>    FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz.part1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 流的拷贝（若还用copyBytes来拷贝，则是拷贝的全部）</span>    <span class="token comment" spellcheck="true">// 相当与1k</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">byte</span><span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 读取128M</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">128</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        fis<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>buf<span class="token punctuation">)</span><span class="token punctuation">;</span>        fos<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>buf<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 5关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java"><code class="language-java">（<span class="token number">2</span>）下载第二块<span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFileSeek2</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 打开输入流</span>    FSDataInputStream fis <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 定位输入数据位置(128M位置处)</span>    fis<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 4 创建输出流</span>    FileOutputStream fos <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"/hadoop-2.7.2.tar.gz.part2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 5 流的对拷</span>    IOUtils<span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>fis<span class="token punctuation">,</span> fos<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 6 关闭资源</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fis<span class="token punctuation">)</span><span class="token punctuation">;</span>    IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fos<span class="token punctuation">)</span><span class="token punctuation">;</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）合并文件</p><p>在Window命令窗口中进入到下载文件目录下，然后执行命令，进行数据合并</p><pre class="line-numbers language-shell"><code class="language-shell">    type hadoop-2.7.2.tar.gz.part2 >> hadoop-2.7.2.tar.gz.part1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>合并完成后，将hadoop-2.7.2.tar.gz.part1重新命名为hadoop-2.7.2.tar.gz。</p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>接下来是HDFS数据流相关讲解，据说是面试重点~</p><blockquote><p>后天就可以看到屁屁了，开心~<br>希望明天bug全解决</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-api操作（HDFS系列四）</title>
      <link href="2020/08/16/hadoop-hdfs-api-cao-zuo-hdfs-xi-lie-si/"/>
      <url>2020/08/16/hadoop-hdfs-api-cao-zuo-hdfs-xi-lie-si/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS客户端相关"><a href="#HDFS客户端相关" class="headerlink" title="HDFS客户端相关"></a>HDFS客户端相关</h2><h3 id="HDFS的API操作"><a href="#HDFS的API操作" class="headerlink" title="HDFS的API操作"></a>HDFS的API操作</h3><h4 id="HDFS文件上传（测试参数优先级）"><a href="#HDFS文件上传（测试参数优先级）" class="headerlink" title="HDFS文件上传（测试参数优先级）"></a>HDFS文件上传（测试参数优先级）</h4><p>1．编写源代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyFromLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"dfs.replication"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 上传文件（第一个地址为本地的，第二个为hdfs上的地址）</span>    fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"over"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2．将hdfs-site.xml拷贝到项目的根目录下（配置文件设置备份数量——这里是1）</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>*<em>注：<br>参数优先级排序：（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）服务器的默认配置<br>*</em></p><h4 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyToLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 执行下载操作(第一个地址是hdfs地址，第二个为本地地址)</span>    <span class="token comment" spellcheck="true">//可选参数</span>    <span class="token comment" spellcheck="true">// boolean delSrc 指是否将原文件删除</span>    <span class="token comment" spellcheck="true">// Path src 指要下载的文件路径</span>    <span class="token comment" spellcheck="true">// Path dst 指将文件下载到的路径</span>    <span class="token comment" spellcheck="true">// boolean useRawLocalFileSystem 是否开启文件校验（若不开启就会产生一个crc的校验文件）</span>    fs<span class="token punctuation">.</span><span class="token function">copyToLocalFile</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件夹删除"><a href="#HDFS文件夹删除" class="headerlink" title="HDFS文件夹删除"></a>HDFS文件夹删除</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDelete</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 执行删除(第一个是要删除的地址；若是删除的是个路径，则第二个必须为true，文件则无所谓)</span>    fs<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/test"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件名更改"><a href="#HDFS文件名更改" class="headerlink" title="HDFS文件名更改"></a>HDFS文件名更改</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testRename</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 2 修改文件名称(第一个为源文件名称，第二个为新文件名称)</span>    fs<span class="token punctuation">.</span><span class="token function">rename</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/loadFile/newTest.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件详情查看"><a href="#HDFS文件详情查看" class="headerlink" title="HDFS文件详情查看"></a>HDFS文件详情查看</h4><p>查看文件名称、权限、长度、块信息</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 2 获取文件详情(第二个参数为递归查看)</span>    RemoteIterator<span class="token operator">&lt;</span>LocatedFileStatus<span class="token operator">></span> listFiles <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 遍历迭代器</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>listFiles<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        LocatedFileStatus status <span class="token operator">=</span> listFiles<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 输出详情</span>        <span class="token comment" spellcheck="true">// 文件名称</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 长度</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 权限</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 分组</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取存储的块信息</span>        BlockLocation<span class="token punctuation">[</span><span class="token punctuation">]</span> blockLocations <span class="token operator">=</span> status<span class="token punctuation">.</span><span class="token function">getBlockLocations</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>BlockLocation blockLocation <span class="token operator">:</span> blockLocations<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 获取块存储的主机节点</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> hosts <span class="token operator">=</span> blockLocation<span class="token punctuation">.</span><span class="token function">getHosts</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>String host <span class="token operator">:</span> hosts<span class="token punctuation">)</span> <span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>host<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"------------------------"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="HDFS文件和文件夹判断"><a href="#HDFS文件和文件夹判断" class="headerlink" title="HDFS文件和文件夹判断"></a>HDFS文件和文件夹判断</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 1 获取文件配置信息</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 判断是文件还是文件夹</span>    FileStatus<span class="token punctuation">[</span><span class="token punctuation">]</span> listStatus <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>FileStatus fileStatus <span class="token operator">:</span> listStatus<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 如果是文件</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>fileStatus<span class="token punctuation">.</span><span class="token function">isFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"f:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"d:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-HDFS-客户端部署（HDFS系列三）</title>
      <link href="2020/08/15/hadoop-hdfs-ke-hu-duan-bu-shu-hdfs-xi-lie-san/"/>
      <url>2020/08/15/hadoop-hdfs-ke-hu-duan-bu-shu-hdfs-xi-lie-san/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS客户端相关"><a href="#HDFS客户端相关" class="headerlink" title="HDFS客户端相关"></a>HDFS客户端相关</h2><h3 id="HDFS客户端环境准备"><a href="#HDFS客户端环境准备" class="headerlink" title="HDFS客户端环境准备"></a>HDFS客户端环境准备</h3><p>1．根据自己电脑的操作系统选择对应的编译后的hadoop jar包保存到非中文路径下（例如：D:\nonblank\hadoop-2.7.2）</p><p>2．配置HADOOP_HOME环境变量</p><p><img src="1.png" alt></p><ol start="3"><li>配置Path环境变量</li></ol><p><img src="2.png" alt></p><p>4．创建一个Maven工程HdfsClientDemo</p><p>5．导入相应的依赖并添加日志</p><p>（1）导入依赖</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span>dependencies<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>junit<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>junit<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span>RELEASE<span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>log4j<span class="token operator">-</span>core<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.8</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>hadoop<span class="token operator">-</span>common<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>hadoop<span class="token operator">-</span>client<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>hadoop<span class="token operator">-</span>hdfs<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>    <span class="token operator">&lt;</span>dependency<span class="token operator">></span>        <span class="token operator">&lt;</span>groupId<span class="token operator">></span>jdk<span class="token punctuation">.</span>tools<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>        <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>jdk<span class="token punctuation">.</span>tools<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>        <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">1.8</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>        <span class="token operator">&lt;</span>scope<span class="token operator">></span>system<span class="token operator">&lt;</span><span class="token operator">/</span>scope<span class="token operator">></span>        <span class="token operator">&lt;</span>systemPath<span class="token operator">></span>$<span class="token punctuation">{</span>JAVA_HOME<span class="token punctuation">}</span><span class="token operator">/</span>lib<span class="token operator">/</span>tools<span class="token punctuation">.</span>jar<span class="token operator">&lt;</span><span class="token operator">/</span>systemPath<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>dependencies<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）添加日志相关</p><p>在src/main/resources目录下，新建一个文件，命名为“log4j.properties”，填写如下内容：</p><pre><code>log4j.rootLogger=INFO, stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%nlog4j.appender.logfile=org.apache.log4j.FileAppenderlog4j.appender.logfile.File=target/spring.loglog4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</code></pre><p>6．创建包名：bigdata.hadoop.hdfs</p><p>7．创建HdfsClient类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClient</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testMkdirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 配置在集群上运行(方式1)</span>        <span class="token comment" spellcheck="true">// configuration.set("fs.defaultFS", "hdfs://hadoop102:9000");</span>        <span class="token comment" spellcheck="true">// FileSystem fs = FileSystem.get(configuration);</span>        <span class="token comment" spellcheck="true">// 方式2(其中user_test为用户名)</span>        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9000"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"user_test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 创建目录</span>        fs<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/user_test/test/sc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关闭资源</span>        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>8．执行程序</p><p>方式1运行时需要配置用户名称</p><p><img src="3.png" alt></p><p><img src="4.png" alt></p><p>客户端去操作HDFS时，是有一个用户身份的。默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=user_test，user_test为用户名称。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop(HDFS)shell命令（HDFS系列二）</title>
      <link href="2020/08/02/hadoop-hdfs-shell-ming-ling-hdfs-xi-lie-er/"/>
      <url>2020/08/02/hadoop-hdfs-shell-ming-ling-hdfs-xi-lie-er/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="HDFS-的-Shell-操作"><a href="#HDFS-的-Shell-操作" class="headerlink" title="HDFS 的 Shell 操作"></a>HDFS 的 Shell 操作</h2><p>1．基本语法</p><pre><code>bin/hadoop fs 具体命令   OR  bin/hdfs dfs 具体命令</code></pre><p>dfs是fs的实现类。</p><p>2．命令大全</p><p>可通过如下命令进行查看</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3．常用命令实操</p><p>（1）启动Hadoop集群（方便后续的测试）</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh    [user_test@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）-help：查询命令参数及功能</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -help rm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）-ls: 显示目录信息</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -ls /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>递归查看</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr /    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -ls -R /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）-mkdir：在HDFS上创建目录</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mkdir -p /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）-moveFromLocal：从本地剪切粘贴到HDFS</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ touch test.txt    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs  -moveFromLocal test.txt  /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>往 test.txt 文件中输入任意内容，等会测试追加</p><p>（6）-appendToFile：追加一个文件到已经存在的文件末尾</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ touch testAppend.txt    [user_test@hadoop102 hadoop-2.7.2]$ vim testAppend.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入任意内容</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -appendToFile testAppend.txt /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）-cat：显示文件内容</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -cat /user/test/input/kongtest.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（8）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs  -chmod  666 /user/test/input/test.txt[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs  -chown  user_test:user   /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（9）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -copyFromLocal README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（10）-copyToLocal：从HDFS拷贝到本地</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -copyToLocal /user/test/input/test.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（11）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -cp /user/test/input/test.txt /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（12）-mv：在HDFS目录中移动文件</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mv /user/test/input/test.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（13）-get：等同于copyToLocal，就是从HDFS下载文件到本地</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -get /user/test/input/test.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（14）-getmerge：合并下载多个文件，比如HDFS的目录 /user/user_test/test下有多个文件:log.1, log.2,log.3,…</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -getmerge /user/user_test/test/* ./merge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（15）-put：等同于copyFromLocal</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -put ./merge.txt /user/test/input/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（16）-tail：显示一个文件的末尾</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -tail /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（17）-rm：删除文件或文件夹</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -rm /user/test/input/merge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（18）-rmdir：删除空目录</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -mkdir /test_null    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -rmdir /test_null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（19）-du统计文件夹的大小信息</p><p>统计整个文件大小</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -du -s -h /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>——&gt; 2.7 K</code></pre><p>分别列出大小</p><pre class="line-numbers language-shell"><code class="language-shell">[user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -du -h /user/test/input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>——&gt;2.1.3 K  /user/test/input/README.txt15     /user/test/input/jinlian.txt1.4 K  /user/test/input/zaiyiqi.txt</code></pre><p>（20）-setrep：设置HDFS中文件的副本数量</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 hadoop-2.7.2]$ hadoop fs -setrep 10 /user/test/input/test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</strong></p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>接下来是HDFS客户端准备，应该是开发向重点了~</p><blockquote><p>美好的周末又结束了，感觉下周将会是任务繁重的一周，一定要顺顺利利啊~<br>同时也要祝屁屁工作顺利哦~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop(HDFS)概述（HDFS系列一）</title>
      <link href="2020/08/02/hadoop-hdfs-gai-shu-hdfs-xi-lie-yi/"/>
      <url>2020/08/02/hadoop-hdfs-gai-shu-hdfs-xi-lie-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>感觉不是很重要，文件块大小那节要明白，其他稍微了解下就可以了~</p><h3 id="产生背景及定义"><a href="#产生背景及定义" class="headerlink" title="产生背景及定义"></a>产生背景及定义</h3><p><img src="1.png" alt></p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><img src="2.png" alt="优点"></p><p><img src="3.png" alt="缺点"></p><h3 id="组成架构（之前概述讲过-）"><a href="#组成架构（之前概述讲过-）" class="headerlink" title="组成架构（之前概述讲过 ）"></a>组成架构（之前概述讲过 ）</h3><p><img src="4.png" alt></p><p><img src="5.png" alt></p><h3 id="文件块大小"><a href="#文件块大小" class="headerlink" title="文件块大小"></a>文件块大小</h3><p><img src="6.png" alt></p><p><strong>注：文件块不能设置太小也不能设置太大。因为如果设置太小，会增加寻址时间，程序会一直在寻找块开始的位置；若块设置太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。HDFS块的大小设置主要取决于磁盘的传输速率</strong></p><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>接下来就是HDFS的一些命令操作了~</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop-HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop源码编译（番外篇）</title>
      <link href="2020/08/01/hadoop-yuan-ma-bian-yi-fan-wai-pian/"/>
      <url>2020/08/01/hadoop-yuan-ma-bian-yi-fan-wai-pian/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop编译源码（如果有64位安装包，就直接跳过这节就可以）"><a href="#Hadoop编译源码（如果有64位安装包，就直接跳过这节就可以）" class="headerlink" title="Hadoop编译源码（如果有64位安装包，就直接跳过这节就可以）"></a>Hadoop编译源码（如果有64位安装包，就直接跳过这节就可以）</h1><h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><ol><li>centOS确定联通外网 </li></ol><p>配置centOS能连接外网。</p><p><strong>注：采用root角色编译，减少文件夹权限出现问题</strong></p><ol start="2"><li>jar包准备(hadoop源码、JDK8、maven、ant 、protobuf)</li></ol><p>（1）hadoop-2.7.2-src.tar.gz</p><p>（2）jdk-8u144-linux-x64.tar.gz</p><p>（3）apache-ant-1.9.9-bin.tar.gz（build工具，打包用的）</p><p>（4）apache-maven-3.0.5-bin.tar.gz</p><p>（5）protobuf-2.5.0.tar.gz（序列化的框架）</p><h2 id="jar包安装"><a href="#jar包安装" class="headerlink" title="jar包安装"></a>jar包安装</h2><p><strong>注：所有操作必须在root用户下完成</strong></p><ol><li><p>JDK解压、配置环境变量 JAVA_HOME和PATH，验证java-version(如下都需要验证是否配置成功)</p><pre><code> [root@hadoop101 software] # tar -zxf jdk-8u144-linux-x64.tar.gz -C /opt/module/ [root@hadoop101 software]# vim /etc/profile</code></pre></li></ol><p>添加一下内容</p><pre class="line-numbers language-shell"><code class="language-shell">#JAVA_HOME：export JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>[root@hadoop101 software]#source /etc/profile</code></pre><p>验证<br>    java -version</p><ol start="2"><li><p>Maven解压、配置  MAVEN_HOME和PATH</p><pre><code> [root@hadoop101 software]# tar -zxvf apache-maven-3.0.5-bin.tar.gz -C /opt/module/ [root@hadoop101 apache-maven-3.0.5]# vi conf/settings.xml</code></pre></li></ol><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span>mirrors<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> mirror     <span class="token operator">|</span> Specifies a repository mirror site to use instead of a given repository<span class="token punctuation">.</span> The repository that     <span class="token operator">|</span> <span class="token keyword">this</span> mirror serves has an ID that matches the mirrorOf element of <span class="token keyword">this</span> mirror<span class="token punctuation">.</span> IDs are used     <span class="token operator">|</span> <span class="token keyword">for</span> inheritance and direct lookup purposes<span class="token punctuation">,</span> and must be unique across the set of mirrors<span class="token punctuation">.</span>     <span class="token operator">|</span><span class="token operator">&lt;</span>mirror<span class="token operator">></span>       <span class="token operator">&lt;</span>id<span class="token operator">></span>mirrorId<span class="token operator">&lt;</span><span class="token operator">/</span>id<span class="token operator">></span>       <span class="token operator">&lt;</span>mirrorOf<span class="token operator">></span>repositoryId<span class="token operator">&lt;</span><span class="token operator">/</span>mirrorOf<span class="token operator">></span>       <span class="token operator">&lt;</span>name<span class="token operator">></span>Human Readable Name <span class="token keyword">for</span> <span class="token keyword">this</span> Mirror<span class="token punctuation">.</span>&lt;<span class="token operator">/</span>name<span class="token operator">></span>       <span class="token operator">&lt;</span>url<span class="token operator">></span>http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>my<span class="token punctuation">.</span>repository<span class="token punctuation">.</span>com<span class="token operator">/</span>repo<span class="token operator">/</span>path<span class="token operator">&lt;</span><span class="token operator">/</span>url<span class="token operator">></span>      <span class="token operator">&lt;</span><span class="token operator">/</span>mirror<span class="token operator">></span>     <span class="token operator">--</span><span class="token operator">></span>        <span class="token operator">&lt;</span>mirror<span class="token operator">></span>                <span class="token operator">&lt;</span>id<span class="token operator">></span>nexus<span class="token operator">-</span>aliyun<span class="token operator">&lt;</span><span class="token operator">/</span>id<span class="token operator">></span>                <span class="token operator">&lt;</span>mirrorOf<span class="token operator">></span>central<span class="token operator">&lt;</span><span class="token operator">/</span>mirrorOf<span class="token operator">></span>                <span class="token operator">&lt;</span>name<span class="token operator">></span>Nexus aliyun<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>                <span class="token operator">&lt;</span>url<span class="token operator">></span>http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>maven<span class="token punctuation">.</span>aliyun<span class="token punctuation">.</span>com<span class="token operator">/</span>nexus<span class="token operator">/</span>content<span class="token operator">/</span>groups<span class="token operator">/</span><span class="token keyword">public</span><span class="token operator">&lt;</span><span class="token operator">/</span>url<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>mirror<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>mirrors<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[root@hadoop101 apache-maven-3.0.5]# vim /etc/profile</code></pre><p>添加内容</p><pre class="line-numbers language-shell"><code class="language-shell">#MAVEN_HOMEexport MAVEN_HOME=/opt/module/apache-maven-3.0.5export PATH=$PATH:$MAVEN_HOME/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>[root@hadoop101 software]#source /etc/profile</code></pre><p>验证<br>    mvn -version</p><ol start="3"><li><p>ant解压、配置  ANT _HOME和PATH</p><pre><code> [root@hadoop101 software]# tar -zxvf apache-ant-1.9.9-bin.tar.gz -C /opt/module/ [root@hadoop101 apache-ant-1.9.9]# vim /etc/profile</code></pre></li></ol><pre class="line-numbers language-shell"><code class="language-shell">#ANT_HOMEexport ANT_HOME=/opt/module/apache-ant-1.9.9export PATH=$PATH:$ANT_HOME/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>[root@hadoop101 software]#source /etc/profile</code></pre><p>验证</p><pre><code>ant -version</code></pre><ol start="4"><li><p>安装  glibc-headers 和  g++  命令如下</p><pre><code> [root@hadoop101 apache-ant-1.9.9]# yum install glibc-headers [root@hadoop101 apache-ant-1.9.9]# yum install gcc-c++</code></pre></li><li><p>安装make和cmake</p><pre><code> [root@hadoop101 apache-ant-1.9.9]# yum install make [root@hadoop101 apache-ant-1.9.9]# yum install cmake</code></pre></li><li><p>解压protobuf ，进入到解压后protobuf主目录，/opt/module/protobuf-2.5.0，然后相继执行命令</p><pre><code> [root@hadoop101 software]# tar -zxvf protobuf-2.5.0.tar.gz -C /opt/module/ [root@hadoop101 opt]# cd /opt/module/protobuf-2.5.0/ [root@hadoop101 protobuf-2.5.0]#./configure  [root@hadoop101 protobuf-2.5.0]# make  [root@hadoop101 protobuf-2.5.0]# make check  [root@hadoop101 protobuf-2.5.0]# make install  [root@hadoop101 protobuf-2.5.0]# ldconfig  [root@hadoop101 hadoop-dist]# vim /etc/profile</code></pre></li></ol><pre class="line-numbers language-shell"><code class="language-shell">#LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/opt/module/protobuf-2.5.0export PATH=$PATH:$LD_LIBRARY_PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>[root@hadoop101 software]#source /etc/profile</code></pre><p>验证<br>    protoc –version</p><ol start="7"><li><p>安装openssl库</p><pre><code> [root@hadoop101 software]#yum install openssl-devel</code></pre></li><li><p>安装 ncurses-devel库</p><pre><code> [root@hadoop101 software]#yum install ncurses-devel</code></pre></li></ol><h2 id="编译源码"><a href="#编译源码" class="headerlink" title="编译源码"></a>编译源码</h2><ol><li><p>解压源码到/opt/目录</p><p>  [root@hadoop101 software]# tar -zxvf hadoop-2.7.2-src.tar.gz -C /opt/</p></li><li><p>进入到hadoop源码主目录</p><p>  [root@hadoop101 hadoop-2.7.2-src]# pwd<br>  ——&gt;<br>  /opt/hadoop-2.7.2-src</p></li><li><p>通过maven执行编译命令</p><p>  [root@hadoop101 hadoop-2.7.2-src]#mvn package -Pdist,native -DskipTests -Dtar</p></li></ol><p>等待时间30分钟左右，最终成功是全部SUCCESS，如图2-42所示。</p><p>图2-42 编译源码</p><ol start="4"><li><p>成功的64位hadoop包在/opt/hadoop-2.7.2-src/hadoop-dist/target下</p><p>  [root@hadoop101 target]# pwd<br>  ——&gt;<br>  /opt/hadoop-2.7.2-src/hadoop-dist/target</p></li><li><p>编译源码过程中常见的问题及解决方案</p></li></ol><p>（1）MAVEN install时候JVM内存溢出</p><p>处理方式：在环境配置文件和maven的执行文件均可调整MAVEN_OPT的heap大小。（详情查阅MAVEN 编译 JVM调优问题</p><p>（2）编译期间maven报错。可能网络阻塞问题导致依赖库下载不完整导致，多次执行命令（一次通过比较难）：</p><pre><code>[root@hadoop101 hadoop-2.7.2-src]#mvn package -Pdist,nativeN -DskipTests -Dtar</code></pre><p>（3）报ant、protobuf等错误，插件下载未完整或者插件版本问题，最开始链接有较多特殊情况，同时推荐</p><p>2.7.0版本的问题汇总帖子 <a href="http://www.tuicool.com/articles/IBn63qf" target="_blank" rel="noopener">http://www.tuicool.com/articles/IBn63qf</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集群时间同步（系列四）</title>
      <link href="2020/08/01/hadoop-ji-qun-shi-jian-tong-bu-xi-lie-si/"/>
      <url>2020/08/01/hadoop-ji-qun-shi-jian-tong-bu-xi-lie-si/</url>
      
        <content type="html"><![CDATA[<h1 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h1><p>时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。</p><p><img src="1.png" alt></p><h2 id="1-时间服务器配置（必须root用户）"><a href="#1-时间服务器配置（必须root用户）" class="headerlink" title="1. 时间服务器配置（必须root用户）"></a>1. 时间服务器配置（必须root用户）</h2><p>（1）检查ntp（网络时间协议）是否安装</p><pre><code>[root@hadoop102 桌面]# rpm -qa|grep ntp</code></pre><p>出现以下内容说明已安装</p><pre><code>ntp-4.2.6p5-10.el6.centos.x86_64fontpackages-filesystem-1.41-1.1.el6.noarchntpdate-4.2.6p5-10.el6.centos.x86_64</code></pre><p>（2）修改ntp配置文件</p><pre><code>[root@hadoop102 桌面]# vi /etc/ntp.conf</code></pre><p>修改内容</p><p>a）授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间</p><pre><code>#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap——&gt;restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</code></pre><p>b）集群在局域网中，不使用其他互联网上的时间</p><pre><code>server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst——&gt;#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst</code></pre><p>c）当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步（添加）</p><pre><code>server 127.127.1.0fudge 127.127.1.0 stratum 10</code></pre><p>（3）修改/etc/sysconfig/ntpd 文件</p><pre><code>[root@hadoop102 桌面]# vim /etc/sysconfig/ntpd</code></pre><p>增加如下内容（让硬件时间与系统时间一起同步）</p><pre><code>SYNC_HWCLOCK=yes</code></pre><p>（4）查看状态并重新启动ntpd服务</p><pre><code>[root@hadoop102 桌面]# service ntpd status[root@hadoop102 桌面]# service ntpd start</code></pre><h2 id="2-其他机器配置（必须root用户）"><a href="#2-其他机器配置（必须root用户）" class="headerlink" title="2. 其他机器配置（必须root用户）"></a>2. 其他机器配置（必须root用户）</h2><p>（1）在其他机器配置10分钟与时间服务器同步一次</p><pre><code>[root@hadoop103桌面]# crontab -e</code></pre><p>编写定时任务：</p><p>标准格式：* * * * *  xxxxx（任务）</p><p>其中第一个 * 代表每一小时第 * 分钟；第二个代表每一天第 * 个小时；第三个代表每月第 * 天；第四个代表每年第 * 个月；第五个代表每周星期 * ；后面的 xxx 是我们要做的任务。</p><pre><code>*/10 * * * * /usr/sbin/ntpdate hadoop102</code></pre><p>这是cronetab定时任务写法，可以搜一下具体的。</p><p>（2）修改任意机器时间</p><pre><code>[root@hadoop103桌面]# date -s &quot;2017-9-11 11:11:11&quot;</code></pre><p>（3）十分钟后查看机器是否与时间服务器同步</p><pre><code>[root@hadoop103桌面]# date</code></pre><p><strong>注：测试的时候，可调成1分钟</strong></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop运行模式——完全分布式（系列三(2)）</title>
      <link href="2020/07/31/hadoop-yun-xing-mo-shi-xi-lie-san-2/"/>
      <url>2020/07/31/hadoop-yun-xing-mo-shi-xi-lie-san-2/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h1><h2 id="完全分布式模式"><a href="#完全分布式模式" class="headerlink" title="完全分布式模式"></a>完全分布式模式</h2><h3 id="前提需要"><a href="#前提需要" class="headerlink" title="前提需要"></a>前提需要</h3><p>准备3台客户机（关闭防火墙、静态ip、主机名称）<br>安装JDK<br>配置环境变量<br>安装Hadoop<br>配置环境变量<br>配置集群<br>单点启动<br>配置ssh<br>群起并测试集群<br><strong>虚拟机准备就绪</strong></p><h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h3><h4 id="集群环境搭建"><a href="#集群环境搭建" class="headerlink" title="集群环境搭建"></a>集群环境搭建</h4><h5 id="1-编写集群分发脚本xsync"><a href="#1-编写集群分发脚本xsync" class="headerlink" title="1. 编写集群分发脚本xsync"></a>1. 编写集群分发脚本xsync</h5><p>（1）scp（secure copy）安全拷贝</p><p>scp：scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）<br>当集群达到一定规模之后，我们不可能一台台机器去拷贝所需要的文件之类的，因此需要用到这个。</p><p>（2）基本语法：</p><pre><code>scp -r $pdir/$fname $user@hadoop$host:$pdir/$fna命令 递归  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称</code></pre><p>（3）案例实操</p><p>在hadoop101上，将hadoop101中/opt/module目录下的软件拷贝到hadoop102上。</p><pre><code>scp -r /opt/module  root@hadoop102:/opt/module</code></pre><p>在hadoop103上，将hadoop101服务器上的/opt/module目录下的软件拷贝到hadoop103上。</p><pre><code>sudo scp -r user_test@hadoop101:/opt/module root@hadoop103:/opt/module</code></pre><p><strong>因为最开始103上的opt，user_test没有权限，所以要用root@xxx</strong></p><p>在hadoop103上操作将hadoop101中/opt/module目录下的软件拷贝到hadoop104上。</p><pre><code>scp -r user_test@hadoop101:/opt/module root@hadoop104:/opt/module</code></pre><p><strong>注意：拷贝过来的/opt/module目录，别忘了在hadoop102、hadoop103、hadoop104上修改所有文件的，所有者和所有者组（sudo chown user_test:user -R /opt/module）</strong></p><p>将hadoop101中/etc/profile文件拷贝到hadoop102的/etc/profile上。</p><pre><code>sudo scp /etc/profile root@hadoop102:/etc/profile</code></pre><p>将hadoop101中/etc/profile文件拷贝到hadoop103的/etc/profile上。</p><pre><code>sudo scp /etc/profile root@hadoop103:/etc/profile</code></pre><p>将hadoop101中/etc/profile文件拷贝到hadoop104的/etc/profile上。</p><pre><code>sudo scp /etc/profile root@hadoop104:/etc/profile</code></pre><p><strong>注意：拷贝过来的配置文件别忘了source一下/etc/profile。</strong></p><h5 id="2-rsync-远程同步工具"><a href="#2-rsync-远程同步工具" class="headerlink" title="2. rsync 远程同步工具"></a>2. rsync 远程同步工具</h5><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p><p>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p><p>（1）基本语法</p><pre><code>rsync -rvl $pdir/$fname $user@hadoop$host:$pdir/$fname命令  选项参数   要拷贝的文件路径/名称    目的用户@主机:目的路径/名称</code></pre><p>参数说明：</p><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-r</td><td>递归</td></tr><tr><td>-v</td><td>显示复制过程</td></tr><tr><td>-l</td><td>拷贝符号连接</td></tr></tbody></table><p>（2）案例实操</p><p>a）把hadoop101机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录</p><pre><code>rsync -rvl /opt/software/ root@hadoop102:/opt/software</code></pre><h5 id="3-xsync集群分发脚本"><a href="#3-xsync集群分发脚本" class="headerlink" title="3. xsync集群分发脚本"></a>3. xsync集群分发脚本</h5><p>（1）需求：循环复制文件到所有节点的相同目录下</p><p>（2）需求分析：</p><p>a）rsync命令原始拷贝：</p><pre><code>rsync -rvl /opt/module root@hadoop103:/opt/</code></pre><p>b）期望脚本：</p><pre><code>xsync要同步的文件名称</code></pre><p>c）说明：在 /home/user_test/bin 这个目录下存放的脚本，user_test用户可以在系统任何地方直接执行。</p><p>（3）脚本实现</p><p>a）在 /home/user_test（自己当前登陆用户名） 目录下创建bin目录，并在 bin 目录下创建 xsync 文件，然后编写脚本</p><pre class="line-numbers language-shell"><code class="language-shell">mkdir bincd bin/touch xsyncvim xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>编写shell脚本</p><pre class="line-numbers language-shell"><code class="language-shell">#!/bin/bash#1 获取输入参数个数，如果没有参数，直接退出pcount=$#if((pcount==0)); thenecho no args;exit;fi#2 获取文件名称p1=$1fname=`basename $p1`echo fname=$fname#3 获取上级目录到绝对路径pdir=`cd -P $(dirname $p1); pwd`echo pdir=$pdir#4 获取当前用户名称user=`whoami`#5 循环for((host=103; host<105; host++)); doecho ------------------- hadoop$host --------------rsync -rvl $pdir/$fname $user@hadoop$host:$pdirdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>b）修改脚本 xsync 具有执行权限</p><pre><code>chmod 777 xsync</code></pre><p>c）调用脚本形式：xsync 文件名称</p><pre><code>sync /home/atguigu/bin</code></pre><p><strong>注意：如果将xsync放到/home/atguigu/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。（可以使用 echo $PATH 来查看全局可用路径）</strong></p><h4 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h4><h5 id="1-集群部署规划"><a href="#1-集群部署规划" class="headerlink" title="1. 集群部署规划"></a>1. 集群部署规划</h5><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode   DataNode</td><td>DataNode</td><td>SecondaryNameNode   DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager   NodeManager</td><td>NodeManager</td></tr></tbody></table><p><strong>注：HDFS 中 NameNode (NN) 和 SecondaryNameNode (SNN) 内存占用差不多，所以最好不要放到一台机器上；YARN 中 ResourceManager 占用内存较多，因此不能跟 NN 和 SNN在一台机器上</strong></p><h5 id="2-配置集群"><a href="#2-配置集群" class="headerlink" title="2. 配置集群"></a>2. 配置集群</h5><p>（1）核心配置文件</p><p>配置core-site.xml</p><pre><code>vim core-site.xml</code></pre><p>在该文件中编写如下配置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定HDFS中NameNode的地址 <span class="token operator">--</span><span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>fs<span class="token punctuation">.</span>defaultFS<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span>hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop102<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定Hadoop运行时产生文件的存储目录 <span class="token operator">--</span><span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>hadoop<span class="token punctuation">.</span>tmp<span class="token punctuation">.</span>dir<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hadoop<span class="token operator">-</span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">/</span>data<span class="token operator">/</span>tmp<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）HDFS配置文件</p><p>配置hadoop-env.sh</p><pre><code>vim hadoop-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置hdfs-site.xml</p><pre><code>vim hdfs-site.xml</code></pre><p>在该文件中编写如下配置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs<span class="token punctuation">.</span>replication<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token number">3</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定Hadoop辅助名称节点主机配置 <span class="token operator">--</span><span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs<span class="token punctuation">.</span>namenode<span class="token punctuation">.</span>secondary<span class="token punctuation">.</span>http<span class="token operator">-</span>address<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop104<span class="token operator">:</span><span class="token number">50090</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）YARN配置文件</p><p>配置yarn-env.sh</p><pre><code>vim yarn-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置yarn-site.xml</p><pre><code>vim yarn-site.xml</code></pre><p>在该文件中增加如下配置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> Reducer获取数据的方式 <span class="token operator">--</span><span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn<span class="token punctuation">.</span>nodemanager<span class="token punctuation">.</span>aux<span class="token operator">-</span>services<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span>mapreduce_shuffle<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定YARN的ResourceManager的地址 <span class="token operator">--</span><span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn<span class="token punctuation">.</span>resourcemanager<span class="token punctuation">.</span>hostname<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop103<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）MapReduce配置文件</p><p>配置mapred-env.sh</p><pre><code>vim mapred-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置mapred-site.xml</p><pre><code>cp mapred-site.xml.template mapred-site.xmlvim mapred-site.xml</code></pre><p>在该文件中增加如下配置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定MR运行在Yarn上 <span class="token operator">--</span><span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce<span class="token punctuation">.</span>framework<span class="token punctuation">.</span>name<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span>yarn<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="3-在集群上分发配置好的Hadoop配置文件"><a href="#3-在集群上分发配置好的Hadoop配置文件" class="headerlink" title="3. 在集群上分发配置好的Hadoop配置文件"></a>3. 在集群上分发配置好的Hadoop配置文件</h5><pre><code>xsync /opt/module/hadoop-2.7.2/ (后面为要同步的文件)</code></pre><h5 id="4-查看文件分发情况"><a href="#4-查看文件分发情况" class="headerlink" title="4. 查看文件分发情况"></a>4. 查看文件分发情况</h5><pre><code>cat /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml</code></pre><h4 id="集群单点启动"><a href="#集群单点启动" class="headerlink" title="集群单点启动"></a>集群单点启动</h4><h5 id="1-集群第一次启动，需要格式化-NameNode"><a href="#1-集群第一次启动，需要格式化-NameNode" class="headerlink" title="1. 集群第一次启动，需要格式化 NameNode"></a>1. 集群第一次启动，需要格式化 NameNode</h5><pre><code>hadoop namenode -format</code></pre><h5 id="2-在-hadoop102-上启动-NameNode"><a href="#2-在-hadoop102-上启动-NameNode" class="headerlink" title="2. 在 hadoop102 上启动 NameNode"></a>2. 在 hadoop102 上启动 NameNode</h5><pre><code>hadoop-daemon.sh start namenodejps （检查启动情况）</code></pre><h5 id="3-在-hadoop102、hadoop103-以及-hadoop104-上分别启动-DataNode"><a href="#3-在-hadoop102、hadoop103-以及-hadoop104-上分别启动-DataNode" class="headerlink" title="3. 在 hadoop102、hadoop103 以及 hadoop104 上分别启动 DataNode"></a>3. 在 hadoop102、hadoop103 以及 hadoop104 上分别启动 DataNode</h5><pre><code>hadoop-daemon.sh start datanodejps</code></pre><h4 id="SSH无密登录配置"><a href="#SSH无密登录配置" class="headerlink" title="SSH无密登录配置"></a>SSH无密登录配置</h4><h5 id="1-配置ssh"><a href="#1-配置ssh" class="headerlink" title="1. 配置ssh"></a>1. 配置ssh</h5><p>（1）基本语法</p><pre><code>ssh xxx（另一台电脑的ip地址）</code></pre><p>（2）ssh连接时出现Host key verification failed的解决方法</p><pre><code>[user_test@hadoop102 opt] $ ssh hadoop103</code></pre><p>若出现以下提示，直接输入yes即可</p><p>The authenticity of host ‘192.168.1.103 (192.168.1.103)’ can’t be established.<br>RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:06.<br>Are you sure you want to continue connecting (yes/no)?<br>Host key verification failed.</p><h5 id="2-无密钥配置"><a href="#2-无密钥配置" class="headerlink" title="2. 无密钥配置"></a>2. 无密钥配置</h5><p>（1）免密登录原理</p><p><img src="1.png" alt></p><p>私钥与公钥成对存在，私钥可解经过公钥加密的信息，公钥可解经过私钥加密的信息。</p><p>（2）生成公钥和私钥（.ssh在用户目录下，是一个隐藏文件）：</p><pre><code>[user_test@hadoop102 .ssh]$ ssh-keygen -t rsa</code></pre><p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>（3）将公钥拷贝到要免密登录的目标机器上</p><pre class="line-numbers language-shell"><code class="language-shell">    [user_test@hadoop102 .ssh]$ ssh-copy-id hadoop102    [user_test@hadoop102 .ssh]$ ssh-copy-id hadoop103    [user_test@hadoop102 .ssh]$ ssh-copy-id hadoop104<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>hadoop102上也需要给自己本身copy一份，不然 ssh hadoop102 仍然需要密码</strong></p><p>*<em>注意：<br>以上为在user_test账户下配置的ssh免密<br>还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104（因为user_test有免密权限，root并没有）；<br>还需要在hadoop103上采用user_test账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。<br>之所以要在 102 和 103 上配 ssh 免密，因为 102 上有 datanode 需要跟别的来进行交互，103 上有rm也需要。<br>*</em></p><ol start="3"><li>.ssh文件夹下（~/.ssh）的文件功能解释</li></ol><table><thead><tr><th>known_hosts</th><th>记录ssh访问过计算机的公钥(public   key)</th></tr></thead><tbody><tr><td>id_rsa</td><td>生成的私钥</td></tr><tr><td>id_rsa.pub</td><td>生成的公钥</td></tr><tr><td>authorized_keys</td><td>存放授权过得无密登录服务器公钥</td></tr></tbody></table><h4 id="集群群起"><a href="#集群群起" class="headerlink" title="集群群起"></a>集群群起</h4><h5 id="1-配置slaves（-opt-module-hadoop-2-7-2-etc-hadoop-slaves）"><a href="#1-配置slaves（-opt-module-hadoop-2-7-2-etc-hadoop-slaves）" class="headerlink" title="1. 配置slaves（/opt/module/hadoop-2.7.2/etc/hadoop/slaves）"></a>1. 配置slaves（/opt/module/hadoop-2.7.2/etc/hadoop/slaves）</h5><pre><code>[user_test@hadoop102 hadoop]$ vim slaves</code></pre><p>在该文件中增加如下内容（datanode节点）：</p><p>hadoop102<br>hadoop103<br>hadoop104</p><p><strong>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</strong></p><p>同步所有节点配置文件</p><pre><code>[user_test@hadoop102 hadoop]$ xsync slaves</code></pre><h5 id="2-启动集群"><a href="#2-启动集群" class="headerlink" title="2. 启动集群"></a>2. 启动集群</h5><p>（1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p><pre><code>[user_test@hadoop102 hadoop]$ bin/hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>[user_test@hadoop102 hadoop]$ sbin/start-dfs.sh[user_test@hadoop102 hadoop]$ jps （分别进行检查，跟之前设计架构比较）</code></pre><p><strong>注：启动的时候注意登录的账户，切换成user_test</strong></p><p>（3）启动YARN</p><pre><code>[user_test@hadoop102 hadoop]$ sbin/start-yarn.sh</code></pre><p><strong>注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</strong></p><p>（4）Web端查看SecondaryNameNode</p><p>a）浏览器中输入：<a href="http://hadoop104:50090/status.html" target="_blank" rel="noopener">http://hadoop104:50090/status.html</a></p><p>b）查看SecondaryNameNode信息</p><p><img src="2.png" alt></p><h5 id="3-集群基本测试"><a href="#3-集群基本测试" class="headerlink" title="3. 集群基本测试"></a>3. 集群基本测试</h5><p>（1）上传文件到集群</p><pre><code>[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -mkdir -p /user/atguigu/input[user_test@hadoop102 hadoop-2.7.2]$ hdfs dfs -put wcinput/wc.input /user/atguigu/input</code></pre><p>（2）上传文件后查看文件存放在什么位置</p><p>a）查看HDFS文件存储路径（大文件会分成多块）</p><pre><code>[user_test@hadoop102 subdir0]$ pwd——&gt;/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0</code></pre><p>b）查看HDFS在磁盘存储文件内容</p><pre><code>[user_test@hadoop102 subdir0]$ cat blk_1073741825</code></pre><p>（3）尝试测试上传压缩文件</p><p>a）拼接</p><pre><code>-rw-rw-r--. 1 user_test user 134217728 5月  23 16:01 blk_1073741836-rw-rw-r--. 1 user_test user   1048583 5月  23 16:01 blk_1073741836_1012.meta-rw-rw-r--. 1 user_test user  63439959 5月  23 16:01 blk_1073741837-rw-rw-r--. 1 user_test user    495635 5月  23 16:01 blk_1073741837_1013.meta[user_test@hadoop102 subdir0]$ cat blk_1073741836&gt;&gt;tmp.file[user_test@hadoop102 subdir0]$ cat blk_1073741837&gt;&gt;tmp.file</code></pre><p>b）解压验证</p><pre><code>[user_test@hadoop102 subdir0]$ tar -zxvf tmp.file</code></pre><p>（4）下载</p><pre><code>[user_test@hadoop102 hadoop-2.7.2]$ bin/hadoop dfs -get /user/atguigu/input/hadoop-2.7.2.tar.gz ./</code></pre><h4 id="集群启动-停止方式总结"><a href="#集群启动-停止方式总结" class="headerlink" title="集群启动/停止方式总结"></a>集群启动/停止方式总结</h4><h5 id="1-各个服务组件逐一启动-停止"><a href="#1-各个服务组件逐一启动-停止" class="headerlink" title="1. 各个服务组件逐一启动/停止"></a>1. 各个服务组件逐一启动/停止</h5><p>（1）分别启动/停止HDFS组件</p><pre><code>hadoop-daemon.sh start/stop namenode/datanode/secondarynamenode</code></pre><p>（2）启动/停止YARN</p><pre><code>yarn-daemon.sh start/stop resourcemanager/nodemanager</code></pre><h5 id="2-各个模块分开启动-停止（配置ssh是前提）常用"><a href="#2-各个模块分开启动-停止（配置ssh是前提）常用" class="headerlink" title="2. 各个模块分开启动/停止（配置ssh是前提）常用"></a>2. 各个模块分开启动/停止（配置ssh是前提）常用</h5><p>（1）整体启动/停止HDFS</p><pre><code>start-dfs.sh   /  stop-dfs.sh</code></pre><p>（2）整体启动/停止YARN</p><pre><code>start-yarn.sh  /  stop-yarn.sh</code></pre><h1 id="待续…"><a href="#待续…" class="headerlink" title="待续…"></a>待续…</h1><p>接下来会有一个集群时间同步的小插曲（centos7之后会自动同步时间，感觉这节意义不是很大，可能是我没懂，溜~），然后是Hadoop源码编译的有关东西。</p><blockquote><p>屁屁被领导指导修改工作报告，希望能够得到领导肯定。我呢，希望会有一定收获，到时候能找一个比较满意的可以转正的实习。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop运行模式（系列三(1)）</title>
      <link href="2020/07/30/hadoop-yun-xing-mo-shi-xi-lie-san-1/"/>
      <url>2020/07/30/hadoop-yun-xing-mo-shi-xi-lie-san-1/</url>
      
        <content type="html"><![CDATA[<p>Hadoop伪分布式模式尝试~</p><h1 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h1><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。</p><p>Hadoop官方网站：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a> （其中有两个案列）</p><h2 id="伪分布式运行模式"><a href="#伪分布式运行模式" class="headerlink" title="伪分布式运行模式"></a>伪分布式运行模式</h2><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><ol><li><p>配置集群</p></li><li><p>启动、测试集群增、删、查</p></li><li><p>执行WordCount案例</p></li></ol><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><h4 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h4><ol><li>配置：hadoop-env.sh（/opt/module/hadoop-2.7.2/etc/hadoop/hadoop-env.sh）</li></ol><p>Linux系统中获取JDK的安装路径：</p><pre><code>echo $JAVA_HOME--&gt;/opt/module/jdk1.8.0_144</code></pre><p>修改JAVA_HOME 路径：</p><pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><ol start="2"><li>配置：core-site.xml（/opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml——文件末尾）</li></ol><pre class="line-numbers language-java"><code class="language-java">    <span class="token operator">&lt;</span>configuration<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定HDFS中NameNode的地址 <span class="token operator">--</span><span class="token operator">></span>        <span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>fs<span class="token punctuation">.</span>defaultFS<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span>hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop101<span class="token operator">:</span><span class="token number">9000</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定Hadoop运行时产生文件的存储目录 <span class="token operator">--</span><span class="token operator">></span>        <span class="token operator">&lt;</span>property<span class="token operator">></span>            <span class="token operator">&lt;</span>name<span class="token operator">></span>hadoop<span class="token punctuation">.</span>tmp<span class="token punctuation">.</span>dir<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>            <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hadoop<span class="token operator">-</span><span class="token number">2.7</span><span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">/</span>data<span class="token operator">/</span>tmp<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>configuration<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>配置：hdfs-site.xml（/opt/module/hadoop-2.7.2/etc/hadoop/hdfs-site.xml——文件末尾）</li></ol><pre class="line-numbers language-java"><code class="language-java">    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定HDFS副本的数量 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs<span class="token punctuation">.</span>replication<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token number">1</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注：如果只有一台机器，即使备份是3也是备份1份，当集群新增机器时，就会自动添加备份</strong> </p><h4 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h4><ol><li><p>格式化NameNode（第一次启动时格式化，以后就不需要格式化，后期格式化先看进程。先关进程，再删文件）——要先jps查看进程，看下进程关了，再删除data和logs文件（在这个路径下/opt/module/hadoop-2.7.2）</p><p> bin/hdfs namenode -format</p></li><li><p>启动NameNode</p><p> sbin/hadoop-daemon.sh start namenode</p></li><li><p>启动DataNode</p><p> sbin/hadoop-daemon.sh start datanode</p></li></ol><h4 id="查看集群"><a href="#查看集群" class="headerlink" title="查看集群"></a>查看集群</h4><ol><li><p>查看是否启动成功</p><p> jps（jdk命令，不安装jdk则无法使用）<br> ——&gt; 13586 NameNode</p><pre><code> 13668 DataNode 13786 Jps</code></pre></li><li><p>web端查看HDFS文件系统<br> <a href="http://hadoop101:50070" target="_blank" rel="noopener">http://hadoop101:50070</a> （hadoop101可以换成网址或者在本地hosts中配置一下）</p></li><li><p>查看日志</p></li></ol><p>日志都在logs文件夹下，可以查看。</p><ol start="4"><li>集群操作</li></ol><p>（1）在HDFS文件系统上创建一个input文件夹</p><pre><code>bin/hdfs dfs -mkdir -p /user/test/input</code></pre><p>（2）将测试文件内容上传到文件系统上</p><pre><code>bin/hdfs dfs -put wcinput/wc.input</code></pre><p>（3）查看文件</p><pre><code>bin/hdfs dfs -ls  /user/test/input/bin/hdfs dfs -cat  /user/test/input/wc.input</code></pre><p>（4）运行MapReduce程序</p><pre><code>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/test/input/ /user/test/output</code></pre><p>（5）查看输出结果<br>命令行输出查看：</p><pre><code>bin/hdfs dfs -cat /user/test/output/p*</code></pre><p>浏览器查看（文件可下载查看）：</p><p><img src="1.png" alt></p><p>（6）将测试文件内容下载到本地</p><pre><code>hdfs dfs -get /user/test/output/part-r-00000 ./wcoutput/</code></pre><p>（7）删除输出结果</p><pre><code>hdfs dfs -rm -r /user/test/output</code></pre><p><strong>思考： 为什么不能一直格式化NameNode，格式化NameNode，要注意什么？</strong></p><pre class="line-numbers language-shell"><code class="language-shell">cd data/tmp/dfs/name/current/cat VERSION——> clusterID=CID-f0330a58-36fa-4a2a-a65f-2688269b5837.................................................cd data/tmp/dfs/data/current/cat VERSION——> clusterID=CID-f0330a58-36fa-4a2a-a65f-2688269b5837<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可见，其中两个集群id是一样的。格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。</p><p><img src="2.png" alt></p><p><strong>先关掉进程，再删除文件，再格式化</strong></p><h2 id="启动YARN运行MapReduce"><a href="#启动YARN运行MapReduce" class="headerlink" title="启动YARN运行MapReduce"></a>启动YARN运行MapReduce</h2><h3 id="操作-1"><a href="#操作-1" class="headerlink" title="操作"></a>操作</h3><ol><li>配置集群在YARN上运行MR</li><li>启动、测试集群增、删、查</li><li>在YARN上执行WordCount案例</li></ol><h3 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h3><ol><li>配置集群</li></ol><p>（1）配置yarn-env.sh（/opt/module/hadoop-2.7.2/etc/hadoop/hadoop-env.sh）<br>配置一下JAVA_HOME（与上面配置 hadoop-env.sh 类似）</p><pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>（2）配置yarn-site.xml（/opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xml——文件末尾）</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> Reducer获取数据的方式 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>            <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn<span class="token punctuation">.</span>nodemanager<span class="token punctuation">.</span>aux<span class="token operator">-</span>services<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>            <span class="token operator">&lt;</span>value<span class="token operator">></span>mapreduce_shuffle<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定YARN的ResourceManager的地址 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn<span class="token punctuation">.</span>resourcemanager<span class="token punctuation">.</span>hostname<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop101<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）配置：mapred-env.sh（/opt/module/hadoop-2.7.2/etc/hadoop/mapred-env.sh）<br>配置一下JAVA_HOME</p><pre><code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>（4）对 mapred-site.xml.template 重新命名为 mapred-site.xml</p><pre><code>mv mapred-site.xml.template mapred-site.xmlvim mapred-site.xml</code></pre><p>添加以下配置</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 指定MR运行在YARN上 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>            <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce<span class="token punctuation">.</span>framework<span class="token punctuation">.</span>name<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>            <span class="token operator">&lt;</span>value<span class="token operator">></span>yarn<span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>启动集群</li></ol><p>（1）启动前必须保证NameNode和DataNode已经启动</p><p>（2）启动ResourceManager</p><pre><code>sbin/yarn-daemon.sh start resourcemanager</code></pre><p>（3）启动NodeManager</p><pre><code>sbin/yarn-daemon.sh start nodemanager</code></pre><ol start="3"><li>配置历史服务器</li></ol><p>配置历史服务器，查看程序的历史运行情况。配置步骤：</p><p>（1）配置mapred-site.xml</p><pre><code>vim mapred-site.xml</code></pre><p>在该文件里面增加如下配置。</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 历史服务器端地址 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce<span class="token punctuation">.</span>jobhistory<span class="token punctuation">.</span>address<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>    <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop101<span class="token operator">:</span><span class="token number">10020</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 历史服务器web端地址 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce<span class="token punctuation">.</span>jobhistory<span class="token punctuation">.</span>webapp<span class="token punctuation">.</span>address<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop101<span class="token operator">:</span><span class="token number">19888</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）启动历史服务器</p><pre><code>sbin/mr-jobhistory-daemon.sh start historyserver</code></pre><p>（3）查看历史服务器是否启动</p><pre><code>jps</code></pre><p>（4）查看JobHistory</p><p><a href="http://hadoop101:19888/jobhistory" target="_blank" rel="noopener">http://hadoop101:19888/jobhistory</a></p><ol start="4"><li>配置日志的聚集</li></ol><p>日志聚集：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。</p><p>好处：可以方便的查看到程序运行详情，方便开发调试。</p><p><strong>注：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager</strong></p><p>开启日志聚集功能具体步骤如下：</p><p>（1）配置yarn-site.xml</p><pre><code>vim yarn-site.xml</code></pre><p>在该文件里面增加如下配置。</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 日志聚集功能使能 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn<span class="token punctuation">.</span>log<span class="token operator">-</span>aggregation<span class="token operator">-</span>enable<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token boolean">true</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> 日志保留时间设置<span class="token number">7</span>天 <span class="token operator">--</span><span class="token operator">></span>    <span class="token operator">&lt;</span>property<span class="token operator">></span>        <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn<span class="token punctuation">.</span>log<span class="token operator">-</span>aggregation<span class="token punctuation">.</span>retain<span class="token operator">-</span>seconds<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">></span>        <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token number">604800</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中日志保留七天是按秒来计算的</p><p>（2）关闭NodeManager 、ResourceManager和HistoryManager</p><pre class="line-numbers language-shell"><code class="language-shell">    sbin/yarn-daemon.sh stop resourcemanager    sbin/yarn-daemon.sh stop nodemanager    sbin/mr-jobhistory-daemon.sh stop historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）启动NodeManager 、ResourceManager和HistoryManager</p><pre class="line-numbers language-shell"><code class="language-shell">    sbin/yarn-daemon.sh start resourcemanager    sbin/yarn-daemon.sh start nodemanager    sbin/mr-jobhistory-daemon.sh start historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）删除HDFS上已经存在的输出文件</p><pre><code>bin/hdfs dfs -rm -R /user/atguigu/output</code></pre><p>（5）执行WordCount程序</p><pre><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input /user/atguigu/output</code></pre><p>（6）查看日志，如图2-37，2-38，2-39所示</p><p><a href="http://hadoop101:19888/jobhistory" target="_blank" rel="noopener">http://hadoop101:19888/jobhistory</a> 点击ApplicationMaster中的logs</p><h3 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h3><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p><ol><li>默认配置文件：</li></ol><table><thead><tr><th>要获取的默认文件</th><th>文件存放在Hadoop的jar包中的位置</th></tr></thead><tbody><tr><td>core-default.xml</td><td>hadoop-common-2.7.2.jar/core-default.xml</td></tr><tr><td>hdfs-default.xml</td><td>hadoop-hdfs-2.7.2.jar/hdfs-default.xml</td></tr><tr><td>yarn-default.xml</td><td>hadoop-yarn-common-2.7.2.jar/yarn-default.xml</td></tr><tr><td>mapred-default.xml</td><td>hadoop-mapreduce-client-core-2.7.2.jar/mapred-default.xml</td></tr></tbody></table><ol start="2"><li>自定义配置文件：core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。（优先级高于默认的）</li></ol><h1 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h1><p>接下来要做的是，hadoop完全分布式模式环境搭建及运行测试</p><blockquote><p>祝：屁屁入职工作顺利并有所收获，皮皮实习顺利没有bug有所收获~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop环境配置（系列二）</title>
      <link href="2020/07/30/hadoop-huan-jing-pei-zhi-xi-lie-er/"/>
      <url>2020/07/30/hadoop-huan-jing-pei-zhi-xi-lie-er/</url>
      
        <content type="html"><![CDATA[<p>Hadoop基本环境搭建（虚拟机配置、jdk以及hadoop安装）</p><h1 id="Hadoop环境配置"><a href="#Hadoop环境配置" class="headerlink" title="Hadoop环境配置"></a>Hadoop环境配置</h1><h2 id="虚拟机环境"><a href="#虚拟机环境" class="headerlink" title="虚拟机环境"></a>虚拟机环境</h2><ol><li><p>克隆虚拟机</p></li><li><p>修改克隆虚拟机的静态IP</p></li><li><p>修改主机名</p></li><li><p>关闭防火墙</p></li><li><p>创建普通用户（以后使用多使用普通用户，不然有些操作会很危险）</p></li><li><p>配置普通用户具有root权限</p></li><li><p>在/opt目录下创建文件夹</p><p> （1）在/opt目录下创建module、software文件夹（module：存放解压缩内容；software：存放压缩包）</p><pre><code> sudo mkdir module sudo mkdir software</code></pre><p> （2）修改module、software文件夹的所有者 </p><pre><code> sudo chown user:user（用户名：组名） module/ software/</code></pre></li></ol><h2 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h2><ol><li><p>上传jdk压缩文件到software文件夹下</p></li><li><p>将jdk压缩包解压缩到module文件夹下<br> tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/</p></li><li><p>配置jdk环境变量</p><p> （1）进入到jdk目录下，获取jdk路径</p><pre><code> pwd</code></pre><p> （2）编辑/etc/profile</p><pre><code> vim sudo /etc/profile  （若vim不可用，使用vi）</code></pre><p> （3）载文件末尾加上java路径</p><pre><code> #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_144 export PATH=$PATH:$JAVA_HOME/bin</code></pre><p> （4）保存退出</p><pre><code> :wq</code></pre><p> （5）使修改后文件生效</p><pre><code> source /etc/profile</code></pre><p> （6）测试是否配置成功</p><pre><code> java -version （会显示 java version &quot;1.8.0_144&quot;... 这就说明成功了）</code></pre></li></ol><p><strong>注：</strong>centos7之后自带了jdk，可以看下版本，版本低于1.7就要卸掉重装了。可用 which java来看下是不是我们所配置的那个路径，如果不是则说明是系统自带的</p><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><ol><li>环境配置</li></ol><p>跟jdk类似——先上传压缩包，然后解压到指定文件夹，然后编辑环境变量（载profile文件末尾加上环境变量）</p><p><strong>hadoop环境变量配置（加在profile文件末尾）：</strong></p><pre class="line-numbers language-shell"><code class="language-shell">##HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>目录结构</li></ol><p><img src="1.png" alt></p><p>（1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本<br>（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件<br>（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）<br>（4）sbin目录：存放启动或停止Hadoop相关服务的脚本<br>（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例</p><h1 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h1><p>接下来要做的是，hadoop几种运行模式的尝试（伪分布式模式以及完全分布式模式）</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop简介（系列一）</title>
      <link href="2020/07/29/hadoop-jian-jie-xi-lie-yi/"/>
      <url>2020/07/29/hadoop-jian-jie-xi-lie-yi/</url>
      
        <content type="html"><![CDATA[<p>之前学过一段时间，好久没用，已经忘得干干净净了。现在只能重新开始，整理学习了~</p><h1 id="Hadoop简介"><a href="#Hadoop简介" class="headerlink" title="Hadoop简介"></a>Hadoop简介</h1><h2 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h2><ol><li>NameNode（nn）：存储文件元数据，以及每个文件的块列表和所在的DataNode等（方便找数据的索引）</li><li>DataNode（dn）：在本地文件系统存储文件块数据，以及数据的校验和（存数据）</li><li>Secondary NameNode（2nn）：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照（并不完全是NameNode的备份，当nn挂了，它只能辅助恢复，并不能完全替代，就像是主治医生和递手术刀的）</li></ol><h2 id="YARN架构概述"><a href="#YARN架构概述" class="headerlink" title="YARN架构概述"></a>YARN架构概述</h2><p>调度CPU算力和内存资源</p><ol><li>ResourceManager（RM）（集群中只有一个，管理整个项目所有调度）</li></ol><p>（1）处理客户端请求（所有请求都会先发给它——作业提交）<br>（2）监控NodeManager<br>（3）启动或监控ApplicationMaster<br>（4）资源分配与调度</p><ol start="2"><li>NodeManager（NM）</li></ol><p>（1）管理单个节点上的资源<br>（2）处理来自RM的命令<br>（3）处理来自ApplicationMaster的命令</p><ol start="3"><li>ApplicationMaster（AM）（项目临时负责任务跟进，非常住进程，一个job就是一个AM）</li></ol><p>（1）负责数据切分<br>（2）为应用程序申请资源并分配给内部任务<br>（3）任务监控与容错</p><ol start="4"><li>Container（非常主进程）</li></ol><p>YARN中资源抽象，封装了某个节点上的多维度资源，如：内存、CPU、磁盘、网络</p><h2 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h2><p>MapReduce将计算过程分为两个阶段：Map（分）和Reduce（汇总）</p><p><img src="1.jpg" alt></p><h2 id="大数据生态体系"><a href="#大数据生态体系" class="headerlink" title="大数据生态体系"></a>大数据生态体系</h2><p><img src="2.jpg" alt></p><p>HBase：类似于大表格<br>Hive、Mahout…：计算引擎（MapReduce）的包装（类似于mabatis是mysql的包装）<br>Kafka是在线计算（流式计算，无穷尽）：评价标准是实时处理速度（口径）；其他为离线计算</p><pre><code>Storm是纯流式计算——来一点处理一点（口径小）Spark不是纯流式处理，先存一部分，然后处理（Flink与其类似）</code></pre><p>Zookeeper：协调各个框架之间关系</p><h1 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h1><p>接下来要做的是，hadoop基本环境搭建（虚拟机、jdk以及hadoop安装）</p><blockquote><p>一切都要顺顺利利呀~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>summernote使用</title>
      <link href="2020/05/17/summernote-shi-yong/"/>
      <url>2020/05/17/summernote-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="Bootstrap-——-summernote"><a href="#Bootstrap-——-summernote" class="headerlink" title="Bootstrap —— summernote"></a>Bootstrap —— summernote</h1><p>官方文档地址：<a href="https://summernote.org/getting-started" target="_blank" rel="noopener">https://summernote.org/getting-started</a></p><h2 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h2><ol><li><p>这里使用cdn引入</p><pre class="line-numbers language-html"><code class="language-html"> <span class="token comment" spellcheck="true">&lt;!-- 插件引入 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://cdnjs.cloudflare.com/ajax/libs/summernote/0.8.9/summernote.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://netdna.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://cdnjs.cloudflare.com/ajax/libs/summernote/0.8.9/summernote.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span> <span class="token comment" spellcheck="true">&lt;!--引入中文JS包--></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.bootcss.com/summernote/0.8.10/lang/summernote-zh-CN.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  //引入中文包，不然编辑器是默认的英文<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>当然也可以用文件引入</p><pre><code>1、将summernote 相应的文件放到工程中（webapp下面）2、建一个jsp文件，在文件中引入相应的js、css文件</code></pre><ol start="2"><li>建一个div区域存放内容，注意写上id</li></ol><pre class="line-numbers language-html"><code class="language-html">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>summernote<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>   //内容载体<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>js初始化</li></ol><pre class="line-numbers language-js"><code class="language-js">    <span class="token comment" spellcheck="true">// 编辑器功能=====================================</span>    <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">"#summernote"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">summernote</span><span class="token punctuation">(</span><span class="token punctuation">{</span>        lang <span class="token punctuation">:</span> <span class="token string">'zh-CN'</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">// 语言</span>        height <span class="token punctuation">:</span> <span class="token number">496</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">// 高度</span>        minHeight <span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">// 最小高度</span>        placeholder <span class="token punctuation">:</span> <span class="token string">'请输入文章内容'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">// 提示       </span>        <span class="token comment" spellcheck="true">// summernote自定义配置(编辑器上方的粗体什么的)</span>        toolbar<span class="token punctuation">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">[</span><span class="token string">'operate'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'undo'</span><span class="token punctuation">,</span><span class="token string">'redo'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'magic'</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'style'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'style'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'bold'</span><span class="token punctuation">,</span> <span class="token string">'italic'</span><span class="token punctuation">,</span> <span class="token string">'underline'</span><span class="token punctuation">,</span> <span class="token string">'clear'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'para'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'height'</span><span class="token punctuation">,</span><span class="token string">'fontsize'</span><span class="token punctuation">,</span><span class="token string">'ul'</span><span class="token punctuation">,</span> <span class="token string">'ol'</span><span class="token punctuation">,</span> <span class="token string">'paragraph'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'font'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'strikethrough'</span><span class="token punctuation">,</span> <span class="token string">'superscript'</span><span class="token punctuation">,</span> <span class="token string">'subscript'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'color'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'color'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'insert'</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'picture'</span><span class="token punctuation">,</span><span class="token string">'video'</span><span class="token punctuation">,</span><span class="token string">'link'</span><span class="token punctuation">,</span><span class="token string">'table'</span><span class="token punctuation">,</span><span class="token string">'hr'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token string">'layout'</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'fullscreen'</span><span class="token punctuation">,</span><span class="token string">'codeview'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        callbacks <span class="token punctuation">:</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// 回调函数</span>        <span class="token comment" spellcheck="true">// 上传图片时使用的回调函数   因为我们input选择的本地图片是二进制图片，需要把二进制图片上传服务器，服务器再返回图片url，就需要用到callback这个回调函数</span>            onImageUpload <span class="token punctuation">:</span> <span class="token keyword">function</span><span class="token punctuation">(</span>files<span class="token punctuation">)</span> <span class="token punctuation">{</span>                 <span class="token keyword">var</span> form<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">FormData</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                form<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">'myFileName'</span><span class="token punctuation">,</span>files<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">//myFileName 是上传的参数名，一定不能写错</span>                $<span class="token punctuation">.</span><span class="token function">ajax</span><span class="token punctuation">(</span><span class="token punctuation">{</span>                    type<span class="token punctuation">:</span><span class="token string">"post"</span><span class="token punctuation">,</span>                    url<span class="token punctuation">:</span><span class="token string">"${path}/Img/upload"</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">//上传服务器地址</span>                    dataType<span class="token punctuation">:</span><span class="token string">'json'</span><span class="token punctuation">,</span>                    data<span class="token punctuation">:</span>form<span class="token punctuation">,</span>                    processData <span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>                    contentType <span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>                    cache <span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>                    success<span class="token punctuation">:</span><span class="token keyword">function</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">{</span>                        console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>data<span class="token punctuation">)</span>                                                    <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'#summernote'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">summernote</span><span class="token punctuation">(</span><span class="token string">'editor.insertImage'</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：</strong> $(‘#summernote’).summernote(‘insertImage’, url, filename); 官方文档提供的图片插入封装函数，在本地环境下服务器返回的url并不能展示在编辑框内，放到生产环境的时候自然会展示在编辑框内（网上搜索才知道，网址具体忘了，侵删）</p><h2 id="最后样式"><a href="#最后样式" class="headerlink" title="最后样式"></a>最后样式</h2><p><img src="1.png" alt></p><h2 id="其他使用"><a href="#其他使用" class="headerlink" title="其他使用"></a>其他使用</h2><ol><li><p>获取编辑器内的HTML内容</p><p> var markupStr = $(‘#summernote’).summernote(‘code’);</p></li></ol><p>如果初始化了多个编辑器，可以通过jquery的eq方法获取某个编辑器的HTML内容。eg,获取第二个编辑器的。</p><pre><code>var markupStr = $(&#39;.summernote&#39;).eq(1).summernote(&#39;code&#39;);</code></pre><ol start="2"><li><p>赋值</p><p> // 这样也是赋成html格式<br> $(‘.summernote’).summernote(‘code’,’要赋的值’);</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>clo-xxx-*使用</title>
      <link href="2020/05/17/clo-xxx-shi-yong/"/>
      <url>2020/05/17/clo-xxx-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="Bootstrap-——-网格系统"><a href="#Bootstrap-——-网格系统" class="headerlink" title="Bootstrap —— 网格系统"></a>Bootstrap —— 网格系统</h1><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>.col-xs-* 超小屏幕 手机 (&lt;768px)</p><p>.col-sm-* 小屏幕 平板 (≥768px)</p><p>.col-md-* 中等屏幕 桌面显示器 (≥992px)</p><p>.col-lg-* 大屏幕 大桌面显示器 (≥1200px)</p><h2 id="关键字说明"><a href="#关键字说明" class="headerlink" title="关键字说明"></a>关键字说明</h2><ol><li><p>col —— column：列；</p></li><li><p>xs —— maxsmall：超小； sm —— small：小；  md —— medium：中等；  lg —— large：大；</p></li><li><p>-*  表示占列，即占自动每行 row 分12列栅格系统比；</p></li><li><p>不管在哪种屏幕上，栅格系统都会自动将每 row 行分12列 col-xs-* 和 col-sm-* 和 col-md-*后面跟的参数表示在当前的屏幕中每个div所占列数。例如 <div class="col-xs-6 col-md-3"> 这个div在屏幕中占的位置是：在超小屏幕中这个div占6列也就是屏幕的一半；在中等屏幕占3列也就是1/4。</div></p></li></ol><p>6、反推，如果我们要在小屏幕上并排显示3个div(12/3个=每个占4 列 )，则用 col-xs-4；在大屏幕上显示6个div(12/6个=每个占2列 ) ，则用 col-md-2；这样我们就可以控制我们自己想要的什么排版了。</p><h2 id="案列"><a href="#案列" class="headerlink" title="案列"></a>案列</h2><h3 id="样式单一使用"><a href="#样式单一使用" class="headerlink" title="样式单一使用"></a>样式单一使用</h3><pre class="line-numbers language-html"><code class="language-html">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>container<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>row<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-4<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-4<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-4<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 说明：每row行共12列，分个3div，每个div平占4列，即3个*4列=12列 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>row<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-4<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-8<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 说明：每row行共12列，分个2div，第1个div占4列，第2个div则占8列，即4列+8列=12列 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>row<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-3<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-6<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-md-3<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>col-md-3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 说明：每row行共12列，分个3div，每1,3个div占3列，第2个div则占6列，即3列+6列+3列=12列 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="混合使用"><a href="#混合使用" class="headerlink" title="混合使用"></a>混合使用</h3><pre class="line-numbers language-html"><code class="language-html"><span class="token comment" spellcheck="true">&lt;!-- 说明：当屏幕尺寸不同时，调用不同的样式--></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>col-xs-12 col-sm-9 col-md-6 col-lg-3<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>测试<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用css绘制类似于聊天框的弹出提示框</title>
      <link href="2020/05/17/shi-yong-css-hui-zhi-lei-si-yu-liao-tian-kuang-de-dan-chu-ti-shi-kuang/"/>
      <url>2020/05/17/shi-yong-css-hui-zhi-lei-si-yu-liao-tian-kuang-de-dan-chu-ti-shi-kuang/</url>
      
        <content type="html"><![CDATA[<h1 id="使用css画出类似于聊天框的弹出提示框"><a href="#使用css画出类似于聊天框的弹出提示框" class="headerlink" title="使用css画出类似于聊天框的弹出提示框"></a>使用css画出类似于聊天框的弹出提示框</h1><p>由于项目需要，要做一个在点击保存按钮，保存成功后，在右边显示保存成功的弹出提示框，然后一秒后消失。于是查阅网络，经过修改改成了自己需要的。</p><h2 id="制作效果"><a href="#制作效果" class="headerlink" title="制作效果"></a>制作效果</h2><p><img src="1.jpg" alt></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre class="line-numbers language-html"><code class="language-html">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>text/css<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token style language-css">            <span class="token selector"><span class="token id">#saveSuccess</span> </span><span class="token punctuation">{</span>                <span class="token property">position</span><span class="token punctuation">:</span> relative<span class="token punctuation">;</span>                <span class="token property">width</span><span class="token punctuation">:</span> <span class="token number">100</span>px<span class="token punctuation">;</span>                <span class="token property">min-height</span><span class="token punctuation">:</span> <span class="token number">30</span>px<span class="token punctuation">;</span>                <span class="token property">background</span><span class="token punctuation">:</span> <span class="token hexcode">#00da88</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">/*圆角*/</span>                <span class="token property">border-radius</span><span class="token punctuation">:</span> <span class="token number">5</span>px<span class="token punctuation">;</span>                  <span class="token property">margin-left</span><span class="token punctuation">:</span> <span class="token number">10</span>px<span class="token punctuation">;</span>                <span class="token property">font-weight</span><span class="token punctuation">:</span> bold<span class="token punctuation">;</span>                <span class="token property">color</span><span class="token punctuation">:</span> white<span class="token punctuation">;</span>                <span class="token property">padding</span><span class="token punctuation">:</span> <span class="token number">10</span>px <span class="token number">20</span>px <span class="token number">10</span>px<span class="token punctuation">;</span>                <span class="token property">line-height</span><span class="token punctuation">:</span> <span class="token number">18</span>px<span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token selector"><span class="token id">#saveSuccess</span><span class="token pseudo-element">::after</span> </span><span class="token punctuation">{</span>                <span class="token property">content</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">;</span>                <span class="token property">display</span><span class="token punctuation">:</span> block<span class="token punctuation">;</span>                <span class="token property">position</span><span class="token punctuation">:</span> absolute<span class="token punctuation">;</span>                <span class="token property">width</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">;</span>                <span class="token property">height</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">;</span>                <span class="token property">border</span><span class="token punctuation">:</span> <span class="token number">8</span>px solid transparent<span class="token punctuation">;</span>                <span class="token property">border-right-color</span><span class="token punctuation">:</span> <span class="token hexcode">#00da88</span><span class="token punctuation">;</span>                <span class="token property">top</span><span class="token punctuation">:</span> <span class="token number">10</span>px<span class="token punctuation">;</span>                <span class="token property">left</span><span class="token punctuation">:</span> -<span class="token number">14</span>px<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        </span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>button<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-sm btn-white<span class="token punctuation">"</span></span> <span class="token attr-name">onclick</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submitHandler()<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>i</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>fa fa-check<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>i</span><span class="token punctuation">></span></span>保 存<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>saveSuccess<span class="token punctuation">"</span></span><span class="token style-attr language-css"><span class="token attr-name"> <span class="token attr-name">style</span></span><span class="token punctuation">="</span><span class="token attr-value"><span class="token property">visibility</span><span class="token punctuation">:</span> hidden<span class="token punctuation">;</span> <span class="token property">display</span><span class="token punctuation">:</span> inline-block<span class="token punctuation">;</span></span><span class="token punctuation">"</span></span><span class="token punctuation">></span></span>保存成功<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span><span class="token punctuation">></span></span><span class="token script language-javascript">        <span class="token keyword">function</span> <span class="token function">submitHandler</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 其他代码</span>            <span class="token comment" spellcheck="true">// 保存成功</span>            success <span class="token punctuation">:</span> <span class="token keyword">function</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token operator">...</span>document<span class="token punctuation">.</span><span class="token function">getElementById</span><span class="token punctuation">(</span><span class="token string">"saveSuccess"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>style<span class="token punctuation">.</span>visibility<span class="token operator">=</span><span class="token string">"visible"</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 设置显示出来</span>                <span class="token comment" spellcheck="true">// 设置属性隐藏</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">$</span><span class="token punctuation">(</span><span class="token string">"#saveSuccess"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">attr</span><span class="token punctuation">(</span><span class="token string">"style.visibility"</span><span class="token punctuation">,</span> <span class="token string">"hidden"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token comment" spellcheck="true">// 1s后隐藏</span>                    <span class="token function">setTimeout</span><span class="token punctuation">(</span><span class="token string">"$('#saveSuccess').hide();"</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                        <span class="token comment" spellcheck="true">// 隐藏后显示，由于属性是隐藏，所以就算是显示出来也看不到</span>                        <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'#saveSuccess'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    </span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot常用注解</title>
      <link href="2020/05/11/springboot-chang-yong-zhu-jie/"/>
      <url>2020/05/11/springboot-chang-yong-zhu-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="SpringBoot-常用注解"><a href="#SpringBoot-常用注解" class="headerlink" title="SpringBoot 常用注解"></a>SpringBoot 常用注解</h1><p>最近由于种种原因，开始学习使用 SpringBoot 了，但是上来发现了好多的注解，一脸懵 * ，于是像整理下，其中大多搜索与网上。</p><h2 id="项目配置相关"><a href="#项目配置相关" class="headerlink" title="项目配置相关"></a>项目配置相关</h2><h3 id="1-SpringBootApplication-注解"><a href="#1-SpringBootApplication-注解" class="headerlink" title="1. @SpringBootApplication 注解"></a>1. @SpringBootApplication 注解</h3><p>@SpringBootApplication是一个复合注解，包含了@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan 这三个注解。</p><p>它们作用分别为：</p><h4 id="SpringBootConfiguration-继承于-Configuration-注解，主要用于加载配置文件"><a href="#SpringBootConfiguration-继承于-Configuration-注解，主要用于加载配置文件" class="headerlink" title="@SpringBootConfiguration 继承于 @Configuration 注解，主要用于加载配置文件"></a>@SpringBootConfiguration 继承于 @Configuration 注解，主要用于加载配置文件</h4><p>标注当前类是配置类，并会将当前类内声明的一个或多个以 @Bean 注解标记的方法的实例纳入到srping容器中，并且实例名就是方法名。</p><h4 id="EnableAutoConfiguration-开启自动配置功能"><a href="#EnableAutoConfiguration-开启自动配置功能" class="headerlink" title="@EnableAutoConfiguration 开启自动配置功能"></a>@EnableAutoConfiguration 开启自动配置功能</h4><p>可以帮助SpringBoot应用将所有符合条件的 @Configuration 配置都加载到当前 SpringBoot 创建并使用的 IoC 容器。借助于Spring框架原有的一个工具类 SpringFactoriesLoader 的支持。</p><h4 id="ComponentScan-主要用于组件扫描和自动装配"><a href="#ComponentScan-主要用于组件扫描和自动装配" class="headerlink" title="@ComponentScan 主要用于组件扫描和自动装配"></a>@ComponentScan 主要用于组件扫描和自动装配</h4><p>自动扫描并加载符合条件的组件或bean定义（被@Component，@Controller，@Service，@Repository注解标记的类），最终将这些bean定义加载到容器中。我们可以通过basePackages等属性指定@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现从声明@ComponentScan所在类的package进行扫描，默认情况下是不指定的，所以SpringBoot的启动类最好放在root package下。等价于<a href="context:component-scan" target="_blank" rel="noopener">context:component-scan</a>的xml配置文件中的配置项。</p><p><strong>因为一般这三个注解会一起使用，因此被包装成了现在的 @SpringBootApplication 注解</strong></p><h3 id="2-ServletComponentScan"><a href="#2-ServletComponentScan" class="headerlink" title="2. @ServletComponentScan"></a>2. @ServletComponentScan</h3><p>Servlet、Filter、Listener 可以直接通过 @WebServlet、@WebFilter、@WebListener 注解自动注册。这样通过注解servlet ，拦截器，监听器的功能而无需其他配置。</p><h3 id="3-MapperScan-spring-boot-添加mybatis相应组建依赖之后就可以使用该注解"><a href="#3-MapperScan-spring-boot-添加mybatis相应组建依赖之后就可以使用该注解" class="headerlink" title="3. @MapperScan:spring-boot 添加mybatis相应组建依赖之后就可以使用该注解"></a>3. @MapperScan:spring-boot 添加mybatis相应组建依赖之后就可以使用该注解</h3><p>支持mybatis组件的一个注解，通过此注解指定mybatis接口类的路径，即可完成对mybatis接口的扫描。</p><p>它和@mapper注解是一样的作用，不同的地方是扫描入口不一样：@mapper需要加在每一个mapper接口类上面。所以大多数情况下，都是在规划好工程目录之后，通过@MapperScan注解配置路径完成mapper接口的注入。</p><h2 id="Controller-相关注解"><a href="#Controller-相关注解" class="headerlink" title="Controller 相关注解"></a>Controller 相关注解</h2><h3 id="1-Controller-控制器，处理http请求"><a href="#1-Controller-控制器，处理http请求" class="headerlink" title="1. @Controller 控制器，处理http请求"></a>1. @Controller 控制器，处理http请求</h3><h3 id="2-RestController-复合注解"><a href="#2-RestController-复合注解" class="headerlink" title="2. @RestController 复合注解"></a>2. @RestController 复合注解</h3><p>@RestController源码</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span>ElementType<span class="token punctuation">.</span>TYPE<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>RUNTIME<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Documented</span>    <span class="token annotation punctuation">@Controller</span>    <span class="token annotation punctuation">@ResponseBody</span>    <span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">RestController</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">/**        * The value may indicate a suggestion for a logical component name,         * to be turned into a Spring bean in case of an autodetected component.         * @return the suggested component name, if any (or empty String otherwise)         * @since 4.0.1         */</span>        <span class="token annotation punctuation">@AliasFor</span><span class="token punctuation">(</span>annotation <span class="token operator">=</span> Controller<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>        String <span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">default</span> <span class="token string">""</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>@RestController注解相当于@ResponseBody + @Controller合在一起的作用。RestController使用的效果是将方法返回的对象直接在浏览器上展示成json格式。</p><h3 id="3-RequestBody"><a href="#3-RequestBody" class="headerlink" title="3. @RequestBody"></a>3. @RequestBody</h3><p>通过HttpMessageConverter读取Request Body并反序列化为Object（泛指）对象</p><h3 id="4-RequestMapping"><a href="#4-RequestMapping" class="headerlink" title="4. @RequestMapping"></a>4. @RequestMapping</h3><p>将 HTTP 请求映射到 MVC 和 REST 控制器的处理方法上</p><p>@GetMapping用于将HTTP get请求映射到特定处理程序的方法注解</p><p>注解简写：@RequestMapping(value = “/say”,method = RequestMethod.GET)等价于：@GetMapping(value = “/say”)</p><p>GetMapping源码等价于@RequestMapping(method = RequestMethod.GET) </p><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span>ElementType<span class="token punctuation">.</span>METHOD<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>RUNTIME<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Documented</span>    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span>method <span class="token operator">=</span> RequestMethod<span class="token punctuation">.</span>GET<span class="token punctuation">)</span>    <span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">GetMapping</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//...</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>PostMapping源码等价于@RequestMapping(method = RequestMethod.POST) </p><pre class="line-numbers language-java"><code class="language-java">    是<span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span>method <span class="token operator">=</span> RequestMethod<span class="token punctuation">.</span>GET<span class="token punctuation">)</span>的缩写    <span class="token annotation punctuation">@PostMapping</span>用于将HTTP post请求映射到特定处理程序的方法注解    <span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span>ElementType<span class="token punctuation">.</span>METHOD<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>RUNTIME<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Documented</span>    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span>method <span class="token operator">=</span> RequestMethod<span class="token punctuation">.</span>POST<span class="token punctuation">)</span>    <span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">PostMapping</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//...</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="取请求参数值"><a href="#取请求参数值" class="headerlink" title="取请求参数值"></a>取请求参数值</h2><h3 id="1-PathVariable-获取url中的数值"><a href="#1-PathVariable-获取url中的数值" class="headerlink" title="1. @PathVariable : 获取url中的数值"></a>1. @PathVariable : 获取url中的数值</h3><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Controller</span>    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span><span class="token string">"/Example"</span><span class="token punctuation">)</span>    <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HelloWorldController</span> <span class="token punctuation">{</span>        <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span><span class="token string">"/getExample/{id}"</span><span class="token punctuation">)</span>        <span class="token keyword">public</span> String <span class="token function">getUser</span><span class="token punctuation">(</span><span class="token annotation punctuation">@PathVariable</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>Integer id<span class="token punctuation">,</span> Model model<span class="token punctuation">)</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"id:"</span><span class="token operator">+</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token string">"user"</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>请求示例：<a href="http://localhost:8080/Example/getExample/123" target="_blank" rel="noopener">http://localhost:8080/Example/getExample/123</a></p><h3 id="2-RequestParam-获取请求参数的值"><a href="#2-RequestParam-获取请求参数的值" class="headerlink" title="2. @RequestParam : 获取请求参数的值"></a>2. @RequestParam : 获取请求参数的值</h3><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Controller</span>    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span><span class="token string">"/Example"</span><span class="token punctuation">)</span>    <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HelloWorldController</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span><span class="token string">"/getExample"</span><span class="token punctuation">)</span>    <span class="token keyword">public</span> String <span class="token function">getUser</span><span class="token punctuation">(</span><span class="token annotation punctuation">@RequestParam</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>Integer id<span class="token punctuation">,</span> Model model<span class="token punctuation">)</span> <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"id:"</span><span class="token operator">+</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token string">"user"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>请求示例：<a href="http://localhost:8080/Example/getExample?id=123" target="_blank" rel="noopener">http://localhost:8080/Example/getExample?id=123</a></p><h3 id="3-RequestHeader-把Request请求header部分的值绑定到方法的参数上"><a href="#3-RequestHeader-把Request请求header部分的值绑定到方法的参数上" class="headerlink" title="3. @RequestHeader 把Request请求header部分的值绑定到方法的参数上"></a>3. @RequestHeader 把Request请求header部分的值绑定到方法的参数上</h3><h3 id="4-CookieValue-把Request-header中关于cookie的值绑定到方法的参数上"><a href="#4-CookieValue-把Request-header中关于cookie的值绑定到方法的参数上" class="headerlink" title="4. @CookieValue 把Request header中关于cookie的值绑定到方法的参数上"></a>4. @CookieValue 把Request header中关于cookie的值绑定到方法的参数上</h3><h2 id="注入-bean-相关"><a href="#注入-bean-相关" class="headerlink" title="注入 bean 相关"></a>注入 bean 相关</h2><h3 id="1-Repository"><a href="#1-Repository" class="headerlink" title="1. @Repository"></a>1. @Repository</h3><p>DAO层注解，DAO层中接口继承 JpaRepository&lt;T,ID extends Serializable&gt;，需要在build.gradle中引入相关jpa的一个jar自动加载。</p><p>Repository注解源码</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span><span class="token punctuation">{</span>ElementType<span class="token punctuation">.</span>TYPE<span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>RUNTIME<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Documented</span>    <span class="token annotation punctuation">@Component</span>    <span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">Repository</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">/**         * The value may indicate a suggestion for a logical component name,         * to be turned into a Spring bean in case of an autodetected component.         * @return the suggested component name, if any (or empty String otherwise)         */</span>        <span class="token annotation punctuation">@AliasFor</span><span class="token punctuation">(</span>annotation <span class="token operator">=</span> Component<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>        String <span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">default</span> <span class="token string">""</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-Service"><a href="#2-Service" class="headerlink" title="2. @Service"></a>2. @Service</h3><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span><span class="token punctuation">{</span>ElementType<span class="token punctuation">.</span>TYPE<span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>RUNTIME<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Documented</span>    <span class="token annotation punctuation">@Component</span>    <span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">Service</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">/**         * The value may indicate a suggestion for a logical component name,         * to be turned into a Spring bean in case of an autodetected component.         * @return the suggested component name, if any (or empty String otherwise)         */</span>        <span class="token annotation punctuation">@AliasFor</span><span class="token punctuation">(</span>annotation <span class="token operator">=</span> Component<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>        String <span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">default</span> <span class="token string">""</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>@Service是@Component注解的一个特例，作用在类上</li><li>@Service注解作用域默认为单例</li><li>使用注解配置和类路径扫描时，被@Service注解标注的类会被Spring扫描并注册为Bean</li><li>@Service用于标注服务层组件,表示定义一个bean</li><li>@Service使用时没有传参数，Bean名称默认为当前类的类名，首字母小写</li><li>@Service(“serviceBeanId”)或@Service(value=”serviceBeanId”)使用时传参数，使用value作为Bean名字</li></ul><h3 id="3-Scope作用域注解"><a href="#3-Scope作用域注解" class="headerlink" title="3. @Scope作用域注解"></a>3. @Scope作用域注解</h3><p>@Scope作用在类上和方法上，用来配置 spring bean 的作用域，它标识 bean 的作用域</p><p>@Scope源码</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span><span class="token punctuation">{</span>ElementType<span class="token punctuation">.</span>TYPE<span class="token punctuation">,</span> ElementType<span class="token punctuation">.</span>METHOD<span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>RUNTIME<span class="token punctuation">)</span>    <span class="token annotation punctuation">@Documented</span>    <span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">Scope</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">/**         * Alias for {@link #scopeName}.         * @see #scopeName         */</span>        <span class="token annotation punctuation">@AliasFor</span><span class="token punctuation">(</span><span class="token string">"scopeName"</span><span class="token punctuation">)</span>        String <span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">default</span> <span class="token string">""</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@AliasFor</span><span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span>        String <span class="token function">scopeName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">default</span> <span class="token string">""</span><span class="token punctuation">;</span>        ScopedProxyMode <span class="token function">proxyMode</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">default</span> ScopedProxyMode<span class="token punctuation">.</span>DEFAULT<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>属性介绍<br>value<br>    singleton   表示该bean是单例的。(默认)<br>    prototype   表示该bean是多例的，即每次使用该bean时都会新建一个对象。<br>    request     在一次http请求中，一个bean对应一个实例。<br>    session     在一个httpSession中，一个bean对应一个实例。</p><p>proxyMode<br>    DEFAULT         不使用代理。(默认)<br>    NO              不使用代理，等价于DEFAULT。<br>    INTERFACES      使用基于接口的代理(jdk dynamic proxy)。<br>    TARGET_CLASS    使用基于类的代理(cglib)。</p><h3 id="4-Entity实体类注解"><a href="#4-Entity实体类注解" class="headerlink" title="4. @Entity实体类注解"></a>4. @Entity实体类注解</h3><ul><li>@Table(name =”数据库表名”)，这个注解也注释在实体类上，对应数据库中相应的表。</li><li>@Id、@Column注解用于标注实体类中的字段，pk字段标注为@Id，其余@Column。</li></ul><h3 id="5-Bean产生一个bean的方法"><a href="#5-Bean产生一个bean的方法" class="headerlink" title="5. @Bean产生一个bean的方法"></a>5. @Bean产生一个bean的方法</h3><p>@Bean明确地指示了一种方法，产生一个bean的方法，并且交给Spring容器管理。支持别名@Bean(“xx-name”)</p><h3 id="6-Autowired-自动导入"><a href="#6-Autowired-自动导入" class="headerlink" title="6. @Autowired 自动导入"></a>6. @Autowired 自动导入</h3><ul><li>@Autowired注解作用在构造函数、方法、方法参数、类字段以及注解上</li><li>@Autowired注解可以实现Bean的自动注入</li></ul><h3 id="7-Component"><a href="#7-Component" class="headerlink" title="7. @Component"></a>7. @Component</h3><p>虽然有了@Autowired,但是我们还是要写一堆bean的配置文件,相当麻烦,而@Component就是告诉spring,我是pojo类,把我注册到容器中吧,spring会自动提取相关信息。那么我们就不用写麻烦的xml配置文件了</p><h2 id="事务注解-Transactional"><a href="#事务注解-Transactional" class="headerlink" title="事务注解 @Transactional"></a>事务注解 @Transactional</h2><p>在Spring中，事务有两种实现方式，分别是编程式事务管理和声明式事务管理两种方式。</p><p>编程式事务管理<br>    编程式事务管理使用TransactionTemplate或者直接使用底层的PlatformTransactionManager。对于编程式事务管理，spring推荐使用TransactionTemplate。</p><p>声明式事务管理<br>    建立在AOP之上的。其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务，通过@Transactional就可以进行事务操作，更快捷而且简单。推荐使用</p><h2 id="全局异常处理"><a href="#全局异常处理" class="headerlink" title="全局异常处理"></a>全局异常处理</h2><p>@ControllerAdvice 统一处理异常</p><p>@ControllerAdvice 注解定义全局异常处理类</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@ControllerAdvice</span>    <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">GlobalExceptionHandler</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>@ExceptionHandler 注解声明异常处理方法</p><pre class="line-numbers language-java"><code class="language-java">    <span class="token annotation punctuation">@ControllerAdvice</span>    <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">GlobalExceptionHandler</span> <span class="token punctuation">{</span>        <span class="token annotation punctuation">@ExceptionHandler</span><span class="token punctuation">(</span>Exception<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>        <span class="token annotation punctuation">@ResponseBody</span>        String <span class="token function">handleException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token string">"Exception Deal!"</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客迁移尝试</title>
      <link href="2020/05/10/bo-ke-qian-yi-chang-shi/"/>
      <url>2020/05/10/bo-ke-qian-yi-chang-shi/</url>
      
        <content type="html"><![CDATA[<p>久违的github博客，博客迟迟没更新，没错这段时间要有（没）大（时）动（间）作（写）了。从前段时间的某一天，因为一些机缘巧合打算正式开始学 springboot 了，想到自己还没深入玩过服务器，于是下定决心用springboot搭一个博客挂到服务器上。</p><p>最终在著名学习网站——B 站上，找到了一个搭建博客的视频（没错是李仁密老师那个），然后一点点开始学习着搭建。同时也尝试着摸索 github 仓库的使用，在 github 上开了一个仓库，专门放博客源码（<a href="https://github.com/Swenchao/SpringBoot-blog）" target="_blank" rel="noopener">https://github.com/Swenchao/SpringBoot-blog）</a> 除此之外，还给大数据提高课的项目代码（目前只有爬虫部分——爬取链家二手房房源）开了一个仓库。</p><p>下面说正题了：</p><h1 id="搭了个新的博客"><a href="#搭了个新的博客" class="headerlink" title="搭了个新的博客"></a>搭了个新的博客</h1><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>由于代码放在了github上托管，自己对与这个的使用也不是很熟悉，因此在某一个过程中，以为自己提交了代码，直到最后发现没有提交，所以自己对李仁密老师源码做出的一些修改也丢失了，难受。又得重新进行修改，源码放在了仓库里，等有空再进行一些修改吧。</p><h2 id="需要改进的地方"><a href="#需要改进的地方" class="headerlink" title="需要改进的地方"></a>需要改进的地方</h2><ol><li>博客总是自动执行删除方法，至今未找到问题，索性直接把删除方法注释掉了</li><li>博客管理页面底部模板还有问题</li><li>markdown编辑器中添加本地图片有问题（网络图片没问题，因此打算发博客前先在csdn博客上放图片，然后这里引用，不知道可不可行）</li><li>关于我 界面太简单，还没来得及修改</li><li>域名还没有申请</li><li>一些静态页面显示还不是很满意</li><li>加密博客功能</li></ol><h2 id="新的博客地址"><a href="#新的博客地址" class="headerlink" title="新的博客地址"></a>新的博客地址</h2><p><a href="http://100.26.126.67:8080/" target="_blank" rel="noopener">http://100.26.126.67:8080/</a> 域名还没申请，将就看吧。</p><h1 id="一些事的说明"><a href="#一些事的说明" class="headerlink" title="一些事的说明"></a>一些事的说明</h1><h2 id="对于这个博客"><a href="#对于这个博客" class="headerlink" title="对于这个博客"></a>对于这个博客</h2><p>以后当然还是会尽量去更新的，毕竟这是自己当初一点点摸索出来的</p><h2 id="对于新的博客"><a href="#对于新的博客" class="headerlink" title="对于新的博客"></a>对于新的博客</h2><p>现在亚马逊免费的服务器上试运行一段时间，挑出毛病，再准备买服务器，进行搭建。目前是 jar 包部署，后期可能尝试下war包。</p><h1 id="最后还是写给屁屁"><a href="#最后还是写给屁屁" class="headerlink" title="最后还是写给屁屁"></a>最后还是写给屁屁</h1><p>我们一定会有一间，像霍比特人一样的小房子~</p><blockquote><p>一切顺利，有所收获~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>R-work1</title>
      <link href="2020/04/05/r-work1/"/>
      <url>2020/04/05/r-work1/</url>
      
        <content type="html"><![CDATA[<h1 id="R作业"><a href="#R作业" class="headerlink" title="R作业"></a>R作业</h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><ol><li>请使用R 软件进行以下编程要求：</li></ol><ul><li><p>请在R 中，执行以下代码（注意：请将studID 数字置换成你的学号）：<br>studID &lt;- 2017120102<br>set.seed(studID)<br>n &lt;- 10000<br>num &lt;- sample(n, 1:100000, replace=TRUE)</p></li><li><p>编写函数，将其命名为findPrime，可以用来查验以上num 物件中质数的数量，<br>并由大到小进行排序，返回前第17,153,2349 个质数（注意：函数要同时能返回<br>质数的数量和第17,153,2349 个质数质数的物件）。</p></li></ul><ol start="2"><li>请使用layout() 将三幅图画在同一个图面上，图面大小安排如下（注意：为了图<br> 面美观，请进行必要的par 参数调整，例如：在layout 指令后，键入以下代码<br> par(mar=c(3,3,1,1), mgp=c(2,0.2,0), tcl=-0.2)）</li></ol><p><img src="1586072291(1).png" alt></p><ul><li>第一幅图——条状图（hist()）。<br>数据：<br>y &lt;- rnorm(100, mean=2000, sd=50)</li></ul><ul><li>第二幅图——气泡图<br>数据：<br>SAT &lt;- data.frame(<br>”studentID” = c(”A”, ”B”, ”C”, ”D”, ”E”, ”F”, ”G”, ”H”),<br>”improvement” = c(100, 57, 80, 191, 5, 10, 25, 123),<br>”origGrades” = c(712, 1105, 690, 687, 725, 1200, 470, 752),<br>”weekInSch” = c(18, 4, 7, 27, 2, 25, 19, 10))</li></ul><ul><li>第三幅图——中国GDP 地图<br>数据：<br>set.seed(1)<br>GDP &lt;- rnorm(34, mean=5000, sd=50)</li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre class="line-numbers language-R"><code class="language-R"># 1studID <- 19202025set.seed(studID)n <- 10000num <- sample(size = n, 1:100000, replace=TRUE)findPrime<-function(num){  res <- numeric(length =  0)  #存放返回质数  index <- 1  #质数个数  for(i in num){    j <- 2    flag <- 0  #是否为质数标志    #  筛选质数    while (j*j <= i) {      if(i %% j == 0){        flag <- 1        break      }      j = j + 1    }    #  是质数存到有序数组中    if(flag == 0){      # browser()      i_temp <- index - 1      #  原本返回数组为空      if(i_temp == 0){        res[i_temp + 1] <- i        index <- index + 1      }      else{        # 不为空进行插入排序，找到合适位置        while(res[i_temp] > i & i_temp >= 1){          res[i_temp + 1] <- res[i_temp]          i_temp <- i_temp - 1          if(i_temp == 0)            break        }        res[i_temp+1] <- i        index = index + 1      }    }  }  l <- c(res, res[17], res[153])  return(l)}res <- findPrime(num)# 2layout(matrix(c(1,3,2,3),2,2))par(mar=c(3,3,1,1), mgp=c(1.5,-0.2,0), tcl=-0.2)y <- rnorm(100, mean=2000, sd=50)hist(y)SAT <- data.frame(  'studentID' = c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'),  'improvement' = c(100, 57, 80, 191, 5, 10, 25, 123),  'origGrades' = c(712, 1105, 690, 687, 725, 1200, 470, 752),  'weekInSch' = c(18, 4, 7, 27, 2, 25, 19, 10))#  当前默认处理数据attach(SAT)plot(x = seq(0,250,50), y = seq(200,1600,250), xlab = "improvement", ylab = "origGrades", type = "n")points(x = improvement,        y = origGrades,       cex = weekInSch/2,       col = studentID, pch = 16)text(improvement, origGrades, studentID)#  调整地图样式par(mar=c(1,3,3,1), mgp=c(1.5,-0.2,0), tcl=-0.2)library(raster)library(rgdal)library(maps)set.seed(1)GDP <- rnorm(34, mean = 5000, sd = 50)#  空间数据导入CN.map <- readOGR(dsn="d:/scwri/Desktop/R/bou2_4p.shp",layer="bou2_4p")projection(CN.map)<- CRS("+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs")chinamaps <- function (mapObj, a, grayscale=FALSE, lo, hi,...){  if (length(a)!=34){    stop ("wrong number of provinces")  }  #  颜色获取  getColor <- function(mapdata, provname, provcol, othercol){    FUN <- function(x, y){      ifelse(x %in% y, which(y==x), 0)    }    colIndex <- sapply(mapdata@data$NAME, FUN=FUN, provname)    cols <- c(othercol, provcol)[colIndex+1];    return(cols)  }  a.long <-  getColor(mapObj, levels(mapObj$NAME), a, "white")  b.long <- ifelse(is.na(a.long), "black", "gray85")  a.long <- ifelse(is.na(a.long), "white", a.long)  #  画图  plot(mapObj, col=a.long, border=b.long, lwd=0.5)}#  颜色主题cols1 <- terrain.colors(34, alpha = 1)chinamaps(mapObj=CN.map, a=rev(cols1)[order(GDP)])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>感觉r中while循环执行好像跟之前接触的有些不同</li></ol><pre class="line-numbers language-R"><code class="language-R"># 不为空进行插入排序，找到合适位置while(res[i_temp] > i & i_temp >= 1){    res[i_temp + 1] <- res[i_temp]    i_temp <- i_temp - 1    if(i_temp == 0)    break}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上代码中，如果  res[i_temp] &gt; i   条件中，res数组越界，则会直接报错而不会进行判断，此处纠结好久（其实以上代码就是一个插入排序）</p><ol start="2"><li>num &lt;- sample(size = n, 1:100000, replace=TRUE)</li></ol><p>sample随机抽样语句，size是样本大小，1:100000是范围，replace是是否有放回</p><ol start="3"><li>layout(matrix(c(1,3,2,3),2,2))</li></ol><p>画布布局。其中matrix中的c(1,3,2,3)表示画布分成四格，第一格是第一幅图；第二个格和第四格是第三幅图；第三格是第二幅图。下面是格子分布：</p><p><img src="1586075348(1).png" alt></p><ol start="4"><li>ifelse(x %in% y, which(y==x), 0)</li></ol><ul><li>%in%：判断前面一个向量内的元素是否在后面一个向量中，返回布尔值</li></ul><pre class="line-numbers language-R"><code class="language-R">a <- c(1,3,13,1443,43,43,4,34,3,4,3)b <- c(1,13,11,1313,434,1)a %in% b# 返回内容# [1]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>ifelse(a,b,c)：如果a成立，则b，否则c</p></li><li><p>颜色主题</p></li></ul><p>heat.colors() 从红色渐变到黄色再变到白色（以体现“高温”、“白热化”）。<br>terrain.colors() 从绿色渐变到黄色再到棕色最后到白色（这些颜色适合表示地理地形）。<br>cm.colors() 从青色渐变到白色再到粉红色。<br>topo.colors() 从蓝色渐变到青色再到黄色最后到棕色。</p>]]></content>
      
      
      <categories>
          
          <category> R </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用类</title>
      <link href="2020/03/31/chang-yong-lei/"/>
      <url>2020/03/31/chang-yong-lei/</url>
      
        <content type="html"><![CDATA[<h1 id="常用类"><a href="#常用类" class="headerlink" title="常用类"></a>常用类</h1><pre><code>1、包装类  √2、String类 ★3、StringBuffer和StringBuilder类  ★4、Math类5、System类6、Arrays类7、BigInteger类和BigDecimal类8、Date日期类、Calendar日历类以及新的日期</code></pre><h2 id="包装类"><a href="#包装类" class="headerlink" title="包装类"></a>包装类</h2><h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><p><strong>回顾</strong></p><pre><code>数据类型    基本数据类型    引用数据类型        数组        用class定义的        用interface定义的    **基本数据类型没有属性和方法**</code></pre><p><strong>包装类需求</strong></p><p>① 获取int类型的最大值<br>② 将某个整数转换成十六进制形式</p><p><strong>概念</strong><br>为八大基本数据类型对应的提供了引用数据类型，则这些引用数据类型称为包装类</p><pre><code>// i 与 i2是一样的int i=10;Integer i2=new Integer(i);</code></pre><h3 id="分类-★"><a href="#分类-★" class="headerlink" title="分类 ★"></a>分类 ★</h3><p>引用类型命名要求首字母大写，前六个为数值类，其父类为Number<br>    byte————————————Byte<br>    short———————————Short<br>    int—————————————Integer<br>    long————————————Long<br>    float—————————— Float<br>    double——————————Double<br>    char————————————Character<br>    boolean—————————Boolean</p><h3 id="基本类型和包装类型之间的转换（针对八大包装类型）-★"><a href="#基本类型和包装类型之间的转换（针对八大包装类型）-★" class="headerlink" title="基本类型和包装类型之间的转换（针对八大包装类型）  ★"></a>基本类型和包装类型之间的转换（针对八大包装类型）  ★</h3><p>jdk5.0之前：</p><pre><code>手动装箱（int 转 Integer）：    方式一：Integer i = new Intege r(10);    方式二：Integer i2 = Integer.valueOf(10);手动拆箱（Integer 转 int）：    int j = i.intValue();</code></pre><p>jdk5.0之后：</p><pre><code>自动装箱：Integer i = 10;自动拆箱：int j = i;</code></pre><h3 id="包装类型和String类型之间的转换"><a href="#包装类型和String类型之间的转换" class="headerlink" title="包装类型和String类型之间的转换"></a>包装类型和String类型之间的转换</h3><p><strong>包装类型——&gt;String类型</strong></p><pre><code>Integer i = 10;//方式1：String s1= i.toString();//方式2：String s2 = String.valueOf(i);//方式3：String s3 = i+&quot;&quot;;System.out.println(s3);</code></pre><p><strong>String——&gt;包装类</strong></p><pre><code>//方式1：Integer j = new Integer(s1);//方式2：Integer j2 = Integer.valueOf(s2);</code></pre><h3 id="基本类型和String类型之间的转换"><a href="#基本类型和String类型之间的转换" class="headerlink" title="基本类型和String类型之间的转换"></a>基本类型和String类型之间的转换</h3><p>基本类型——&gt;String类型</p><pre><code>int i = 10;//方式1：String s=i+&quot;&quot;;//方式2：String s2 = String.valueOf(i);</code></pre><p>String——&gt;基本类型（除了char类型）</p><pre><code>int j = Integer.parseInt(s);char c = s.charAt(0);</code></pre><h3 id="总结包装类中涉及到的API"><a href="#总结包装类中涉及到的API" class="headerlink" title="总结包装类中涉及到的API"></a>总结包装类中涉及到的API</h3><p>通用方法</p><pre><code>valueOf：将String类型或基本类型转换成对应的包装类型parseXX：将String类型转换成对应的基本类型xxValue：将包装类型转换成对应的基本类型</code></pre><p>Character类的特有方法：<br>    toUpperCase：转换为大写<br>    toLowerCase：…..小写<br>    isUpperCase：判断某个字符是否为大写<br>    isLowerCase：……………小写<br>    isDigit：判断某个字符是否为数字<br>    isLetter：判断某个字符是否为字母<br>    isWhiteSpace：判断某个字符是否为空格</p><p><strong>例1</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestInteger</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        Integer m <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//自动装箱，实则调用Integer类的valueOf（方法中-127 - 128之间的数是地址相等的，其他的则是new）</span>        Integer n <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>m <span class="token operator">==</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//        只要有new，地址肯定不同</span>        Integer x <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//new Integer(128);</span>        Integer y <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//new Integer(128)</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>x <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2</strong></p><pre class="line-numbers language-java"><code class="language-java">Integer i1 <span class="token operator">=</span> <span class="token number">127</span>；<span class="token keyword">int</span> i2 <span class="token operator">=</span> <span class="token number">127</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>i1 <span class="token operator">==</span> i2<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//true（双等里面有一个是int，则按int值是否相等来判断）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="String类"><a href="#String类" class="headerlink" title="String类"></a>String类</h2><h3 id="理解-1"><a href="#理解-1" class="headerlink" title="理解"></a>理解</h3><p>String类用于保存一组字符串序列的（”john”、”” 都相当于字符串常量对象）</p><h3 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h3><p>方式1：直接赋值</p><pre><code>String s  = &quot;hello&quot;;</code></pre><p>方式2：通过调用构造器</p><pre><code>String s = new String(&quot;hello&quot;);  //其中hello为任意字符串</code></pre><p><strong>两种创建对象方式的区别</strong></p><p>方式一：先去常量池查看是否有“hello”字符序列，如果没有，则创建，如果有直接引用该地址（s指向的是常量池的对象）</p><p>方式二：需要在堆中创建对象，该对象维护了一个value属性，value指向常量池的“hello”，如果常量池中没有“hello”，则创建，再指向；如果已经有了，则直接用value指向（s指向的是堆中的对象）</p><p><img src="%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200328173811.png" alt></p><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>String类保存的是字符串常量，里面一旦赋值，则值不能更改，只能更改地址</p><h3 id="常见方法"><a href="#常见方法" class="headerlink" title="常见方法"></a>常见方法</h3><pre><code>length 获取字符串字符个数charAt 获取指定索引处的字符（0 - length-1）toUpperCase 转大写toLowerCase 转小写indexOf 获取字符或字符串第一次出现的索引(0 - length-1)，如果找不到返回-1lastIndexOf 获取字符或字符串最后一次出现的索引，如果找不到返回-1startsWith 判断是否以xx开头endsWith 判断是否以XX结尾regionMatches 判断是否某范围内的子串一致    regionMatches(toffset, other, ooffset, len)    toffset：源字符串起始位置    other：另一个字符串    ooffset：目标字符串起始位置    len：目标字符串中要比较字符串长度contains 判断子串是否存在，返回true|falsecompareTo 比较两个字符串大小（&quot;a&quot;.compareTo(&quot;b&quot;)  //-1）equals/equalsIgnoreCase 判断字符串内容是否相等（是否忽略大小写）substring 截取指定索引之后（包含指定索引）的子串    &quot;abcdefg&quot;.substring(4) //efg    &quot;abcdefg&quot;.substring(0,3) //abcreplace/replaceAll 替换    s.replace(oldChar,newChar)trim 去前后空格split 根据指定字符拆分concat 拼接字符串toCharArray 转换成字符数组</code></pre><h2 id="StringBuffer类（StringBuilder与此类似，只不过加了个同步-synchronized关键字-）"><a href="#StringBuffer类（StringBuilder与此类似，只不过加了个同步-synchronized关键字-）" class="headerlink" title="StringBuffer类（StringBuilder与此类似，只不过加了个同步(synchronized关键字)）"></a>StringBuffer类（StringBuilder与此类似，只不过加了个同步(synchronized关键字)）</h2><h3 id="理解-2"><a href="#理解-2" class="headerlink" title="理解"></a>理解</h3><p>StringBuffer类相当于String类增强版，也是用于保存字符串的。也可以实现对字符串的更新、处理操作</p><h3 id="String类和StringBuffer的对比"><a href="#String类和StringBuffer的对比" class="headerlink" title="String类和StringBuffer的对比"></a>String类和StringBuffer的对比</h3><p>相同点：都用于保存字符串，都可以对字符串进行一些增删或其他处理的操作</p><p>不同点：<br>        String类用于保存字符串常量<br>        StringBuffer类用于保存字符串变量</p><h3 id="StringBuffer类创建对象"><a href="#StringBuffer类创建对象" class="headerlink" title="StringBuffer类创建对象"></a>StringBuffer类创建对象</h3><p><strong>只能通过调用构造器创建对象！</strong></p><pre><code>new StringBuffer（）; 构造一个初始容量为16的char数组new StringBuffer(string);构造一个初始容量为string.length+16的数组，并初始化值为stringnew StringBuffer(capacity)；构造一个初始容量为capacity的char数组</code></pre><h3 id="常见方法-1"><a href="#常见方法-1" class="headerlink" title="常见方法"></a>常见方法</h3><pre><code>append 在后面增加字符（可以为任意类型）delete 删除某区间字符    replace(start,end)    start：开始索引    end：结束索引+1replace 修改确定区间字符    replace(start,end,str)    start：开始索引    end：结束索引+1    str：替换字符串indexOf 查找某字符在字符串中位置insert 插入字符    insert(index,str)    index：插入位置索引    str：插入字符串reverse 反转字符length 字符串中实际字符个数</code></pre><h3 id="StringBuffer类和String类之间的转换"><a href="#StringBuffer类和String类之间的转换" class="headerlink" title="StringBuffer类和String类之间的转换"></a>StringBuffer类和String类之间的转换</h3><p><strong>StringBuffer——&gt;String</strong></p><pre class="line-numbers language-java"><code class="language-java">    StringBuffer buffer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuffer</span><span class="token punctuation">(</span><span class="token string">"john"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//方式一：</span>    String s1 <span class="token operator">=</span> buffer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//方式二：</span>    String s2 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>String——&gt;StringBuffer</strong></p><pre class="line-numbers language-java"><code class="language-java">    String s <span class="token operator">=</span> <span class="token string">"鸠摩智"</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//方式一：</span>    StringBuffer b1 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuffer</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//方式二：</span>    StringBuffer b2 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuffer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    b2<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="StringBuffer和StringBuilder的对比"><a href="#StringBuffer和StringBuilder的对比" class="headerlink" title="StringBuffer和StringBuilder的对比"></a>StringBuffer和StringBuilder的对比</h3><table><thead><tr><th align="left"></th><th align="left">共同点</th><th align="left">版本</th><th align="center">线程安全（同步）</th><th align="right">效率</th></tr></thead><tbody><tr><td align="left">StringBuffer</td><td align="left">保存可变字符串</td><td align="left">老</td><td align="center">安全</td><td align="right">较低</td></tr><tr><td align="left">StringBuilder</td><td align="left">保存可变字符串</td><td align="left">新</td><td align="center">不安全</td><td align="right">较高</td></tr></tbody></table><p><strong>效率：StringBuilder&gt;StringBuffer&gt;String</strong></p><h2 id="Math类"><a href="#Math类" class="headerlink" title="Math类"></a>Math类</h2><pre><code>sqrt 求开方pow 求幂    pow(a,b) a的b次方ceil 向上取整floor 向下取整round 四舍五入，返回整型（接用floor实现）abs 绝对值random 随机数（0-1之间小数）max 最大值min 最小值</code></pre><h2 id="Arrays"><a href="#Arrays" class="headerlink" title="Arrays"></a>Arrays</h2><p>操作数组的各种方法</p><h3 id="常见方法："><a href="#常见方法：" class="headerlink" title="常见方法："></a>常见方法：</h3><pre><code>sort(T[]) 对数组的元素进行自然排序，要求元素必须实现了Comparablesort(T[],Comparator) 对数组的元素进行定制排序，元素本身可以不实现Comparable(自己重写)    sort(a,new comparator(){        //重写方法        public int compare(Object o1,Object o2){            //用于比较的重写的方法        }    })binarySearch(T[],key) 对数组通过二分搜索法进行查找，如果key找到了，返回索引（排好序之后的），否则返回负数。（**要求：要查找的数组必须提前排好序！**）copyOf(T[],length) 复制数组的元素（底层实现为arrayCopy）    T[]：要复制的数组    length：新数组长度（若长，则用null补齐，若短则截取）equals(T1[],T3[]) 判断两个数组的内容是否相等（考虑顺序）fill(T[],key) 填充数组的各元素值为keytoString() 将数组各元素进行拼接，返回String</code></pre><h2 id="System类"><a href="#System类" class="headerlink" title="System类"></a>System类</h2><h3 id="常见方法-2"><a href="#常见方法-2" class="headerlink" title="常见方法"></a>常见方法</h3><pre><code>arrayCopy 复制数组元素，一般使用Arrays.copyOf代替    System.arraycopy(src, index1, dest, index2, length)        src：要复制数组        index1：要复制数组开始索引        dest：目标数组        index：目标数组开始索引        length：复制长度exit 退出程序currentTimeMillens 获取当前时间距离1970-1-1的毫秒数。gc 运行垃圾回收器</code></pre><h2 id="BigDecimal和BigInteger类"><a href="#BigDecimal和BigInteger类" class="headerlink" title="BigDecimal和BigInteger类"></a>BigDecimal和BigInteger类</h2><p>BigInteger 用于保存数值范围更大的整数</p><p>BigDecimal 用于保存精度更高的浮点型</p><h3 id="常见方法-3"><a href="#常见方法-3" class="headerlink" title="常见方法"></a>常见方法</h3><pre><code>add 加法substract减法multiply乘法divide除法，注意：可以添加参数2设置四舍五入模式</code></pre><h2 id="日期类"><a href="#日期类" class="headerlink" title="日期类"></a>日期类</h2><h3 id="第一代日期"><a href="#第一代日期" class="headerlink" title="第一代日期"></a>第一代日期</h3><p><strong>java.util.Date类     （获取日期）</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//创建Date对象</span><span class="token comment" spellcheck="true">//方式一：调用无参构造器(获取系统当前时间)</span>Date d1 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>d1<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//方式二：调用有参构造器(获取距离基准时间(1970.01.01.00.00)指定毫秒数的日期对象)  不建议使用！</span>Date d2 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token number">92345678</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>d2<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>java.text.SimpleDateFormat类 （格式化日期）</strong></p><p><strong>例1</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDateFormat1</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> ParseException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//创建日期对象</span>    Date d <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//根据默认格式创建SimpleDateFormat对象</span>    SimpleDateFormat sdf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SimpleDateFormat</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//---------------------方法----------------</span>    <span class="token comment" spellcheck="true">//格式日期：Date————>String </span>    String format <span class="token operator">=</span> sdf<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>format<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 20-3-31 下午12:30</span>    <span class="token comment" spellcheck="true">//解析日期：String————>Date</span>    String  s <span class="token operator">=</span> <span class="token string">"2020-03-31 下午3:22"</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//因为这里面格式可能不对，所以会加一个异常</span>    Date parse <span class="token operator">=</span> sdf<span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>parse<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// Tue Mar 31 15:22:00 CST 2020</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDateFormat2</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> ParseException<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//创建日期对象：Fri Mar 30 15:16:41 CST 2018</span>    Date d <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//根据指定格式创建SimpleDateFormat对象</span>    SimpleDateFormat sdf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SimpleDateFormat</span><span class="token punctuation">(</span><span class="token string">"yyyy年MM月dd日hh小时mm分钟ss秒"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//格式可进行更改（星期、上午下午都可以加）</span>    <span class="token comment" spellcheck="true">//---------------------方法----------------</span>    <span class="token comment" spellcheck="true">//格式日期：Date————>String </span>    String format <span class="token operator">=</span> sdf<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>format<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//2020年03月31日12小时42分钟20秒</span>    <span class="token comment" spellcheck="true">//解析日期：String————>Date</span>    String  s <span class="token operator">=</span> <span class="token string">"2008年12月30日 01小时26分钟36秒"</span><span class="token punctuation">;</span>    Date parse <span class="token operator">=</span> sdf<span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>parse<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//Tue Dec 30 01:26:36 CST 2008</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="第二代日期"><a href="#第二代日期" class="headerlink" title="第二代日期"></a>第二代日期</h3><p>java.util.Calendar类  为特定瞬间与指定年 月 日等日历字段之间的转换提供了一些方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//1.获取Calendar对象</span>Calendar c <span class="token operator">=</span> Calendar<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//2.通过调用方法获取各个日历字段</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"年："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>YEAR<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"月："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>MONTH<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"日："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>DAY_OF_MONTH<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"小时："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>HOUR<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"分钟："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>MINUTE<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"秒："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>SECOND<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期："</span><span class="token operator">+</span>c<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>DAY_OF_WEEK<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意结果，月会少1，星期是多1</strong></p><h3 id="第三代日期-jdk8新特性"><a href="#第三代日期-jdk8新特性" class="headerlink" title="第三代日期(jdk8新特性)"></a>第三代日期(jdk8新特性)</h3><p>LocalDate|LocalTime|LocalDateTime类：类似于Calendar</p><p>Instant：类似于Date</p><p>DateTimeFormatter：类似于SimpleDateFormat</p><p><strong>例1</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">test1</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//1.获取LocalDateTime对象</span>        LocalDateTime now <span class="token operator">=</span> LocalDateTime<span class="token punctuation">.</span><span class="token function">now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.获取各个日历字段</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getYear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getMonthValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//数字</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getMonth</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//英语</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getDayOfMonth</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getHour</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getMinute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getSecond</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>now<span class="token punctuation">.</span><span class="token function">getDayOfWeek</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">test2</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    LocalDateTime now  <span class="token operator">=</span> LocalDateTime<span class="token punctuation">.</span><span class="token function">now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//1.根据指定的格式创建DateTimeFormatter对象</span>    DateTimeFormatter dtf <span class="token operator">=</span> DateTimeFormatter<span class="token punctuation">.</span><span class="token function">ofPattern</span><span class="token punctuation">(</span><span class="token string">"yyyy年MM月dd日 HH小时mm分钟ss秒"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//H24小时制</span>    <span class="token comment" spellcheck="true">//2.--------------调用方法-----------------------</span>    <span class="token comment" spellcheck="true">//格式日期：Date——>String</span>    String format <span class="token operator">=</span> dtf<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>now<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>format<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//解析日期：String——>Date</span>    LocalDateTime parse <span class="token operator">=</span> LocalDateTime<span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span><span class="token string">"2020年03月31日 16小时02分钟06秒"</span><span class="token punctuation">,</span>dtf<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>parse<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例3</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testInstant</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//1.获取Instant对象</span>    Instant instant <span class="token operator">=</span> Instant<span class="token punctuation">.</span><span class="token function">now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//2.Instant和Date之间的转换</span>    <span class="token comment" spellcheck="true">//①Instant——>Date</span>    Date date <span class="token operator">=</span> Date<span class="token punctuation">.</span><span class="token function">from</span><span class="token punctuation">(</span>instant<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//②Date——>Instant</span>    Instant instant2 <span class="token operator">=</span> date<span class="token punctuation">.</span><span class="token function">toInstant</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>instant2<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>异常</title>
      <link href="2020/03/27/yi-chang/"/>
      <url>2020/03/27/yi-chang/</url>
      
        <content type="html"><![CDATA[<h2 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h2><pre><code>1、异常的概念2、异常体系图★3、常见的异常4、异常处理的概念5、异常处理的分类 ★6、自定义异常【了解】7、throw和throws的对比【面试题】</code></pre><h3 id="异常的概念"><a href="#异常的概念" class="headerlink" title="异常的概念"></a>异常的概念</h3><p><img src="1584971508(1).png" alt></p><p><img src="1584971604(1).png" alt></p><h3 id="异常的体系图"><a href="#异常的体系图" class="headerlink" title="异常的体系图"></a>异常的体系图</h3><p><img src="1584971338(1).png" alt></p><h3 id="常见的运行异常介绍"><a href="#常见的运行异常介绍" class="headerlink" title="常见的运行异常介绍"></a>常见的运行异常介绍</h3><pre><code>NullPointerException 空指针异常    当试图使用null对象的属性或方法时ArrayIndexOutOfBoundsException 数组下标越界异常    当试图使用数组的索引超过范围：0——length-1ClassCastException 类型转换异常    当试图将不是该类型的实例强转成该类型ArithmeticException 数学运算异常    除数为0时NumberFormatException 数字格式不正确    当试图将字符串转换成数值时，如果该字符串不是有效的数值格式</code></pre><h3 id="异常处理的概念"><a href="#异常处理的概念" class="headerlink" title="异常处理的概念"></a>异常处理的概念</h3><p>处理程序中发生的不正常现象，称为异常处理</p><h3 id="异常处理好处"><a href="#异常处理好处" class="headerlink" title="异常处理好处"></a>异常处理好处</h3><p>a、提高用户的体验性（可打印友好提示）<br>b、让正常的代码和容易出错的代码进行了分离，提高代码的语义性和维护性<br>c、让try catch块后面的语句继续执行</p><h3 id="异常处理的分类-★"><a href="#异常处理的分类-★" class="headerlink" title="异常处理的分类 ★"></a>异常处理的分类 ★</h3><h4 id="方式一：自己处理"><a href="#方式一：自己处理" class="headerlink" title="方式一：自己处理"></a>方式一：自己处理</h4><p><strong>语法</strong></p><pre><code>try{①//容易出现异常的代码②③}catch(异常类型A e){    //处理语句1 ④}catch(异常类型B e){    //处理语句1 ⑤}catch(异常类型C e){    //处理语句1 ⑥}finally{    //最后一定执行的语句 ⑦}</code></pre><p><strong>执行顺序</strong></p><p>如果 try 出现了异常，则 try 块中下面的语句将不再执行，而是执行 catch 块的语句，最后执行 finally 块的语句</p><p>如果 try 未出现异常，则 try 块中下面的语句需要执行，catch块的语句不再执行，最后执行 finally 块的语句</p><p><strong>注意事项</strong></p><ol><li>catch块可以省略</li><li>也可以多个，但如果catch块中有父类异常类型，必须放在最后！</li><li>finally块可以省略</li></ol><p><strong>例1</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Scanner<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestException4</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        Scanner input  <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Scanner</span><span class="token punctuation">(</span>System<span class="token punctuation">.</span>in<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//        try部分运行到错误处，将不会再往下执行</span>        <span class="token keyword">try</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//            其中有可能有多种错误，则后面可放多个 catch 块</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"请输入a:"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            String a <span class="token operator">=</span> input<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"请输入b:"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            String b<span class="token operator">=</span> input<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//判断两个字符串是否相等</span><span class="token comment" spellcheck="true">//            a=null;// 若将a赋成null，则不管是什么错误，下面只会报空指针错误，因为try下面部分都不会再执行</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"相等"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">//将字符串转换成int类型</span>            <span class="token keyword">int</span> num1 <span class="token operator">=</span> Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> num2 <span class="token operator">=</span> Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//数学运算</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"div="</span><span class="token operator">+</span>num1<span class="token operator">/</span>num2<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//容易出现异常</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"哈哈"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//          若某种错误忘记是哪一种，则直接用 Exception 父类，但这个catch块要放到最后</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span><span class="token punctuation">(</span>NumberFormatException e<span class="token punctuation">)</span><span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"数字格式不正确吧"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span><span class="token punctuation">(</span>ArithmeticException e<span class="token punctuation">)</span><span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"除数为0了吧！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span><span class="token punctuation">(</span>NullPointerException e<span class="token punctuation">)</span><span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"空指针了吧"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span><span class="token punctuation">(</span>Exception e<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//            catch块中有父类异常类型，必须放在最后</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"下标越界吧"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">finally</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//            最后一定要执行的语句</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"try catch块后面的语句"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestException1</span> <span class="token punctuation">{</span>    <span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">method</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> names <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>names<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"john"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>names<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">else</span><span class="token punctuation">{</span>                names<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"lucy"</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ArrayIndexOutOfBoundsException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// TODO Auto-generated catch block</span>            <span class="token keyword">return</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">NullPointerException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// TODO Auto-generated catch block</span>            <span class="token keyword">return</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">finally</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//            若此句不注释，则无论怎么执行都是只返回4，因为try catch无论怎样，最后总是执行finally块中的</span><span class="token comment" spellcheck="true">//            return 4;</span>            <span class="token comment" spellcheck="true">//此时返回3并且输出222222</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"222222"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">//此句不会再执行</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"333333"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//        Scanner input = new Scanner(System.in);</span><span class="token comment" spellcheck="true">//        int  i=input.nextInt();</span><span class="token comment" spellcheck="true">//        System.out.println(i);</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token function">method</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>总结</strong></p><ol><li><p>并不是try块中的语句越多越好，因为会影响效率（try要检测错误类型，所以会影响效率）</p></li><li><p>尽量使用多个catch代替多个try catch（将出错部分都放入try中，然后多个catch处理）</p></li></ol><h4 id="方式二：抛给他人处理"><a href="#方式二：抛给他人处理" class="headerlink" title="方式二：抛给他人处理"></a>方式二：抛给他人处理</h4><p><strong>语法</strong></p><pre><code>修饰符 返回类型 方法名(参数列表) throws 异常类型A{    //容易出现异常的代码}异常类型A为 方法中出现的异常类型或其父类类型</code></pre><p><strong>执行机制</strong></p><ol><li><p>将异常抛给调用方，调用方可以继续处理，如果继续往上抛，可以一直抛到jvm，jvm则最后处理方式：打印错误堆栈日志！</p></li><li><p>如果对异常不进行任何处理，则默认采取的方式为抛出的方式</p></li><li><p>子类方法抛出的异常要么相同，要么为其子类类型</p></li></ol><p><strong>例1</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestException5</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args <span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token function">method1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">method1</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token function">method2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">method2</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token function">method3</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">method3</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token function">method4</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">method4</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception<span class="token punctuation">{</span>        <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//下标越界异常</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Son</span> <span class="token keyword">extends</span> <span class="token class-name">Father</span><span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">method</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> NullPointerException <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">method</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">class</span> <span class="token class-name">Father</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">method</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> RuntimeException<span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="生成异常对象"><a href="#生成异常对象" class="headerlink" title="生成异常对象"></a>生成异常对象</h3><ol><li>系统自动生成，只能针对系统定义好的异常类型</li><li>手动抛出，可以针对系统定义好的异常类型或自定义的异常类型<br>throw new 异常类型();</li></ol><p><strong>例</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestException7</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        Scanner input  <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Scanner</span><span class="token punctuation">(</span>System<span class="token punctuation">.</span>in<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"年龄："</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> age <span class="token operator">=</span> input<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>age<span class="token operator">></span><span class="token number">120</span> <span class="token operator">||</span> age<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">//生成一个异常对象</span><span class="token comment" spellcheck="true">//            AgeIllegalException ae = new AgeIllegalException("年龄不合法！");</span><span class="token comment" spellcheck="true">//            throw ae;</span><span class="token comment" spellcheck="true">//            throw new AgeIllegalException("年龄不合法！");  //与上面两句效果相同</span>            <span class="token keyword">try</span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">//下面两句效果一样，因此自定义异常可有可无</span>                <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span><span class="token string">"年龄不合法！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//                throw new AgeIllegalException("年龄不合法！");</span>            <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//                e.printStackTrace();</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"出错了，信息："</span><span class="token operator">+</span>e<span class="token punctuation">.</span><span class="token function">getMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"年龄是："</span><span class="token operator">+</span>age<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">class</span> <span class="token class-name">AgeIllegalException</span> <span class="token keyword">extends</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">AgeIllegalException</span><span class="token punctuation">(</span>String msg<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span>msg<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token function">AgeIllegalException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h3><ol><li>生成异常方式和区别</li><li>throw 和 throws对比</li></ol><table><thead><tr><th></th><th>意思</th><th>后面跟的东西</th><th>放的位置</th></tr></thead><tbody><tr><td>throw</td><td>手动生成异常</td><td>异常对象</td><td>方法体中，一般搭配if使用</td></tr><tr><td>throws</td><td>异常生成的另一种方式</td><td>异常类型</td><td>方法声明处</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java面向对象（下）</title>
      <link href="2020/03/22/java-mian-xiang-dui-xiang-xia/"/>
      <url>2020/03/22/java-mian-xiang-dui-xiang-xia/</url>
      
        <content type="html"><![CDATA[<p>忘了从某天决定学学java，刚开始笔记都记在了本子上，实在不想再用电子版重新写了，就写从面向对象（下）开始写吧.<br>陆陆续续终于把面向对象下补充完了，后续接着更新吧~</p><h1 id="面向对象（下"><a href="#面向对象（下" class="headerlink" title="面向对象（下)"></a>面向对象（下)</h1><pre><code>1、内部类2、枚举3、注解</code></pre><h2 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h2><h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><p>一个类中又完整的嵌套了另一个类结构，被嵌套的类称为内部类。外面的类称为外部类,和内部类无关的外部类称为外部其他类。</p><p><code>class A{   //外部类    String name;    public void method(){        class C{   //内部类（也可放在方法里面）            String anme;        }        for(){            class D{   //内部类(也可放在循环中)                String anme;            }        }    }    class B{   //内部类        String anme;    }}class Other{   //外部其他类}</code></p><h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><p>可以直接访问外部类中的所有成员，包含私有的！！！</p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>定义在成员位置上:（类B）<br>    成员内部类（没有使用static修饰) 相对使用较多<br>    静态内部类（使用static修饰）</p><p>定义在局部位置上：（类 C D）<br>    局部内部类（有类名）<br>    匿名内部类(没有类名) 相对使用较多</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><h4 id="成员内部类"><a href="#成员内部类" class="headerlink" title="成员内部类"></a>成员内部类</h4><p>① 类中可以有五大普通成员，不能有静态成员！（因为静态成员随着外部类的加载而加载，但成员内部类随着外部类的对象创建而加载）</p><p>② 可以添加任意访问修饰符，遵循访问权限限定！</p><p><strong>例：</strong></p><p><code>class Outer{    protected class Inner{//        public Inner(){//            //        }//        static{//            //        }//        class InnerInner{//            class InnerInner2{//                //            }//            //        }    }    private String name = &quot;张翠山&quot;;    public void method(){    }}</code></p><p>③ 互访原则：</p><blockquote><p>内部类———&gt;外部类<br>   直接访问，包含任意成员（私有的也可以）<br>外部类———&gt;内部类<br>   不能直接访问，需要通过创建内部类对象再去访问，包含任意成员（私有的也可以）<br><strong>语法：</strong>new Inner().方法();<br>外部其他类———&gt;内部类<br>不能直接访问，需要通过创建内部类对象再去访问，只能访问在权限范围内的成员（私有的不可以！！！）<br><strong>语法：</strong>new Outer().new Inner().方法();</p></blockquote><p><strong>例：</strong></p><p><code>public class TestInner1 {    public static void main(String[] args) {        Outer o = new Outer();        o.new Inner().show();  //外部其他类访问内部类，先创建对象再调成员//               o.new Inner().color=&quot;&quot;;  //私有的不可访问    }}class Outer{    protected class Inner{        private String color;        private String name=&quot;张无忌&quot;;        public  void show(){            System.out.println(Outer.this.name);            method();  //内部类访问外部类，可直接访问        }    }    private String name = &quot;张翠山&quot;;    public void method(){        new Inner().show();  //外部类访问内部类成员方式        new Inner().color=&quot;&quot;;  //外部访问内部，私有成员也可    }}</code></p><p>④ 当外部类和内部类成员重名时，默认访问的是内部类的成员，遵循就近原则。如果非要访问外部类的成员，可以通过外部类名.this.成员的方式！</p><p><strong>例：</strong></p><p><code>public class TestInner1 {    public static void main(String[] args) {    }}class Outer{    protected class Inner{        private String color;        private String name=&quot;张无忌&quot;;        public  void show(){            System.out.println(Outer.this.name);  //张翠山            System.out.println(name);  //张无忌//            System.out.println(TestInner1.this.color);  //报错        }    }    private String name = &quot;张翠山&quot;;    public void method(){        new Inner().show();  //外部类访问内部类成员方式        new Inner().color=&quot;&quot;;  //外部访问内部，私有成员也可    }}</code></p><h4 id="静态内部类"><a href="#静态内部类" class="headerlink" title="静态内部类"></a>静态内部类</h4><p>① 类中可以有任意五大成员，包含普通和静态</p><p>② 可以添加任意访问修饰符，遵循访问权限限定！</p><p><strong>例：</strong></p><p><code>class Outer2{    private static String name=&quot;段正淳&quot;;    //静态内部类    public static class Inner2{        static int age;        public void show(){            System.out.println(Outer2.name);        }        static{        }        public Inner2(){        }        static class InnerInner{        }    }    //外部类的方法    public void method(){        new Inner2().show();        new Inner2().age=12;    }}</code></p><p>③ 互访原则：</p><blockquote><p>内部类———&gt;外部类<br>   可以直接访问外部类的静态成员，包含私有的，但不能直接访问外部类的普通成员（遵循静态成员的特点）<br>外部类———&gt;内部类<br>   不能直接访问，必须通过创建内部类对象去访问，包含私有的！<br>   <strong>语法：</strong>new 内部类对象().方法();<br>外部其他类——&gt;内部类<br>   不能直接访问，必须通过创建内部类对象去访问，必须遵守访问权限限定，不包含私有的！<br>   <strong>语法：</strong>new 外部类.内部类().方法();</p></blockquote><p><strong>例：</strong></p><p><code>public class TestInner2 {    public static void main(String[] args) {        new Outer2.Inner2().show();  //其他外部类访问静态内部类，类是静态的，因此不需要创建对象    }}class Outer2{    private static String name=&quot;段正淳&quot;;    private String name1;    //静态内部类    public static class Inner2{        String name = &quot;段誉&quot;;        private int age;        public void show(){//            System.out.println(Outer2.name1);  //内部类访问外部类，报错            System.out.println(Outer2.name);  //内部类访问外部类，不能访问普通成员            System.out.println(name);  //内部类访问外部类，不能访问普通成员        }     }    //外部类的方法    public void method(){        new Inner2().show();  //外部类访问内部类        new Inner2().age=12;    }}</code></p><p>④ 当外部类和内部类成员重名时，默认访问内部类的成员，遵循就近原则，如果非要访问外部类的成员,可以通过外部类名.成员 的方式！</p><p><strong>例：</strong></p><p><code>class Outer2{    private static String name=&quot;段正淳&quot;;    //静态内部类    public static class Inner2{        String name = &quot;段誉&quot;;        public void show(){            System.out.println(Outer2.name);  //段正淳（name是静态的，因此类可直接调）            System.out.println(name);  //段誉（内部类成员）        }     }}</code> </p><h4 id="局部内部类"><a href="#局部内部类" class="headerlink" title="局部内部类"></a>局部内部类</h4><p>① 类中可以有五大成员,但不能有静态成员（和类的加载顺序有关）</p><p>② 不能有访问修饰符和static修饰符；作用域：仅仅是定义它的方法或代码块中，而且遵循前向引用（先声明再使用）</p><p><strong>例：</strong></p><p><code>class Outer3{    private String name;    public Object method(){//        Inner3 i = new Inner3();  //会报错，因为在此之前并没有inner3         class Inner3{            private String color;            public void show(){                System.out.println(name);            }        }         Inner3 i = new Inner3();  //前向引用    }}</code></p><p>③ 互访原则</p><blockquote><p>内部类————&gt;外部类<br>直接访问，包含私有的<br>外部类————&gt;内部类<br>只能在作用域范围内，通过创建对象并访问(包含私有的！)<br><strong>语法：</strong>new Inner().方法();</p></blockquote><p><strong>补充：</strong><br>    局部内部类可以访问外部类的局部变量，但只能访问，不能更新！（只能访问外部类的final修饰的局部变量！）</p><pre><code>原因：局部内部类的生命周期&gt;局部变量生命周期，所以不能直接访问一个可能已经消亡的变量。于是将局部变量复制了一个拷贝让局部内部类使用，但不能更新，因为如果更新，会导致两个变量的值不一致！（见下面例2解释）jdk7:要求局部内部类中访问的局部变量必须显式的声明final修饰符jdk8:局部内部类中访问的局部变量不用显式的声明final修饰符</code></pre><p><strong>例1：</strong></p><p><code>class Outer3{    private String name;    public void print(){//        new Inner3().show();  //外部类访问内部类，报错，无法访问    }    public Object method(){        int age =99;  //外部类局部变量        final int ageTemp = 100;         class Inner3{            private String color;            public void show(){//                System.out.println(name);  //访问外部类成员可以//                name=&quot;john&quot;;  //修改也可以                System.out.println(age);  //访问外部类局部变量可以//                age++;  //修改外部类局部变量报错                ageTemp++;  //不会报错（只能访问final修饰的）            }        }         Inner3 i = new Inner3();         i.show();  //外部类访问内部类    }}</code></p><p><strong>例2：</strong></p><p><code>class Outer3{    private String name;    public void print(){        Object x = method();  //接下来对象x可能会有操作    }    public Object method(){        int age =99;  //外部类局部变量         class Inner3{            private String color;            public void show(){                System.out.println(age);  //访问外部类局部变量可以//                age++;  //修改外部类局部变量报错            }        }         Inner3 i = new Inner3();         return i;    }}</code></p><p><strong>解释：</strong>从上面代码可知，age是method()方法中的局部变量，因此在method() 方法执行完消亡的时候，age也会随着消亡，但是Inner3却在方法结束的时候，作为参数传回了print方法，因此此时并没有消亡，甚至还会有下一步操作，所以生命周期不同。</p><h4 id="匿名内部类"><a href="#匿名内部类" class="headerlink" title="匿名内部类"></a>匿名内部类</h4><p><strong>语法</strong></p><pre><code>new 类名或接口名(参数){    //类体};</code></pre><p>因为其为匿名类，因此并没有名字，所以直接new。其中，类名或接口名是其依赖的父类或接口</p><p><strong>功能</strong></p><p>创建了一个匿名内部类&amp;创建了一个该类对象</p><pre><code>new  A(){    //类体};</code></pre><p>创建A的子类&amp;创建A的子类对象</p><pre><code>new A();</code></pre><p>创建A本类的对象</p><p><strong>例：</strong></p><p><code>class Outer4{    private String name;    public void method(){        //定义匿名内部类        new Fly(){            @Override            public void fly() {                // TODO Auto-generated method stub            }        };    }}interface Fly{    void fly();}</code></p><p><strong>特点</strong></p><p>① 类中可以有除了构造器之外的其他成员（属性、方法、初始化块、内部类），不可以有静态成员！</p><p>② 不能添加访问修饰符和static；作用域：仅仅在定义它的方法或代码块中使用，并且遵循前向引用的特点！</p><p><strong>例：</strong></p><p><code>class Outer4{    private String name;    public void method(){        int i=999;        //定义匿名内部类        new Fly(){            class Inner{}            String color;            public void show(){            }            {            }            @Override            public void fly() {                // TODO Auto-generated method stub            }        };        //使用1        Fly a = new Fly(){            @Override            public void fly() {                // TODO Auto-generated method stub            }        };        a.fly();        //使用2        new Fly(){            @Override            public void fly() {                // TODO Auto-generated method stub            }        }.fly();    }}interface Fly{    void fly();}</code></p><p>③ 互访原则：</p><blockquote><p>内部类———&gt;外部类的成员<br>直接访问，包含私有的成员<br>外部类———&gt;内部类的成员<br>只能在作用域内，通过匿名内部类的对象去访问，包含私有的成员<br><strong>语法：</strong>父类或接口名  引用名 = 匿名内部类对象;<br>引用名.方法();</p></blockquote><p><strong>补充</strong><br>    匿名内部类可以访问外部类的局部变量，但只能读取，不能更新！（只能访问外部类的final修饰的局部变量！）<br>    原因：同上局部内部类<br>    jdk7:要求局部内部类中访问的局部变量必须显式的声明final修饰符<br>    jdk8:局部内部类中访问的局部变量不用显式的声明final修饰符</p><p>④ 应用场景：当做接口的实例作为实参传递给方法！</p><p><strong>例：</strong></p><p><code>public class TestInner4 {    public static void main(String[] args) {//        method(new Fly());  //接口不可直接这么掉//        method(new MyClass());//方式一：传统的方式（先声明一个类，然后传参）        //匿名内部类        method(new Fly(){            @Override            public void fly() {                System.out.println(&quot;我要飞啊飞&quot;);            }        });        //代表示例1：        TreeSet set = new TreeSet(new Comparator(){            @Override            public int compare(Object o1, Object o2) {                // TODO Auto-generated method stub                return 0;            }        });        //代表示例2：        Thread t= new Thread(new Runnable(){            @Override            public void run() {                // TODO Auto-generated method stub            }        });    }    public static void method(Fly a){        a.fly();    }}interface Fly{    void fly();}</code></p><h2 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h2><h3 id="枚举的理解"><a href="#枚举的理解" class="headerlink" title="枚举的理解"></a>枚举的理解</h3><p>枚举其实就是一个类，枚举类的实例是一组限定的对象 </p><h3 id="传统的方式创建枚举（单例类）-【了解】"><a href="#传统的方式创建枚举（单例类）-【了解】" class="headerlink" title="传统的方式创建枚举（单例类） 【了解】"></a>传统的方式创建枚举（单例类） 【了解】</h3><p>对比</p><p>单例类</p><blockquote><p>1、构造器私有化<br>2、本类内部创建对象<br>3、通过public static方法，对外暴露该对象</p></blockquote><p>枚举类</p><blockquote><p>1、构造器私有化<br>2、本类内部创建一组对象，添加public static修饰符，直接暴露对象（其实就是单例类中后两步的合并，若不合并，则枚举类中有几种就会有几个public static方法，比较繁琐）</p></blockquote><p><strong>例1：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestEnum1</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//引用枚举类的对象</span><span class="token comment" spellcheck="true">//        Gender g = new Gender();//错误</span>        Gender g1 <span class="token operator">=</span> Gender<span class="token punctuation">.</span>BOY<span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>g1<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//如果没有重写toString方法，则显示的是地址</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">class</span> <span class="token class-name">Gender</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//1、构造器私有化    </span>    <span class="token keyword">private</span> <span class="token function">Gender</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//2.本类内部创建一组对象，添加public static修饰符，直接暴露对象（因为boy和girl不会更改，所以加了final修饰符）</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Gender BOY <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Gender</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Gender GIRL <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Gender</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">"这是一个性别"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestEnum1</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//引用枚举类的对象</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>Season<span class="token punctuation">.</span>SPRING<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>Season<span class="token punctuation">.</span>SUMMER<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">//简单示例2：提供有参构造</span><span class="token keyword">class</span> <span class="token class-name">Season</span><span class="token punctuation">{</span>    <span class="token keyword">private</span> String name<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//季节名称</span>    <span class="token keyword">private</span> String description<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//季节描述</span>    <span class="token comment" spellcheck="true">//2.本类内部创建一组对象，添加public static修饰符，直接暴露对象</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Season SPRING <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Season</span><span class="token punctuation">(</span><span class="token string">"春天"</span><span class="token punctuation">,</span><span class="token string">"春风又绿江大南"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Season SUMMER <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Season</span><span class="token punctuation">(</span><span class="token string">"夏天"</span><span class="token punctuation">,</span><span class="token string">"接天莲叶无穷碧"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Season AUTUMN <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Season</span><span class="token punctuation">(</span><span class="token string">"秋天"</span><span class="token punctuation">,</span><span class="token string">"霜叶红于二月花"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Season WINTER <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Season</span><span class="token punctuation">(</span><span class="token string">"冬天"</span><span class="token punctuation">,</span><span class="token string">"千树万树梨花开"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">private</span> <span class="token function">Season</span><span class="token punctuation">(</span>String name<span class="token punctuation">,</span> String description<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>description <span class="token operator">=</span> description<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getDescription</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> description<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">"Season [name="</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">", description="</span> <span class="token operator">+</span> description <span class="token operator">+</span> <span class="token string">"]"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用enum关键字定义枚举（jdk5-0引入）【掌握】"><a href="#使用enum关键字定义枚举（jdk5-0引入）【掌握】" class="headerlink" title="使用enum关键字定义枚举（jdk5.0引入）【掌握】"></a>使用enum关键字定义枚举（jdk5.0引入）【掌握】</h3><p><strong>例1（Gender类改写）：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//class换成enum</span><span class="token keyword">enum</span> Gender<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//匿名类对象必须放在枚举类第一行，另外匿名类每次都是public static final 的因此修饰符也可去掉；另外枚举类的类型当然都是一样的，所以gender可省略；默认都是无参构造，因此可省略构造方法，所以new Gender()可省略</span>    BOY<span class="token punctuation">,</span>GIRL<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/*    //1、构造器私有化        private Gender(){}    //2.本类内部创建一组对象，添加public static修饰符，直接暴露对象（因为boy和girl不会更改，所以加了final修饰符）    public static final Gender BOY = new Gender();    public static final Gender GIRL = new Gender();    */</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">"这是一个性别"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例2（使用）：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestEnum2</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//引用枚举类的对象</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>Gender2<span class="token punctuation">.</span>GIRL<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//默认调用toString()方法，此时此方法已经在enum类中进行了改写，返回的是匿名类对象名字（GIRL）</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>例3（Season类改写）：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">enum</span> Season2<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//2.本类内部创建一组对象，添加public static修饰符，直接暴露对象</span>    <span class="token comment" spellcheck="true">//有参构造</span>    <span class="token function">SPRING</span><span class="token punctuation">(</span><span class="token string">"春天"</span><span class="token punctuation">,</span><span class="token string">"春风又绿江大南"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">SUMMER</span> <span class="token punctuation">(</span><span class="token string">"夏天"</span><span class="token punctuation">,</span><span class="token string">"接天莲叶无穷碧"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">AUTUMN</span> <span class="token punctuation">(</span><span class="token string">"秋天"</span><span class="token punctuation">,</span><span class="token string">"霜叶红于二月花"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">WINTER</span><span class="token punctuation">(</span><span class="token string">"冬天"</span><span class="token punctuation">,</span><span class="token string">"千树万树梨花开"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> String name<span class="token punctuation">;</span>    <span class="token keyword">private</span> String description<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//1、构造器私有化    </span>    <span class="token keyword">private</span> <span class="token function">Season2</span><span class="token punctuation">(</span>String name<span class="token punctuation">,</span> String description<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>description <span class="token operator">=</span> description<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">getDescription</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> description<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>特点：</p><blockquote><p>1、使用enum关键字代替class关键字</p><p>2、对象（常量）的创建必须放在枚举类中的第一句<br><strong>语法：</strong> 对象名(实参列表),对象名(实参列表);</p><p>3、如果是无参构造，则无参构造的定义和实参列表都可以省略</p></blockquote><h3 id="介绍枚举类的常见方法【了解】"><a href="#介绍枚举类的常见方法【了解】" class="headerlink" title="介绍枚举类的常见方法【了解】"></a>介绍枚举类的常见方法【了解】</h3><p><strong>toString：</strong>Enum类已经重写过了，返回的是当前对象的常量名。自定义的枚举类可以继续重写该方法</p><p><strong>name：</strong>Enum类中的name方法返回的是当前对象的常量名（同toString），但自定义的枚举类不可以继续重写该方法</p><p><strong>values：</strong>一个静态方法，用于返回指定的枚举类中的所有枚举常量</p><p><strong>valueOf：</strong>一个静态方法，将一个有效的字符串转换成枚举对象</p><p><strong>例：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestEnum3</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//        System.out.println(Color2.RED.toString());</span><span class="token comment" spellcheck="true">//        System.out.println(Color2.RED.name());</span>        <span class="token comment" spellcheck="true">//返回Color2中所有的枚举常量</span>        Color2<span class="token punctuation">[</span><span class="token punctuation">]</span> values <span class="token operator">=</span> Color2<span class="token punctuation">.</span><span class="token function">values</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//输出所有枚举常量</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>values<span class="token punctuation">.</span>length<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//            System.out.println(values[i].name());</span><span class="token comment" spellcheck="true">//        }</span>        <span class="token comment" spellcheck="true">//将字符串转换成枚举对象（RED变量必须是枚举类存在的）</span>        Color2 c <span class="token operator">=</span> Color2<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span><span class="token string">"RED"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">enum</span> Color2<span class="token punctuation">{</span>    <span class="token function">RED</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">BLUE</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">BLACK</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">YELLOW</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">GREEN</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> redValue<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getRedValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> redValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getGreenValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> greenValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getBlueValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> blueValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> greenValue<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> blueValue<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token function">Color2</span><span class="token punctuation">(</span><span class="token keyword">int</span> redValue<span class="token punctuation">,</span> <span class="token keyword">int</span> greenValue<span class="token punctuation">,</span> <span class="token keyword">int</span> blueValue<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>redValue <span class="token operator">=</span> redValue<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>greenValue <span class="token operator">=</span> greenValue<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>blueValue <span class="token operator">=</span> blueValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token comment" spellcheck="true">//    public String toString(){</span><span class="token comment" spellcheck="true">//        return redValue+"\t"+greenValue+"\t"+blueValue;</span><span class="token comment" spellcheck="true">//    }</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>练习</strong></p><p>声明Week枚举类，其中包含星期一至星期日的定义；<br>在TestWeek类中声明方法中printWeek(Week week)，根据参数值打印相应的中文星期字符串。<br>在main方法中接受一个命令行参数，代表星期一至星期日，打印该值对应的枚举值，然后以此枚举值调用printWeek方法，输出中文星期。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestEnum2</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//将传入的参数转换成枚举类型</span>        String s <span class="token operator">=</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        Week week <span class="token operator">=</span> Week<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">printWeek</span><span class="token punctuation">(</span>week<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">printWeek</span><span class="token punctuation">(</span>Week week<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">switch</span><span class="token punctuation">(</span>week<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token comment" spellcheck="true">//switch中判断的变量的类型：int、char、byte、short、String、枚举</span>        <span class="token keyword">case</span> MONDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期一"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">case</span> TUESDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期二"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">case</span> WEDNESDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期三"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">case</span> THURSDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期四"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">case</span> FRIDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期五"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">case</span> SATURDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期六"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">case</span> SUNDAY<span class="token operator">:</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"星期日"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">enum</span> Week<span class="token punctuation">{</span>    <span class="token function">MONDAY</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">TUESDAY</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">WEDNESDAY</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">THURSDAY</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">FRIDAY</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">SATURDAY</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token function">SUNDAY</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> value<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token function">Week</span><span class="token punctuation">(</span><span class="token keyword">int</span> value<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>value <span class="token operator">=</span> value<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> value<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="枚举类如何实现接口【掌握】"><a href="#枚举类如何实现接口【掌握】" class="headerlink" title="枚举类如何实现接口【掌握】"></a>枚举类如何实现接口【掌握】</h3><p>特点：</p><p>1.和普通类实现接口一样，只是允许枚举常量也有自己对抽象方法的特有实现！</p><p><strong>语法</strong></p><pre><code>enum A implements 接口1，接口2{    常量1(参数){    //特有抽象方法的实现    },    常量2(参数){    //抽象方法的实现    }    //类对抽象方法的实现}</code></pre><p><strong>例：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestEnum4</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        Show s <span class="token operator">=</span> Color4<span class="token punctuation">.</span>RED<span class="token punctuation">;</span>        s<span class="token punctuation">.</span><span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//调用自己特有重新</span>        Color4<span class="token punctuation">.</span>BLACK<span class="token punctuation">.</span><span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//调用枚举类中重写</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">interface</span> <span class="token class-name">Fly</span><span class="token punctuation">{</span>    <span class="token keyword">void</span> <span class="token function">fly</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">interface</span> <span class="token class-name">Show</span><span class="token punctuation">{</span>    <span class="token keyword">void</span> <span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">//可多实现接口</span><span class="token keyword">enum</span> Color4 <span class="token keyword">implements</span> <span class="token class-name">Show</span><span class="token punctuation">,</span>Fly<span class="token punctuation">{</span>    <span class="token function">RED</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//对抽象方法特有实现</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"我是红色"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token function">BLUE</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"我是蓝色"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token function">Green</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"我是绿色"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token function">BLACK</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> redValue<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> greenValue<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> blueValue<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getRedValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> redValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getGreenValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> greenValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getBlueValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> blueValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token function">Color4</span><span class="token punctuation">(</span><span class="token keyword">int</span> redValue<span class="token punctuation">,</span> <span class="token keyword">int</span> greenValue<span class="token punctuation">,</span> <span class="token keyword">int</span> blueValue<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>redValue <span class="token operator">=</span> redValue<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>greenValue <span class="token operator">=</span> greenValue<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>blueValue <span class="token operator">=</span> blueValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">display</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"我是一个颜色：三原色："</span><span class="token operator">+</span>redValue<span class="token operator">+</span><span class="token string">","</span><span class="token operator">+</span>greenValue<span class="token operator">+</span><span class="token string">","</span><span class="token operator">+</span>blueValue<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">fly</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// TODO Auto-generated method stub</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.enum类不能再继承其他类，因为已经隐式的直接继承了Enum类</p><h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><h3 id="注解的理解"><a href="#注解的理解" class="headerlink" title="注解的理解"></a>注解的理解</h3><p>定义：用于修饰java中的数据（属性、方法、构造器、类等），相当于程序中的补充文字。不改变程序的逻辑，但可以被编译器或运行时解析，并做相应处理</p><h3 id="内置的三种基本注解【掌握】"><a href="#内置的三种基本注解【掌握】" class="headerlink" title="内置的三种基本注解【掌握】"></a>内置的三种基本注解【掌握】</h3><h4 id="Override"><a href="#Override" class="headerlink" title="@Override"></a>@Override</h4><p><strong>源码</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span>ElementType<span class="token punctuation">.</span>METHOD<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">//只能用于修饰方法</span><span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>SOURCE<span class="token punctuation">)</span><span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">Override</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>只能用于修饰方法，检测被修饰的方法是否为有效的重写，如果不是，则报编译错误！ </p><h4 id="Deparecated"><a href="#Deparecated" class="headerlink" title="@Deparecated"></a>@Deparecated</h4><p>用于表明被修饰的数据已经过时，不建议使用，为了新老版本的兼容，没有贸然的废弃，只是提醒！</p><p>可以用于修饰：类或接口、属性、方法、构造、局部变量、包、参数</p><h4 id="Suppresswarnings"><a href="#Suppresswarnings" class="headerlink" title="@Suppresswarnings"></a>@Suppresswarnings</h4><p><strong>源码</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//用于修饰类或接口、属性、方法、构造、局部变量、参数</span><span class="token annotation punctuation">@Target</span><span class="token punctuation">(</span><span class="token punctuation">{</span>TYPE<span class="token punctuation">,</span> FIELD<span class="token punctuation">,</span> METHOD<span class="token punctuation">,</span> PARAMETER<span class="token punctuation">,</span> CONSTRUCTOR<span class="token punctuation">,</span> LOCAL_VARIABLE<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>SOURCE<span class="token punctuation">)</span><span class="token keyword">public</span> @<span class="token keyword">interface</span> <span class="token class-name">SuppressWarnings</span> <span class="token punctuation">{</span>    String<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用于抑制程序中的编译警告</p><h3 id="自定义注解【了解】"><a href="#自定义注解【了解】" class="headerlink" title="自定义注解【了解】"></a>自定义注解【了解】</h3><ol><li><p>定义注解的关键字@interface</p></li><li><p>注解类体中的成员是：<br> 参数类型 方法名();</p></li></ol><p><strong>注意：</strong></p><blockquote><p>①参数类型只能是 八大基本类型、String、枚举类、Class类型或上述类型的数组类型</p><p>②方法名遵循标识符的命名规则和规范，但建议使用value。<br>   因为使用时，可以省略方法名</p><p>③可以在定义方法时，指定默认值，语法：<br>   参数类型 方法名() default 默认值;</p></blockquote><p><strong>例：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestAnn2</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@MyAnn1</span><span class="token punctuation">(</span><span class="token string">"yy"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//若方法名为value，则这么写</span><span class="token comment" spellcheck="true">//    @MyAnn1(name = "yy") //若方法名为name，则这么写</span><span class="token comment" spellcheck="true">//    @MyAnn1(name = "xx", value = "yy") //若方法有两个，则都要写上</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">enum</span> Gender<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token annotation punctuation">@Retention</span><span class="token punctuation">(</span>RetentionPolicy<span class="token punctuation">.</span>SOURCE<span class="token punctuation">)</span>@<span class="token keyword">interface</span> <span class="token class-name">MyAnn1</span><span class="token punctuation">{</span>    String <span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//    String name() default "xx"; //这里加了默认值，则在使用的时候就可不用传值</span><span class="token comment" spellcheck="true">//    Gender name(); //没错，参数类型可以为枚举类型</span><span class="token comment" spellcheck="true">//    Gender[] name(); //参数类型可为数组</span><span class="token comment" spellcheck="true">//    Person name(); //报错，参数类型不能是Person（自己的定义的）</span><span class="token punctuation">}</span><span class="token keyword">class</span> <span class="token class-name">Person</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>使用注解</li></ol><p>在被修饰的数据上方，添加注解即可，语法：<br>    @注解类型(方法名=值)<br>若参数类型为数组，则用{}，包起来，如：Suppresswarnings<br>    @Suppresswarnings(value = {“…”,”…”,”…”})</p><h3 id="元注解"><a href="#元注解" class="headerlink" title="元注解"></a>元注解</h3><p>Retention:用于指明被修饰的注解可以保留多长<br>    RententionPolicy:SOURCE（源码） CLASS（编译器-默认） RUNTIME（运行时）</p><p>Target：用于指明被修饰的注解可以用于修饰哪些数据<br>    ElementType:TYPE LOCAL_VARIABLE FIELD METHOD等</p><p>Documented：能否在生成的帮助文档中显示</p><p>Inherited：注解是否具备继承性</p>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试问题（一）</title>
      <link href="2020/03/07/mian-shi-wen-ti-yi/"/>
      <url>2020/03/07/mian-shi-wen-ti-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="面试问题整理（一）"><a href="#面试问题整理（一）" class="headerlink" title="面试问题整理（一）"></a>面试问题整理（一）</h1><h2 id="字节跳动"><a href="#字节跳动" class="headerlink" title="字节跳动"></a>字节跳动</h2><h3 id="1-什么是hashmap"><a href="#1-什么是hashmap" class="headerlink" title="1. 什么是hashmap"></a>1. 什么是hashmap</h3><p>hashmap就是存储键值对的一种散列结构，里面存储的实体包括Key，Value和一个指向自己的next指针</p><hr><h3 id="2-hashmap底层是怎么实现的"><a href="#2-hashmap底层是怎么实现的" class="headerlink" title="2. hashmap底层是怎么实现的"></a>2. hashmap底层是怎么实现的</h3><p>HashMap 底层是 hash 数组和单向链表实现，数组中的每个元素都是链表，由 Node 内部类（实现 Map.Entry&lt;K,V&gt;接口）实现，HashMap 通过 put &amp; get 方法存储和获取。</p><p>存储对象时，将 K/V 键值传给 put() 方法：<br>① 调用 hash(K) 方法计算 K 的 hash 值，然后结合数组长度，计算得数组下标；<br>② 调整数组大小（当容器中的元素个数大于 capacity * loadfactor 时，容器会进行扩容resize 为 2n）；<br>③ 如果 K 的 hash 值在 HashMap 中不存在，则执行插入，若存在，则发生碰撞；如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 true，则更新键值对； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 false，则插入链表的尾部（JDK 1.7 之前使用头插法、JDK 1.8 使用尾插法）或者红黑树中（树的添加方式）。<br><strong>注意：</strong>当碰撞导致链表大于 TREEIFY_THRESHOLD = 8 时，就把链表转换成红黑树</p><p>获取对象时，将 K 传给 get() 方法：<br>① 调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标；<br>② 顺序遍历链表，equals()方法查找相同 Node 链表中 K 值对应的 V 值。</p><p><strong>hashCode 是定位的，存储位置；equals是定性的，比较两者是否相等</strong></p><hr><h3 id="3-hashmap冲突"><a href="#3-hashmap冲突" class="headerlink" title="3. hashmap冲突"></a>3. hashmap冲突</h3><p>hashmap有hash函数来计算存储位置，那就有可能两个对象经过hash函数计算出一个位置，这就是hash冲突，两个不同对象的hashcode相同，这种现象称为hash冲突。</p><hr><h3 id="4-hashmap冲突怎么解决"><a href="#4-hashmap冲突怎么解决" class="headerlink" title="4. hashmap冲突怎么解决"></a>4. hashmap冲突怎么解决</h3><p>① 开放定址法：如果hash函数根据当前key值计算出的hashcode已经存在 p=hash（key），就根据当前算出的p再次hash得p1…直到计算出没有hash冲突的p。</p><p>② 再hash法：一个hashmap不光只有一个hash函数，当发生hash碰撞时，根据另外一个hash函数计算出另一个hashcode。</p><p>③ 链地址法：将所有哈希地址相同的都链接在同一个链表中 ，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况（hashmap采用这个方法来解决hash冲突）。<br><strong>jdk1.7中直接采用链表，而jdk1.8中为链表的长度设置的定值，如果超过这个定值就是用红黑树来存值。</strong></p><p>④ 建立一个公共缓冲区：一旦发生hash冲突时，将值存入这个公共缓冲区。</p><hr><h3 id="5-hash扩容"><a href="#5-hash扩容" class="headerlink" title="5. hash扩容"></a>5. hash扩容</h3><p>初始创建hashmap时，定义了hashmap的大小，而每一个初始的hashmap有一个扩容因子，默认是0.75。也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会重新调整map的大小（默认是进行二的次幂式扩大），并将原来的对象放入新的bucket数组中，这个过程叫作rehashing。但是每次rehash都会花费更多的时间，所以每次定义hashmap都应该考虑hashmap的大小，避免rehash的次数。因为它调用hash方法找到新的bucket位置。这个值只可能在两个地方，一个是原下标的位置，另一种是在下标为&lt;原下标+原容量&gt;的位置</p><h3 id="6-hashmap为什么线程不安全以及不安全情况"><a href="#6-hashmap为什么线程不安全以及不安全情况" class="headerlink" title="6. hashmap为什么线程不安全以及不安全情况"></a>6. hashmap为什么线程不安全以及不安全情况</h3><p>感觉讲不明白，等看看hashmap源码再来优化讲一下吧</p><p><a href="https://my.oschina.net/muziH/blog/1596801" target="_blank" rel="noopener">https://my.oschina.net/muziH/blog/1596801</a></p><hr><h3 id="7-http"><a href="#7-http" class="headerlink" title="7. http"></a>7. http</h3><p><strong>http 和 https区别</strong></p><p>① HTTP 是不安全的，而 HTTPS 是安全的<br>② HTTP 标准端口是80 ，而 HTTPS 的标准端口是443<br>③ 在OSI 网络模型中，HTTP工作于应用层，而HTTPS 的安全传输机制工作在传输层<br>④ HTTP 无法加密，而HTTPS 对传输的数据进行加密<br>⑤ HTTP无需证书，而HTTPS 需要CA机构wosign的颁发的SSL证书</p><p><strong>什么是Http协议无状态协议？怎么解决Http协议无状态协议？</strong></p><p>无状态协议对于事务处理没有记忆能力。也就是说，当客户端一次Http请求完成以后后，客户端再发送一次Http请求，Http并不知道当前客户端是一个“老用户”。</p><p>可以使用Cookie来解决无状态的问题，Cookie就相当于一个通行证，第一次访问的时候给客户端发送一个Cookie，当客户端再次来的时候，拿着Cookie(通行证)，那么服务器就知道这个是”老用户“。</p><p><strong>一次完整的Http事务是怎么样的一个过程</strong></p><p>域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户</p><p><strong>http的报文结构</strong></p><p>① 请求报文—–从客户端向服务器发送请求报文。</p><p>请求报文的结构如下图：</p><p><img src="1.png" alt></p><p>② 响应报文—–从服务器到客户的回答。</p><p>响应报文的结构如下图：</p><p><img src="2.png" alt></p><p>http请求报文和响应报文都是由三个部分组成。可以看出这两种报文的区别就在于开始行不同。<br>① 开始行：用于区别是请求报文还是响应报文。在请求报文中的开始行叫做请求行，而在响应报文的开始行叫做状态行。<br>② 首部行：用于说明浏览器、服务器、或报文主体的一些信息。首部可以有好几行，单页可以不用。<br>③ 实体主体：在请求报文一般必用这个字段，在响应报文中返回请求的内容，也可以不用。<br>请求报文的第一行“请求行”只有三个内容，方法，请求资源的URL，以及Http的版本。这里的方法是对请求的对象进行的操作，这些方法实际上也就是一些命令。请求报文的类型就是由它采用的方法决定的。</p><hr><h3 id="8-get-和-post-比较"><a href="#8-get-和-post-比较" class="headerlink" title="8. get 和 post 比较"></a>8. get 和 post 比较</h3><p>GET - 从指定的服务器中获取数据<br>POST - 提交数据给指定的服务器处理</p><p>GET方法：</p><p>使用GET方法时，查询字符串（键值对）被附加在URL地址后面一起发送到服务器：</p><p>特点：</p><p>① GET请求能够被缓存<br>② GET请求会保存在浏览器的浏览记录中<br>③ 以GET请求的URL能够保存为浏览器书签<br>④ GET请求有长度限制<br>⑤ GET请求主要用以获取数据</p><hr><p>POST方法：</p><p>使用POST方法时，查询字符串在POST信息中单独存在，和HTTP请求一起发送到服务器：</p><p>特点：<br>① POST请求不能被缓存下来<br>② POST请求不会保存在浏览器浏览记录中<br>③ 以POST请求的URL无法保存为浏览器书签<br>④ POST请求没有长度限制</p>]]></content>
      
      
      <categories>
          
          <category> 面试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InterviewSummary</title>
      <link href="2020/03/06/interviewsummary-1/"/>
      <url>2020/03/06/interviewsummary-1/</url>
      
        <content type="html"><![CDATA[<h1 id="面试总结（一）"><a href="#面试总结（一）" class="headerlink" title="面试总结（一）"></a>面试总结（一）</h1><h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>一周两个面试，一个字节跳动基础架构，一个微软亚洲研究院。字节跳动真的是惨不忍睹，微软的要比字节稍好一点，但是，结果很可能是一样，尴尬~ ：）</p><h2 id="字节跳动"><a href="#字节跳动" class="headerlink" title="字节跳动"></a>字节跳动</h2><h3 id="面试问题"><a href="#面试问题" class="headerlink" title="面试问题"></a>面试问题</h3><p><strong>1. 什么是hashmap</strong><br><strong>2. hashmap底层是怎么实现的</strong><br><strong>3. hashmap冲突以及怎么解决</strong><br><strong>4. hash扩容</strong><br><strong>5. hashmap为什么线程不安全以及不安全情况</strong><br><strong>6. 数据库加锁</strong><br><strong>7. 线程进程区别，进程拥有什么资源</strong><br><strong>8. http结构</strong></p><p>问题差不多就这些，明天整合下补充下再整理下答案（java视频中有）</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>首先自己太水在先，被人家吊打没话说；其次今晚上在看答案的时候才意识到：这些hashmap有关知识点是给java开发的必备问题，可是他们没写要java开发却一直问我这个，有点无语，可能就是根本不想要我吧。</p><p>这次算是看透了吧，原本以为自己很厉害，到头来，真的是水的不行啊，以后继续努力吧~ </p><p>另外这次的面试官真的很让人恶心，我也不知道他在对面干啥，感觉脸上一直带着一副很不屑的表情，真恶心~   当然也有可能是我心理作用。</p><p>每次接到字节跳动的面试都感觉极度不舒服（本该是件开心的事，我也不知道为什么会这样，可能真的受挫吧），可能自己实力真的还没达到那个水平吧。嗯，继续努力，争取有一个拒绝字节跳动的机会。</p><h2 id="微软亚洲研究院-DKI组"><a href="#微软亚洲研究院-DKI组" class="headerlink" title="微软亚洲研究院 DKI组"></a>微软亚洲研究院 DKI组</h2><h3 id="面试问题-1"><a href="#面试问题-1" class="headerlink" title="面试问题"></a>面试问题</h3><p><strong>1. 说一个自己做的项目里面比较完整的</strong><br><strong>2. xgboost实现原理</strong><br><strong>3. xgboost每棵树是回归树还是分类树</strong><br><strong>4. boosting和bagging区别</strong><br><strong>5. auc和acc和roc区别联系 roc图像怎么画</strong><br><strong>6. 寻找每层最左边的节点</strong><br><strong>7. 快速排序</strong><br><strong>8. CNN</strong></p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>这次面试感觉稍微比字节跳动的好点，感觉面试官也挺有耐心的（可能是心理作用）。</p><p>机器学的东西非常欠缺；说话不够主动等着面试官问；口头禅太多，面试官问完，可以略作停顿思考一下；面试官问某个问题的时候，如果接触过，就说了结果XXX，稍微说一下，学会主动举例子；表情管理（微表情太多，不自信）</p><p>嗯，这次面试结束了，结果基本是没希望，不过没事，经过屁屁指点，确实感觉到了自己很多的不足，以后每次都要注意吧，逐渐改掉。</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>以后面试，如果可以录音，就录音；不可以的话，面试完，赶紧记录下所问问题，不然很容易遗忘，另外还要及时整理答案。</p>]]></content>
      
      
      <categories>
          
          <category> 面试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>稍微说点吧</title>
      <link href="2020/03/04/shao-wei-shuo-dian-ba/"/>
      <url>2020/03/04/shao-wei-shuo-dian-ba/</url>
      
        <content type="html"><![CDATA[<p>明天又要受虐，迎接新的失败了，想想都闹心，😔~</p><h1 id="家里基本装修完了"><a href="#家里基本装修完了" class="headerlink" title="家里基本装修完了"></a>家里基本装修完了</h1><p>爸妈在家可能真的有点闲，突发奇想要装修，终于在吵吵闹闹的三天之内整完了。这几天家里闹闹吵吵的确实也没学多少，但是正在努力去养成每天记点什么的习惯，希望能坚持下去，到时候看到，多少知道自己留下了点东西。</p><h1 id="明天要受虐了"><a href="#明天要受虐了" class="headerlink" title="明天要受虐了"></a>明天要受虐了</h1><p>嗯，说也开心，说也不开心。一边希望自己能有面试的机会，希望得到公司认可，一边又害怕失败，感觉什么也没准备好。或许是太中意这个实习机会了吧。据我估计，明天99.9999%概率仍然不过，可能这也未必是坏事吧。也许是老天爷觉得这个公司不适合我，正在让我逐渐对这个公司失去原本的热诚吧~</p><p>周五还有一个，那个倒是轻松些，虽然机会不错，但是说真的，我觉得自己不太适合那个，听天由命吧~</p><h1 id="碎碎的感想"><a href="#碎碎的感想" class="headerlink" title="碎碎的感想"></a>碎碎的感想</h1><p>不知道为何，这几天脑子里总是无缘无故冒出一些奇奇怪怪的想法的碎片，一直理不清到底是什么。试图去抓的时候，又仿佛匆匆从脑子中跑掉，无从抓起，突然就毫无思绪，跑的干干净净。或许是这两天家里太乱，事又比较多，不太适合仔细琢磨吧。</p><p>可是那些想法有的时候又是那样虚无，感觉从没想过；有时候有hu~的一下蹦到脑子里，感觉到它确确实实存在过。</p><p>等忙完这几天吧，好好去理一下，有些问题确实也应该好好思考下了。呵~ 或许这几天之后，那些想法又逃的无影无踪了，谁知道呢~</p><h1 id="最后写给屁屁"><a href="#最后写给屁屁" class="headerlink" title="最后写给屁屁"></a>最后写给屁屁</h1><p>当然写给屁屁的，每天是不能少的。</p><p>渴望着老去，不再为个人生计费力，不再为细枝末节伤神<br>从此只关心，柴米油盐还有你~</p><blockquote><p>希望一切顺利~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>必备知识点（四）</title>
      <link href="2020/03/04/bi-bei-zhi-shi-dian-si/"/>
      <url>2020/03/04/bi-bei-zhi-shi-dian-si/</url>
      
        <content type="html"><![CDATA[<h1 id="必备知识点（四）"><a href="#必备知识点（四）" class="headerlink" title="必备知识点（四）"></a>必备知识点（四）</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><h4 id="插入类排序"><a href="#插入类排序" class="headerlink" title="插入类排序"></a>插入类排序</h4><p><strong>直接插入排序</strong></p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">InsertSort</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n <span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> j <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> R<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 不断往前替换</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>j <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> temp <span class="token operator">&lt;</span> R<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            R<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> R<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token operator">--</span>j<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        R<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>折半插入排序</strong></p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">BinaryInsertSortup</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n <span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> right <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> R<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> left <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>right <span class="token operator">&lt;=</span> left<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">int</span> mid <span class="token operator">=</span> <span class="token punctuation">(</span>left <span class="token operator">+</span> right<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>temp <span class="token operator">>=</span> R<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span>                left <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>temp <span class="token operator">&lt;</span> R<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span>                right <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">int</span> k <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token punctuation">;</span> k <span class="token operator">></span> right <span class="token punctuation">;</span> <span class="token operator">--</span>k<span class="token punctuation">)</span>            R<span class="token punctuation">[</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> R<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">;</span>        R<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="交换类排序"><a href="#交换类排序" class="headerlink" title="交换类排序"></a>交换类排序</h4><p><strong>起泡排序</strong></p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">BubbleSort</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> n <span class="token operator">-</span> <span class="token number">1</span> <span class="token punctuation">;</span> i <span class="token operator">></span> <span class="token number">1</span> <span class="token punctuation">;</span> <span class="token operator">--</span>i<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> flag <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//是否交换标志</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">1</span> <span class="token punctuation">;</span> j <span class="token operator">&lt;=</span> i <span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>R<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">></span> R<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                flag <span class="token operator">=</span> <span class="token number">1</span>；                <span class="token keyword">int</span> temp <span class="token operator">=</span> R<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>                R<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> R<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                R<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp；            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>flag <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>快速排序</strong></p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">QuickSort</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> low<span class="token punctuation">,</span> <span class="token keyword">int</span> high<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> i <span class="token operator">=</span> low<span class="token punctuation">,</span> j <span class="token operator">=</span> high<span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>low <span class="token operator">&lt;</span> high<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> R<span class="token punctuation">[</span>low<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">while</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j <span class="token operator">&amp;&amp;</span> temp <span class="token operator">&lt;=</span> R<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token operator">--</span>j<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 此时R[j]&lt;temp，所以放到左边</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j<span class="token punctuation">)</span><span class="token punctuation">{</span>                R<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> R<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token operator">++</span>i<span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">while</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j <span class="token operator">&amp;&amp;</span> temp <span class="token operator">></span> R<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token operator">++</span>i<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 此时R[i]>temp，所以放到右边</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j<span class="token punctuation">)</span><span class="token punctuation">{</span>                R<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> R<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token operator">--</span>j<span class="token punctuation">;</span>            <span class="token punctuation">}</span>            R<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 将最开始的R[i]放到合适位置</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 两边递归</span>        <span class="token function">QuickSort</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> low<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token number">-1</span><span class="token punctuation">)</span>；        <span class="token function">QuickSort</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">int</span> high<span class="token punctuation">)</span>；    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="选择类排序"><a href="#选择类排序" class="headerlink" title="选择类排序"></a>选择类排序</h4><p><strong>简单选择排序</strong></p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">SelectSort</span><span class="token punctuation">(</span><span class="token keyword">int</span> R<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n <span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> k <span class="token operator">=</span> i<span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> i<span class="token operator">+</span><span class="token number">1</span> <span class="token punctuation">;</span> j <span class="token operator">&lt;</span> n <span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>R<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> R<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>                k <span class="token operator">=</span> j<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        temp <span class="token operator">=</span> R<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        R<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> R<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">;</span>        R<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="多路归并排序"><a href="#多路归并排序" class="headerlink" title="多路归并排序"></a>多路归并排序</h4><p>直接拿letcode题目来做例子吧~（letcode 23）<br>算是暴力归并吧（两两比较合成一个）</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> ListNode <span class="token function">mergeKLists</span><span class="token punctuation">(</span>ListNode<span class="token punctuation">[</span><span class="token punctuation">]</span> lists<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>lists <span class="token operator">==</span> null <span class="token operator">||</span> lists<span class="token punctuation">.</span>length <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">return</span> null<span class="token punctuation">;</span>        <span class="token keyword">int</span> left <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token keyword">int</span> right <span class="token operator">=</span> lists<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>right <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">while</span><span class="token punctuation">(</span>left <span class="token operator">&lt;</span> right<span class="token punctuation">)</span> <span class="token punctuation">{</span>                lists<span class="token punctuation">[</span>left<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">merge</span><span class="token punctuation">(</span>lists<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">,</span> lists<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                left<span class="token operator">++</span><span class="token punctuation">;</span>                right<span class="token operator">--</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            left <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> lists<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> ListNode <span class="token function">merge</span><span class="token punctuation">(</span>ListNode node1<span class="token punctuation">,</span> ListNode node2<span class="token punctuation">)</span> <span class="token punctuation">{</span>        ListNode head <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ListNode</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ListNode pre <span class="token operator">=</span> head<span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>node1 <span class="token operator">!=</span> null <span class="token operator">&amp;&amp;</span> node2 <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>node1<span class="token punctuation">.</span>val <span class="token operator">&lt;</span> node2<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">{</span>                pre<span class="token punctuation">.</span>next <span class="token operator">=</span> node1<span class="token punctuation">;</span>                node1 <span class="token operator">=</span> node1<span class="token punctuation">.</span>next<span class="token punctuation">;</span>                pre <span class="token operator">=</span> pre<span class="token punctuation">.</span>next<span class="token punctuation">;</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                pre<span class="token punctuation">.</span>next <span class="token operator">=</span> node2<span class="token punctuation">;</span>                node2 <span class="token operator">=</span> node2<span class="token punctuation">.</span>next<span class="token punctuation">;</span>                pre <span class="token operator">=</span> pre<span class="token punctuation">.</span>next<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        pre<span class="token punctuation">.</span>next <span class="token operator">=</span> node1 <span class="token operator">==</span> null <span class="token operator">?</span> node2 <span class="token operator">:</span> node1<span class="token punctuation">;</span>        <span class="token keyword">return</span> head<span class="token punctuation">.</span>next<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 知识储备 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识储备 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>碎碎念的流水账</title>
      <link href="2020/03/02/sui-sui-nian-de-liu-shui-zhang/"/>
      <url>2020/03/02/sui-sui-nian-de-liu-shui-zhang/</url>
      
        <content type="html"><![CDATA[<p>哎，一天天好快的啊。感觉什么没做又是一天过去了~</p><h1 id="家里开始做装修"><a href="#家里开始做装修" class="headerlink" title="家里开始做装修"></a>家里开始做装修</h1><p>就在昨天晚饭的时候，还没在犹豫要不要装修，今早上就动工了，幸亏今早上起来的早点，没被做工的看到我睡懒觉的样子，维持一直以来好孩子的形象。</p><p>家里需要各种材料各种工具，我得一直候着去买，一趟又一趟，这是预示着，字节的面试要凉凉啊~  可是我超级想去字节的，太难了，牛人好多，自己还有好多地方需要努力啊。</p><p>我本来就性子急，所以很多事情对爸妈确实有点过分，可是当时一下没忍住啊，做过又难受后悔。哎，以后一定要努力去控制自己的情绪~</p><h1 id="自己好水"><a href="#自己好水" class="headerlink" title="自己好水"></a>自己好水</h1><p>这几天零零碎碎翻书过程中，发现自己本科学的东西真的好水啊，什么都是一直半解，只懂皮毛，学了一学期都不如几天学的（自己总结原因：没走心；理解水平确实没有达到）。在不断恶补中，希望能在找工作的时候有个好结果。</p><h1 id="写给屁屁"><a href="#写给屁屁" class="headerlink" title="写给屁屁"></a>写给屁屁</h1><p>幸福就是，我旁边的女生是屁屁~</p><h1 id="最后今天就到这吧，时间不早了，明天还得早起"><a href="#最后今天就到这吧，时间不早了，明天还得早起" class="headerlink" title="最后今天就到这吧，时间不早了，明天还得早起~"></a>最后今天就到这吧，时间不早了，明天还得早起~</h1>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>必备知识点（三）</title>
      <link href="2020/03/02/bi-bei-zhi-shi-dian-san/"/>
      <url>2020/03/02/bi-bei-zhi-shi-dian-san/</url>
      
        <content type="html"><![CDATA[<h1 id="必备知识点（三）"><a href="#必备知识点（三）" class="headerlink" title="必备知识点（三）"></a>必备知识点（三）</h1><h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><h3 id="1-进程和线程区别"><a href="#1-进程和线程区别" class="headerlink" title="1. 进程和线程区别"></a>1. 进程和线程区别</h3><p>(1) 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。<br>(2) 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程，会引起进程切换。<br>(3) 系统开销：创建、撤销或切换进程，系统都要为之分配、回收资源或保存环境，开销远比线程大。<br>(4) 通信方面：线程间可以通过直接读取统一进程中的数据进行通信，但是进程通信需要借助IPC。</p><h3 id="2-存储管理"><a href="#2-存储管理" class="headerlink" title="2. 存储管理"></a>2. 存储管理</h3><h4 id="分页式"><a href="#分页式" class="headerlink" title="分页式"></a>分页式</h4><p>把内存空间分成大小相等、位置固定的若干小分区，每个小分区简称为一个存储块，并编号为0，1，2，3，…，n块，每个存储块的大小由不同系统决定。把用户的逻辑地址空间分成与存储块大小相等的若干页，依次为0，1，2，…，n页。当作业提出存储分配请求时，系统首先根据存储块大小把作业分成若干页。每一页可存储在内存的任一空白块内。此时只要建立程序的逻辑页与内存的存储块之间的对应关系，借助动态地址重定位技术，原本连续的用户作业在分散的不连续块中，就能够正常投入运行。</p><hr><h4 id="分段式"><a href="#分段式" class="headerlink" title="分段式"></a>分段式</h4><p>作业的地址空间由若干个逻辑分段组成，每一分段是一组逻辑意义完整的信息集合，并有自己的段名。每个段都是以0开始的连续的一维地址空间，整个作业则构成了二维地址空间。以段为基本单位分配内存，且每一段必须分配连续的内存空间，但各段之间不要求连续。所谓分段式管理，就是管理由若干段组成的作业，并且按段来进行存储分配。</p><hr><h4 id="段页式"><a href="#段页式" class="headerlink" title="段页式"></a>段页式</h4><p>(1) 作业地址空间进行段式管理（将作业地址空间分成若干个逻辑分段，每段都有自己的段名）<br>(2) 每段内分成若干大小固定的页，每段从零开始为自己的各页依次编写连续页号<br>(3) 对内存地址的管理仍然和分页管理一样，将其分成若干个与页面大小相同的物理块，对内存地空间的分配是以物理块为单位。</p><h3 id="3-分段与分页的区别"><a href="#3-分段与分页的区别" class="headerlink" title="3. 分段与分页的区别"></a>3. 分段与分页的区别</h3><p>(1) 页是信息的物理单位。分页的目的是实现离散分配，减少外部碎片，提高内存利用率。段是逻辑的基本单位。每一段在逻辑上是一组相对完整的信息集合。<br>(2) 分页式存储管理的作业地址空间是一维的，而分段式存储管理的作业地址空间是二维的。<br>(3) 页的大小固定且由系统决定是等长的。而段长度不固定。<br>(4) 分页的有点体现在内存空间的管理上，而分段的优点体现在地址空间的管理上。</p><h3 id="4-进程的PCB里还有哪些东西？"><a href="#4-进程的PCB里还有哪些东西？" class="headerlink" title="4. 进程的PCB里还有哪些东西？"></a>4. 进程的PCB里还有哪些东西？</h3><ul><li>进程状态</li><li>程序计数器</li><li>CPU寄存器</li><li>CPU调度信息</li><li>内存管理信息</li><li>记账信息</li><li>I/O状态信息</li></ul><h3 id="5-进程通信（进程间信息交换）"><a href="#5-进程通信（进程间信息交换）" class="headerlink" title="5. 进程通信（进程间信息交换）"></a>5. 进程通信（进程间信息交换）</h3><p>进程同步与互斥，由于交换信息量少，可以看作低级通信。</p><p><strong>共享存储</strong></p><ul><li>基于共享数据结构的通信方式<br>比较低效，只适于传送少量数据</li><li>基于共享存储区的通信方式<br>为了传送大量数据，在存储区中划出的一块共享存储区，多个进程可以通过对共享存储区进行读写数据实现通信。</li></ul><p>(1) 向系统申请共享存储区中的一个分区<br>(2) 指定该分区的关键字；如果已经给其他进程分配了这样的存储区，将该分区的描述符返回给申请者<br>(3) 申请者将申请到的共享分区挂到本进程上。</p><p><strong>消息传递</strong></p><p>两个进程可以通过互相发送消息进行通信，消息是通过消息缓冲区在进程间互相传递的。</p><p><strong>共享文件</strong></p><p>也叫管道通信机制。管道是连接读写进程的一个特殊文件，允许进程按先进先出方式传送数据，也能使进程同步执行操作</p>]]></content>
      
      
      <categories>
          
          <category> 知识储备 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识储备 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>必备知识点（二）</title>
      <link href="2020/03/01/bi-bei-zhi-shi-dian-er/"/>
      <url>2020/03/01/bi-bei-zhi-shi-dian-er/</url>
      
        <content type="html"><![CDATA[<h1 id="必备知识点（二）"><a href="#必备知识点（二）" class="headerlink" title="必备知识点（二）"></a>必备知识点（二）</h1><h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><h4 id="1-TCP-UDP（都属于传输层）"><a href="#1-TCP-UDP（都属于传输层）" class="headerlink" title="1. TCP UDP（都属于传输层）"></a>1. TCP UDP（都属于传输层）</h4><h5 id="1-定义"><a href="#1-定义" class="headerlink" title="(1)定义"></a>(1)定义</h5><p><strong>TCP：</strong>传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议<br><strong>优点：</strong>可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。<br><strong>缺点：</strong> 慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击</p><p><strong>UDP：</strong> UDP 为应用程序提供了一种无需建立连接就可以发送封装的 IP 数据包的方法<br><strong>优点：</strong>快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。<br><strong>缺点：</strong> 不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包</p><hr><h5 id="2-区别"><a href="#2-区别" class="headerlink" title="(2)区别"></a>(2)区别</h5><p>① TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接<br>② TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付<br>③ TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的。<br>UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）<br>④ 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信<br>⑤ TCP首部开销20字节;UDP的首部开销小，只有8个字节<br>⑥ TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道</p><p><img src="2.jpg" alt></p><hr><p><strong>PS：</strong><br>面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。</p><p>面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。</p><h5 id="3-TCP怎么保证可靠传输"><a href="#3-TCP怎么保证可靠传输" class="headerlink" title="(3)TCP怎么保证可靠传输"></a>(3)TCP怎么保证可靠传输</h5><p><strong>校验和</strong><br>计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。<br>发送方：在发送数据之前计算检验和，并进行校验和的填充。<br>接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。<br><strong>注：</strong>如果接收方比对校验和与发送方不一致，那么数据一定传输有误。但是如果接收方比对校验和与发送方一致，数据不一定传输成功</p><hr><p><strong>确认应答与序列号</strong><br>序列号：TCP传输时将每个字节的数据都进行了编号，这就是序列号。<br>确认应答：TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文。这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数<br><strong>注：</strong>序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一。</p><hr><p><strong>超时重传</strong><br>在进行TCP传输时，由于确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发送完数据后，迟迟没有等到接收方的ACK报文，发生这种情况会有两个原因：<br>① 数据在传输过程中由于网络原因等直接全体丢包，接收方根本没有接收到。<br>② 接收方接收到了响应的数据，但是发送的ACK报文响应却由于网络原因丢包了。</p><p>为了解决以上情况便产生了超时重传机制。简单理解就是发送方在发送完数据后等待一个时间没有接收到ACK报文，那么对刚才发送的数据进行重新发送。如果是由于①造成的，接收方收到二次重发的数据后，便进行ACK应答；如果是②造成的，接收方发现接收的数据已存在（判断存在的根据就是序列号，所以上面说序列号还有去除重复数据的作用），那么直接丢弃，仍旧发送ACK应答。</p><hr><p><strong>连接管理</strong><br>三次握手和四次挥手，稍后细说</p><hr><p><strong>流量控制</strong><br>接收端要对接收到的数据进行处理，如果发送端的发送速度太快，接收端来不及处理，导致接收端的结束缓冲区很快的填充满了。此时如果发送端仍旧发送数据，那么接下来发送的数据便可能发生丢包，继而导致丢包的一系列连锁反应。而TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。</p><p><strong>注：</strong>在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道，窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小。这个数字越大，证明接收端接收缓冲区的剩余空间越大，网络的吞吐量越大。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。</p><hr><p><strong>拥塞控制</strong><br>TCP传输的过程中，发送端开始发送数据的时候，如果刚开始就发送大量的数据，那么就可能造成一些问题。网络可能在开始的时候就很拥堵，如果给网络中在扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。</p><p>所以TCP引入了慢启动的机制，在开始发送数据时，先发送少量的数据探路。探清当前的网络状态如何，再决定多大的速度进行传输。这时候就引入一个叫做拥塞窗口的概念。发送刚开始定义拥塞窗口为 1，每次收到ACK应答，拥塞窗口加 1。在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小比对，取较小的值作为实际发送的窗口。</p><p>拥塞窗口的增长是指数级别的。慢启动的机制只是说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。为了控制拥塞窗口的增长，不能使拥塞窗口单纯的加倍，设置一个拥塞窗口的阈值，当拥塞窗口大小超过阈值时，不能再按照指数来增长，而是线性的增长。在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，发生超时重传时，慢启动的阈值会为原来的一半（这里的原来指的是发生网络拥塞时拥塞窗口的大小），同时拥塞窗口重置为 1。 </p><h4 id="2-三次握手四次挥手"><a href="#2-三次握手四次挥手" class="headerlink" title="2. 三次握手四次挥手"></a>2. 三次握手四次挥手</h4><h5 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h5><p><strong>过程</strong></p><p><img src="%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt></p><p>B的TCP服务器进程先创建传输控制块TCB，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN（收听）状态，等待客户的连接请求。若有，则作出响应。<br>① 第一次握手：A的TCP客户进程也是首先创建传输控制块TCB，然后向B发出连接请求报文段，（首部的同步位SYN=1，初始序号seq=x），（SYN=1的报文段不能携带数据）但要消耗掉一个序号，此时TCP客户进程进入SYN-SENT（同步已发送）状态。<br>② 第二次握手：B收到连接请求报文段后，如同意建立连接，则向A发送确认，在确认报文段中（SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y），测试TCP服务器进程进入SYN-RCVD（同步收到）状态；<br>③ 第三次握手：TCP客户进程收到B的确认后，要向B给出确认报文段（ACK=1，确认号ack=y+1，序号seq=x+1）（初始为seq=x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。TCP连接已经建立，A进入ESTABLISHED（已建立连接）。<br>当B收到A的确认后，也进入ESTABLISHED状态。</p><hr><p><strong>为什么采用三次握手（也就是说为什么要在A最后还要再发送一次确认）</strong><br>是为了防止已经失效的请求报文端，再次传到B，因而产生错误。</p><p>正常情况</p><p>client发送了连接请求，但是请求报文因为种种原因丢失而未确认。于是A超时重传，再一次发送请求连接报文。server收到了，然后再发送请求确认报文，并最终完成client与server的连接。数据传输结束后，释放连接。这个过程中，client一共发送了两个请求连接报文段，第一个丢失，第二个到达server。</p><p>异常情况</p><p>client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用三次握手，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。</p><p>因此采用三次握手的办法可以防止上述现象发生。</p><hr><h5 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h5><p><strong>四次挥手</strong></p><p><img src="%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" alt></p><p>① A的应用进程先向其TCP发出连接释放报文段（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN-WAIT-1（终止等待1）状态，等待B的确认。<br>② B收到连接释放报文段后即发出确认报文段，（ACK=1，确认号ack=u+1，序号seq=v），B进入CLOSE-WAIT（关闭等待）状态，此时的TCP处于半关闭状态，A到B的连接释放。<br>③ A收到B的确认后，进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。<br>④ B没有要向A发出的数据，B发出连接释放报文段（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），B进入LAST-ACK（最后确认）状态，等待A的确认。<br>⑤ A收到B的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），A进入TIME-WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，A才进入CLOSED状态。</p><hr><p><strong>为什么采用四次挥手</strong><br>客户端发送FIN后，进入终止等待状态，服务器收到客户端连接释放报文段后，就立即给客户端发送确认，服务器就进入CLOSE_WAIT状态，此时TCP服务器进程就通知高层应用进程，因而从客户端到服务器的连接就释放了。此时是“半关闭状态”，即客户端不可以发送给服务器，服务器可以发送给客户端。</p><p>此时，如果服务器没有数据报发送给客户端，其应用程序就通知TCP释放连接，然后发送给客户端连接释放数据报，并等待确认。客户端发送确认后，进入TIME_WAIT状态，但是此时TCP连接还没有释放，然后经过等待计时器设置的2MSL后，才进入到CLOSE状态。</p><hr><p><strong>为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？</strong><br>2MSL是指两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。</p><p>一切顺利情况下，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是有时网络是不可靠的，因此可能最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。</p><p>在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。</p><p><strong>总结（为什么采用三次握手四次挥手）</strong><br>因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。</p><h4 id="3-如果已经建立了连接，但是客户端突然出现故障了怎么办"><a href="#3-如果已经建立了连接，但是客户端突然出现故障了怎么办" class="headerlink" title="3. 如果已经建立了连接，但是客户端突然出现故障了怎么办"></a>3. 如果已经建立了连接，但是客户端突然出现故障了怎么办</h4><p>TCP设有一个保活计时器，如果客户端如果出现故障，服务器则不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p><h4 id="4-TCP-IP协议"><a href="#4-TCP-IP协议" class="headerlink" title="4. TCP/IP协议"></a>4. TCP/IP协议</h4><h5 id="协议分层"><a href="#协议分层" class="headerlink" title="协议分层"></a>协议分层</h5><p><img src="1.jpg" alt></p>]]></content>
      
      
      <categories>
          
          <category> 知识储备 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识储备 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>必备知识点（一）</title>
      <link href="2020/02/29/bi-bei-zhi-shi-dian-yi/"/>
      <url>2020/02/29/bi-bei-zhi-shi-dian-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="必备知识点（一）"><a href="#必备知识点（一）" class="headerlink" title="必备知识点（一）"></a>必备知识点（一）</h1><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><h4 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h4><h5 id="1-Innodb的索引实现为什么是B-树，B和B-区别"><a href="#1-Innodb的索引实现为什么是B-树，B和B-区别" class="headerlink" title="1. Innodb的索引实现为什么是B+树，B和B+区别"></a>1. Innodb的索引实现为什么是B+树，B和B+区别</h5><h6 id="1-区别"><a href="#1-区别" class="headerlink" title="(1) 区别"></a>(1) 区别</h6><p>① B+树，n个关键字就会有n棵子树；B树，n个关键字有n+1棵树</p><p>② B+树，记录都在叶子节点上，其他节点都是索引；B树所有节点都有记录</p><p>③ B+树可以从最后叶节点出发顺序查找</p><h6 id="2-B-树好处"><a href="#2-B-树好处" class="headerlink" title="(2) B+树好处"></a>(2) B+树好处</h6><p>① 单一节点存储更多元素，减少I/O操作</p><p>② 所有查询都到叶子节点，查询稳定</p><p>③ B+树所有有序节点形成有序链，方便范围查询</p><p>** PS：B+树索引又分为：聚集索引、辅助索引（非聚集索引）**</p><p>聚集索引：每个叶子节点都有一整行数据</p><p>辅助索引：叶子节点中有每行数据索引</p><h4 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h4><h5 id="1-分布式锁"><a href="#1-分布式锁" class="headerlink" title="1. 分布式锁"></a>1. 分布式锁</h5><h6 id="1-满足条件"><a href="#1-满足条件" class="headerlink" title="(1) 满足条件"></a>(1) 满足条件</h6><p>  ① 在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；<br>  ② 高可用的获取锁与释放锁；<br>  ③ 高性能的获取锁与释放锁；<br>  ④ 具备可重入特性；<br>  ⑤ 具备锁失效机制，防止死锁；<br>  ⑥ 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败。</p><hr><h6 id="2-CAP理论"><a href="#2-CAP理论" class="headerlink" title="(2) CAP理论"></a>(2) CAP理论</h6><p>一致性、可用性、分区容错性</p><p>任何一个分布式系统都无法同时满足，最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。</p><hr><h6 id="3-三种方式"><a href="#3-三种方式" class="headerlink" title="(3) 三种方式"></a>(3) 三种方式</h6><p>① 基于数据库实现分布式锁</p><p>  a. 创建表:</p><p>  <code>DROP TABLE IF EXISTS method_lock;</code><br>  <code>CREATE TABLE method_lock (</code><br>  <code>id int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,</code><br>  <code>method_name varchar(64) NOT NULL COMMENT &#39;锁定的方法名&#39;,</code><br>  <code>desc varchar(255) NOT NULL COMMENT &#39;备注信息&#39;,</code><br>  <code>update_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,</code><br>  <code>PRIMARY KEY (id),</code><br>  <code>UNIQUE KEY uidx_method_name (method_name) USING BTREE</code><br>  <code>) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 COMMENT=&#39;锁定中的方法&#39;;</code></p><p>  b. 想要执行某个方法，就使用这个方法名向表中插入数据：</p><p>  <code>NSERT INTO method_lock (method_name, desc) VALUES (&#39;methodName&#39;, &#39;测试的methodName&#39;);</code></p><p>  因为我们对<code>method_name</code>做了<strong>唯一性约束</strong>，这里 如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。</p><p>  c. 成功插入则获取锁，执行完成后删除对应的行数据释放锁：</p><p>  <code>delete from method_lock where method_name =&#39;methodName&#39;;</code></p><p>  <strong>PS:需要结局问题</strong></p><p>  1、因为是基于数据库实现的，数据库的可用性和性能将直接影响分布式锁的可用性及性能，所以，数据库需要双机部署、数据同步、主备切换；</p><p>  2、不具备可重入的特性，因为同一个线程在释放锁之前，行数据一直存在，无法再次成功插入数据，所以，需要在表中新增一列，用于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁；</p><p>  3、没有锁失效机制，因为有可能出现成功插入数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后一直获取不到锁，所以，需要在表中新增一列，用于记录失效时间，并且需要有定时任务清除这些失效的数据；</p><p>  4、不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。</p><p>  5、在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现方式将会越来越复杂；依赖数据库需要一定的资源开销，性能问题需要考虑。</p><hr><p>②基于缓存（Redis等）实现分布式锁 </p><p>  原因：Redis有很高的性能；Redis命令对此支持较好，实现起来比较方便</p><p>  命令：</p><p>  <strong>SETNX</strong>    SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。</p><p>  <strong>expire</strong>    expire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。</p><p>  <strong>delete</strong>    delete key：删除key</p><p>  原理：</p><p>  (1) 获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。</p><p>  (2) 获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。</p><p>  (3) 释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放。</p><hr><p>③ 基于Zookeeper实现分布式锁</p><p>ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树</p><p>步骤：</p><p>(1) 创建一个目录mylock； </p><p>(2) 线程A想获取锁就在mylock目录下创建临时顺序节点；</p><p>(3) 获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁； </p><p>(4) 线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；</p><p>(5) 线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。</p><hr><h5 id="2-redis的事务跟数据库的事务一样吗"><a href="#2-redis的事务跟数据库的事务一样吗" class="headerlink" title="2. redis的事务跟数据库的事务一样吗"></a>2. redis的事务跟数据库的事务一样吗</h5><p><a href="http://www.pianshen.com/article/1554287056/" target="_blank" rel="noopener">http://www.pianshen.com/article/1554287056/</a></p><h5 id="3-Redis多个Client同时修改redis服务器中同一个key怎么办？（redis并发竞争问题？）"><a href="#3-Redis多个Client同时修改redis服务器中同一个key怎么办？（redis并发竞争问题？）" class="headerlink" title="3. Redis多个Client同时修改redis服务器中同一个key怎么办？（redis并发竞争问题？）"></a>3. Redis多个Client同时修改redis服务器中同一个key怎么办？（redis并发竞争问题？）</h5><p>Redis的并发竞争问题，主要是发生在并发写竞争。</p><p>方法：分布式锁+时间戳；消息队列</p><p>(1) 分布式锁+时间戳</p><p>如果对key操作不需要按顺序执行，则直接使用分布式锁就可以。谁抢到谁操作。<br>如果对key操作需要按顺序执行，则在写入系统时，要加一个时间戳</p><p>(2) 消息队列</p><p>在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。</p><p>把Redis.set操作放在队列中使其串行化,必须的一个一个执行</p><h5 id="4-Redis扩容机制-渐进式单线程扩容"><a href="#4-Redis扩容机制-渐进式单线程扩容" class="headerlink" title="4. Redis扩容机制(渐进式单线程扩容)"></a>4. Redis扩容机制(渐进式单线程扩容)</h5><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><h5 id="1-悲观锁-乐观锁"><a href="#1-悲观锁-乐观锁" class="headerlink" title="1. 悲观锁 乐观锁"></a>1. 悲观锁 乐观锁</h5><p><strong>悲观锁（写操作多的情况）</strong></p><p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）</p><p><strong>乐观锁（读操作多的情况）</strong></p><p>总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用<code>版本号机制</code>和<code>CAS算法</code>实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。</p><hr><p>版本号机制：一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。</p><p>CAS：compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步。<br>步骤：需要读写的内存值 V；进行比较的值 A；拟写入的新值 B<br>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。</p><h5 id="2-原子类实现原理"><a href="#2-原子类实现原理" class="headerlink" title="2.原子类实现原理"></a>2.原子类实现原理</h5><h5 id="3-数据库的隔离级别有哪些"><a href="#3-数据库的隔离级别有哪些" class="headerlink" title="3. 数据库的隔离级别有哪些"></a>3. 数据库的隔离级别有哪些</h5><p>读未提交（Read Uncommitted）：可以读到未提交数据，查询未上锁<br>读提交（Read Committed）：只能读到已经提交了的内容<br>可重复读（Repeated Read）<br>串行化（Serializable）</p><p><img src="595592-20180731181114233-1607869534.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 知识储备 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识储备 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最近有点慌~</title>
      <link href="2020/02/27/zui-jin-you-dian-huang/"/>
      <url>2020/02/27/zui-jin-you-dian-huang/</url>
      
        <content type="html"><![CDATA[<p> 想要实习，怎奈自己太菜；面试无助，惶恐，惶恐~</p><p> 在屁屁的督促下，终于投完了前几天找的实习。哎，又要开始新的一波受虐了。</p><h1 id="一、要开始知识储备了"><a href="#一、要开始知识储备了" class="headerlink" title="一、要开始知识储备了"></a>一、要开始知识储备了</h1><p>去年的多次实习面试受挫，现在想想面试都觉得害怕，感觉自己怎么都没准备好，什么都是一知半解，没有能拿得出手的东西，惆怅啊~<br>看了好多大佬的简历，突然觉得自己的简历真的是没法看啊，项目都只限于完成基本功能，还技术含量不高，没法做到量化。实习经历也很惨淡，说是实习，实则外包，很难堪啊。就连技术也只是那些简单的，而且偏python，简历上几乎没有一点别的，难受~<br>哎，太难了。真的要去好好准备一下自己的知识储备了，还要再丰满下项目经历，所以开了一个知识储备专栏，专门用来写，以后搜集到的面试题目吧。另外算法的刷题也要提上日程了，争取面试不会卡住。</p><h1 id="二、家里来了机器人"><a href="#二、家里来了机器人" class="headerlink" title="二、家里来了机器人"></a>二、家里来了机器人</h1><p>在我不断的“怂恿”下，爸妈同意买了扫地机器人。嗯，使用感受还不错，路径规划挺好，清扫程度也在线上。对，买的是石头t6，现在看来小米也是不错的，开始对小米产生转变了呢。</p><h1 id="三、仍然坚持运动啊"><a href="#三、仍然坚持运动啊" class="headerlink" title="三、仍然坚持运动啊"></a>三、仍然坚持运动啊</h1><p>每天坚持运动一小时，常坐真的不舒服啊，而且体重好像也在涨。哎，什么时候开学啊，再不开学，我就快胖死了。</p><h1 id="四、最后写给屁屁"><a href="#四、最后写给屁屁" class="headerlink" title="四、最后写给屁屁"></a>四、最后写给屁屁</h1><p>疫情，疫情，快走开；屁屁，快到碗里来~</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020/2/22</title>
      <link href="2020/02/22/2020-2-22/"/>
      <url>2020/02/22/2020-2-22/</url>
      
        <content type="html"><![CDATA[<p>嗯，今天可以说是比较充实的一天了。感觉做了好多好多事，也学了好几个新东西呢。</p><h3 id="今天清华的提高课开课了呢"><a href="#今天清华的提高课开课了呢" class="headerlink" title="今天清华的提高课开课了呢"></a>今天清华的提高课开课了呢</h3><p>今天下午是2020年清华第一次课呢，这学期的课好像是围绕R展开的呢，老师讲了一下午R的基本使用。之前你虽然学过，但是真的就是糊弄过去的，这次应该好好学了呢，觉得还是挺有意思的。今下午老师布置了两个作业，也很快写完了（毕竟刚开始学，布置的作业有点简单）。不过有点不爽的是，这学期还是要交报告，去年交报告，幸亏有大佬一直带着，这学期可能没那么好的运气了，希望还能碰到大神：）</p><h3 id="数据分析的那个项目做好了呢"><a href="#数据分析的那个项目做好了呢" class="headerlink" title="数据分析的那个项目做好了呢"></a>数据分析的那个项目做好了呢</h3><p>今天也把一个招聘信息的数据分析的项目做完了，用了scrapy + flask + echart框架。scrapy和flask之前就用过，这次算是复习下吧，不过说实话，这个flask的架构搭的是真的不好呢。对，用的mysql + mongodb数据库。其实整个项目框架上并没有什么难度的，难就难在一直在调数据库，清洗数据，取数据上。经过这次，对于python操作数据库的坑又熟悉了好几个，比如说：1. update_one()函数怎么进行已有数据更新，没有数据插入操作（upsert=true啊）；2.mongodb不需要创建集合，插入的时候会自己创建的；3. mysql匹配字段%的使用；4. mysql语句的使用（建表的快速方法）<br>最后希望这个项目能狗来个开门红吧~    （我会拿这个钱来给屁屁买礼物或者全部给屁屁）</p><h3 id="经过屁屁的经营，咸鱼已经有回报了呢"><a href="#经过屁屁的经营，咸鱼已经有回报了呢" class="headerlink" title="经过屁屁的经营，咸鱼已经有回报了呢"></a>经过屁屁的经营，咸鱼已经有回报了呢</h3><p>之前爬的和讯网的数据一直想挂在咸鱼上卖出去，由于拖延症，便一直拖着，就在前天在屁屁经营下，咸鱼杂货铺，顺利开张了，并且已经了两份了呢。今晚上屁屁还把他自己的面试经验啥的挂上去了呢，希望屁屁的也可以卖出去。<br>求老天爷保佑，我跟屁屁都能挣大钱~</p><h3 id="今天还运动了呢"><a href="#今天还运动了呢" class="headerlink" title="今天还运动了呢"></a>今天还运动了呢</h3><p>下午的时候去打了羽毛球，出汗了。晚上还做了健腹轮，要保证不能有小肚子啊。以后要坚持运动的，不然会变胖的。</p><h3 id="最后是写给屁屁的"><a href="#最后是写给屁屁的" class="headerlink" title="最后是写给屁屁的"></a>最后是写给屁屁的</h3><p>为什么要胸怀大志呢，只愿与你无忧无虑其一生呢~</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>假装自己有了博客</title>
      <link href="2020/02/20/jia-zhuang-zi-ji-you-liao-bo-ke/"/>
      <url>2020/02/20/jia-zhuang-zi-ji-you-liao-bo-ke/</url>
      
        <content type="html"><![CDATA[<p>​        仿佛大佬们都有自己的博客，所以也想自己整个，但是怎奈水平太低，一直无从下手。这次在家时间长就决心整一个了，先从github page开始吧。经过几天的折腾，也终于弄的有点模样了。那就来写第一篇博客试试吧。<br>​        有点惭愧，博客模板还是从网上找的大佬做好的模板直接拖过来改的，有些东西还是不太懂，以后慢慢琢磨改进吧。</p><h1 id="一、搭建步骤（简单说下吧，自己也有些不是很懂）"><a href="#一、搭建步骤（简单说下吧，自己也有些不是很懂）" class="headerlink" title="一、搭建步骤（简单说下吧，自己也有些不是很懂）"></a>一、搭建步骤（简单说下吧，自己也有些不是很懂）</h1><hr><ol><li>有自己的git账号（新建一个，这个简单）</li><li>建立一个仓库，仓库名称要跟自己的用户名一样（不然网址会很奇怪）。然后选一个主题，这样你就能看到毫无装饰的博客了。接下来就是去来美化它了。<br><img src="1.jpg" alt><br>就是图片中两个画红框的地方要是一样的，这样最后博客的地址才会是<a href="https://xxx.github.io" target="_blank" rel="noopener">https://xxx.github.io</a> 这样。</li><li>然后创建本地git仓库，使用hexo来自动生成静态页面（这一步网上很多教程都是一样的，当然前提是已经装好node.js）<br>添加国内镜像：npm config set registry <a href="https://registry.npm.taobao.org" target="_blank" rel="noopener">https://registry.npm.taobao.org</a> 这样以后装东西会快点<br>安装hexo：npm i hexo-cli -g 这是全局安装，要是不想全局安装，可以把 “-g” 改成 “-save”<br>初始化：npm init<br>安装依赖库：npm install<br>这样准备工作就做完了，可以生成静态界面看到最开始博客的模样了<br>生成静态页面：hexo g<br>打开本地服务器：hexo s<br>然后打开浏览器输入  <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a>  就可以看到了</li><li>剩下的就是去下载主题，来进行个性化修改了，一般每个主题都会有说明，可以按着步骤来进行修改的。<br>我这个主题是：<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">https://github.com/blinkfox/hexo-theme-matery</a><br>然后是大牛经过更改的：<a href="https://github.com/godweiyang/hexo-matery-modified" target="_blank" rel="noopener">https://github.com/godweiyang/hexo-matery-modified</a><br>PS：如果没有科学上网，建议clone到本地，不然其中的依赖很多，下载会失败<h1 id="二、接下来做什么"><a href="#二、接下来做什么" class="headerlink" title="二、接下来做什么"></a>二、接下来做什么</h1></li><li>因为这个假期实在太长，若是没有计划就真的荒废了，所以决定以后每天会上传一份学习总结，争取早日找到满意实习，拿到中意offer。</li><li>有些东西得找个地方记一记，不然真的会忘掉，所以以后有什么收获也会记一下。</li><li>嗯，还要继续学习这个博客的美化，希望早日让它看起来像那么回事。</li></ol><p>最后，希望屁屁和自己在新的一年都要顺顺利利，心想事成。</p><blockquote><p>我不帅，但我很温柔~</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
